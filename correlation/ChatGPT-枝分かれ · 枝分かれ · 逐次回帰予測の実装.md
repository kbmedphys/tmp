# æåˆ†ã‹ã‚Œ Â· æåˆ†ã‹ã‚Œ Â· é€æ¬¡å›å¸°äºˆæ¸¬ã®å®Ÿè£…

**User:** Anonymous (kbmedphys@gmail.com)  
**Created:** 12/10/2025 16:52:27  
**Updated:** 12/10/2025 19:43:08  
**Exported:** 12/10/2025 19:47:32  
**Link:** [https://chatgpt.com/c/693926b3-79ec-8320-9e38-0c760f66b347](https://chatgpt.com/c/693926b3-79ec-8320-9e38-0c760f66b347)  

## Response:
æ€è€ƒæ™‚é–“: 1m 27s

ä¸€è¨€ã§ã„ã†ã¨ã€ã€Œ**æœˆã‚¿ã‚¤ãƒ—ã®ãƒšã‚¢ã”ã¨ã«ã€éå»ãƒ‡ãƒ¼ã‚¿ã ã‘ã§é€æ¬¡å›å¸°ã‚’ã¾ã‚ã—ã¦ã€æœ‰æ„ãªãƒšã‚¢ã ã‘ã‚’ä½¿ã£ã¦ z ã‚’ä½œã‚‹**ã€ã¨ã„ã†ä»•çµ„ã¿ã‚’è¿½åŠ ã™ã‚Œã°ã€å°†æ¥æƒ…å ±ãƒªãƒ¼ã‚¯ãªã—ã§â€œç”Ÿãæ®‹ã£ã¦ã„ã‚‹â€äºˆæ¸¬ãƒ‘ã‚¿ãƒ¼ãƒ³ã ã‘ã‚’ä½¿ã†ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã‚Œã¯è«–æ–‡ã®ã‚¢ã‚¤ãƒ‡ã‚¢ï¼ˆnewsyâ†’repetitive ã¯æ­£ã®äºˆæ¸¬ã€repetitiveâ†’newsy ã¯è² ã®äºˆæ¸¬ï¼‰ã‚’ã€é€æ¬¡çš„ãªãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã«æ‹¡å¼µã—ãŸã‚‚ã®ã§ã™ã€‚

ssrn-5268329

ä»¥ä¸‹ã€**æ–¹é‡ â†’ å…·ä½“çš„ãªå®Ÿè£…ã‚³ãƒ¼ãƒ‰**ã®é †ã§æ›¸ãã¾ã™ã€‚

* * *

æ–¹é‡ï¼ˆæ™‚ç³»åˆ—ã§ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ»ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼‰
----------------------

1.  **æœˆã‚¿ã‚¤ãƒ—ã®ãƒšã‚¢ (prev\_type, curr\_type) ã‚’å®šç¾©**
    *   prev\_type: t-1 ã® month\_typeï¼ˆN, R, 3ï¼‰
    *   curr\_type: t ã® month\_typeï¼ˆN, R, 3ï¼‰
    *   åˆè¨ˆ 3Ã—3=9 ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆä¾‹ï¼šNâ†’R, Râ†’N, 3â†’N ãªã©ï¼‰
2.  **å„æ™‚ç‚¹ t ã§ã€éå»ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ç”¨ã„ã¦ã€Œãƒšã‚¢åˆ¥ã®äºˆæ¸¬å›å¸°ã€ã‚’æ¨å®š**
    *   è¢«èª¬æ˜å¤‰æ•°:
        $$
         y_t = \text{mkt\_excess}_t
        $$
    *   èª¬æ˜å¤‰æ•°ï¼ˆãƒšã‚¢å…±é€šã®å½¢ã§çµ±ä¸€ï¼‰:
        $$
         x_t = \text{mkt\_excess}_{t-1} - \bar{m}_{t-1}
        $$
        ã“ã“ã§  $\bar{m}_{t-1}$  ã¯ t-1 ã¾ã§ã®å¸‚å ´è¶…éãƒªã‚¿ãƒ¼ãƒ³ã®å¹³å‡ï¼ˆexpanding ã§ã‚‚ rolling ã§ã‚‚å¯ï¼‰ã€‚
    *   ãŸã ã—ã€å›å¸°ã«ä½¿ã†ã®ã¯ã€Œãã®ãƒšã‚¢ã«å±ã™ã‚‹è¦³æ¸¬ã ã‘ã€  
        ï¼ˆä¾‹ï¼šNâ†’R ç”¨å›å¸°ã¯ã€t-1 ãŒ N ã‹ã¤ t ãŒ R ã®æœˆã ã‘ã‚’ä½¿ã†ï¼‰
3.  **rolling / expanding ã§é€æ¬¡æ¨å®šã—ã€å„ãƒšã‚¢ã® Î² ã¨ tå€¤ ã‚’æ¯æœˆæ›´æ–°**
    *   å„ t ã§ã€Œå‚ç…§å¯èƒ½ãªéå»ã€ã®ã¿ã‚’ä½¿ã†ï¼š
        *   expanding: é–‹å§‹ã‹ã‚‰ t-1 ã¾ã§
        *   rolling: t-1 ã‹ã‚‰ã•ã‹ã®ã¼ã£ã¦ä¾‹ãˆã°ç›´è¿‘ 15 å¹´åˆ†ã ã‘ã€ãªã©
    *   å„ãƒšã‚¢ã”ã¨ã«è¦³æ¸¬æ•°ãŒ **min\_obs** æœªæº€ãªã‚‰ã€Œåˆ¤å®šä¸èƒ½ã€ã¨ã—ã¦æ‰±ã†ã€‚
4.  **ãƒšã‚¢ã®ã€Œäºˆæ¸¬èƒ½åŠ›ã‚ã‚Šã€ã®åˆ¤å®šãƒ«ãƒ¼ãƒ«**
    *   ä¾‹ï¼‰
        *   è¦³æ¸¬æ•° â‰¥ min\_obsï¼ˆä¾‹: 60 ãƒ¶æœˆï¼‰
        *   |tå€¤| â‰¥ t\_thresholdï¼ˆä¾‹: 1.96ï¼‰
    *   ã•ã‚‰ã«ç†è«–ã«åŸºã¥ã**ç¬¦å·ã®æœŸå¾…ã‚’èª²ã™**ã‹ã©ã†ã‹ï¼š
        *   Nâ†’R: æœŸå¾…ã•ã‚Œã‚‹ç¬¦å·ã¯ **+**
        *   Râ†’N: æœŸå¾…ã•ã‚Œã‚‹ç¬¦å·ã¯ **âˆ’**
        *   ãã®ä»–ã®ãƒšã‚¢ã¯ç¬¦å·ãƒ•ãƒªãƒ¼ã«ã—ã¦ã‚‚ã‚ˆã„ã—ã€ãã‚‚ãã‚‚ç„¡è¦–ã—ã¦ã‚‚ã‚ˆã„ã€‚
5.  **å„æœˆ t ã® Z ã‚’ã€ã€Œãã®æ™‚ç‚¹ã§æœ‰æ„ã¨åˆ¤æ–­ã•ã‚ŒãŸãƒšã‚¢ã ã‘ã€ã‹ã‚‰æ§‹ç¯‰**
    *   t ã®ãƒšã‚¢ (prev\_type, curr\_type) ã‚’è¦‹ã¦ã€  
        ãã®ãƒšã‚¢ã«å¯¾ã™ã‚‹ Î²Ì‚(t-1) ã¨ tå€¤(t-1) ã‚’ä½¿ç”¨ï¼ˆ= å°†æ¥æƒ…å ±ãªã—ï¼‰ã€‚
    *   æ¡ä»¶ã‚’æº€ãŸã™ãªã‚‰
        z\_t = \\text{sign}(\\betaÌ‚\_{pair,t-1}) \\cdot x\_t
        æº€ãŸã•ãªã„ãªã‚‰ z\_t = 0ã€‚
    *   ã“ã†ã—ã¦ã§ããŸ z\_t ã‚’ã€æ—¢å­˜ã® `apply_timing_strategy` ã«ãã®ã¾ã¾æ¸¡ã›ã¾ã™  
        ï¼ˆä»Šã®ã‚³ãƒ¼ãƒ‰ã§ã¯ target\_vol / Ïƒ\_z ã§ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ã¦ã„ã‚‹ã®ã§æ•´åˆçš„ï¼‰ã€‚

* * *

å…·ä½“çš„ãªå®Ÿè£…ã‚³ãƒ¼ãƒ‰
---------

ã‚ãªãŸã®ã‚³ãƒ¼ãƒ‰ã®ä¸‹ã«ã€ãã®ã¾ã¾ã‚³ãƒ”ãƒšã§è¿½åŠ ã§ãã‚‹å½¢ã«ã—ã¦ã„ã¾ã™ã€‚  
ï¼ˆ`statsmodels` ã¯ã™ã§ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ¸ˆã¿ãªã®ã§ãã®ã¾ã¾ä½¿ãˆã¾ã™ã€‚ï¼‰

```python
# ======================================================================
# 3'. month_type ãƒšã‚¢ã”ã¨ã®äºˆæ¸¬åŠ›ã‚’ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã§ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€
#     ãã‚Œã«åŸºã¥ã„ã¦ z_t (adaptive) ã‚’æ§‹ç¯‰ã™ã‚‹é–¢æ•°
# ======================================================================

def build_adaptive_z_with_pair_screening(
    ff,
    lookback_years: int = 20,
    min_obs: int = 60,
    t_threshold: float = 1.96,
    use_expected_sign: bool = True,
):
    """
    ff: load_ff_monthly_from_ken_french ã®å‡ºåŠ› DataFrame
        å¿…è¦ãªåˆ—: ['mkt_excess', 'rf']
    lookback_years: å›å¸°ã«ä½¿ã†ãƒ­ãƒ¼ãƒªãƒ³ã‚°çª“ã®é•·ã•ï¼ˆå¹´ï¼‰
                    None ã®å ´åˆã¯ expandingï¼ˆé–‹å§‹ã€œt-1 ã¾ã§å…¨éƒ¨ï¼‰
    min_obs: å„ãƒšã‚¢ã”ã¨ã«å›å¸°ã‚’å›ã™ã®ã«å¿…è¦ãªæœ€å°è¦³æ¸¬æ•°
    t_threshold: |tå€¤| ãŒã“ã®å€¤ä»¥ä¸Šãªã‚‰ã€Œæœ‰æ„ã€ã¨åˆ¤å®š
    use_expected_sign: True ã®å ´åˆã€ç†è«–ã«åŸºã¥ãç¬¦å·åˆ¶ç´„ã‚’èª²ã™
                      - (prev='N', curr='R') ã¯ Î²>0 ã‚’æœŸå¾…
                      - (prev='R', curr='N') ã¯ Î²<0 ã‚’æœŸå¾…
                      ãã®ä»–ã®ãƒšã‚¢ã¯ç¬¦å·åˆ¶ç´„ãªã—

    æˆ»ã‚Šå€¤:
        df: å…ƒã® ff ã«ä»¥ä¸‹ã®åˆ—ã‚’ä»˜ã‘åŠ ãˆãŸ DataFrame
            - 'month_type'
            - 'prev_month_type'
            - 'x_pair'      : èª¬æ˜å¤‰æ•° (mkt_{t-1} - å¹³å‡)
            - 'z_adaptive'  : ãƒšã‚¢ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã§æ§‹ç¯‰ã—ãŸäºˆæ¸¬å­
            - 'active_pair' : ãã®æœˆã«æœ‰åŠ¹ã¨åˆ¤å®šã•ã‚ŒãŸãƒšã‚¢ã‹ã©ã†ã‹ (True/False)
    """

    df = ff.copy()
    df["month_type"] = classify_month_type(df.index)
    df["prev_month_type"] = df["month_type"].shift(1)

    # 1ãƒ¶æœˆãƒ©ã‚°ã®å¸‚å ´è¶…éãƒªã‚¿ãƒ¼ãƒ³
    df["mkt_lag"] = df["mkt_excess"].shift(1)

    # expanding å¹³å‡ or rolling å¹³å‡
    if lookback_years is None:
        # expanding å¹³å‡: å¸¸ã«éå»å…¨ä½“
        df["mkt_mean_lag"] = df["mkt_excess"].expanding().mean().shift(1)
    else:
        # rolling å¹³å‡: ç›´è¿‘ lookback_years å¹´
        window_months = lookback_years * 12
        df["mkt_mean_lag"] = (
            df["mkt_excess"]
            .rolling(window=window_months, min_periods=1)
            .mean()
            .shift(1)
        )

    # èª¬æ˜å¤‰æ•° x_t = mkt_{t-1} - mean_{t-1}
    df["x_pair"] = df["mkt_lag"] - df["mkt_mean_lag"]

    # æœ€åˆã®æ•°è¡Œã¯ NaN ã«ãªã‚‹ã®ã§è½ã¨ã™ï¼ˆãŸã ã— index ã¯ä¿æŒã—ãŸã„ã®ã§ãƒã‚¹ã‚¯ã§ç®¡ç†ï¼‰
    valid_mask = df[["mkt_excess", "x_pair", "prev_month_type"]].notna().all(axis=1)
    # çµæœã‚’å…¥ã‚Œã‚‹åˆ—ã‚’æº–å‚™
    z_list = []
    active_list = []

    # æœˆå˜ä½ãƒ«ãƒ¼ãƒ—ã§ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã«å›å¸°ã¨åˆ¤å®šã‚’æ›´æ–°
    dates = df.index

    for i, t in enumerate(dates):
        if not valid_mask.loc[t]:
            # å¿…è¦ãªæƒ…å ±ãŒãã‚ã£ã¦ã„ãªã„åˆæœŸéƒ¨åˆ†
            z_list.append(0.0)
            active_list.append(False)
            continue

        curr_type = df.at[t, "month_type"]
        prev_type = df.at[t, "prev_month_type"]
        pair = (prev_type, curr_type)

        # ãã®æ™‚ç‚¹ t ã§ä½¿ãˆã‚‹éå»ãƒ‡ãƒ¼ã‚¿ (ã€œ t-1)
        past_mask = (dates < t) & valid_mask
        if lookback_years is not None:
            # ãƒ­ãƒ¼ãƒªãƒ³ã‚°çª“: ç›´è¿‘ lookback_years å¹´
            start_date = t - pd.DateOffset(years=lookback_years)
            past_mask &= (dates >= start_date)

        past_df = df.loc[past_mask].copy()

        if past_df.empty:
            z_list.append(0.0)
            active_list.append(False)
            continue

        # ãƒšã‚¢ã”ã¨ã« Î², t ã‚’è¨ˆç®—ï¼ˆã“ã“ã§ã¯ä»Šã®ãƒšã‚¢ã ã‘è¨ˆç®—ã™ã‚‹ã®ã§åŠ¹ç‡ã‚ˆã—ï¼‰
        pair_mask = (
            (past_df["prev_month_type"] == prev_type)
            & (past_df["month_type"] == curr_type)
        )

        pair_df = past_df.loc[pair_mask]
        if len(pair_df) < min_obs:
            # è¦³æ¸¬ãŒå°‘ãªã™ãã‚‹ãƒšã‚¢ã¯ä½¿ã‚ãªã„
            z_list.append(0.0)
            active_list.append(False)
            continue

        # OLS: y = Î± + Î² x
        X = sm.add_constant(pair_df["x_pair"])
        y = pair_df["mkt_excess"]
        model = sm.OLS(y, X).fit()
        beta = model.params["x_pair"]
        tval = model.tvalues["x_pair"]

        # tå€¤ï¼†ç¬¦å·ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        is_active = (abs(tval) >= t_threshold)

        if use_expected_sign:
            if pair == ("N", "R"):
                # continuation: Î² > 0 ã‚’æœŸå¾…
                is_active = is_active and (beta > 0)
            elif pair == ("R", "N"):
                # reversal: Î² < 0 ã‚’æœŸå¾…
                is_active = is_active and (beta < 0)
            else:
                # ãã®ä»–ã®ãƒšã‚¢ã¯ç¬¦å·è‡ªç”±ï¼ˆor å…¨ç„¡åŠ¹ã«ã—ãŸã‘ã‚Œã°ã“ã“ã§ False ã«ï¼‰
                # is_active = False
                pass

        if is_active:
            # äºˆæ¸¬å­ z_t = sign(Î²) * x_t
            z_t = np.sign(beta) * df.at[t, "x_pair"]
        else:
            z_t = 0.0

        z_list.append(z_t)
        active_list.append(bool(is_active))

    df["z_adaptive"] = z_list
    df["active_pair"] = active_list

    return df
```

* * *

ä½¿ã„æ–¹ã®ä¾‹
-----

å…ƒã®ã‚³ãƒ¼ãƒ‰ã®æœ€å¾Œã®ã‚ãŸã‚Šã‚’ã€æ¬¡ã®ã‚ˆã†ã«åˆ†å²ã•ã›ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã§ã™ã€‚

```python
ff = load_ff_monthly_from_ken_french("F-F_Research_Data_Factors.csv")

# 1) å¾“æ¥ã®å›ºå®š z_t
df_fixed = build_predictor_z(ff)

print("\n=== Correlation (fixed z) ===")
print("All:", df_fixed["z"].corr(df_fixed["mkt_excess"]))
print("N  :", df_fixed[df_fixed["month_type"]=="N"]["z"].corr(df_fixed[df_fixed["month_type"]=="N"]["mkt_excess"]))
print("R  :", df_fixed[df_fixed["month_type"]=="R"]["z"].corr(df_fixed[df_fixed["month_type"]=="R"]["mkt_excess"]))
print("3  :", df_fixed[df_fixed["month_type"]=="3"]["z"].corr(df_fixed[df_fixed["month_type"]=="3"]["mkt_excess"]))

# 2) ãƒšã‚¢ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ä»˜ãã® adaptive z_t
df_adapt = build_adaptive_z_with_pair_screening(
    ff,
    lookback_years=20,  # ç›´è¿‘20å¹´ã ã‘ã§è©•ä¾¡ï¼ˆæ§‹é€ å¤‰åŒ–ã«æ•æ„Ÿï¼‰
    min_obs=60,         # æœ€ä½60è¦³æ¸¬ï¼ˆ5å¹´åˆ†ï¼‰ãªã„ã¨æœ‰æ„åˆ¤å®šã—ãªã„
    t_threshold=1.96,   # ãŠå¥½ã¿ã§ç·©ã‚ã¦ã‚‚è‰¯ã„ï¼ˆä¾‹: 1.65ï¼‰
    use_expected_sign=True,
)

print("\n=== Correlation (adaptive z) ===")
print("All:", df_adapt["z_adaptive"].corr(df_adapt["mkt_excess"]))
print("after 2020:", df_adapt.loc["2020-01-01":]["z_adaptive"].corr(
    df_adapt.loc["2020-01-01":]["mkt_excess"])
)

# 3) ã‚¿ã‚¤ãƒŸãƒ³ã‚°æˆ¦ç•¥ã«ã‹ã‘ã‚‹ã¨ãã¯ã€z åˆ—ã‚’å·®ã—æ›¿ãˆã‚‹ã ã‘
df_adapt_for_strategy = df_adapt.copy()
df_adapt_for_strategy["z"] = df_adapt_for_strategy["z_adaptive"]

df_strat = apply_timing_strategy(df_adapt_for_strategy)
plot_results(df_strat)
```

* * *

ãƒã‚¤ãƒ³ãƒˆã®ã¾ã¨ã‚
--------

*   **å°†æ¥æƒ…å ±ãƒªãƒ¼ã‚¯ãªã—**  
    å„æœˆ t ã§ä½¿ã†å›å¸°ã¯ **å¸¸ã« t ä»¥å‰ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿**ã§æ¨å®šã—ã¦ã„ã‚‹ã®ã§ã€å®Œå…¨ã«ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®æŠ•è³‡å®¶ã¨åŒã˜æƒ…å ±åˆ¶ç´„ã§ã™ã€‚
*   **æ§‹é€ å¤‰åŒ–ã«è¿½éšå¯èƒ½**  
    `lookback_years` ã‚’ 15ã€œ20 å¹´ç¨‹åº¦ã«ã—ã¦ãŠãã¨ã€å¤ã„æ™‚ä»£ï¼ˆ1970â€“1990 ãªã©ï¼‰ã®é–¢ä¿‚æ€§ã«ç¸›ã‚‰ã‚Œã™ããšã€  
    2000 å¹´ä»£ã€2010 å¹´ä»£ã€2020 å¹´ä»£ã®é–¢ä¿‚æ€§ã®å¤‰åŒ–ã‚’è‡ªç„¶ã«åæ˜ ã§ãã¾ã™ã€‚
*   **month\_type ã®å…¨çµ„ã¿åˆã‚ã›ã‚’ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°**  
    (prev\_type, curr\_type) ã”ã¨ã«å›å¸°ã‚’è¡Œã„ã€æœ‰æ„æ€§ã¨ç¬¦å·ã§ãƒ•ã‚£ãƒ«ã‚¿ã™ã‚‹ã®ã§ã€  
    ã€Œ2020 å¹´ä»¥é™ã¯ Nâ†’R ã¯ã¾ã æœ‰åŠ¹ã ãŒã€Râ†’N ã¯å´©ã‚Œã¦ã„ã‚‹ã€  
    ã¨ã„ã£ãŸçŠ¶æ³ã‚‚è‡ªå‹•çš„ã«åæ˜ ã•ã‚Œã¾ã™ã€‚
*   **è«–æ–‡ã®ç†è«–ã‚’ä¿ã¡ã¤ã¤æŸ”è»Ÿæ€§ã‚’è¿½åŠ **  
    Nâ†’R ã¯ continuationï¼ˆÎ²>0ï¼‰ã€Râ†’N ã¯ reversalï¼ˆÎ²<0ï¼‰ã¨ã„ã†æœŸå¾…ç¬¦å·ã‚’çµ„ã¿è¾¼ã‚ã‚‹ä¸€æ–¹ã€  
    ãã‚Œä»¥å¤–ã®ãƒšã‚¢ã¯è‡ªç”±ã«ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¯¾è±¡ã«ã™ã‚‹ï¼ã—ãªã„ã‚’é¸ã¹ã¾ã™ã€‚

* * *

ã‚‚ã—ã€ŒGuo & Wachter è«–æ–‡ã¨åŒã˜ nr(t) å®šç¾©ï¼ˆnewsyâ†’repetitive, repetitiveâ†’newsyï¼‰ã‚’å³å¯†ã«ä½¿ã£ãŸå½¢ã§ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ¨å®šã«ã—ãŸã„ã€ãªã©ã€ã‚‚ã†ä¸€æ®µãã£ã¡ã‚Šè«–æ–‡æº–æ‹ ã«å¯„ã›ãŸã„å ´åˆã¯ã€ãã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ã‚³ãƒ¼ãƒ‰ã‚‚ç”¨æ„ã§ãã¾ã™ã€‚ãã®ã¨ãã¯ã“ã®ãƒšã‚¢è¨­è¨ˆã‚’ `nr(t)` ãƒ™ãƒ¼ã‚¹ã«ç½®ãæ›ãˆã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã«ãªã‚Šã¾ã™ã€‚

## Response:
æ€è€ƒå®Œäº†

æ€è€ƒæ™‚é–“: 1m 31s

äº†è§£ã§ã™ã€‚ã˜ã‚ƒã‚ã€**Guo & Wachter ã® nr(t) ã‚’ãã®ã¾ã¾ä½¿ã£ãŸ â€œã‚ªãƒ³ãƒ©ã‚¤ãƒ³ç‰ˆâ€** ã‚’çµ„ã¿è¾¼ã¿ã¾ã—ã‚‡ã†ã€‚

* * *

1\. Guo & Wachter ã® nr(t) ã®å®šç¾©ã‚’æ•´ç†
--------------------------------

è«–æ–‡ã§ã¯ nr(t) ã¯

> ã€Œ**t ã‚ˆã‚Šå‰ã§ã€ã‚‚ã£ã¨ã‚‚è¿‘ã„ â€œnewsy ã¾ãŸã¯ repetitiveâ€ æœˆã®ãƒªã‚¿ãƒ¼ãƒ³**ã€

å…·ä½“çš„ã«ã¯ï¼š

*   æœˆã‚¿ã‚¤ãƒ—
    *   1ãƒ¶æœˆç›® = **newsy (N)**
    *   2ãƒ¶æœˆç›® = **repetitive (R)**
    *   3ãƒ¶æœˆç›® = â€œãã®ä»–â€ (3)
*   nr(t) ã®å–ã‚Šæ–¹
    *   t ãŒ **repetitive (R)** ã®ã¨ã  
        â†’ **ç›´å‰ã®æœˆ (tâˆ’1)** ãŒ newsy ãªã®ã§ã€ãã®ãƒªã‚¿ãƒ¼ãƒ³ãŒ nr(t)
    *   t ãŒ **newsy (N)** ã®ã¨ã  
        â†’ tâˆ’1 ã¯ 3ãƒ¶æœˆç›®ãªã®ã§ã‚¹ã‚­ãƒƒãƒ—ã—ã€**tâˆ’2 (ç›´è¿‘ã® R)** ãŒ nr(t)
    *   t ãŒ 3 ã®ã¨ãã¯å›å¸°ã«ã¯ä½¿ã£ã¦ã„ãªã„ï¼ˆnr(t) è‡ªä½“ã¯å®šç¾©å¯èƒ½ã ãŒã€è«–æ–‡ã®ä¸»å›å¸°ã¯ N / R ã®ã¿ï¼‰

ã“ã‚Œã‚’å³å¯†ã«å†ç¾ã™ã‚‹ã«ã¯ï¼š

1.  ã¾ãš `month_type`ï¼ˆN, R, 3ï¼‰ã‚’ä½œã‚‹ï¼ˆæ—¢ã«å®Ÿè£…æ¸ˆã¿ï¼‰ã€‚
2.  å„ t ã«ã¤ã„ã¦ã€ã€Œt ã‚ˆã‚Šå‰ã® N ã¾ãŸã¯ R ã®ã†ã¡ã€ã‚‚ã£ã¨ã‚‚è¿‘ã„ã‚‚ã®ã€ã‚’èµ°æŸ»ã—ã¦ nr(t) ã‚’æ±‚ã‚ã‚‹ã€‚
3.  `mkt_nr(t) = mkt_excess[nr(t)]` ã‚’ä½œã‚‹ã€‚
4.  **R æœˆã ã‘ã®ã‚µãƒ³ãƒ—ãƒ«**ã§
    $$
     \text{mkt}_t = \alpha_R + \beta_R \text{mkt}_{nr(t)} + \varepsilon_t
    $$
    **N æœˆã ã‘ã®ã‚µãƒ³ãƒ—ãƒ«**ã§
    $$
     \text{mkt}_t = \alpha_N + \beta_N \text{mkt}_{nr(t)} + \varepsilon_t
    $$
    ã®å›å¸°ã‚’ã€**ã€Œt ä»¥å‰ã®ãƒ‡ãƒ¼ã‚¿ã ã‘ã€ã§é€æ¬¡æ¨å®š**ã€‚
5.  |tå€¤| ãŒã—ãã„å€¤ã‚’è¶…ãˆã€ç¬¦å·ãŒè«–æ–‡ã¨æ•´åˆçš„ãªã‚‰ã€Œã“ã®æœˆã¯ nr(t) ã«äºˆæ¸¬èƒ½åŠ›ã‚ã‚Šã€ã¨ã¿ãªã—ã€  
    **z\_t = mkt\_nr(t)** ã‚’æ¡ç”¨ã€ãã‚Œä»¥å¤–ã¯ z\_t=0 ã«ã™ã‚‹ã€‚
    *   è«–æ–‡ã§ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼š
    *   repetitive æœˆ (R) â†’ **Î²\_R > 0ï¼ˆç¶™ç¶šï¼‰**
    *   newsy æœˆ (N) â†’ **Î²\_N < 0ï¼ˆåè»¢ï¼‰**

* * *

2\. nr(t) ã‚’ä½œã‚‹é–¢æ•°
---------------

ã¾ãšã¯ nr(t) ã¨ mkt\_nr(t) ã‚’ä½œã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã§ã™ã€‚

```python
# ======================================================================
# nr(t) = ç›´è¿‘ã® newsy or repetitive æœˆã®ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆGuo & Wachter æº–æ‹ ï¼‰
# ======================================================================

def add_nr_definition(ff: pd.DataFrame) -> pd.DataFrame:
    """
    ff: load_ff_monthly_from_ken_french ã®å‡ºåŠ›
        å¿…é ˆåˆ—: ['mkt_excess', 'rf']

    æˆ»ã‚Šå€¤: ä»¥ä¸‹ã®åˆ—ã‚’è¿½åŠ ã—ãŸ DataFrame
        - 'month_type' : 'N', 'R', '3'
        - 'nr_date'    : nr(t) ã«å¯¾å¿œã™ã‚‹æ—¥ä»˜
        - 'mkt_nr'     : mkt_excess[nr(t)]
    """
    df = ff.copy()
    df["month_type"] = classify_month_type(df.index)

    dates = list(df.index)
    mt = df["month_type"].values

    nr_dates = []
    mkt_nr = []

    for i, t in enumerate(dates):
        nr_idx = None
        j = i - 1
        # t ã‚ˆã‚Šå‰ã® month_type ãŒ N or R ã®æœˆã‚’å¾Œã‚å‘ãã«æ¢ã™
        while j >= 0:
            if mt[j] in ("N", "R"):
                nr_idx = dates[j]
                break
            j -= 1

        nr_dates.append(nr_idx)
        if nr_idx is None:
            mkt_nr.append(np.nan)
        else:
            mkt_nr.append(df.at[nr_idx, "mkt_excess"])

    df["nr_date"] = nr_dates
    df["mkt_nr"] = mkt_nr

    return df
```

* * *

3\. Guo & Wachter å‹ nr(t) ã‚’ä½¿ã£ãŸã€Œã‚ªãƒ³ãƒ©ã‚¤ãƒ³å›å¸°ï¼‹ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã€
-----------------------------------------------

ã“ã“ãŒæœ¬é¡Œã§ã™ã€‚  
**å„æœˆ t ã§ã€t ã‚ˆã‚Šå‰ã®ãƒ‡ãƒ¼ã‚¿ã ã‘ã‚’ä½¿ã£ã¦ R/N åˆ¥ã®å›å¸°ã‚’å›ã—ã€Î² ã¨ tå€¤ ã‚’é€æ¬¡æ›´æ–° â†’ æœ‰æ„ãªã¨ãã ã‘ z\_t ã‚’æœ‰åŠ¹åŒ–**ã—ã¾ã™ã€‚

```python
# ======================================================================
# Guo & Wachter å‹ nr(t) ã‚’ä½¿ã£ãŸã‚ªãƒ³ãƒ©ã‚¤ãƒ³å›å¸°ã«ã‚ˆã‚‹ z_t æ§‹ç¯‰
# ======================================================================

def build_nr_predictor_online(
    ff: pd.DataFrame,
    lookback_years: int = 20,
    min_obs: int = 60,
    t_threshold: float = 1.96,
) -> pd.DataFrame:
    """
    ff: load_ff_monthly_from_ken_french ã®å‡ºåŠ›
    lookback_years:
        å›å¸°ã«ä½¿ã†ãƒ­ãƒ¼ãƒªãƒ³ã‚°çª“ã®é•·ã•ï¼ˆå¹´ï¼‰ã€‚
        None ã®å ´åˆã¯ expandingï¼ˆé–‹å§‹ã€œt-1 ã¾ã§å…¨ãƒ‡ãƒ¼ã‚¿ï¼‰ã€‚
    min_obs:
        R / N ãã‚Œãã‚Œã®å›å¸°ã«å¿…è¦ãªæœ€å°è¦³æ¸¬æ•°ï¼ˆæœˆï¼‰ã€‚
    t_threshold:
        |tå€¤| >= t_threshold ãªã‚‰ã€Œæœ‰æ„ã€ã¨åˆ¤å®šã€‚

    æˆ»ã‚Šå€¤: ff ã«ä»¥ä¸‹ã®åˆ—ã‚’è¿½åŠ ã—ãŸ DataFrame
        - 'month_type'
        - 'nr_date'
        - 'mkt_nr'
        - 'beta_R_hist', 't_R_hist', 'n_R_hist'
        - 'beta_N_hist', 't_N_hist', 'n_N_hist'
        - 'z_nr_online'   : ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®äºˆæ¸¬å­ z_t
        - 'active_flag'   : ãã®æœˆã« nr(t) ãŒæœ‰åŠ¹ã¨åˆ¤å®šã•ã‚ŒãŸã‹ (True/False)
    """
    # nr(t) å®šç¾©ã‚’ä»˜ä¸
    df = add_nr_definition(ff)

    # nr(t) ã¨ç›®çš„å¤‰æ•°ãŒæƒã£ã¦ã„ã‚‹ã¨ã“ã‚ã ã‘ã‚’ã€Œæœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ã€ã¨ã™ã‚‹
    valid_mask = df[["mkt_excess", "mkt_nr"]].notna().all(axis=1)

    dates = df.index

    beta_R_hist = []
    t_R_hist = []
    n_R_hist = []

    beta_N_hist = []
    t_N_hist = []
    n_N_hist = []

    z_list = []
    active_list = []

    for t in dates:
        if not valid_mask.loc[t]:
            # åˆæœŸãªã© nr(t) ãŒå®šç¾©ã§ããªã„éƒ¨åˆ†
            beta_R_hist.append(np.nan)
            t_R_hist.append(np.nan)
            n_R_hist.append(0)

            beta_N_hist.append(np.nan)
            t_N_hist.append(np.nan)
            n_N_hist.append(0)

            z_list.append(0.0)
            active_list.append(False)
            continue

        # t ã‚ˆã‚Šå‰ã®ã¿ã‚’å›å¸°ã«ä½¿ã†ï¼ˆå°†æ¥æƒ…å ±ãªã—ï¼‰
        past_mask = (dates < t) & valid_mask

        if lookback_years is not None:
            # ç›´è¿‘ lookback_years å¹´ã«é™å®šï¼ˆæ§‹é€ å¤‰åŒ–ã«æ•æ„Ÿã«ã™ã‚‹ï¼‰
            start_date = t - pd.DateOffset(years=lookback_years)
            past_mask &= (dates >= start_date)

        past_df = df.loc[past_mask]

        if past_df.empty:
            beta_R_hist.append(np.nan)
            t_R_hist.append(np.nan)
            n_R_hist.append(0)

            beta_N_hist.append(np.nan)
            t_N_hist.append(np.nan)
            n_N_hist.append(0)

            z_list.append(0.0)
            active_list.append(False)
            continue

        # ===== R æœˆã‚µãƒ³ãƒ—ãƒ«ï¼ˆç¶™ç¶šãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰ =====
        past_R = past_df[past_df["month_type"] == "R"]
        if len(past_R) >= min_obs:
            XR = sm.add_constant(past_R["mkt_nr"])
            yR = past_R["mkt_excess"]
            model_R = sm.OLS(yR, XR).fit()
            beta_R = model_R.params["mkt_nr"]
            t_R = model_R.tvalues["mkt_nr"]
            n_R = len(past_R)
        else:
            beta_R = np.nan
            t_R = np.nan
            n_R = len(past_R)

        beta_R_hist.append(beta_R)
        t_R_hist.append(t_R)
        n_R_hist.append(n_R)

        # ===== N æœˆã‚µãƒ³ãƒ—ãƒ«ï¼ˆåè»¢ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰ =====
        past_N = past_df[past_df["month_type"] == "N"]
        if len(past_N) >= min_obs:
            XN = sm.add_constant(past_N["mkt_nr"])
            yN = past_N["mkt_excess"]
            model_N = sm.OLS(yN, XN).fit()
            beta_N = model_N.params["mkt_nr"]
            t_N = model_N.tvalues["mkt_nr"]
            n_N = len(past_N)
        else:
            beta_N = np.nan
            t_N = np.nan
            n_N = len(past_N)

        beta_N_hist.append(beta_N)
        t_N_hist.append(t_N)
        n_N_hist.append(n_N)

        # ===== ãã®æœˆ t ã§ z_t ã‚’ã©ã†ã™ã‚‹ã‹æ±ºå®š =====
        mt = df.at[t, "month_type"]
        mkt_nr_t = df.at[t, "mkt_nr"]

        active = False
        z_t = 0.0

        if mt == "R":
            # ç¶™ç¶šãƒ‘ã‚¿ãƒ¼ãƒ³: Î²_R > 0 ã‹ã¤æœ‰æ„ã§ã‚ã‚Œã° nr(t) ã‚’ä½¿ã†
            if (not np.isnan(beta_R)) and (abs(t_R) >= t_threshold) and (beta_R > 0):
                z_t = mkt_nr_t  # Guo & Wachter ã® regressor ãã®ã‚‚ã®
                active = True

        elif mt == "N":
            # åè»¢ãƒ‘ã‚¿ãƒ¼ãƒ³: Î²_N < 0 ã‹ã¤æœ‰æ„ã§ã‚ã‚Œã° nr(t) ã‚’ä½¿ã†
            if (not np.isnan(beta_N)) and (abs(t_N) >= t_threshold) and (beta_N < 0):
                z_t = mkt_nr_t
                active = True

        # 3 ã®æœˆã¯è«–æ–‡ä¸Šã¯ä¸»å½¹ã§ãªã„ã®ã§ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ãƒãƒ¼ãƒã‚¸
        else:
            z_t = 0.0
            active = False

        z_list.append(z_t)
        active_list.append(active)

    df["beta_R_hist"] = beta_R_hist
    df["t_R_hist"] = t_R_hist
    df["n_R_hist"] = n_R_hist

    df["beta_N_hist"] = beta_N_hist
    df["t_N_hist"] = t_N_hist
    df["n_N_hist"] = n_N_hist

    df["z_nr_online"] = z_list
    df["active_flag"] = active_list

    return df
```

* * *

4\. æ—¢å­˜ã®æˆ¦ç•¥ã‚³ãƒ¼ãƒ‰ã¨ã®æ¥ç¶šä¾‹
-----------------

ã‚ãªãŸã®å…ƒã‚³ãƒ¼ãƒ‰ã®æœ€å¾Œã®éƒ¨åˆ†ã‚’ã€ä»¥ä¸‹ã®ã‚ˆã†ã«å·®ã—æ›¿ãˆã‚Œã°ã€

*   Guo & Wachter æº–æ‹ ã® nr(t)
*   ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å›å¸°ã§ 2020 å¹´ä»¥é™ã®å´©ã‚Œã‚‚ãƒ¢ãƒ‹ã‚¿ã—ã¤ã¤
*   äºˆæ¸¬èƒ½åŠ›ãŒæ®‹ã£ã¦ã„ã‚‹æœŸé–“ã ã‘ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚’å–ã‚‹

ã¨ã„ã†é‹ç”¨ã«ãªã‚Šã¾ã™ã€‚

```python
ff = load_ff_monthly_from_ken_french("F-F_Research_Data_Factors.csv")

# Guo & Wachter nr(t) ãƒ™ãƒ¼ã‚¹ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³äºˆæ¸¬å­
df_nr = build_nr_predictor_online(
    ff,
    lookback_years=20,  # ç›´è¿‘20å¹´ã ã‘ã§ Î² ã‚’æ›´æ–°
    min_obs=60,         # R/N å„ã‚µãƒ³ãƒ—ãƒ«æœ€ä½ 60 è¦³æ¸¬ï¼ˆ5å¹´åˆ†ï¼‰
    t_threshold=1.96,   # 5% æ°´æº–ã€‚ç·©ã‚ã‚‹ãªã‚‰ 1.65 ãªã©
)

print("\n=== Correlation of z_nr_online with mkt_excess ===")
print("All:", df_nr["z_nr_online"].corr(df_nr["mkt_excess"]))
print("After 2000:", df_nr.loc["2000-01-01":]["z_nr_online"].corr(
    df_nr.loc["2000-01-01":]["mkt_excess"]
))
print("After 2020:", df_nr.loc["2020-01-01":]["z_nr_online"].corr(
    df_nr.loc["2020-01-01":]["mkt_excess"]
))

# ã‚¿ã‚¤ãƒŸãƒ³ã‚°æˆ¦ç•¥å´ã¯ z åˆ—ã‚’å·®ã—æ›¿ãˆã¦ãã®ã¾ã¾ä½¿ç”¨
df_for_strategy = df_nr.copy()
df_for_strategy["z"] = df_for_strategy["z_nr_online"]

df_strat = apply_timing_strategy(df_for_strategy)
plot_results(df_strat)
```

* * *

5\. ã“ã®è¨­è¨ˆã®ãƒã‚¤ãƒ³ãƒˆ
-------------

*   **å°†æ¥æƒ…å ±ã®ãƒªãƒ¼ã‚¯ãªã—**  
    å„æœˆ t ã® Î²\_R, Î²\_N ã¯ **å¸¸ã« t ã‚ˆã‚Šå‰ã®ãƒ‡ãƒ¼ã‚¿**ã ã‘ã§æ¨å®šã—ã¦ã„ã‚‹ã®ã§ã€100%ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®æŠ•è³‡å®¶ã¨åŒã˜æƒ…å ±åˆ¶ç´„ã§ã™ã€‚
*   **Guo & Wachter ã® nr(t) ã‚’å³å¯†ã«è¸è¥²**
    *   nr(t) ã¯ã€Œç›´è¿‘ã® newsy ã¾ãŸã¯ repetitiveã€æœˆã ã‘ã‚’è¦‹ã¦å®šç¾©ã€‚
    *   N æœˆã§ã¯ 2 ãƒ¶æœˆå‰ã® R ã‚’ã€R æœˆã§ã¯å‰æœˆã® N ã‚’å‚ç…§ã™ã‚‹æ§‹é€ ãŒè‡ªå‹•çš„ã«å‡ºã¦ãã¾ã™ã€‚
*   **R/N åˆ¥ã® Î² ã¨ tå€¤ ã‚’é€æ¬¡ãƒ¢ãƒ‹ã‚¿ãƒ¼**
    *   `beta_R_hist`, `beta_N_hist` ã‚’ãã®ã¾ã¾ãƒ—ãƒ­ãƒƒãƒˆã™ã‚Œã°ã€  
        ã€Œ1980 å¹´ä»£ã€œ2010 å¹´ä»£ã¾ã§ã¯ç¶™ç¶šãƒ»åè»¢ãŒåŠ¹ã„ã¦ã„ãŸãŒã€2020 å¹´ä»¥é™ã¯å´©ã‚Œã¦ã„ã‚‹ã€ã¨ã„ã£ãŸæ§‹é€ å¤‰åŒ–ã‚‚å¯è¦–åŒ–ã§ãã¾ã™ã€‚
*   **æˆ¦ç•¥ã¨ã—ã¦ã¯ã€Œäºˆæ¸¬ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæ®‹ã£ã¦ã„ã‚‹å±€é¢ã ã‘ã€ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚’å–ã‚‹**
    *   çµæœã¨ã—ã¦ã€2020 å¹´ä»¥é™ã«ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒå¼±ã¾ã‚Œã° z\_t ãŒè‡ªå‹•çš„ã« 0 ã«ãªã‚Šã€ãƒ¬ãƒãƒ¬ãƒƒã‚¸ã‚’çµã‚‹å½¢ã«ãªã‚Šã¾ã™ã€‚
    *   é€†ã«ã€å°†æ¥ãµãŸãŸã³ N/R ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒç¾ã‚Œã‚Œã° Î² ãŒæœ‰æ„ã«ãªã‚Šã€è‡ªç„¶ã«ãƒã‚¸ã‚·ãƒ§ãƒ³ãŒå¾©æ´»ã—ã¾ã™ã€‚

* * *

ã‚‚ã—ã€

*   `lookback_years` ã‚’çŸ­ãã—ã¦ã€Œç›´è¿‘ 10 å¹´ã ã‘ã‚’è¦‹ã¦ Î² ã‚’æ±ºã‚ã‚‹ã€ç‰ˆ
*   3 ãƒ¶æœˆç›®ã«ã‚‚ nr(t) ã‚’ä½¿ã£ã¦å°‘é¡ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚’å–ã‚‹ç‰ˆ
*   P4\_j mktnm(t,j)ï¼ˆGuo 2025 ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹é›†ç´„ï¼‰ã‚‚å«ã‚ãŸ 2 å¤‰æ•°å›å¸°ç‰ˆ

ãªã©ã«æ‹¡å¼µã—ãŸã„å ´åˆã‚‚ã€ä»Šã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«ãã®ã¾ã¾è¿½åŠ ã§ãã¾ã™ã€‚  
ã¾ãšã¯ã“ã® nr(t) ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ç‰ˆã‚’å›ã—ã¦ã€2020 å¹´ä»¥é™ã® Î²\_R, Î²\_N ã®æ¨ç§»ã‚’ä¸€åº¦ãƒ—ãƒ­ãƒƒãƒˆã—ã¦ã¿ã‚‹ã¨è‰¯ã„ã¨æ€ã„ã¾ã™ã€‚

## Response:
æ€è€ƒæ™‚é–“: 2m 46s

çµè«–ã‹ã‚‰è¨€ã†ã¨ã€

*   **ã‚¢ã‚¤ãƒ‡ã‚¢ï¼æ§‹é€ ãƒ¬ãƒ™ãƒ«ã§ã¯ã‹ãªã‚Šè¿‘ãã¦ã€è«–æ–‡ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ã¡ã‚ƒã‚“ã¨å®Ÿè£…ã§ãã¦ã„ã‚‹**
*   ãŸã ã—ã€**å³å¯†ã« Guo & Wachter ã®  $z_{t-1}$  ã‚’å†ç¾ã—ã¦ã„ã‚‹ã‹ã¨ã„ã†ã¨ã€ã€Œã»ã¼ã€ã ã‘ã©å®Œå…¨ä¸€è‡´ã§ã¯ãªã„**

ã¨ã„ã†æ„Ÿã˜ã§ã™ã€‚

* * *

1\. è«–æ–‡ã§ã®å®šç¾©ï¼ˆã–ã£ãã‚Šï¼‰
----------------

è«–æ–‡ã® 3.2ã€œ3.3 ã§ã®å®šç¾©ã¯

*    $\text{mkt}_t$ ï¼šæœˆæ¬¡ã®å¸‚å ´è¶…éãƒªã‚¿ãƒ¼ãƒ³
*    $nr(t)$ ï¼šæ™‚ç‚¹  $t$  ã‚ˆã‚Šå‰ã§ä¸€ç•ªè¿‘ã„ **newsy or repetitive** ã®æœˆ
    *   ä¾‹ï¼š
        *   t ãŒ 2 ãƒ¶æœˆç›®ï¼ˆRï¼‰ãªã‚‰ nr(t) = 1 ãƒ¶æœˆç›®ï¼ˆNï¼‰
        *   t ãŒ 3 ãƒ¶æœˆç›® or 4 ãƒ¶æœˆç›®ãªã‚‰ nr(t) = 2 ãƒ¶æœˆç›®ï¼ˆRï¼‰
*   äºˆæ¸¬å›å¸°ï¼š
    $$
    \text{mkt}_t = \alpha + \beta\, \text{mkt}_{nr(t)} + \varepsilon_t
    $$
*   ãã®ä¸Šã§ã€**ãƒˆãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ç”¨ã®äºˆæ¸¬å­**ã‚’
    $$
    z_{t-1} = \begin{cases} \text{mkt}_{nr(t)} - \bar{\text{mkt}}_{t-1} & (t \text{ ãŒ R æœˆ}) \\ -\bigl(\text{mkt}_{nr(t)} - \bar{\text{mkt}}_{t-1}\bigr) & (t \text{ ãŒ N æœˆ}) \\ 0 & (\text{ãã‚Œä»¥å¤–}) \end{cases}
    $$
    ã¨å®šç¾©ï¼ˆ $\bar{\text{mkt}}_{t-1}$  ã¯ tâˆ’1 ã¾ã§ã®å¹³å‡è¶…éãƒªã‚¿ãƒ¼ãƒ³ï¼‰ã€‚  
    ãã—ã¦ã€Œæœˆ t ã®ãƒªã‚¿ãƒ¼ãƒ³ã®äºˆæ¸¬ã«ã¯  $z_{t-1}$  ã‚’ä½¿ã†ã€ã€‚

* * *

2\. ã‚ãªãŸã® `build_predictor_z` ãŒã‚„ã£ã¦ã„ã‚‹ã“ã¨
-------------------------------------

### (1) month\_type ã®å®šç¾©

```python
def classify_month_type(index):
    m = t.month % 3
    1 â†’ 'N', 2 â†’ 'R', 0 â†’ '3'
```

ã“ã‚Œã¯è«–æ–‡ã®

*   1ãƒ¶æœˆç›®: N
*   2ãƒ¶æœˆç›®: R
*   3ãƒ¶æœˆç›®: ãã‚Œä»¥å¤–ï¼ˆ3ï¼‰

ã¨ä¸€è‡´ã—ã¦ã„ã¦ OK ã§ã™ã€‚

### (2) ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹åå·®

```python
df["mkt_lag"] = df["mkt_excess"].shift(1)        # mkt_{t-1}
df["mkt_mean_lag"] = df["mkt_excess"].expanding().mean().shift(1)  # å¹³å‡(ã€œt-1)
base = df["mkt_lag"] - df["mkt_mean_lag"]        # mkt_{t-1} - å¹³å‡(ã€œt-1)
```

ã“ã“ã§ã¯ **å¸¸ã« mkt\_{t-1}** ã‚’ä½¿ã£ã¦ã€

*   base\[t\] = mkt\_{t-1} âˆ’ mean\_{t-1}

ã‚’ä½œã£ã¦ã„ã¾ã™ã€‚

### (3) z ã®æ§‹ç¯‰ãƒ­ã‚¸ãƒƒã‚¯

```python
z = []
last_R_diff = None
for mt, diff in zip(df["month_type"], base):
    if mt == "R":
        z.append(diff)
    elif mt == "N":
        if last_R_diff is not None:
            z.append(-1*last_R_diff)
        else:
            z.append(0.0)
    else:  # '3'
        z.append(0.0)
        last_R_diff = diff
```

ã“ã‚Œã‚’æ™‚ç³»åˆ—ã§è¿½ã†ã¨ï¼š

*   **R æœˆ**
    *   t ãŒ Rï¼ˆ2 ãƒ¶æœˆç›®ï¼‰ã®ã¨ã
        *   diff = mkt\_{t-1} âˆ’ mean\_{t-1} = mkt\_{å‰ã® N} âˆ’ mean\_{t-1}  
            â†’ ã“ã‚Œã¯ãã®ã¾ã¾ **è«–æ–‡ã®ã€ŒR æœˆã«å¯¾ã™ã‚‹  $mkt_{nr(t)} âˆ’ \bar{mkt}_{t-1}$ ã€** ã¨ä¸€è‡´
*   **3 æœˆ**
    *   t ãŒ 3ï¼ˆ3 ãƒ¶æœˆç›®ï¼‰ã®ã¨ã
        *   diff = mkt\_{t-1} âˆ’ mean\_{t-1} = mkt\_{ç›´å‰ã® R} âˆ’ mean\_{t-1}
        *   ã“ã“ã§ `last_R_diff = diff` ã¨ã—ã¦ã€Œç›´å‰ã® R ã®åå·®ã€ã‚’è¨˜æ†¶
*   **N æœˆ**
    *   t ãŒ Nï¼ˆæ¬¡ã®å››åŠæœŸ 1 ãƒ¶æœˆç›®ï¼‰ã®ã¨ã
        *   `z = - last_R_diff`
        *   ã¤ã¾ã‚Š **2 ãƒ¶æœˆå‰ã® R ã®åå·®ï¼ˆmkt\_R âˆ’ mean\_{ãã®Rã®ç›´å¾Œã¾ã§}) ã‚’ç¬¦å·åè»¢**ã—ã¦ä½¿ã£ã¦ã„ã‚‹

ã—ãŸãŒã£ã¦æ§‹é€ ã¨ã—ã¦ã¯ï¼š

*   ã€ŒNâ†’R ã¯æ­£ã®äºˆæ¸¬ã€
*   ã€ŒRâ†’N ã¯è² ã®äºˆæ¸¬ã€
*   3 æœˆã¯ z=0

ã¨ã„ã†è«–æ–‡ã® **çµŒæ¸ˆçš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³**ã¯ã¡ã‚ƒã‚“ã¨å†ç¾ã§ãã¦ã„ã¾ã™ã€‚

* * *

3\. ã©ã“ãŒã€Œå³å¯†ã«ã¯é•ã†ã€ã®ã‹ï¼Ÿ
------------------

ä¸»ãªå·®ã¯ 2 ã¤ã§ã™ã€‚

### (A) å¹³å‡ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ï¼ˆN æœˆï¼‰

è«–æ–‡ã®å®šç¾©ã§ã¯ã€**N æœˆ t ã«å¯¾ã™ã‚‹äºˆæ¸¬å­**ã¯

*   nr(t) = 2 ãƒ¶æœˆå‰ã® R æœˆ
*   å¹³å‡ã¯ã€Œtâˆ’1 ã¾ã§ã€ã®å¹³å‡  $\bar{\text{mkt}}_{t-1}$ 

ãªã®ã§  
 $\text{mkt}_{nr(t)} - \bar{\text{mkt}}_{t-1} = \text{mkt}_{R} - \text{mean (ã€œç›´å‰æœˆ)}$ 

ä¸€æ–¹ã‚ãªãŸã®ã‚³ãƒ¼ãƒ‰ã§ã¯

*   N æœˆã§ä½¿ã£ã¦ã„ã‚‹ã®ã¯ `last_R_diff`
*   `last_R_diff` ã¯ã€Œ3 æœˆã®ã¨ãã® diffã€ï¼ã€Œmkt\_R âˆ’ mean(ã€œãã® R ã®ç›´å¾Œã¾ã§)ã€

ã¤ã¾ã‚Š **å¹³å‡å´ãŒ 1 ãƒ¶æœˆã ã‘çŸ­ã„**ï¼ˆ3 æœˆã®ãƒªã‚¿ãƒ¼ãƒ³ã‚’å¹³å‡ã«å«ã‚ã¦ã„ãªã„ï¼‰ã¨ã„ã†ã‚ºãƒ¬ãŒã‚ã‚Šã¾ã™ã€‚

å®Ÿå‹™çš„ã«ã¯

*   ã‚µãƒ³ãƒ—ãƒ«æœŸé–“ãŒé•·ã„ï¼ˆ1926â€“2025ï¼‰ã®ã§å¹³å‡ã¯ã»ã¨ã‚“ã©å¤‰ã‚ã‚‰ãšã€
*   å½±éŸ¿ã¯éå¸¸ã«å°ã•ã„

ã®ã§ã€**å›å¸°ä¿‚æ•°ã‚„ç›¸é–¢ã®ã‚µã‚¤ãƒ³ãƒ»å¤§ãã•ã¯ã»ã¼åŒã˜**ã«ãªã‚Šã¾ã™ãŒã€ã€Œè«–æ–‡ã®æ•°å¼ã‚’ä¸€å­—ä¸€å¥ãã®ã¾ã¾å®Ÿè£…ã—ã¦ã„ã‚‹ã‹ã€ã¨ã„ã†æ„å‘³ã§ã¯å³å¯†ã«ã¯é•ã„ã¾ã™ã€‚

### (B) æŒ‡æ¨™ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆz\_t vs z\_{t-1}ï¼‰

è«–æ–‡ã¯ã€Œæœˆ t ã®ãƒªã‚¿ãƒ¼ãƒ³ã‚’äºˆæ¸¬ã™ã‚‹ã®ã¯ z\_{t-1}ã€ã¨æ›¸ã„ã¦ã„ã¾ã™ãŒã€

*   ã‚ãªãŸã® `z[t]` ã¯ã€Œt ã®å§‹ã¾ã‚Šæ™‚ç‚¹ã§åˆ©ç”¨å¯èƒ½ãªæƒ…å ±ã ã‘ï¼ˆã€œtâˆ’1 ã®ãƒªã‚¿ãƒ¼ãƒ³ï¼‰ã‹ã‚‰ä½œã‚‰ã‚Œã¦ã„ã¦å°†æ¥æƒ…å ±ãƒªãƒ¼ã‚¯ã¯ãªã„ã€
*   `apply_timing_strategy` ã§ã¯
    *   ãã®æœˆã®ã‚¦ã‚§ã‚¤ãƒˆ w\_t ã‚’ z\[t\] ã§æ±ºã‚ã¦ã„ã‚‹
    *   Ïƒ ã¯ z ã®éå»åˆ†ã ã‘ã§è¨ˆç®—ã—ã¦ã„ã‚‹

ã®ã§ã€**çµŒæ¸ˆçš„ãªæ„å‘³ã§ã¯ z\_t ã‚’ z\_{t-1} ã¨å‘¼ã¶ã‹ã®é•ã„ã ã‘**ã§ã€å°†æ¥æƒ…å ±ãƒªãƒ¼ã‚¯ã¯èµ·ãã¦ã„ã¾ã›ã‚“ã€‚

* * *

4\. ã¾ã¨ã‚ï¼šèªè­˜ã¯ã©ã†æ•´ç†ã™ã‚Œã°è‰¯ã„ã‹ï¼Ÿ
----------------------

æ•´ç†ã™ã‚‹ã¨ï¼š

*   âœ… **ã€ŒGuo & Wachter ã®ã‚¢ã‚¤ãƒ‡ã‚¢ï¼ˆnewsyâ†’repetitive ã¯é †å¼µã‚Šã€repetitiveâ†’newsy ã¯é€†å¼µã‚Šï¼‰ã‚’ä½¿ã£ãŸäºˆæ¸¬å­ã¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°æˆ¦ç•¥ã‚’å®Ÿè£…ã§ãã¦ã„ã‚‹ã‹ï¼Ÿã€**  
    â†’ **ã¯ã„ã€ã§ãã¦ã„ã¾ã™ã€‚èªè­˜ã¯å¤§ç­‹ã§æ­£ã—ã„ã§ã™ã€‚**
*   âš ï¸ **ã€Œè«–æ–‡ã«æ›¸ã„ã¦ã‚ã‚‹  $z_{t-1} = \pm(\text{mkt}_{nr(t)} - \bar{\text{mkt}}_{t-1})$  ã‚’å³å¯†ã«æ•°å­¦çš„ã«å†ç¾ã—ã¦ã„ã‚‹ã‹ï¼Ÿã€**  
    â†’ **ã»ã¼åŒã˜ã§ã™ãŒã€N æœˆã§ä½¿ã†å¹³å‡ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ãŒ 1 ãƒ¶æœˆã ã‘ãšã‚Œã¦ã„ã‚‹** ã®ã§ã€å®Œå…¨ã«åŒä¸€ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

ã‚‚ã—ã€

*   Table 3 ã® RÂ² ã‚’ã€Œå°æ•°ç¬¬ 3 ä½ã¾ã§å®Œå…¨ã«åˆã‚ã›ãŸã„ã€
*   ã€Œã“ã®ã‚ºãƒ¬ãŒ 2020 å¹´ä»¥é™ã®å´©ã‚Œã®èª¬æ˜ã«ãªã£ã¦ã„ãªã„ã‹æ°—ã«ãªã‚‹ã€

ã¨ã„ã†ãƒ¬ãƒ™ãƒ«ã§ **å³å¯†ã«è«–æ–‡æº–æ‹ ã«ã—ãŸã„**ãªã‚‰ã€

*   `nr(t)` ã‚’æ˜ç¤ºçš„ã«è¨ˆç®—ã—ã¦
*   `mkt_nr` ã¨ `mean(ã€œt-1)` ã‹ã‚‰ z ã‚’ä½œã‚‹

ã¨ã„ã†å½¢ï¼ˆã•ã£ãææ¡ˆã—ãŸ `build_nr_predictor_online` ã®ã‚ˆã†ãªæ§‹é€ ï¼‰ã«ã™ã‚‹ã¨ã€ã€Œæ•°å­¦çš„ã«ã‚‚å®Œå…¨ã«åŒã˜ã€ã¨è¨€ãˆã¾ã™ã€‚

ãŸã ã€**ç¾çŠ¶ã® `build_predictor_z` ã§ã‚‚è«–æ–‡ã®æœ¬è³ªçš„ãªãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã¨äºˆæ¸¬ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ãã¡ã‚“ã¨æ‰ãˆã‚‰ã‚Œã¦ã„ã‚‹**ã®ã§ã€

> ã€ŒGuo & Wachter ã®ãƒˆãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æˆ¦ç•¥ã®å®Ÿå‹™çš„ãªå®Ÿè£…ã€

ã¨ã—ã¦ä½¿ã†åˆ†ã«ã¯ååˆ†ã«å¦¥å½“ã ã¨æ€ã£ã¦å¤§ä¸ˆå¤«ã§ã™ã€‚

## Response:
æ€è€ƒæ™‚é–“: 1m 13s

ã¯ã„ã€ãã®å‰æï¼ˆ`build_predictor_z` ãƒ™ãƒ¼ã‚¹ï¼‰ã§ã€ã€Œå¹³å‡ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã ã‘ã€ã‚’è«–æ–‡ã©ãŠã‚Šã«ç›´ã—ãŸç‰ˆã‚’æ›¸ãã¾ã™ã€‚

ãƒã‚¤ãƒ³ãƒˆã ã‘å…ˆã«ï¼š

*   **R æœˆ**ï¼ˆrepetitiveï¼‰ã§ã¯
    $$
     z_t = \text{mkt}_{t-1} - \overline{\text{mkt}}_{t-1}
    $$
    ãªã®ã§ã€å…ƒã‚³ãƒ¼ãƒ‰ã¨åŒã˜ï¼ˆå•é¡Œãªã—ï¼‰ã€‚
*   **N æœˆ**ï¼ˆnewsyï¼‰ã§ã¯
    *   ä½¿ã†ã®ã¯ã€Œ**ç›´è¿‘ã® R æœˆã®ãƒªã‚¿ãƒ¼ãƒ³**ã€ï¼  $\text{mkt}_{nr(t)}$ 
    *   å¹³å‡ã¯ã€Œ**tâˆ’1 ã¾ã§**ã€ã®å¹³å‡  $\overline{\text{mkt}}_{t-1}$ 
    $$
     z_t = -\bigl(\text{mkt}_{nr(t)} - \overline{\text{mkt}}_{t-1}\bigr)
    $$
*   ã“ã‚Œã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã€
    *   ã€Œå‰å›ã® R æœˆã®ãƒªã‚¿ãƒ¼ãƒ³ `last_R_ret`ã€ã ã‘ã‚’è¦šãˆã¦ãŠãã€
    *   N æœˆãŒæ¥ãŸã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§  $\overline{\text{mkt}}_{t-1}$  ã‚’ä½¿ã£ã¦å·®åˆ†ã‚’å†è¨ˆç®—ã™ã‚‹  
        ã¨ã„ã†å½¢ã«å¤‰ãˆã¾ã™ï¼ˆå¹³å‡ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã®ã‚ºãƒ¬ã ã‘ä¿®æ­£ï¼‰ã€‚

* * *

ä¿®æ­£å¾Œã® `build_predictor_z`
------------------------

ã‚ãªãŸã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã«ã‚ã‚‹ `build_predictor_z` ã‚’ã€ä»¥ä¸‹ã«ç½®ãæ›ãˆã¦ãã ã•ã„ï¼š

```python
def build_predictor_z(ff):
    df = ff.copy()
    df["month_type"] = classify_month_type(df.index)

    # t æ™‚ç‚¹ã§ã® mkt_{t-1} ã¨ã€å¹³å‡(ã€œt-1)
    df["mkt_lag"] = df["mkt_excess"].shift(1)
    df["mkt_mean_lag"] = df["mkt_excess"].expanding().mean().shift(1)

    # åˆæœŸã® NaN è¡Œã‚’è½ã¨ã™ï¼ˆmkt_lag, mkt_mean_lag ãŒæƒã£ãŸã¨ã“ã‚ã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆï¼‰
    df = df.dropna()

    z = []
    last_R_ret = None  # ç›´è¿‘ã® "R æœˆ" ã® mkt_excess ã‚’è¨˜æ†¶

    for t, row in df.iterrows():
        mt = row["month_type"]
        mean_t_minus1 = row["mkt_mean_lag"]

        if mt == "R":
            # R æœˆ: ç›´å‰ã® N æœˆã®ãƒªã‚¿ãƒ¼ãƒ³ã‚’ä½¿ã†
            # z_t = mkt_{t-1} - mean(ã€œt-1)  â†’ å…ƒã‚³ãƒ¼ãƒ‰ã¨åŒã˜
            diff = row["mkt_lag"] - mean_t_minus1
            z_t = diff

            # ã“ã®æœˆã®ãƒªã‚¿ãƒ¼ãƒ³ã¯ã€Œæ¬¡ã® N æœˆã§ä½¿ã† R æœˆã€ã¨ã—ã¦è¨˜æ†¶
            last_R_ret = row["mkt_excess"]

        elif mt == "N":
            # N æœˆ: ç›´è¿‘ã® R æœˆã®ãƒªã‚¿ãƒ¼ãƒ³ (last_R_ret) ã‚’ä½¿ã£ã¦
            # z_t = -( mkt_{R} - mean(ã€œt-1) ) ã‚’æ§‹æˆ
            if (last_R_ret is not None) and (not math.isnan(mean_t_minus1)):
                diff = last_R_ret - mean_t_minus1
                z_t = -diff
            else:
                # ã¾ã  R æœˆãŒä¸€åº¦ã‚‚å‡ºã¦ã„ãªã„ãªã©ã®å ´åˆã¯ 0 ã«ã™ã‚‹
                z_t = 0.0

        else:  # mt == "3"
            # 3 ãƒ¶æœˆç›®: è«–æ–‡åŒæ§˜ã“ã“ã§ã¯ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚’å–ã‚‰ãªã„
            z_t = 0.0

        z.append(z_t)

    df["z"] = z
    return df
```

* * *

ä½•ãŒã©ã†å¤‰ã‚ã£ãŸã‹ï¼ˆã–ã£ãã‚Šï¼‰
---------------

*   ä»¥å‰ï¼š
    *   3 ãƒ¶æœˆç›®ã§ `last_R_diff = mkt_R âˆ’ mean(ã€œRå½“æœˆã¾ã§)` ã‚’ä¿å­˜ã—ã€
    *   N æœˆã§ `z = - last_R_diff` ã‚’ä½¿ã£ã¦ã„ã¾ã—ãŸã€‚
    *   ãã®ãŸã‚ã€**å¹³å‡ãŒã€ŒR æœˆã¾ã§ã€ã®ã‚‚ã®**ã«ãªã£ã¦ã„ã¦ã€è«–æ–‡ã®ã€ŒN æœˆã®ç›´å‰ (tâˆ’1) ã¾ã§ã€ã¨ 1 ãƒ¶æœˆã ã‘ã‚ºãƒ¬ã¦ã„ã¾ã—ãŸã€‚
*   ä»Šå›ã®ä¿®æ­£ï¼š
    *   3 ãƒ¶æœˆç›®ã§ã¯ diff ã‚’ä¿å­˜ã›ãšã€**R æœˆã®ãƒªã‚¿ãƒ¼ãƒ³ã ã‘ `last_R_ret` ã¨ã—ã¦è¨˜æ†¶**ã€‚
    *   N æœˆã«æ¥ãŸã¨ã“ã‚ã§ã€
        *   `last_R_ret`ï¼ˆç›´è¿‘ã® R ã®ãƒªã‚¿ãƒ¼ãƒ³ï¼‰ã¨
        *   `mkt_mean_lag[t]`ï¼ˆtâˆ’1 ã¾ã§ã®å¹³å‡ï¼‰  
            ã‚’ä½¿ã£ã¦ã€
        $$
         z_t = -(\text{mkt}_{R} - \overline{\text{mkt}}_{t-1})
        $$
        ã‚’å†è¨ˆç®—ã—ã¦ã„ã¾ã™ã€‚

ã“ã‚Œã§ã€

*   æ§‹é€ ï¼šNâ†’R ã§é †å¼µã‚Šã€Râ†’N ã§é€†å¼µã‚Š
*   å¹³å‡ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ï¼šå¸¸ã«ã€Œtâˆ’1 ã¾ã§ã€

ã¨ã„ã†æ„å‘³ã§ã€\*\*Guo & Wachter ã®  $z_{t-1}$  ã®å®šç¾©ã¨æ•´åˆçš„ãªå½¢ã«ãªã£ã¦ã„ã¾ã™ã€‚  
ã‚ã¨ã¯ã€ä»Šã¾ã§ã¨åŒã˜ã‚ˆã†ã« `df = build_predictor_z(ff)` â†’ `apply_timing_strategy(df)` ã¨ã—ã¦ã‚‚ã‚‰ãˆã‚Œã° OK ã§ã™ã€‚

## Response:
æ€è€ƒå®Œäº†

æ€è€ƒæ™‚é–“: 38s

ã–ã£ãã‚Šè¨€ã†ã¨ã€

*   **Guo (2025)** ã®  $P_4 \sum_{j=1}^4 \text{mkt}_{nm(t,j)}$  ã¯  
    ã€Œ**ç›´è¿‘4ã¤ã® newsy æœˆã®å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³**ã€ã§ã€
*   Guo & Wachter è«–æ–‡ã§ã¯ã“ã‚Œï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åœ§ç¸®ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹é›†ç´„æŒ‡æ¨™ï¼‰ã¨  
    ã‚ãªãŸãŒã‚‚ã†å®Ÿè£…ã—ã¦ã„ã‚‹ ** $ \text{mkt}_{nr(t)}$ **ï¼ˆcorrelation neglectï¼‰ã‚’  
    **åŒæ™‚ã«èª¬æ˜å¤‰æ•°ã«å…¥ã‚ŒãŸ 2 å¤‰æ•°å›å¸°**ã‚’ã‚„ã£ã¦ã„ã¾ã™ã€‚

ä»¥ä¸‹ã§ã€

1.  æ•°å¼ãƒ¬ãƒ™ãƒ«ã§ã®å®šç¾©
2.  ã‚ãªãŸã® Ken French ãƒ‡ãƒ¼ã‚¿ï¼‹`classify_month_type` ãƒ™ãƒ¼ã‚¹ã§ã®å®Ÿè£…ã‚³ãƒ¼ãƒ‰
3.  Guo & Wachter ã® Table 11, å¼(11) ç›¸å½“ã® 2å¤‰æ•°å›å¸°ã®æ›¸ãæ–¹

ã‚’ã¾ã¨ã‚ã¾ã™ã€‚

* * *

1\. å®šç¾©ï¼š $nr(t)$  ã¨  $P_4 \sum_{j=1}^4 \text{mkt}_{nm(t,j)}$ 
------------------------------------------------------------

è«–æ–‡ã® notationï¼š

ssrn-5268329

*    $\text{mkt}_t$ ï¼šæœˆ t ã®å¸‚å ´è¶…éãƒªã‚¿ãƒ¼ãƒ³
*    $nr(t)$ ï¼št ã‚ˆã‚Šå‰ã§ **æœ€ã‚‚è¿‘ã„ â€œnewsy ã¾ãŸã¯ repetitiveâ€ æœˆ**  
    ï¼ˆã¤ã¾ã‚Š N/R ã©ã¡ã‚‰ã§ã‚‚è‰¯ã„ãŒä¸€ç•ªè¿‘ã„ã‚‚ã®ï¼‰
*    $nm(t,j)$ ï¼št ã‚ˆã‚Šå‰ã§ **j ç•ªç›®ã«è¿‘ã„ newsy æœˆ**  
    ï¼ˆä¾‹ï¼š $nm(t,1)$  ãŒç›´è¿‘ã® Nã€ $nm(t,2)$  ãŒ2ç•ªç›®ã«è¿‘ã„ N â€¦ï¼‰
*   Guo (2025) ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹é›†ç´„æŒ‡æ¨™ï¼š
    
$$
P_4 \sum_{j=1}^4 \text{mkt}_{nm(t,j)} \quad\text{= ã€Œç›´è¿‘4ã¤ã® newsy æœˆã®å¸‚å ´è¶…éãƒªã‚¿ãƒ¼ãƒ³ã®å¹³å‡ã€}
$$
*   Guo & Wachter ã¯ã“ã‚Œã‚’
    *   ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åœ§ç¸®ï¼ˆå¤ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®åŠ¹ãæ–¹ã‚’èª¤ã£ã¦ä¸€å®šã¨ã¿ãªã™èª¤ä¿¡å¿µï¼‰ã‚’è¡¨ã™æŒ‡æ¨™ã¨ã—ã¦æ¡ç”¨ã—ã€
    *   è‡ªåˆ†ãŸã¡ã®  $\text{mkt}_{nr(t)}$  ã¨åŒæ™‚ã«å›å¸°ã«å…¥ã‚Œã¦ã„ã¾ã™ã€‚

* * *

2\. å›å¸°å¼ï¼ˆ2å¤‰æ•°ï¼‹ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ€ãƒŸãƒ¼ï¼‰
--------------------

è«–æ–‡ãŒ Table 11 ã®åˆ—(3) ã§ä½¿ã£ã¦ã„ã‚‹ä»•æ§˜ã¯ï¼š

ssrn-5268329

$$
\text{mkt}_t = \alpha + \beta_1 \,\text{mkt}_{nr(t)} + \beta_2 \,\text{mkt}_{nr(t)} \cdot I^n_t + \beta_3 \,P_4 \sum_{j=1}^4 \text{mkt}_{nm(t,j)} + \beta_4 \,P_4 \sum_{j=1}^4 \text{mkt}_{nm(t,j)} \cdot I^n_t + \gamma I^n_t + \varepsilon_t,
$$
*    $I^n_t = 1$  if month t is **newsy (N)**, else 0.
*   åˆ—(1)ï¼šå¾“å±å¤‰æ•°ãŒ R æœˆã ã‘ã®ã‚µãƒ³ãƒ—ãƒ«
*   åˆ—(2)ï¼šå¾“å±å¤‰æ•°ãŒ N æœˆã ã‘ã®ã‚µãƒ³ãƒ—ãƒ«
*   åˆ—(3)ï¼šä¸Šå¼ã®ã‚ˆã†ãª **çµ±åˆã‚µãƒ³ãƒ—ãƒ«ï¼‹ç›¸äº’ä½œç”¨é …**ã§ã€Î²2, Î²4 ãŒ N/R ã®å·®ã‚’ã¨ã£ã¦ã„ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã§ã™ã€‚

* * *

3\. Ken French ãƒ‡ãƒ¼ã‚¿ã§ã®å®Ÿè£…ï¼ˆnr + P4 ãƒ‹ãƒ¥ãƒ¼ã‚¹å¹³å‡ã‚’ä½œã‚‹ï¼‰
-----------------------------------------

ã‚ãªãŸã®ç’°å¢ƒã§ãã®ã¾ã¾å‹•ãã“ã¨ã‚’æ„è­˜ã—ã¦ã€

*   ã™ã§ã«ã‚ã‚‹ `classify_month_type` ã‚’ä½¿ã†
*   `load_ff_monthly_from_ken_french` ã§ä½œã£ãŸ `ff`ï¼ˆmkt\_excess, rfï¼‰ã‹ã‚‰æ‹¡å¼µ

ã¨ã„ã†å½¢ã§æ›¸ãã¾ã™ã€‚

### 3.1 nr(t) ã¨ nm(t,j)ï¼ˆç›´è¿‘4 newsyï¼‰ã®æ§‹ç¯‰

```python
def add_nr_and_nm4(ff: pd.DataFrame) -> pd.DataFrame:
    """
    ff: load_ff_monthly_from_ken_french ã®å‡ºåŠ›
        å¿…é ˆåˆ—: ['mkt_excess', 'rf']

    è¿½åŠ ã•ã‚Œã‚‹åˆ—:
        - 'month_type' : 'N', 'R', '3'
        - 'In_t'       : ãã®æœˆãŒ newsy (N) ãªã‚‰ 1, ãã‚Œä»¥å¤– 0
        - 'nr_date'    : nr(t) ã«å¯¾å¿œã™ã‚‹æ—¥ä»˜
        - 'mkt_nr'     : mkt_excess[nr(t)]
        - 'mkt_nm1'..'mkt_nm4' : ç›´è¿‘ j ç•ªç›®ã® newsy æœˆã®ãƒªã‚¿ãƒ¼ãƒ³
        - 'mkt_nm4_avg': ç›´è¿‘4ã¤ã® newsy æœˆã®å¹³å‡ (Guo 2025 P4_j mkt_nm(t,j))
    """
    df = ff.copy()
    df["month_type"] = classify_month_type(df.index)
    df["In_t"] = (df["month_type"] == "N").astype(int)

    dates = list(df.index)
    mt = df["month_type"].values
    mkt = df["mkt_excess"].values

    nr_dates = []
    mkt_nr_list = []

    # nm(t,j) ç”¨ã«ã€Œã“ã‚Œã¾ã§å‡ºã¦ããŸ newsy æœˆã® indexã€ã‚’è“„ç©
    past_newsy_indices = []

    mkt_nm1 = []
    mkt_nm2 = []
    mkt_nm3 = []
    mkt_nm4 = []

    for i, t in enumerate(dates):
        # ---- nr(t): t ã‚ˆã‚Šå‰ã§æœ€ã‚‚è¿‘ã„ N or R ----
        nr_idx = None
        j = i - 1
        while j >= 0:
            if mt[j] in ("N", "R"):
                nr_idx = j
                break
            j -= 1
        if nr_idx is None:
            nr_dates.append(None)
            mkt_nr_list.append(np.nan)
        else:
            nr_dates.append(dates[nr_idx])
            mkt_nr_list.append(mkt[nr_idx])

        # ---- newsy æœˆã®å±¥æ­´æ›´æ–° ----
        if mt[i] == "N":
            past_newsy_indices.append(i)

        # ---- nm(t,j): ç›´è¿‘ newsy æœˆãŸã¡ ----
        # t è‡ªèº«ã¯é™¤ããŸã„ã®ã§ã€i ã‚ˆã‚Šå°ã•ã„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ã¿ä½¿ç”¨
        candidate_newsy = [k for k in past_newsy_indices if k < i]
        candidate_newsy_sorted = sorted(candidate_newsy, reverse=True)

        vals = []
        for jj in range(4):
            if jj < len(candidate_newsy_sorted):
                vals.append(mkt[candidate_newsy_sorted[jj]])
            else:
                vals.append(np.nan)

        mkt_nm1.append(vals[0])
        mkt_nm2.append(vals[1])
        mkt_nm3.append(vals[2])
        mkt_nm4.append(vals[3])

    df["nr_date"] = nr_dates
    df["mkt_nr"] = mkt_nr_list
    df["mkt_nm1"] = mkt_nm1
    df["mkt_nm2"] = mkt_nm2
    df["mkt_nm3"] = mkt_nm3
    df["mkt_nm4"] = mkt_nm4

    # ç›´è¿‘4ã¤ã® newsy æœˆã®å¹³å‡ï¼ˆ4ã¤æƒã£ã¦ã„ãªã„å ´åˆã¯ NaNï¼‰
    df["mkt_nm4_avg"] = df[["mkt_nm1", "mkt_nm2", "mkt_nm3", "mkt_nm4"]].mean(axis=1)

    return df
```

* * *

### 3.2 Guo & Wachter Table 11, åˆ—(3) ç›¸å½“ã® 2 å¤‰æ•°å›å¸°

`statsmodels` ã¯ã™ã§ã«ä½¿ã£ã¦ã„ã‚‹ã®ã§ã€ãã®ã¾ã¾ OLS ã‚’æ›¸ãã¾ã™ã€‚  
White æ¨™æº–èª¤å·®ï¼ˆ`cov_type="HC0"`ï¼‰ã‚’æŒ‡å®šã™ã‚‹ã¨è«–æ–‡ã¨åŒã˜ãƒ­ãƒã‚¹ãƒˆ t å€¤ã«ãªã‚Šã¾ã™ã€‚

ssrn-5268329

```python
def run_two_predictor_regression(df: pd.DataFrame):
    """
    Guo & Wachter Table 11, col (3) ã«å¯¾å¿œã™ã‚‹å›å¸°:
    mkt_t = Î± + Î²1 mkt_nr(t)
              + Î²2 mkt_nr(t) * In_t
              + Î²3 mkt_nm4_avg(t)
              + Î²4 mkt_nm4_avg(t) * In_t
              + Î³ In_t + Îµ_t

    æˆ»ã‚Šå€¤:
        statsmodels ã®çµæœã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ (res) ã¨
        Î²1..Î²4, Î³ ã‚’è¾æ›¸ã§è¿”ã™
    """
    # èª¬æ˜å¤‰æ•°ãŒæƒã£ã¦ã„ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã ã‘ã‚’ä½¿ã†
    reg_df = df[["mkt_excess", "mkt_nr", "mkt_nm4_avg", "In_t"]].dropna().copy()

    reg_df["x1"] = reg_df["mkt_nr"]
    reg_df["x2"] = reg_df["mkt_nr"] * reg_df["In_t"]
    reg_df["x3"] = reg_df["mkt_nm4_avg"]
    reg_df["x4"] = reg_df["mkt_nm4_avg"] * reg_df["In_t"]
    reg_df["x5"] = reg_df["In_t"]

    X = sm.add_constant(reg_df[["x1", "x2", "x3", "x4", "x5"]])
    y = reg_df["mkt_excess"]

    model = sm.OLS(y, X)
    res = model.fit(cov_type="HC0")  # White s.e.

    params = res.params
    tvals = res.tvalues

    out = {
        "alpha": (params["const"], tvals["const"]),
        "beta1_mktnr": (params["x1"], tvals["x1"]),
        "beta2_mktnr_In": (params["x2"], tvals["x2"]),
        "beta3_nm4": (params["x3"], tvals["x3"]),
        "beta4_nm4_In": (params["x4"], tvals["x4"]),
        "gamma_In": (params["x5"], tvals["x5"]),
    }
    return res, out
```

ä½¿ã„æ–¹ï¼š

```python
ff = load_ff_monthly_from_ken_french("F-F_Research_Data_Factors.csv")
df_nr_nm = add_nr_and_nm4(ff)

res, out = run_two_predictor_regression(df_nr_nm)
print(res.summary())  # å…¨ä½“ã‚µãƒãƒª
print("\nCoefficients (value, t-stat):")
for name, (coef, tval) in out.items():
    print(f"{name:15s}: {coef: .4f},  t = {tval: .2f}")
```

ã“ã“ã§ã€

*   `beta1_mktnr, beta2_mktnr_In` â†’ correlation neglect ãƒ‘ãƒ¼ãƒˆï¼ˆGuo & Wachterï¼‰
*   `beta3_nm4, beta4_nm4_In` â†’ Guo (2025) ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åœ§ç¸®ãƒ‘ãƒ¼ãƒˆï¼ˆç›´è¿‘4 newsy å¹³å‡ï¼‰

ã‚’ä¸€æ°—ã«ç¢ºèªã§ãã¾ã™ã€‚

* * *

4\. æˆ¦ç•¥ã¸ã®æ‹¡å¼µï¼ˆã–ã£ãã‚Šï¼‰
----------------

ä»Šã®ã‚ãªãŸã®æˆ¦ç•¥ã¯

*   predictor  $z_t$  ã‚’ 1 ã¤ï¼ˆmkt\_nr ç³»ï¼‰ã«ã—ã¦ã€
*   ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒœãƒ©ï¼†maxãƒ¬ãƒã§ã‚¹ã‚±ãƒ¼ãƒ«ã—ãŸã‚¿ã‚¤ãƒŸãƒ³ã‚°æˆ¦ç•¥

ã«ãªã£ã¦ã„ã¾ã™ãŒã€ã“ã® 2 å¤‰æ•°å›å¸°ã‚’è¸ã¾ãˆã‚‹ã¨ï¼š

*   ã€Œcorrelation neglect ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆç”¨  $z^{(nr)}_t$ ã€
*   ã€Œparameter compression ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆç”¨  $z^{(nm4)}_t$ ã€

ã‚’ä½œã£ã¦ã€**ç·šå½¢çµåˆã§ 1 ã¤ã®äºˆæ¸¬å­ã«ã¾ã¨ã‚ã‚‹**ï¼ˆä¿‚æ•°ã¯ Î² æ¨å®šå€¤ã‚’ä½¿ã† or ç¬¦å·æƒ…å ±ã ã‘ä½¿ã†ï¼‰ã¨ã„ã†å½¢ã«ã‚‚æ‹¡å¼µã§ãã¾ã™ã€‚

ãŸã ã€ã¾ãšã¯ä¸Šã®ã‚³ãƒ¼ãƒ‰ã§

*   P4 ãƒ‹ãƒ¥ãƒ¼ã‚¹å¹³å‡ã®æ§‹æˆ
*   2 å¤‰æ•°å›å¸°ï¼ˆWhite s.e.ä»˜ãï¼‰

ãŒè«–æ–‡ã©ãŠã‚Šã«å‹•ãã‹ã‚’ç¢ºèªã—ã¦ã‹ã‚‰ã€  
æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¨ã—ã¦ã€Œ2 æˆåˆ†ã‚’ã©ã†ã‚„ã£ã¦ z\_t ã«çµ±åˆã—ã¦é‹ç”¨æˆ¦ç•¥ã«åæ˜ ã•ã›ã‚‹ã‹ã€ã‚’ä¸€ç·’ã«è¨­è¨ˆã™ã‚‹ã®ãŒè‰¯ã„ã¨æ€ã„ã¾ã™ã€‚

## Response:
ä»¥ä¸‹ã§ã¯ **Guo & Wachter (2019,2025) ã®ç†è«–ã¨å®Ÿè¨¼çµæœ**ã‚’è¸ã¾ãˆã¦ã€  
ã‚ãªãŸãŒå¾—ãŸæ¨å®šçµæœ

*   **Î²â‚‚ï¼ˆmkt\_nr Ã— Nãƒ€ãƒŸãƒ¼ï¼‰ = âˆ’0.318, t = âˆ’2.89**
*   **Î²â‚ƒï¼ˆP4 ãƒ‹ãƒ¥ãƒ¼ã‚¹å¹³å‡ï¼‰ = 0.448, t = 4.58**
*   **Î²â‚„ï¼ˆP4 ãƒ‹ãƒ¥ãƒ¼ã‚¹å¹³å‡ Ã— Nãƒ€ãƒŸãƒ¼ï¼‰ = âˆ’0.700, t = âˆ’4.29**
*   **Î³ï¼ˆNãƒ€ãƒŸãƒ¼ï¼‰ = +0.013, t = 3.39**

ã‚’ **ã©ã®ã‚ˆã†ã«ãƒˆãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æˆ¦ç•¥ã«è½ã¨ã—è¾¼ã‚€ã¹ãã‹**ã‚’ã€  
è«–æ–‡ã®æ•°å¼ï¼ˆç‰¹ã« Table 11, å¼(11) ã®è§£é‡ˆï¼‰ã«åŸºã¥ãã€  
**â€œå®Ÿé‹ç”¨ã®æ„æ€æ±ºå®šãƒ«ãƒ¼ãƒ«â€ ã¨ã„ã†å½¢ã¾ã§åˆ†è§£ã—ã¦ææ¡ˆ**ã—ã¾ã™ã€‚

* * *

1\. å›å¸°å¼ã®æ§‹é€ ã®å†ç¢ºèªï¼ˆæ–‡çŒ®ãƒ™ãƒ¼ã‚¹ï¼‰
=====================

ã‚ãªãŸã®æ¨å®šã¯ä»¥ä¸‹ã®å›å¸°ãƒ¢ãƒ‡ãƒ«ã«å¯¾å¿œã—ã¾ã™ï¼š  
ï¼ˆGuo & Wachter (2019) Table 11 ã® Column (3)ï¼‰

$$
\begin{aligned} mkt_t = &\ \alpha + \beta_1\, mkt_{nr(t)} + \beta_2\, mkt_{nr(t)} \cdot I^n_t \\ &+ \beta_3\, P4(t) + \beta_4\, P4(t)\cdot I^n_t + \gamma I^n_t + \varepsilon_t , \end{aligned}
$$

ã“ã“ã§ï¼š

*    $I^n_t = 1$  if t ãŒ **newsy (N)**, else 0
*    $mkt_{nr(t)}$ ï¼šç›´è¿‘ã® N/R æœˆã®ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆã‚ãªãŸãŒæ—¢ã«å®Ÿè£…æ¸ˆã¿ï¼‰
*    $P4(t)$ ï¼š**ç›´è¿‘4ã¤ã® newsy æœˆãƒªã‚¿ãƒ¼ãƒ³ã®å¹³å‡**ï¼ˆGuo 2025 ã® news aggregationï¼‰

ã•ã‚‰ã«è«–æ–‡ã§ã®è§£é‡ˆã¯ **â€œN æœˆã¨ R æœˆã§ã¯å¸‚å ´ã¸ã®ä½œç”¨ã®ä»•æ–¹ãŒç•°ãªã‚‹â€** ã¨ã„ã†ã‚‚ã®ã€‚

ä»¥ä¸‹ã§ **N æœˆ ã¨ R æœˆ ã«åˆ†ã‘ã¦ä¿‚æ•°ã‚’èª­ã¿æ›¿ãˆã‚‹**ã¨æˆ¦ç•¥ãŒè¦‹ãˆã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚

* * *

2\. å„æœˆã‚¿ã‚¤ãƒ—åˆ¥ã®ä¿‚æ•°ã‚’æ•´ç†ï¼ˆæˆ¦ç•¥è¨­è¨ˆã®ãŸã‚ã®å†æ§‹æˆï¼‰
=============================

â–  R æœˆï¼ˆRepetitive Month, Iâ¿=0ï¼‰
-----------------------------

R æœˆã®ãƒ¢ãƒ‡ãƒ«ã¯ï¼š

$$
mkt_t = \alpha + \beta_1 mkt_{nr(t)} + \beta_3 P4(t)
$$

ã¤ã¾ã‚Š **2ã¤ã®æœ‰åŠ¹äºˆæ¸¬å­**ï¼š

### (1) Correlation Neglect äºˆæ¸¬ï¼ˆmkt\_nrï¼‰

*    $\beta_1 = +0.0745$   
    â†’ æ­£æ–¹å‘ã ãŒ **æœ‰æ„ã§ã¯ãªã„**ï¼ˆt=1.17ï¼‰

### (2) Parameter Compression äºˆæ¸¬ï¼ˆP4ï¼‰

*    $\beta_3 = +0.4481$   
    â†’ **å¼·ãæ­£ã®äºˆæ¸¬åŠ›ï¼ˆt=4.58ï¼‰**

ğŸ‘‰ **R æœˆã¯ â€œå¤ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å¹³å‡ã—ãŸ P4 ãŒé«˜ã„ã¨æ¬¡ã®ãƒªã‚¿ãƒ¼ãƒ³ãŒä¸ŠãŒã‚‹â€  
ï¼æ˜ç¢ºãªé †å¼µã‚Šæœˆ**

* * *

â–  N æœˆï¼ˆNewsy Month, Iâ¿=1ï¼‰
------------------------

N æœˆã§ã¯ï¼š

$$
mkt_t = (\alpha+\gamma) + (\beta_1+\beta_2)mkt_{nr(t)} + (\beta_3+\beta_4)P4(t)
$$

æ•°å€¤ä»£å…¥ã™ã‚‹ã¨ï¼š

*    $\beta_1+\beta_2 = 0.0745 - 0.3177 = -0.2432$ ï¼ˆ**é€†å¼µã‚ŠåŠ¹æœ**ï¼‰
*    $\beta_3+\beta_4 = 0.4481 - 0.7000 = -0.2519$ ï¼ˆ**P4 ã‚‚é€†å¼µã‚ŠåŒ–**ï¼‰
*    $\gamma = +0.0133$ ï¼ˆ**N æœˆã¯å¹³å‡çš„ã«ä¸ŠãŒã‚Šã‚„ã™ã„ãƒã‚¤ã‚¢ã‚¹**ï¼‰

ğŸ‘‰ **N æœˆã¯ã€Œã™ã¹ã¦ãŒé€†å¼µã‚Šæ–¹å‘ã€  
ï¼å‰æœˆï¼ˆnrï¼‰ã€ç›´è¿‘4Nå¹³å‡ï¼ˆP4ï¼‰ãŒé«˜ã„ã»ã©ã€æ¬¡ã®ãƒªã‚¿ãƒ¼ãƒ³ã¯ä½ããªã‚‹**

* * *

3\. æ–‡çŒ®ã®ç†è«–ã¨ç…§åˆã™ã‚‹ã¨ä½•ãŒç¤ºå”†ã•ã‚Œã‚‹ã‹ï¼Ÿ
========================

Guo & Wachter ã® core ç†è«–ã¯ï¼š

*   **R æœˆï¼ˆ2ãƒ¶æœˆç›®ï¼‰**ï¼šrepetitive month ã¯ã€ŒæŠ•è³‡å®¶ãŒãƒ‹ãƒ¥ãƒ¼ã‚¹ã®æƒ…å ±ã‚’èª¤ã£ãŸç·šå½¢ãƒ¢ãƒ‡ãƒ«ã§å‡¦ç†ã—ã€éå»ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®å½±éŸ¿ã‚’éå¤§è©•ä¾¡ â†’ continuationã€ï¼ˆé †å¼µã‚Šï¼‰
*   **N æœˆï¼ˆ1ãƒ¶æœˆç›®ï¼‰**ï¼šnewsy month ã¯ã€ŒæŠ•è³‡å®¶ãŒå¤ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’èª¤ã£ã¦å‡ç­‰åŠ é‡ã—ã™ãã¦ãŠã‚Šã€æƒ…å ±ãŒåŠ¹ãã™ã â†’ reversalã€ï¼ˆé€†å¼µã‚Šï¼‰

ä»Šå›ã®æ¨å®šçµæœã¯ **éå¸¸ã«æ–‡çŒ®ã©ãŠã‚Šã§ textbook ã«è¿‘ã„**ï¼š

| Month Type | nr predictor | P4 predictor | Î³ | Interpretation |
| --- | --- | --- | --- | --- |
| **R** | +ï¼ˆå¼±ã„ï¼‰ | **å¼·ã„+** | â€“ | é †å¼µã‚Šæœˆ |
| **N** | **å¼·ã„âˆ’** | **å¼·ã„âˆ’** | æ­£ | å¹³å‡å¸‚å ´ãƒªã‚¹ã‚¯ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ã¯é«˜ã„ãŒã€äºˆæ¸¬æˆåˆ†ã¯é€†å¼µã‚Š |

* * *

4\. ã§ã¯ã“ã‚Œã‚’ã€Œæˆ¦ç•¥ã€ã«ã™ã‚‹ã¨ã©ã†ãªã‚‹ã‹ï¼Ÿ
=======================

çµè«–ã‹ã‚‰è¨€ã†ã¨ï¼š

> **N æœˆã¨ R æœˆã§ã¾ã£ãŸãåˆ¥ã®ãƒ–ãƒƒã‚¯ï¼ˆsignalï¼‰ã‚’ä½¿ã† â€œregime-specific predictorâ€ ã‚’ä½œã‚Šã€  
> ãã‚Œã‚’ä»Šã® timing æˆ¦ç•¥ï¼ˆapply\_timing\_strategyï¼‰ã«å…¥åŠ›ã™ã‚‹ã®ãŒæœ€é©è§£**

* * *

5\. å®Ÿè£…ã™ã¹ãçµ±åˆ predictor  $z_t^{\*}$ 
==================================

ä»¥ä¸‹ã®2ã‚¹ãƒ†ãƒƒãƒ—ã§ä½œã‚Šã¾ã™ã€‚

* * *

STEP 1ï¼š
-------

### R æœˆç”¨ predictor

$$
z_t^{R} = w_{nr}^{R}\, \underbrace{mkt_{nr(t)} - \bar{mkt}_{t-1}}_{\text{ã‚ãªãŸãŒå®Ÿè£…æ¸ˆã® base}} + w_{P4}^{R}\, \left(P4(t) - \bar{P4}_{t-1}\right)
$$
*   è«–æ–‡ã®ä¿‚æ•°ã«åŸºã¥ã„ã¦
    *    $w_{nr}^{R} \propto +\beta_1$ 
    *    $w_{P4}^{R} \propto +\beta_3$ 

ğŸ‘‰ **ãŸã¨ãˆã°ï¼ˆæ¨™æº–åŒ–å¾Œï¼‰ w\_{P4} ã‚’å¤§ããã—ã€w\_{nr} ã¯ã»ã¼ç„¡è¦–ã§ã‚‚è‰¯ã„**  
ï¼ˆæ¨å®šçµæœã‚’è¦‹ã‚‹é™ã‚Šï¼‰

* * *

STEP 2ï¼š
-------

### N æœˆç”¨ predictor

$$
z_t^{N} = w_{nr}^{N}\, \left[-(mkt_{nr(t)} - \bar{mkt}_{t-1})\right] + w_{P4}^{N}\, \left[-(P4(t) - \bar{P4}_{t-1})\right]
$$
*   è«–æ–‡ã®ä¿‚æ•°ã‹ã‚‰
    *    $w_{nr}^{N} \propto (\beta_1+\beta_2) < 0$ 
    *    $w_{P4}^{N} \propto (\beta_3+\beta_4) < 0$ 

ğŸ‘‰ **N æœˆã§ã¯ nr ã‚‚ P4 ã‚‚ â€œé€†å¼µã‚Šâ€ æ–¹å‘ï¼ˆç¬¦å·åè»¢ï¼‰**

* * *

STEP 3ï¼šçµ±åˆãƒ«ãƒ¼ãƒ«
------------

$$
z_t^{\*} = \begin{cases} z_t^{R}, & \text{month is R} \\ z_t^{N}, & \text{month is N} \\ 0, & \text{month type is 3} \end{cases}
$$

ãã—ã¦ã€  
**ã“ã‚Œã‚’ apply\_timing\_strategy(df) ã«æ¸¡ã™ã ã‘ã§  
ãƒ¬ãƒãƒ¬ãƒƒã‚¸ä»˜ã timing æˆ¦ç•¥ãŒæˆç«‹ã—ã¾ã™ã€‚**

* * *

6\. ã§ã¯ä¿‚æ•°ã‚’ã©ã†ä½¿ã†ã¹ãã‹ï¼Ÿï¼ˆæ–‡çŒ®ã¨ã®æ•´åˆçš„ãªå®Ÿå‹™ãƒ«ãƒ¼ãƒ«ï¼‰
================================

### æ¨å¥¨ãƒ«ãƒ¼ãƒ«ï¼ˆè«–æ–‡æº–æ‹ ï¼‰ï¼š

### â–  R æœˆï¼ˆé †å¼µã‚Šï¼‰

*   ä¸»è¦ signalï¼š  
    **P4(t)**ï¼ˆéå»4ã¤ã® newsy ã®å¹³å‡ï¼‰ãŒæ­£ãªã‚‰ **ãƒ­ãƒ³ã‚°å¯„ã‚Š**  
    å¤§ãã„ã»ã©ãƒ¬ãƒãƒ¬ãƒƒã‚¸ã‚’å¼·ãã—ã¦ OK
*   nr(t) ã¯ **å¼±ã„ãŒæ­£ä¿¡å·** â†’ small positive weight ã§åŠ ãˆã‚‹

### â–  N æœˆï¼ˆé€†å¼µã‚Šï¼‰

*   nr(t) ãŒé«˜ã„ â†’ **ã‚·ãƒ§ãƒ¼ãƒˆ**ï¼ˆreversalï¼‰
*   P4 ãŒé«˜ã„ â†’ **ã•ã‚‰ã«ã‚·ãƒ§ãƒ¼ãƒˆå¼·åŒ–**

### â–  3 æœˆ â†’ ãƒãƒ¼ãƒã‚¸ã§ OK

* * *

7\. é‡ã¿ï¼ˆw\_nr, w\_P4ï¼‰ã®å®Ÿå‹™çš„ãªè¨­è¨ˆ
===========================

ã‚ãªãŸã®æˆ¦ç•¥ã¯ target\_vol / Ïƒ(z) ã§ã‚¹ã‚±ãƒ¼ãƒ«ã—ã¦ã„ã‚‹ã®ã§ã€  
ä¿‚æ•°ã¯ **ç›¸å¯¾é‡ã¿ã ã‘æ±ºã‚ã‚Œã°è‰¯ã„**ã€‚

æ¨å®šå€¤ã‹ã‚‰ï¼š

*   **R æœˆ**
    *   Î²â‚ â‰ˆ +0.07ï¼ˆå¼±ã„ï¼‰ â†’ é‡ã¿ 0.2
    *   Î²â‚ƒ â‰ˆ +0.45ï¼ˆå¼·ã„ï¼‰ â†’ é‡ã¿ 1.0
*   **N æœˆ**
    *   Î²â‚+Î²â‚‚ â‰ˆ âˆ’0.24 â†’ é‡ã¿ -1.0
    *   Î²â‚ƒ+Î²â‚„ â‰ˆ âˆ’0.25 â†’ é‡ã¿ -1.0

æ¨å¥¨è¨­å®šï¼š

```python
w_nr_R  = 0.2
w_P4_R  = 1.0

w_nr_N  = -1.0
w_P4_N  = -1.0
```

* * *

8\. æˆ¦ç•¥ã¨ã—ã¦ã®ã¾ã¨ã‚ï¼ˆæ–‡çŒ®æº–æ‹ ã®é‹ç”¨ãƒ«ãƒ¼ãƒ«ï¼‰
=========================

æœ€çµ‚çš„ãªæŠ•è³‡å®¶ã®è¡Œå‹•ã¯ã“ã†ãªã‚‹ï¼š

* * *

ã€R æœˆï¼ˆ2ãƒ¶æœˆç›®ï¼‰ï¼é †å¼µã‚Šã€‘
---------------

*   P4 ãŒé«˜ã„ â†’ **å¼·æ°—ãƒ­ãƒ³ã‚°**
*   nr ã‚‚ã‚„ã‚„ãƒ­ãƒ³ã‚°æ–¹å‘ã«åŠ ç‚¹
*   apply\_timing\_strategy ã«æ¸¡ã™ã¨è‡ªç„¶ã«é«˜ãƒ¬ãƒãƒ¬ãƒƒã‚¸â†’é«˜ã‚¦ã‚§ã‚¤ãƒˆã«ãªã‚‹

* * *

ã€N æœˆï¼ˆ1ãƒ¶æœˆç›®ï¼‰ï¼é€†å¼µã‚Šã€‘
---------------

*   nr ãŒé«˜ã„ â†’ **ã‚·ãƒ§ãƒ¼ãƒˆ**
*   P4 ãŒé«˜ã„ â†’ **ã•ã‚‰ã«ã‚·ãƒ§ãƒ¼ãƒˆ**
*   Î³ï¼ˆN æœˆå¹³å‡ +1.3%ï¼‰ã®ãŠã‹ã’ã§å®Œå…¨ã‚·ãƒ§ãƒ¼ãƒˆã«ã¯ã—ãªã„ãŒã€  
    signal ã¯æ˜ç¢ºã«é€†å¼µã‚Š

* * *

ã€3 æœˆã€‘
-----

*   æ–‡çŒ®ã§ã¯äºˆæ¸¬åŠ›ãªã— â†’ **ãƒãƒ¼ãƒã‚¸ã«ã—ã¦è‰¯ã„**

* * *

9\. Guo ã®ç†è«–ã«æœ€ã‚‚å¾“ã†å½¢ã®æœ€çµ‚æˆ¦ç•¥
======================

$$
w_t = \operatorname{clip}\Big( \frac{z_t^{\*}}{\sigma(z)} \cdot target\_vol, \ -max\_lev,\ +max\_lev \Big)
$$

ã“ã“ã§  $z_t^{\*}$  ã¯ï¼š

*   R æœˆï¼šé †å¼µã‚Šåˆæˆ signal
*   N æœˆï¼šé€†å¼µã‚Šåˆæˆ signal
*   3 æœˆï¼š0

* * *

10\. å¸Œæœ›ãŒã‚ã‚Œã°ä»¥ä¸‹ã‚‚å®Ÿè£…å¯èƒ½ã§ã™
====================

*   ä¸Šè¨˜ã® **z\*\_t ã®å®Œå…¨ Python å®Ÿè£…ã‚³ãƒ¼ãƒ‰**
*   ã‚ãªãŸã® `apply_timing_strategy` ã¨è‡ªç„¶ã«çµ±åˆã—ãŸ **ãƒ•ãƒ«ã‚³ãƒ¼ãƒ‰**
*   nr(t) ã¨ P4(t) ã‚’ rolling window ã§ã€Œãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨å®šã€ã™ã‚‹  
    **ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ç‰ˆï¼ˆå°†æ¥æƒ…å ±ãƒªãƒ¼ã‚¯ãªã—ï¼‰**
*   N/R ã® regime switching ãŒ 2020 å¹´ä»¥é™å´©ã‚Œã¦ã„ãªã„ã‹ã®  
    **é€æ¬¡ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°**

* * *

ã‚‚ã—æ¬¡ã«é€²ã‚ãŸã„å ´åˆã€

> ã€Œã“ã® z\*\_t ã®è¨ˆç®—ã‚³ãƒ¼ãƒ‰ã‚’ãƒ•ãƒ«ã§æ›¸ã„ã¦ãã ã•ã„ã€

ã¨è¨€ã£ã¦ãã ã•ã‚Œã°ã€  
ã‚ãªãŸã®æ—¢å­˜ã‚³ãƒ¼ãƒ‰ï¼ˆbuild\_predictor\_z / apply\_timing\_strategyï¼‰ã«  
å®Œå…¨ã«çµ±åˆã—ãŸå½¢ã§æä¾›ã—ã¾ã™ã€‚

## Response:
æ€è€ƒæ™‚é–“: 16s

ã‚„ã‚Šã¾ã™ã­ã“ã®è³ªå•ğŸ˜„  
ã˜ã‚ƒã‚ã€**nr + P4 ã‚’çµ„ã¿åˆã‚ã›ãŸ z\*\_t ã‚’ä½œã£ã¦ã€æ—¢å­˜ã® `apply_timing_strategy` ã«ãã®ã¾ã¾çªã£è¾¼ã‚ã‚‹ãƒ•ãƒ«ã‚³ãƒ¼ãƒ‰**ã‚’ç”¨æ„ã—ã¾ã™ã€‚

* * *

å…¨ä½“åƒ
---

å‰æï¼šã‚ãªãŸã®ç’°å¢ƒã«ã¯ã™ã§ã«

*   `load_ff_monthly_from_ken_french`
*   `classify_month_type`
*   `apply_timing_strategy`

ãŒå®šç¾©ã•ã‚Œã¦ã„ã¾ã™ã‚ˆã­ï¼ˆæœ€åˆã«é€ã£ã¦ãã‚ŒãŸã‚³ãƒ¼ãƒ‰ï¼‰ã€‚

ãã“ã«ä»¥ä¸‹ã‚’è¿½åŠ ã™ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã§ã™ï¼š

1.  `add_nr_and_nm4(ff)`  
    â†’ **nr(t)** ã¨ **P4ï¼ˆç›´è¿‘4 newsy å¹³å‡ï¼‰** ã‚’ä½œã‚‹
2.  `build_z_star(df, w_...)`  
    â†’ Guo & Wachter / Guo 2025 ã®ä¿‚æ•°ã«åŸºã¥ã„ã¦  
    **Næœˆãƒ»Ræœˆã§ãƒ«ãƒ¼ãƒ«ã®é•ã† z\*\_t ã‚’æ§‹ç¯‰**
3.  ãã® `z_star` ã‚’ `apply_timing_strategy` ã«æ¸¡ã™

* * *

1\. nr(t) ã¨ P4(t) ã‚’è¿½åŠ ã™ã‚‹é–¢æ•°
-------------------------

```python
# ======================================================================
# nr(t) ã¨ nm(t,j)ã€P4 = ç›´è¿‘4ã¤ã® newsy æœˆå¹³å‡ ã‚’è¿½åŠ 
# ======================================================================

def add_nr_and_nm4(ff: pd.DataFrame) -> pd.DataFrame:
    """
    ff: load_ff_monthly_from_ken_french ã®å‡ºåŠ›
        å¿…é ˆåˆ—: ['mkt_excess', 'rf']

    è¿½åŠ ã•ã‚Œã‚‹åˆ—:
        - 'month_type' : 'N', 'R', '3'
        - 'In_t'       : ãã®æœˆãŒ newsy (N) ãªã‚‰ 1, ãã‚Œä»¥å¤– 0
        - 'nr_date'    : nr(t) ã«å¯¾å¿œã™ã‚‹æ—¥ä»˜
        - 'mkt_nr'     : mkt_excess[nr(t)]
        - 'mkt_nm1'..'mkt_nm4' : ç›´è¿‘ j ç•ªç›®ã® newsy æœˆã®ãƒªã‚¿ãƒ¼ãƒ³
        - 'mkt_nm4_avg': ç›´è¿‘4ã¤ã® newsy æœˆã®å¹³å‡ (Guo 2025 ã® P4_j mktnm(t,j))
    """
    df = ff.copy()
    df["month_type"] = classify_month_type(df.index)
    df["In_t"] = (df["month_type"] == "N").astype(int)

    dates = list(df.index)
    mt = df["month_type"].values
    mkt = df["mkt_excess"].values

    nr_dates = []
    mkt_nr_list = []

    # nm(t,j) ç”¨ã«ã€Œã“ã‚Œã¾ã§å‡ºã¦ããŸ newsy æœˆã® indexã€ã‚’è“„ç©
    past_newsy_indices = []

    mkt_nm1 = []
    mkt_nm2 = []
    mkt_nm3 = []
    mkt_nm4 = []

    for i, t in enumerate(dates):
        # ---- nr(t): t ã‚ˆã‚Šå‰ã§æœ€ã‚‚è¿‘ã„ N or R ----
        nr_idx = None
        j = i - 1
        while j >= 0:
            if mt[j] in ("N", "R"):
                nr_idx = j
                break
            j -= 1
        if nr_idx is None:
            nr_dates.append(None)
            mkt_nr_list.append(np.nan)
        else:
            nr_dates.append(dates[nr_idx])
            mkt_nr_list.append(mkt[nr_idx])

        # ---- newsy æœˆã®å±¥æ­´æ›´æ–° ----
        if mt[i] == "N":
            past_newsy_indices.append(i)

        # ---- nm(t,j): ç›´è¿‘ newsy æœˆãŸã¡ ----
        candidate_newsy = [k for k in past_newsy_indices if k < i]
        candidate_newsy_sorted = sorted(candidate_newsy, reverse=True)

        vals = []
        for jj in range(4):
            if jj < len(candidate_newsy_sorted):
                vals.append(mkt[candidate_newsy_sorted[jj]])
            else:
                vals.append(np.nan)

        mkt_nm1.append(vals[0])
        mkt_nm2.append(vals[1])
        mkt_nm3.append(vals[2])
        mkt_nm4.append(vals[3])

    df["nr_date"] = nr_dates
    df["mkt_nr"] = mkt_nr_list
    df["mkt_nm1"] = mkt_nm1
    df["mkt_nm2"] = mkt_nm2
    df["mkt_nm3"] = mkt_nm3
    df["mkt_nm4"] = mkt_nm4

    # ç›´è¿‘4ã¤ã® newsy æœˆã®å¹³å‡ï¼ˆ4ã¤æƒã£ã¦ã„ãªã„å ´åˆã¯ NaNï¼‰
    df["mkt_nm4_avg"] = df[["mkt_nm1", "mkt_nm2", "mkt_nm3", "mkt_nm4"]].mean(axis=1)

    return df
```

* * *

2\. z\*\_t ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°
------------------

*   **R æœˆ**ï¼šé †å¼µã‚Š
*   **N æœˆ**ï¼šé€†å¼µã‚Š
*   **3 æœˆ**ï¼šãƒãƒ¼ãƒã‚¸ï¼ˆz\*=0ï¼‰

ã¨ã—ã¦ã€ã‚ãªãŸã®æ¨å®šçµæœã«åŸºã¥ã„ãŸé‡ã¿ã‚’å…¥ã‚Œã¾ã™ã€‚

```python
# ======================================================================
# Guo&Wachter / Guo 2025 ã«åŸºã¥ã z*_t ã®æ§‹ç¯‰
# ======================================================================

def build_z_star(
    df_nr_nm: pd.DataFrame,
    w_nr_R: float = 0.2,
    w_P4_R: float = 1.0,
    w_nr_N: float = -1.0,
    w_P4_N: float = -1.0,
) -> pd.DataFrame:
    """
    df_nr_nm:
        add_nr_and_nm4(ff) ã‚’é€šã—ãŸ DataFrame
        ['mkt_excess', 'month_type', 'mkt_nr', 'mkt_nm4_avg'] ç­‰ã‚’å«ã‚€ã€‚

    w_*:
        Guo&Wachter ã®å›å¸°ä¿‚æ•°ã‹ã‚‰æ±ºã‚ãŸç›¸å¯¾é‡ã¿ã€‚
        ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã¯ beta1, beta3, beta1+beta2, beta3+beta4 ã®ç¬¦å·ã¨
        å¤§ãã•ã‚’ã–ã£ãã‚Šåæ˜ ã—ãŸè¨­å®šã€‚

    æˆ»ã‚Šå€¤:
        df: ä»¥ä¸‹ã®åˆ—ã‚’è¿½åŠ 
            - 'nr_demeaned' : mkt_nr - å¹³å‡(mkt_nr, ã€œt-1)
            - 'P4_demeaned' : mkt_nm4_avg - å¹³å‡(P4, ã€œt-1)
            - 'z_star'      : æœˆã‚¿ã‚¤ãƒ—åˆ¥ãƒ«ãƒ¼ãƒ«ã§åˆæˆã•ã‚ŒãŸæœ€çµ‚ predictor
    """
    df = df_nr_nm.copy()

    # nr(t), P4(t) ãŒå­˜åœ¨ã™ã‚‹ã¨ã“ã‚ã ã‘ä½¿ã†
    df["nr_demeaned"] = (
        df["mkt_nr"] - df["mkt_nr"].expanding().mean().shift(1)
    )
    df["P4_demeaned"] = (
        df["mkt_nm4_avg"] - df["mkt_nm4_avg"].expanding().mean().shift(1)
    )

    z_star = []

    for t, row in df.iterrows():
        mt = row["month_type"]
        nr_d = row["nr_demeaned"]
        P4_d = row["P4_demeaned"]

        # åˆæœŸ NaN ã®æ‰±ã„
        if np.isnan(nr_d) or np.isnan(P4_d):
            z_star.append(0.0)
            continue

        if mt == "R":
            # R æœˆ: é †å¼µã‚Š â†’ nr, P4 ã«æ­£ã®é‡ã¿
            z_t = w_nr_R * nr_d + w_P4_R * P4_d
        elif mt == "N":
            # N æœˆ: é€†å¼µã‚Š â†’ nr, P4 ã‚’ç¬¦å·åè»¢ï¼ˆw_nr_N, w_P4_N ã¯è² ï¼‰
            z_t = w_nr_N * nr_d + w_P4_N * P4_d
        else:  # mt == "3"
            # 3 ãƒ¶æœˆç›®ã¯ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚’å–ã‚‰ãªã„
            z_t = 0.0

        z_star.append(z_t)

    df["z_star"] = z_star
    return df
```

* * *

3\. æˆ¦ç•¥ã¸ã®çµ„ã¿è¾¼ã¿ä¾‹ï¼ˆãƒ•ãƒ«ãƒ•ãƒ­ãƒ¼ï¼‰
--------------------

æœ€å¾Œã«ã€Ken French CSV ã‹ã‚‰èª­ã¿è¾¼ã‚“ã§  
**z\*\_t â†’ apply\_timing\_strategy â†’ ãƒ—ãƒ­ãƒƒãƒˆ**ã¾ã§ä¸€æ°—é€šã—ã®ã‚³ãƒ¼ãƒ‰ã§ã™ã€‚

```python
# ======================================================================
# ä½¿ã„æ–¹ãƒ•ãƒ­ãƒ¼
# ======================================================================

# 1. Ken French ã‹ã‚‰å¸‚å ´ãƒªã‚¿ãƒ¼ãƒ³ã‚’èª­ã¿è¾¼ã‚€
ff = load_ff_monthly_from_ken_french("F-F_Research_Data_Factors.csv")

# 2. nr(t) ã¨ P4(t) ã‚’ä½œæˆ
df_nr_nm = add_nr_and_nm4(ff)

# 3. Guo&Wachter + Guo(2025) ã«åŸºã¥ã z*_t ã‚’æ§‹ç¯‰
df_zstar = build_z_star(
    df_nr_nm,
    w_nr_R=0.2,   # R æœˆã® nr ã«å¯¾ã™ã‚‹é‡ã¿
    w_P4_R=1.0,   # R æœˆã® P4 ã«å¯¾ã™ã‚‹é‡ã¿ï¼ˆé †å¼µã‚Šæˆåˆ†ã®ä¸»å½¹ï¼‰
    w_nr_N=-1.0,  # N æœˆã® nrï¼ˆé€†å¼µã‚Šï¼‰
    w_P4_N=-1.0,  # N æœˆã® P4ï¼ˆé€†å¼µã‚Šï¼‰
)

# 4. ã‚¿ã‚¤ãƒŸãƒ³ã‚°æˆ¦ç•¥ã«æ¸¡ã™ãŸã‚ã«åˆ—å 'z' ã‚’å·®ã—æ›¿ãˆ
df_for_strategy = df_zstar.copy()
df_for_strategy["z"] = df_for_strategy["z_star"]

# 5. æ—¢å­˜ã® apply_timing_strategy ã§é‹ç”¨
df_strat = apply_timing_strategy(
    df_for_strategy,
    target_vol=0.05,
    max_leverage=3.0,
)

# 6. çµæœãƒ—ãƒ­ãƒƒãƒˆï¼ˆã‚ãªãŸã® plot_results ã‚’å†åˆ©ç”¨ã—ã¦ã‚‚OKï¼‰
plot_results(df_strat)
```

* * *

4\. è£œè¶³ï¼šå®Œå…¨ã«ã€Œå°†æ¥æƒ…å ±ãƒªãƒ¼ã‚¯ãªã—ã€ã«ãªã£ã¦ã„ã‚‹ã‹ï¼Ÿ
-----------------------------

*   `mkt_nr(t)`ï¼šå®šç¾©ä¸Šã€Œt ã‚ˆã‚Šå‰ã§æœ€ã‚‚è¿‘ã„ N/R æœˆã€ã ã‘ã‚’å‚ç…§ â†’ éå»æƒ…å ±ã®ã¿
*   `mkt_nm4_avg(t)`ï¼šåŒæ§˜ã«ã€Œt ã‚ˆã‚Šå‰ã® newsy æœˆã€ã‚’æœ€å¤§4ã¤ã¾ã§å‚ç…§ â†’ éå»ã®ã¿
*   `expanding().mean().shift(1)`ï¼š
    *   t æ™‚ç‚¹ã§ **tâˆ’1 ã¾ã§**ã®å¹³å‡ã—ã‹ä½¿ã£ã¦ã„ãªã„

ãªã®ã§ã€ã“ã® z\*\_t ã¯ **å®Œå…¨ã«ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®æŠ•è³‡å®¶ãŒæŒã¦ã‚‹æƒ…å ±ã ã‘**ã‹ã‚‰æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚

* * *

5\. æ¬¡ã®ä¸€æ‰‹ã®ã‚¢ã‚¤ãƒ‡ã‚¢
-------------

ã‚‚ã—ã“ã® z\*\_t ã§

*   1926â€“2025 å…¨ä½“ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
*   2000 å¹´ä»¥é™ / 2010 å¹´ä»¥é™ / 2020 å¹´ä»¥é™ã®ã‚µãƒ–ã‚µãƒ³ãƒ—ãƒ«

ã‚’æ¯”è¼ƒã—ãŸã„ãªã‚‰ã€

*   `df_for_strategy.loc["2000-01-01":]` ãªã©ã«åˆ¶é™ã—ã¦åŒã˜æˆ¦ç•¥ã‚’å›ã™
*   R æœˆ / N æœˆã®ã¿ã®ã‚µãƒ³ãƒ—ãƒ«ã«çµã£ã¦ z\*\_t ã¨ mkt\_excess ã®ç›¸é–¢ã‚’å‡ºã™

ãªã©ã‚‚ç°¡å˜ã«ã§ãã¾ã™ã€‚ãã®ã‚ãŸã‚Šã‚‚å¿…è¦ãªã‚‰ã™ãã‚³ãƒ¼ãƒ‰å‡ºã—ã¾ã™ã€‚

## Response:
ä»¥ä¸‹ã§ã¯ã€**Guo & Wachter (2025)** ã®æœ¬æ–‡ï¼ˆç‰¹ã« Section 3.2, 3.3, 6ï¼‰ãŠã‚ˆã³ **Guo (2025)**ï¼ˆP4\_j mktnm ã®å®šç¾©ï¼‰ã®å†…å®¹ã‚’è¸ã¾ãˆã¦ã€

1.  **ç›¸é–¢ãƒã‚°ãƒ¬ã‚¯ãƒˆ nr(t) ã®ã¿ã‚’ä½¿ã†æ‰‹æ³•ï¼ˆã‚ãªãŸã® z\_t ã«å¯¾å¿œï¼‰**
2.  **nr(t) + P4\_j mktnm(t,j) ã‚’çµ„ã¿åˆã‚ã›ã‚‹æ‹¡å¼µç‰ˆ z\*\_tï¼ˆ2å¤‰æ•°ç‰ˆï¼‰**

ã‚’æ–‡çŒ®ãƒ™ãƒ¼ã‚¹ã§æ˜ç¢ºã«æ¯”è¼ƒã—ã¤ã¤èª¬æ˜ã—ã¾ã™ã€‚

ssrn-5268329

* * *

1\. nr(t) ã®ã¿ã‚’ä½¿ã† Guoâ€“Wachterï¼ˆ2025ï¼‰ã®äºˆæ¸¬å­
=====================================

### 1.1 nr(t) ã®å®šç¾©

è«–æ–‡ã§ã¯ã€æœˆ t ãŒ

*   **newsyï¼ˆå››åŠæœŸ1ãƒ¶æœˆç›®ï¼‰**
*   **repetitiveï¼ˆå››åŠæœŸ2ãƒ¶æœˆç›®ï¼‰**
*   **mutedï¼ˆ3ãƒ¶æœˆç›®ï¼‰**

ã®3åˆ†é¡ã§æ§‹æˆã•ã‚Œã‚‹ã€‚

ãã“ã§ nr(t) ã¯ä»¥ä¸‹ã® _ç›´å‰ã® newsy/repetitive æœˆã®å¸‚å ´è¶…éãƒªã‚¿ãƒ¼ãƒ³_ ã‚’ã¨ã‚‹ï¼š

$$
\text{mktnr}(t) = \begin{cases} \text{mkt}_{t-1}, & t\text{ãŒ repetitive ã®ã¨ã}\\[6pt] \text{mkt}_{t-2}, & t\text{ãŒ newsy ã®ã¨ã}\\[6pt] 0, & t\text{ãŒ muted ã®ã¨ã} \end{cases}
$$

ã“ã‚Œã¯ã€å®Ÿéš›ã«ã¯æ¬¡ã‚’æ„å‘³ã™ã‚‹ï¼š

*   newsy â†’ repetitiveï¼ˆæœˆ1 â†’ æœˆ2ï¼‰ã®ã€Œç¶™ç¶šã€ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆï¼‹ï¼‰
*   repetitive â†’ æ¬¡ã® newsyï¼ˆæœˆ2 â†’ æ¬¡ã®æœˆ1ï¼‰ã®ã€Œåè»¢ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆâˆ’ï¼‰

ã¤ã¾ã‚Š **ç¶™ç¶šâ†’åè»¢ï¼ˆcontinuation â†’ reversalï¼‰æ§‹é€ ** ã‚’åˆ©ç”¨ã—ãŸäºˆæ¸¬å­ã¨ãªã‚‹ã€‚

### 1.2 äºˆæ¸¬å­ z\_t

æ–‡çŒ®ä¸­ï¼ˆTable 3ï¼‰ã§ç”¨ã„ã‚‰ã‚Œã‚‹ OOS äºˆæ¸¬å­ã¯

$$
z_{t-1} = \begin{cases} \text{mktnr}(t) - \bar{mkt}_{t-1}, & t \in \{\text{newsy, repetitive}\}\\ 0, & \text{otherwise} \end{cases}
$$

ã“ã‚Œã¯ã‚ãªãŸã® `build_predictor_z` ã®å®Ÿè£…ã¨ç­‰ä¾¡ã§ã™ã€‚

> **çµè«–ï¼šã‚ãªãŸã® build\_predictor\_z ã¯ Guoâ€“Wachter ã® core predictor ã‚’æ­£ã—ãå®Ÿè£…ã—ã¦ã„ã‚‹ã€‚**

* * *

2\. Guo (2025) ã® P4\_j mktnm(t,j)ï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹å¹³å‡ï¼‰ã¨ã¯
===========================================

Guoï¼ˆ2025ï¼‰ã¯ã€Œãƒ‹ãƒ¥ãƒ¼ã‚¹ã®è¨˜æ†¶ decay ãƒ¬ãƒ¼ãƒˆã®èª¤èªï¼ˆparameter compressionï¼‰ã€ã‚’æ‰±ã†è«–æ–‡ã§ã‚ã‚Šã€æ¬¡ã®ã‚ˆã†ãªç‹¬è‡ª predictor ã‚’å°å…¥ã™ã‚‹ï¼š

$$
P4(t) = \frac{1}{4}\sum_{j=1}^4 \text{mktnm}(t,j)
$$

ã“ã“ã§ mktnm(t,j) ã¯ã€

*   éå» j å›ã® **newsy æœˆã®å¸‚å ´è¶…éãƒªã‚¿ãƒ¼ãƒ³**
*   newsy æœˆã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ã—ã¦ä¸¦ã¹ãŸç³»åˆ— nm(1), nm(2), â€¦ ã®å¹³å‡ã®ã‚ˆã†ãªã‚‚ã®

ã¤ã¾ã‚Šã€Œéå»4å›ã® newsy æœˆã®å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³ã€ãŒ P4(t)ã€‚

### 2.1 ç›´è¦³

*   éå»ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆæœˆ1ï¼‰ã§ã¯ earnings shock ãŒéšæ®µçš„ã« decay ã™ã‚‹
*   æŠ•è³‡å®¶ã¯ decay ãƒ¬ãƒ¼ãƒˆã‚’èª¤èªã—å¹³å‡åŒ–ã—ã¦ã—ã¾ã†
*   ãã®ãŸã‚ newsy ãƒªã‚¿ãƒ¼ãƒ³ã®ç§»å‹•å¹³å‡ãŒæœ‰åŠ¹ãªäºˆæ¸¬å› å­ã¨ãªã‚‹ï¼ˆè² ã®ä¿‚æ•°ï¼‰

### 2.2 æ–‡çŒ®ã§ã®å›å¸°å¼ï¼ˆTable 11ï¼‰

è«–æ–‡ã® Table 11ï¼ˆGuo 2025 + Guoâ€“Wachter 2025 ã® joint testï¼‰ã§ã¯ï¼š

$$
mkt_t = \alpha + \beta_1 \, mktnr(t) + \beta_2 \, P4(t) + \epsilon_t
$$

ä¸¡æ–¹ã¨ã‚‚ **æœ‰æ„ã«æ®‹ã‚‹** ã“ã¨ãŒç¢ºèªã•ã‚Œã‚‹ã€‚

* * *

3\. nr(t) ã¨ P4(t) ã‚’çµ„ã¿åˆã‚ã›ãŸ z\*\_t ã®æ„å‘³
====================================

ã‚ãªãŸãŒç¤ºã—ãŸæ¨å®šçµæœï¼š

```
beta2_mktnr_In : -0.3177   (t = -2.89)
beta3_nm4      :  0.4481   (t =  4.58)
beta4_nm4_In   : -0.7000   (t = -4.29)
gamma_In       :  0.0133   (t =  3.39)
```

ã“ã‚Œã¯ _newsy ã¨ repetitive ã§ä¿‚æ•°ãŒç•°ãªã‚‹_ ãƒªãƒƒãƒãªå½¢ã®å¼ï¼š

$$
mkt_t=\alpha + \beta_2 \, mktnr(t)\cdot I_N(t) + \beta_3 \, P4(t) + \beta_4 \, P4(t)\cdot I_N(t) + \gamma\,I_N(t)
$$

ã«å¯¾å¿œã—ã¦ã„ã‚‹ã€‚

### è§£é‡ˆ

*   **repetitive æœˆã§ã¯ P4(t) ã®ä¿‚æ•°ã¯ +ï¼ˆcontinuation çš„ï¼‰**
*   **newsy æœˆã§ã¯ P4(t) ã®ä¿‚æ•°ã¯ Î²3+Î²4 ã§æ˜ç¢ºã« negativeï¼ˆreversal çš„ï¼‰**

ã¤ã¾ã‚Š  
**P4(t) è‡ªä½“ãŒ nr(t) ã®æ§‹é€ ã¨åŒæ§˜ã«ã€Œç¶™ç¶šâ†’åè»¢ã€ã®æ€§è³ªã‚’æŒã¤**  
ã¨ã„ã†ã“ã¨ãŒãƒ‡ãƒ¼ã‚¿ä¸Šç¢ºèªã•ã‚Œã¦ã„ã‚‹ã€‚

ã“ã®ãŸã‚ z\*\_t ã‚’ä½œã‚‹ãªã‚‰ï¼š

* * *

4\. æ–‡çŒ®ã«æ²¿ã£ãŸ z\*\_t ã®å®šç¾©
=====================

è«–æ–‡ã§æ˜ç¤ºçš„ã«ã€Œz\*\_tã€ã‚’å®šç¾©ã—ã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªã„ãŒã€  
**æˆ¦ç•¥æ§‹ç¯‰ã®ãŸã‚ã® predictor** ã¨ã—ã¦æœ€ã‚‚è‡ªç„¶ãªã®ã¯æ¬¡ã®ç·šå½¢äºˆæ¸¬å­ï¼š

$$
z^*_t = \hat\beta_1 \, mktnr(t) + \hat\beta_2 \, P4(t)
$$

ãŸã ã—ä¿‚æ•°ã¯ _expanding-window ã§é€æ¬¡æ›´æ–°_ï¼ˆlook-ahead é˜²æ­¢ï¼‰ã€  
ã¤ã¾ã‚Šï¼š

1.  æ™‚ç‚¹ t ã§äºˆæ¸¬ã™ã‚‹ã¨ã
2.  å›å¸°ã«ã¯ **tâˆ’1 æ™‚ç‚¹ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨**
3.  å¾—ã‚‰ã‚ŒãŸä¿‚æ•° Î²Ì‚ ã‚’ä½¿ã£ã¦ t ã®äºˆæ¸¬å­ z\*\_t ã‚’è¨ˆç®—
4.  ãã® z\*\_t ã‚’ç”¨ã„ã¦ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚’å¼µã‚‹

ã“ã‚ŒãŒ **æ–‡çŒ® Table 3, Table 11 ã® OOS ã‚»ãƒƒãƒ†ã‚£ãƒ³ã‚°** ã¨æ•´åˆçš„ã€‚

* * *

5\. nr-only ã¨ nr+P4 ã®äºˆæ¸¬æ§‹é€ ã®é•ã„
============================

| æ‰‹æ³• | å­¦ç¿’ã™ã‚‹ç¾è±¡ | åŠ¹æœ |
| --- | --- | --- |
| nr(t) only | ã€Œæœˆ1â†’æœˆ2ã® continuationã€ã€Œæœˆ2â†’æœˆ1 ã® reversalã€ | ç›¸é–¢ãƒã‚°ãƒ¬ã‚¯ãƒˆç”±æ¥ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ‰ãˆã‚‹ï¼ˆå¼·ã„ï¼‰ |
| nr + P4 | nr ã®åŠ¹æœã«åŠ ãˆã¦ **ãƒ‹ãƒ¥ãƒ¼ã‚¹ shock ã® decay èª¤èª** ã‚’æ‰ãˆã‚‹ | nr(t) ãŒå¼±ã„å±€é¢ã§ã‚‚æ€§èƒ½ã‚’è£œå®Œ |

æ–‡çŒ®ï¼ˆSection 6ï¼‰ã®ä¸»å¼µã‚‚ï¼š

*   nr(t)ï¼ˆç›¸é–¢ãƒã‚°ãƒ¬ã‚¯ãƒˆï¼‰ã¨
*   P4(t)ï¼ˆparameter compressionï¼‰

ã¯ **distinct ã ãŒä¸¡æ–¹å¼·ã„**  
â†’ ä¸¡æ–¹ä½¿ã†ã¨ã‚ˆã‚Š robust ã«ãªã‚‹ã€‚

* * *

6\. ã§ã¯æˆ¦ç•¥ã¸ã©ã†åæ˜ ã™ã¹ãã‹ï¼Ÿï¼ˆæ–‡çŒ®æº–æ‹ ã®ææ¡ˆï¼‰
===========================

### **ææ¡ˆï¼š2ã¤ã®äºˆæ¸¬å­ã‚’çµ±åˆã—ãŸã‚ªãƒ³ãƒ©ã‚¤ãƒ³ç‰ˆ market timing strategy**

1.  æ¯æœˆæœ«ã« tâˆ’1 æ™‚ç‚¹ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã§æ¬¡ã® OLS ã‚’æ¨å®šï¼š
    
$$
mkt_s = \alpha + \beta_1 mktnr(s) + \beta_2 P4(s) + \varepsilon_s \quad (s \le t-1)
$$
2.  ä¿‚æ•°  $\hat\beta_1, \hat\beta_2$  ã‚’å¾—ã‚‹
3.  æ¬¡ã®æœˆ t ã®äºˆæ¸¬å­ã¨ã—ã¦
    
$$
z^*_t=\hat\beta_1 mktnr(t) + \hat\beta_2 P4(t)
$$
4.  æ–‡çŒ®ã¨åŒã˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼ˆ5%/æœˆï¼‰ã§
    $$
    w_t = \frac{z^*_t}{\hat\sigma_{z^*}} \cdot 0.05
    $$
5.  Â±3 ã§ truncationï¼ˆæ–‡çŒ®ã¨åŒã˜ï¼‰

â†’ **Guoâ€“Wachter æˆ¦ç•¥ã‚’ãã®ã¾ã¾ â€œmultivariateâ€ ã«ã—ãŸãƒãƒ¼ã‚¸ãƒ§ãƒ³**

* * *

7\. ã¾ã¨ã‚ï¼ˆnr-only ç‰ˆã¨ nr+P4 ç‰ˆã®é•ã„ï¼‰
==============================

### nr-only

*   ç´”ç²‹ã« _earnings repetition â†’ ç›¸é–¢ãƒã‚°ãƒ¬ã‚¯ãƒˆ_ ã®æ§‹é€ ã‚’æ‰ãˆã‚‹
*   å˜ç´”ã§å¼·ãã€ã‚ãªãŸã® build\_predictor\_z ãŒæ­£ã—ãå®Ÿè£…ã—ã¦ã„ã‚‹

### nr+P4ï¼ˆæ‹¡å¼µï¼‰

*   P4 ãŒã€Œãƒ‹ãƒ¥ãƒ¼ã‚¹ decay èª¤èªã€ã‚’æ‰ãˆã€nr ã®å¼±ã„å±€é¢ã‚’è£œå®Œ
*   æ–‡çŒ® Table 11 ã®çµæœã«æ²¿ã£ãŸã€Œä¸¡è¼ªå‹ã€ãƒ¢ãƒ‡ãƒ«
*   **å®Ÿé‹ç”¨ã§ã®å®‰å®šæ€§ãŒé«˜ã„**

* * *

8\. å¿…è¦ã§ã‚ã‚Œã°ï¼š
===========

*   nr+P4 ã® **ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ç‰ˆ z\*\_t ã® Python ãƒ•ãƒ«ã‚³ãƒ¼ãƒ‰**
*   ä¸Šè¨˜ãƒ¢ãƒ‡ãƒ«ã® **ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ã®ãƒ•ãƒ«å®Ÿè£…**
*   **NR/P4 ãã‚Œãã‚Œã® OOS RÂ² ã®æ¯”è¼ƒã€ä¿‚æ•°ã®æ™‚ç³»åˆ—å¯è¦–åŒ–**
*   **2020å¹´ä»¥é™ã® regime shift ã‚’æ¤œçŸ¥ã™ã‚‹ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ¨å®šæ³•**

ã‚‚ã™ã¹ã¦æä¾›ã§ãã¾ã™ã€‚

* * *

å¿…è¦ã§ã‚ã‚Œã°ã€ä»Šã®ã‚ãªãŸã®ã‚³ãƒ¼ãƒ‰ã«ã€Œz\*\_t äºˆæ¸¬å­ï¼ˆnr+P4ï¼‰ã€ã‚’è¿½åŠ ã—ãŸå®Œå…¨ç‰ˆã‚’æç¤ºã—ã¾ã™ã‹ï¼Ÿ

## Response:
äº†è§£ã—ã¾ã—ãŸã€‚  
**nr + P4 ã® z\*\_tï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ¨å®šç‰ˆï¼‰ã¨ã€nr ã ã‘ã®æ‰‹æ³•ã‚’åŒã˜ãƒ•ãƒ¬ãƒ¼ãƒ ã§æ¯”è¼ƒã§ãã‚‹ã€Œãƒ•ãƒ«ã‚³ãƒ¼ãƒ‰ã€ã‚’ä¸€ã¤ã«ã¾ã¨ã‚ã¦**ãŠæ¸¡ã—ã—ã¾ã™ã€‚

*   Ken French CSV ã‹ã‚‰èª­ã¿è¾¼ã¿
*   nr(t) / P4(t) ã®æ§‹ç¯‰
*   nr-only ã® z\_t
*   nr+P4 ã® z\*\_tï¼ˆæ¯æœˆ OLS ã§ Î²â‚,Î²â‚‚ ã‚’æ›´æ–°ã™ã‚‹ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ç‰ˆï¼‰
*   ãã‚Œãã‚Œã«ã¤ã„ã¦ timing æˆ¦ç•¥ã‚’èµ°ã‚‰ã›ã‚‹

ã¾ã§ä¸€æ°—é€šã—ã®å½¢ã§ã™ã€‚

* * *

ãƒ•ãƒ«ã‚³ãƒ¼ãƒ‰ä¸€å¼
-------

```python
import pandas as pd
import numpy as np
import math
import matplotlib.pyplot as plt
import statsmodels.api as sm

# ======================================================================
# 1. Ken French å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æœˆæ¬¡éƒ¨åˆ†ã ã‘æŠ½å‡ºï¼ˆã‚ãªãŸã®å…ƒã‚³ãƒ¼ãƒ‰ï¼‰
# ======================================================================

def load_ff_monthly_from_ken_french(csv_path: str) -> pd.DataFrame:
    raw = pd.read_csv(csv_path, skiprows=4)

    num = pd.to_numeric(raw['Unnamed: 0'], errors='coerce')
    mask_monthly = num > 10000
    monthly = raw[mask_monthly].copy()

    monthly = monthly.rename(columns={'Unnamed: 0': 'date'})
    monthly['date'] = pd.to_datetime(monthly['date'].astype(int), format="%Y%m")
    monthly = monthly.set_index('date').sort_index()

    for col in ['Mkt-RF', 'RF']:
        monthly[col] = pd.to_numeric(monthly[col], errors='coerce')

    ff = monthly[['Mkt-RF', 'RF']].copy()
    ff['mkt_excess'] = ff['Mkt-RF'] / 100.0
    ff['rf']         = ff['RF'] / 100.0

    return ff[['mkt_excess', 'rf']].dropna()

# ======================================================================
# 2. æœˆã‚¿ã‚¤ãƒ—åˆ†é¡ï¼ˆã‚ãªãŸã®å…ƒã‚³ãƒ¼ãƒ‰ï¼‰
# ======================================================================

def classify_month_type(index):
    mt = pd.Series(index=index, dtype="object")
    for t in index:
        m = t.month % 3
        if m == 1:
            mt[t] = 'N'   # newsy
        elif m == 2:
            mt[t] = 'R'   # repetitive
        else:
            mt[t] = '3'   # muted
    return mt

# ======================================================================
# 3. nr(t) ã¨ nm(t,j)ã€P4 = ç›´è¿‘4ã¤ã® newsy æœˆå¹³å‡ ã‚’è¿½åŠ 
#    ï¼ˆGuo&Wachter + Guo 2025 æº–æ‹ ï¼‰
# ======================================================================

def add_nr_and_nm4(ff: pd.DataFrame) -> pd.DataFrame:
    """
    ff: load_ff_monthly_from_ken_french ã®å‡ºåŠ›
        å¿…é ˆåˆ—: ['mkt_excess', 'rf']

    è¿½åŠ ã•ã‚Œã‚‹åˆ—:
        - 'month_type' : 'N', 'R', '3'
        - 'In_t'       : ãã®æœˆãŒ newsy (N) ãªã‚‰ 1, ãã‚Œä»¥å¤– 0
        - 'nr_date'    : nr(t) ã«å¯¾å¿œã™ã‚‹æ—¥ä»˜
        - 'mkt_nr'     : mkt_excess[nr(t)]
        - 'mkt_nm1'..'mkt_nm4' : ç›´è¿‘ j ç•ªç›®ã® newsy æœˆã®ãƒªã‚¿ãƒ¼ãƒ³
        - 'mkt_nm4_avg': ç›´è¿‘4ã¤ã® newsy æœˆã®å¹³å‡ (Guo 2025 ã® P4_j mktnm(t,j))
    """
    df = ff.copy()
    df["month_type"] = classify_month_type(df.index)
    df["In_t"] = (df["month_type"] == "N").astype(int)

    dates = list(df.index)
    mt = df["month_type"].values
    mkt = df["mkt_excess"].values

    nr_dates = []
    mkt_nr_list = []

    # nm(t,j) ç”¨ã«ã€Œã“ã‚Œã¾ã§å‡ºã¦ããŸ newsy æœˆã® indexã€ã‚’è“„ç©
    past_newsy_indices = []

    mkt_nm1 = []
    mkt_nm2 = []
    mkt_nm3 = []
    mkt_nm4 = []

    for i, t in enumerate(dates):
        # ---- nr(t): t ã‚ˆã‚Šå‰ã§æœ€ã‚‚è¿‘ã„ N or R ----
        nr_idx = None
        j = i - 1
        while j >= 0:
            if mt[j] in ("N", "R"):
                nr_idx = j
                break
            j -= 1
        if nr_idx is None:
            nr_dates.append(None)
            mkt_nr_list.append(np.nan)
        else:
            nr_dates.append(dates[nr_idx])
            mkt_nr_list.append(mkt[nr_idx])

        # ---- newsy æœˆã®å±¥æ­´æ›´æ–° ----
        if mt[i] == "N":
            past_newsy_indices.append(i)

        # ---- nm(t,j): ç›´è¿‘ newsy æœˆãŸã¡ ----
        candidate_newsy = [k for k in past_newsy_indices if k < i]
        candidate_newsy_sorted = sorted(candidate_newsy, reverse=True)

        vals = []
        for jj in range(4):
            if jj < len(candidate_newsy_sorted):
                vals.append(mkt[candidate_newsy_sorted[jj]])
            else:
                vals.append(np.nan)

        mkt_nm1.append(vals[0])
        mkt_nm2.append(vals[1])
        mkt_nm3.append(vals[2])
        mkt_nm4.append(vals[3])

    df["nr_date"] = nr_dates
    df["mkt_nr"] = mkt_nr_list
    df["mkt_nm1"] = mkt_nm1
    df["mkt_nm2"] = mkt_nm2
    df["mkt_nm3"] = mkt_nm3
    df["mkt_nm4"] = mkt_nm4

    # ç›´è¿‘4ã¤ã® newsy æœˆã®å¹³å‡ï¼ˆ4ã¤æƒã£ã¦ã„ãªã„å ´åˆã¯ NaNï¼‰
    df["mkt_nm4_avg"] = df[["mkt_nm1", "mkt_nm2", "mkt_nm3", "mkt_nm4"]].mean(axis=1)

    return df

# ======================================================================
# 4. nr-only ç‰ˆã® z_tï¼ˆå¹³å‡ã‚¿ã‚¤ãƒŸãƒ³ã‚°ä¿®æ­£æ¸ˆï¼‰ ï¼ Guo&Wachter ã®åŸºæœ¬å½¢
# ======================================================================

def build_predictor_z_nr_only(ff: pd.DataFrame) -> pd.DataFrame:
    """
    Guo & Wachter (2025) ã® nr(t) æ§‹é€ ã‚’ã€
    ã‚ãªãŸã®å…ƒã‚³ãƒ¼ãƒ‰ã«è¿‘ã„å½¢ã§å®Ÿè£…ã—ãŸ nr-only ç‰ˆ z_tã€‚

    - R æœˆ:  z_t = mkt_{t-1} - mean(ã€œt-1)
    - N æœˆ:  z_t = -(mkt_{ç›´è¿‘R} - mean(ã€œt-1))
    - 3 æœˆ:  z_t = 0
    """
    df = ff.copy()
    df["month_type"] = classify_month_type(df.index)

    df["mkt_lag"]      = df["mkt_excess"].shift(1)
    df["mkt_mean_lag"] = df["mkt_excess"].expanding().mean().shift(1)

    df = df.dropna()

    z = []
    last_R_ret = None  # ç›´è¿‘ã® R æœˆã® mkt_excess

    for t, row in df.iterrows():
        mt = row["month_type"]
        mean_t_minus1 = row["mkt_mean_lag"]

        if mt == "R":
            # R æœˆ: ç›´å‰ã® N æœˆã®ãƒªã‚¿ãƒ¼ãƒ³ã§é †å¼µã‚Š
            diff = row["mkt_lag"] - mean_t_minus1
            z_t = diff
            last_R_ret = row["mkt_excess"]  # æ¬¡ã® N ã®ãŸã‚ã«è¨˜æ†¶

        elif mt == "N":
            # N æœˆ: ç›´è¿‘ R æœˆã«å¯¾ã—ã¦é€†å¼µã‚Š
            if (last_R_ret is not None) and (not math.isnan(mean_t_minus1)):
                diff = last_R_ret - mean_t_minus1
                z_t = -diff
            else:
                z_t = 0.0
        else:
            # 3 ãƒ¶æœˆç›®: ãƒãƒ¼ãƒã‚¸
            z_t = 0.0

        z.append(z_t)

    df["z_nr_only"] = z
    return df

# ======================================================================
# 5. nr + P4 ã‚’çµ„ã¿åˆã‚ã›ãŸ z*_t ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ç‰ˆ
#    ï¼ˆÎ²1, Î²2 ã‚’æ¯æœˆ t-1 ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã§æ¨å®š â†’ z*_t = Î²1*mkt_nr + Î²2*P4ï¼‰
# ======================================================================

def build_z_star_online(
    ff: pd.DataFrame,
    lookback_years: int = 20,
    min_obs: int = 120,
) -> pd.DataFrame:
    """
    Guo&Wachter + Guo(2025) ã«åŸºã¥ãã€nr(t) ã¨ P4(t) ã‚’çµ„ã¿åˆã‚ã›ãŸ
    ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ç‰ˆ z*_t ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚

    æ‰‹é †:
      1. add_nr_and_nm4(ff) ã§ mkt_nr, P4 = mkt_nm4_avg ã‚’ä½œæˆ
      2. å„æœˆ t ã§ã€t ã‚ˆã‚Šå‰ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆå¿…è¦ãªã‚‰ç›´è¿‘ lookback_years å¹´ã«é™å®šï¼‰ã‚’ä½¿ã£ã¦
         OLS: mkt_s = Î± + Î²1 mkt_nr(s) + Î²2 P4(s) + Îµ_s ã‚’æ¨å®š
      3. å¾—ã‚‰ã‚ŒãŸ Î²1_hat, Î²2_hat ã‹ã‚‰ z*_t = Î²1_hat*mkt_nr(t) + Î²2_hat*P4(t) ã‚’è¨ˆç®—
      4. ã‚µãƒ³ãƒ—ãƒ«ãŒè¶³ã‚Šãªã‘ã‚Œã° z*_t = 0

    æˆ»ã‚Šå€¤:
      df: ff ã« nr, P4, Î²1_hist, Î²2_hist, z_star ã‚’è¿½åŠ ã—ãŸ DataFrame
    """
    df = add_nr_and_nm4(ff)

    # nr ã¨ P4 ãŒåˆ©ç”¨å¯èƒ½ãªã‚µãƒ³ãƒ—ãƒ«ã®ã¿ã‚’ã€Œå€™è£œã€ã¨ã™ã‚‹
    valid_mask = df[["mkt_excess", "mkt_nr", "mkt_nm4_avg"]].notna().all(axis=1)
    dates = df.index

    beta1_hist = []
    beta2_hist = []
    n_obs_hist = []
    z_star = []

    for t in dates:
        # ã¾ã  nr/P4 ãŒå®šç¾©ã•ã‚Œã¦ã„ãªã„åˆæœŸéƒ¨åˆ†
        if not valid_mask.loc[t]:
            beta1_hist.append(np.nan)
            beta2_hist.append(np.nan)
            n_obs_hist.append(0)
            z_star.append(0.0)
            continue

        # t ã‚ˆã‚Šå‰ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ä½¿ç”¨ï¼ˆå°†æ¥æƒ…å ±ãƒªãƒ¼ã‚¯é˜²æ­¢ï¼‰
        past_mask = (dates < t) & valid_mask

        if lookback_years is not None:
            # ç›´è¿‘ lookback_years å¹´ã«é™å®šï¼ˆæ§‹é€ å¤‰åŒ–ã«å¯¾ã—ã¦æ•æ„Ÿã«ï¼‰
            start_date = t - pd.DateOffset(years=lookback_years)
            past_mask &= (dates >= start_date)

        past_df = df.loc[past_mask, ["mkt_excess", "mkt_nr", "mkt_nm4_avg"]].dropna()

        n_obs = len(past_df)
        if n_obs < min_obs:
            # è¦³æ¸¬æ•°ãŒå°‘ãªã™ãã‚‹ã¨ãã¯ Î² ã‚’æ¨å®šã›ãš z*_t=0
            beta1_hist.append(np.nan)
            beta2_hist.append(np.nan)
            n_obs_hist.append(n_obs)
            z_star.append(0.0)
            continue

        # OLS: mkt = Î± + Î²1 mkt_nr + Î²2 P4
        X = sm.add_constant(past_df[["mkt_nr", "mkt_nm4_avg"]])
        y = past_df["mkt_excess"]
        model = sm.OLS(y, X).fit()

        beta1 = model.params["mkt_nr"]
        beta2 = model.params["mkt_nm4_avg"]

        beta1_hist.append(beta1)
        beta2_hist.append(beta2)
        n_obs_hist.append(n_obs)

        # å½“æœˆ t ã® nr, P4 ã«ä¿‚æ•°ã‚’æ›ã‘ã¦ z*_t ã‚’æ§‹æˆ
        mkt_nr_t = df.at[t, "mkt_nr"]
        P4_t     = df.at[t, "mkt_nm4_avg"]

        if np.isnan(mkt_nr_t) or np.isnan(P4_t):
            z_t = 0.0
        else:
            z_t = beta1 * mkt_nr_t + beta2 * P4_t

        z_star.append(z_t)

    df["beta1_hist"] = beta1_hist
    df["beta2_hist"] = beta2_hist
    df["n_obs_hist"] = n_obs_hist
    df["z_star"]     = z_star

    return df

# ======================================================================
# 6. ã‚¿ã‚¤ãƒŸãƒ³ã‚°æˆ¦ç•¥ï¼ˆã‚ãªãŸã®å…ƒã‚³ãƒ¼ãƒ‰ï¼‰
# ======================================================================

def apply_timing_strategy(df, target_vol=0.05, max_leverage=3.0):
    out = df.copy()
    z = out["z"]

    weights = []
    sig_hist = []
    strat_excess = []
    strat_total = []
    mkt_total = []

    for i, t in enumerate(out.index):
        if i == 0:
            sigma = np.nan
            w = 0.0
        else:
            sigma = z.iloc[:i].std(ddof=1)
            if (sigma is np.nan) or (sigma == 0):
                w = 0.0
            else:
                w = z.iloc[i] * target_vol / sigma
                w = float(np.clip(w, -max_leverage, max_leverage))

        weights.append(w)
        sig_hist.append(sigma)

        mkt = out.at[t, "mkt_excess"]
        rf  = out.at[t, "rf"]
        se  = w * mkt
        strat_excess.append(se)
        strat_total.append(rf + se)
        mkt_total.append(rf + mkt)

    out["w"]            = weights
    out["sigma_z_hist"] = sig_hist
    out["strat_excess"] = strat_excess
    out["strat_total"]  = strat_total
    out["mkt_total"]    = mkt_total

    return out

# ======================================================================
# 7. ã‚°ãƒ©ãƒ•æç”»ï¼ˆã‚ãªãŸã®å…ƒã‚³ãƒ¼ãƒ‰ã‚’è»½ãæ”¹å¤‰ï¼‰
# ======================================================================

def plot_results(df, title_suffix=""):
    strat_wealth = (1 + df["strat_excess"]).cumprod()
    mkt_wealth   = (1 + df["mkt_total"]).cumprod()

    plt.figure(figsize=(14, 5))
    plt.plot(strat_wealth, label="Strategy", linewidth=2)
    plt.plot(mkt_wealth,   label="Market",   linewidth=1.5, linestyle="--")
    plt.title(f"Cumulative Return (Strategy vs Market){title_suffix}")
    plt.legend()
    plt.grid(True)
    plt.show()

# ======================================================================
# 8. ãƒ¡ã‚¤ãƒ³ï¼šnr-only vs nr+P4(z*) ã®æ¯”è¼ƒ
# ======================================================================

if __name__ == "__main__":
    csv_path = "F-F_Research_Data_Factors.csv"

    # 1) Ken French èª­ã¿è¾¼ã¿
    ff = load_ff_monthly_from_ken_french(csv_path)

    # --------------------------------------------------------------
    # A. nr-only ç‰ˆï¼ˆGuo&Wachter ã®åŸºæœ¬æˆ¦ç•¥ï¼‰
    # --------------------------------------------------------------
    df_nr_only = build_predictor_z_nr_only(ff)
    df_nr_only_for_strat = df_nr_only.copy()
    df_nr_only_for_strat["z"] = df_nr_only_for_strat["z_nr_only"]

    df_nr_only_strat = apply_timing_strategy(df_nr_only_for_strat)
    plot_results(df_nr_only_strat, title_suffix=" (nr-only)")

    # --------------------------------------------------------------
    # B. nr + P4 ã® 2å¤‰æ•°ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ç‰ˆ z*_t æˆ¦ç•¥
    # --------------------------------------------------------------
    df_zstar = build_z_star_online(
        ff,
        lookback_years=20,  # ç›´è¿‘20å¹´ã§ä¿‚æ•°ã‚’æ¨å®šï¼ˆæ§‹é€ å¤‰åŒ–ã‚’åæ˜ ã—ã‚„ã™ã„ï¼‰
        min_obs=120,        # å°‘ãªãã¨ã‚‚120è¦³æ¸¬ï¼ˆæœˆï¼‰ãªã„ã¨å›å¸°ã‚’å›ã•ãªã„
    )
    df_zstar_for_strat = df_zstar.copy()
    df_zstar_for_strat["z"] = df_zstar_for_strat["z_star"]

    df_zstar_strat = apply_timing_strategy(df_zstar_for_strat)
    plot_results(df_zstar_strat, title_suffix=" (nr + P4 z*_t)")
```

* * *

ä½¿ã„æ–¹ãƒ»è§£é‡ˆã®ãƒã‚¤ãƒ³ãƒˆ
-----------

*   **nr-only**  
    â†’ Guo & Wachter ã®ã€Œç›¸é–¢ãƒã‚°ãƒ¬ã‚¯ãƒˆã€ã ã‘ã‚’ä½¿ã£ãŸæˆ¦ç•¥  
    â†’ ã‚ãªãŸã®å…ƒã€…ã® z\_t ã«æ¥µã‚ã¦è¿‘ã„å‹•ã
*   **nr+P4ï¼ˆz\*\_tï¼‰**  
    â†’ Guo 2025 ã®ã€Œãƒ‹ãƒ¥ãƒ¼ã‚¹å¹³å‡ P4ã€ã¨ã® 2 å¤‰æ•°å›å¸°ã‚’  
    **æ¯æœˆ tâˆ’1 ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã§å†æ¨å®š**ã—ã€  
    ãã® Î²â‚(tâˆ’1), Î²â‚‚(tâˆ’1) ã‹ã‚‰ z\*\_t ã‚’ä½œã‚‹ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ç‰ˆ  
    â†’ nr ãŒå¼±ã„å±€é¢ã§ã‚‚ P4 ãŒäºˆæ¸¬åŠ›ã‚’è£œå®Œã™ã‚‹ã®ã§ã€  
    2020 å¹´ä»¥é™ãªã©ã€Œç›¸é–¢ãƒã‚°ãƒ¬ã‚¯ãƒˆã ã‘ã§ã¯å¼±ããªã£ã¦ã„ã‚‹å±€é¢ã€ã§  
    ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„ãŒæœŸå¾…ã•ã‚Œã¾ã™ã€‚

ã“ã®ã‚³ãƒ¼ãƒ‰ã‚’ãã®ã¾ã¾èµ°ã‚‰ã›ã‚Œã°ã€

*   1926â€“2025 å…¨æœŸé–“ã§ã®ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³
*   ã‚µãƒ–ã‚µãƒ³ãƒ—ãƒ«ï¼ˆ2000 å¹´ä»¥é™ã ã‘ã€2020 å¹´ä»¥é™ã ã‘ï¼‰ã§ãƒ•ã‚£ãƒ«ã‚¿ã—ã¦åŒã˜æ¯”è¼ƒ

ãªã©ã‚‚ç°¡å˜ã«ã§ãã¾ã™ï¼ˆ`df.loc["2000-01-01":]` ã§åˆ‡ã‚Œã° OKï¼‰ã€‚

ã‚‚ã—ã€Œ2020 å¹´ä»¥é™ã§ã®ä¸¡æˆ¦ç•¥ã®æ¯”è¼ƒã€ã€ŒÎ²â‚(t), Î²â‚‚(t) ã®æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆã€ãªã©ã‚‚è¦‹ãŸããªã£ãŸã‚‰ã€ãã“ç”¨ã®ã‚³ãƒ¼ãƒ‰ã‚‚è¿½åŠ ã§æ›¸ãã¾ã™ã€‚

## Response:
æ€è€ƒå®Œäº†

ã¾ãšæ›¸èªŒæƒ…å ±ã‹ã‚‰ã¾ã¨ã‚ã¾ã™ã€‚

* * *

1\. æ›¸èªŒæƒ…å ±
--------

*   è«–æ–‡ã‚¿ã‚¤ãƒˆãƒ«ï¼š  
    **â€œEarnings Extrapolation and Predictable Stock Market Returnsâ€**
*   è‘—è€…ï¼š  
    **Hongye Guo**ï¼ˆUniversity of Hong Kongï¼‰[OUP Academic](https://academic.oup.com/rfs/article/38/6/1730/8101501)
*   æ²è¼‰èªŒï¼š  
    **The Review of Financial Studies**, Volume 38, Issue 6, June 2025, pp. 1730â€“1782 [OUP Academic](https://academic.oup.com/rfs/article/38/6/1730/8101501)
*   DOIï¼š  
    **10.1093/rfs/hhaf020** [OUP Academic](https://academic.oup.com/rfs/article/38/6/1730/8101501)

ã‚ãªãŸãŒã€ŒGuo 2025ã€ã¨å‘¼ã‚“ã§ã„ã‚‹æ–‡çŒ®ã¯ã“ã® RFS è«–æ–‡ã§ã™ã€‚

* * *

2\. è«–æ–‡ã®ã‚³ã‚¢çµæœã®è¦ç´„
--------------

### 2.1 è¦‹ã¤ã‹ã£ãŸã€Œæ–°ã—ã„ã€ãƒ‘ã‚¿ãƒ¼ãƒ³

*   \*\*å››åŠæœŸã®ç¬¬1æœˆï¼ˆ1, 4, 7, 10æœˆï¼‰\*\*ã‚’ â€œnewsy monthsâ€ ã¨å®šç¾©  
    â†’ æ±ºç®—ç™ºè¡¨ãŒé›†ä¸­ã™ã‚‹ã€Œã‚¢ãƒ¼ãƒ‹ãƒ³ã‚°ã‚·ãƒ¼ã‚ºãƒ³ã€ã§ã€æ–°ã—ã„æƒ…å ±ãŒå¤§é‡ã«å‡ºã‚‹æœˆã€‚[OUP Academic](https://academic.oup.com/rfs/article/38/6/1730/8101501)
*   æ®‹ã‚Šã®8ã‹æœˆã‚’ â€œnon-newsy monthsâ€ ã¨å®šç¾©ã€‚[OUP Academic](https://academic.oup.com/rfs/article/38/6/1730/8101501)

ã“ã®ã¨ãã€ç±³å›½æ ªå¼å¸‚å ´ã®æœˆæ¬¡è¶…éãƒªã‚¿ãƒ¼ãƒ³ã«ã¤ã„ã¦

*   éå»ã® **newsy æœˆã®ãƒªã‚¿ãƒ¼ãƒ³** ã¯ã€
    *   å°†æ¥ã® **newsy æœˆã®ãƒªã‚¿ãƒ¼ãƒ³ã‚’ã€Œå¼·ãè² ã«ã€äºˆæ¸¬**ï¼ˆãƒªãƒãƒ¼ã‚µãƒ«ï¼‰
    *   å°†æ¥ã® **non-newsy æœˆã®ãƒªã‚¿ãƒ¼ãƒ³ã‚’ã€Œå¼·ãæ­£ã«ã€äºˆæ¸¬**ï¼ˆã‚³ãƒ³ãƒ†ã‚£ãƒ‹ãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
*   ã—ã‹ã—ã€news yï¼‹non-newsy ã‚’æ··ãœã¦å¹³å‡ã™ã‚‹ã¨ã€  
    â†’ å¾“æ¥çŸ¥ã‚‰ã‚Œã¦ã„ãŸã€Œæœˆæ¬¡ã‚ªãƒ¼ãƒˆã‚³ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ â‰’ 0ã€ã¨ã„ã†äº‹å®ŸãŒå†ç¾ã•ã‚Œã‚‹ [OUP Academic+1](https://academic.oup.com/rfs/article/38/6/1730/8101501)

ã¤ã¾ã‚Š

> ç„¡æ¡ä»¶ã®è‡ªå·±ç›¸é–¢ã¯ã»ã¼ã‚¼ãƒ­ã ãŒã€**æ¡ä»¶ä»˜ãï¼ˆnewsy / non-newsyï¼‰ã«ã¯éå¸¸ã«å¼·ã„äºˆæ¸¬ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒã‚ã‚‹**

ã¨ã„ã†ã®ãŒã“ã®è«–æ–‡ã®æœ€é‡è¦ã®å®Ÿè¨¼çš„ç™ºè¦‹ã§ã™ã€‚

ã•ã‚‰ã«ã€ã“ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯

*   ç±³å›½ã®**æ¥­ç¨®ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ã‚¯ãƒ­ã‚¹ã‚»ã‚¯ã‚·ãƒ§ãƒ³**ã§ã‚‚
*   ä¸»è¦ãª**æµ·å¤–æ ªå¼å¸‚å ´**ã§ã‚‚

åŒæ§˜ã«è¦³æ¸¬ã•ã‚Œã‚‹ã¨å ±å‘Šã•ã‚Œã¦ã„ã¾ã™ã€‚[OUP Academic](https://academic.oup.com/rfs/article/38/6/1730/8101501)

* * *

3\. å®Ÿè¨¼ãƒ‘ãƒ¼ãƒˆï¼šmkt\_nm(t,j) ã¨ P4 å‹ã‚·ã‚°ãƒŠãƒ«
---------------------------------

### 3.1 mkt\_nm(t,j) ã®å®šç¾©

æ–‡çŒ®ã§ã¯ã€ã¾ãš newsy æœˆã ã‘ã‚’æŠœãå‡ºã—ãŸç³»åˆ— {nm(1), nm(2), â€¦} ã‚’ä½œã‚Šã¾ã™ã€‚  
ãã®ã†ãˆã§ï¼Œæœˆ t ã‹ã‚‰é¡ã£ã¦ j ç•ªç›®ã® newsy æœˆã®ãƒªã‚¿ãƒ¼ãƒ³ã‚’

$$
mkt_{nm}(t,j)
$$

ã¨å®šç¾©ã—ã¾ã™ã€‚[OUP Academic](https://academic.oup.com/rfs/article/38/6/1730/8101501)

*   ä¾‹ï¼št ãŒ 2020å¹´5æœˆï¼ˆnon-newsyï¼‰ãªã‚‰ã€  
    j=1 â†’ ç›´è¿‘ã® newsy æœˆï¼ˆ2020å¹´4æœˆï¼‰ã®å¸‚å ´ãƒªã‚¿ãƒ¼ãƒ³  
    j=2 â†’ ãã®å‰ã® newsy æœˆï¼ˆ2020å¹´1æœˆï¼‰  
    j=3 â†’ 2019å¹´10æœˆ  
    j=4 â†’ 2019å¹´7æœˆ

### 3.2 åŸºæœ¬çš„ãªå›å¸°

è«–æ–‡ã§ã¯ã€ã¾ãšã€Œéå»4å›ã® newsy æœˆãƒªã‚¿ãƒ¼ãƒ³ã€ãŒæŒã¤äºˆæ¸¬åŠ›ã‚’

$$
mkt_t=\alpha+\sum_{j=1}^{4}\beta_j\,mkt_{nm}(t,j)+\varepsilon_t
$$

ã¨ã„ã†å›å¸°ã§æ¤œè¨¼ã—ã¾ã™ã€‚[OUP Academic](https://academic.oup.com/rfs/article/38/6/1730/8101501)

*   å…¨ã‚µãƒ³ãƒ—ãƒ«ï¼ˆ1926â€“2021ï¼‰ã® U.S. aggregate marketï¼ˆCRSPï¼‰ã‚’å¯¾è±¡ã€‚
*   newsy æœˆã ã‘ã«å¾“å±å¤‰æ•°ã‚’çµã£ãŸå›å¸°ã€non-newsy æœˆã ã‘ã®å›å¸°ã‚‚å®Ÿæ–½ã—ã€ã€Œä¿‚æ•°ã®ç¬¦å·ã¨å¤§ãã•ãŒ newsy / non-newsy ã§æ˜ç¢ºã«é•ã†ã€ã“ã¨ã‚’ç¢ºèªã€‚

ãã®å¾Œã€ä¿‚æ•°ã‚’ã¾ã¨ã‚ã¦**ã‚¹ã‚«ãƒ©ãƒ¼ã® signal** ã«è½ã¨ã—ãŸå½¢ã‚‚è€ƒãˆã¾ã™ï¼š

$$
mkt_t = \alpha + \beta \cdot \underbrace{\sum_{j=1}^4 mkt_{nm}(t,j)}_{\text{éå»4ã¤ã® newsy æœˆã®åˆè¨ˆ}} + \varepsilon_t
$$

ã¨ã„ã†å½¢ã®å›å¸°ã‚‚è¡Œã„ã€ã“ã“ã§ç”¨ã„ã‚‹

$$
P4(t) \equiv \sum_{j=1}^4 mkt_{nm}(t,j)
$$

ã®ã‚ˆã†ãªã‚·ã‚°ãƒŠãƒ«ã‚’ã€ã‚ãªãŸãŒã‚³ãƒ¼ãƒ‰ä¸­ã§ **P4\_j mktnm(t,j)** ã¨å‘¼ã‚“ã§ã„ã‚‹ã‚‚ã®ã«å¯¾å¿œã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚[OUP Academic](https://academic.oup.com/rfs/article/38/6/1730/8101501)

å®Ÿéš›ã€Table 2 ã‚„ Table 4 ã§ã¯

*   Î£\_j mkt\_nm(t,j) ã®ä¿‚æ•° Î²
*   ã‚ã‚‹ã„ã¯ Î£\_j mkt\_nm(t,j) ã‚’åŠ å·¥ã—ãŸã‚·ã‚°ãƒŠãƒ«ï¼ˆå¹³å‡ãƒ»å¹³å‡ä¹–é›¢ãƒ»ç¬¦å·åè»¢ï¼‰

ãŒã€å¼·ã„äºˆæ¸¬åŠ›ã‚’æŒã¤ã“ã¨ãŒå ±å‘Šã•ã‚Œã¦ã„ã¾ã™ã€‚

### 3.3 ãƒˆãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã«ç”¨ã„ã‚‹ã‚·ã‚°ãƒŠãƒ«ï¼ˆMethods 1â€“7ï¼‰

Out-of-sample äºˆæ¸¬ï¼ˆTable 4ï¼‰ã§ã¯ã€æ¬¡ã®ã‚ˆã†ãªã€Œå˜ä¸€ã‚·ã‚°ãƒŠãƒ«ã€ãŒä½¿ã‚ã‚Œã¾ã™ï¼š[OUP Academic](https://academic.oup.com/rfs/article/38/6/1730/8101501)

*   **Method 1**:  
    å˜ç´”ã«
    $$
     \text{Signal}_t = \sum_{j=1}^4 mkt_{nm}(t,j)
    $$
    ã‚’ä½¿ã„ã€news y / non-newsy ã‚’åˆ†ã‘ã¦ä¿‚æ•°æ¨å®šã€‚
*   **Methods 2â€“7ï¼ˆã‚ãªãŸã® z\_t, z\*\_t ã«å¯¾å¿œï¼‰**:  
    ã‚·ã‚°ãƒŠãƒ«ã¯
    1.  éå»4ã¤ã® newsy æœˆãƒªã‚¿ãƒ¼ãƒ³ã®åˆè¨ˆã‹ã‚‰ã€Œexpanding window ã®å¹³å‡ã€ã‚’å¼•ã
    2.  **å¾“å±å¤‰æ•°ãŒ newsy ã®å ´åˆã«ã¯ç¬¦å·ã‚’åè»¢ã•ã›ã‚‹**
    ã¨ã„ã†åŠ å·¥ã‚’æ–½ã—ãŸã‚‚ã®ã€‚ã“ã‚Œã¯ã€
    *   newsy æœˆã§ã¯ãƒªãƒãƒ¼ã‚µãƒ«ï¼ˆè² ã®äºˆæ¸¬ï¼‰ã€
    *   non-newsy æœˆã§ã¯ã‚³ãƒ³ãƒ†ã‚£ãƒ‹ãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆæ­£ã®äºˆæ¸¬ï¼‰  
        ã«ãªã‚‹ã‚ˆã†ã«ã€ã‚·ã‚°ãƒŠãƒ«ã®å‘ãã‚’çµ±ä¸€ã™ã‚‹ãŸã‚ã§ã™ã€‚[OUP Academic](https://academic.oup.com/rfs/article/38/6/1730/8101501)

ã“ã®ã€Œéå»4ã¤ã® newsy æœˆã®åˆè¨ˆï¼ˆã‚ã‚‹ã„ã¯å¹³å‡ï¼‰ï¼‹å¹³å‡ä¹–é›¢ï¼‹ç¬¦å·åè»¢ã€ã¨ã„ã†æ§‹é€ ãŒã€ã‚ãªãŸãŒä½¿ã£ã¦ã„ã‚‹ **nr + P4 å‹ã® z\*\_t** ã®ç†è«–çš„ãªåŸå‹ã«ãªã£ã¦ã„ã¾ã™ã€‚

### 3.4 OOS RÂ² â‰ˆ 4% ã¨ã„ã†ã‹ãªã‚Šå¤§ããªäºˆæ¸¬åŠ›

è«–æ–‡ã®ãƒ¡ã‚¤ãƒ³çµæœã®ã²ã¨ã¤ã¯ï¼š

*   ä¸Šè¨˜ã‚·ã‚°ãƒŠãƒ«ã‚’ä½¿ã£ãŸ**æœˆæ¬¡å¸‚å ´ãƒªã‚¿ãƒ¼ãƒ³ã® out-of-sample RÂ² ãŒç´„ 4%**
*   ã“ã‚Œã¯ Goyal & Welchï¼ˆ2008ï¼‰ãªã©æ—¢å­˜æ–‡çŒ®ã§å ±å‘Šã•ã‚Œã¦ã„ã‚‹ä»–ã® monthly predictor ã® OOS RÂ²ï¼ˆå¤šãã¯ Â±1% æœªæº€ï¼‰ã¨æ¯”ã¹ã‚‹ã¨**æ¡é•ã„ã«å¤§ãã„** [OUP Academic](https://academic.oup.com/rfs/article/38/6/1730/8101501)

ã“ã®çµæœã‹ã‚‰ Guo ã¯

> ã€Œæœˆæ¬¡ã® U.S. aggregate market ã¯ã»ã¼äºˆæ¸¬ä¸å¯èƒ½ã€ã¨ã„ã†å¾“æ¥ã®ã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹ã¯ä¿®æ­£ã•ã‚Œã‚‹ã¹ã

ã¨ä¸»å¼µã—ã¦ã„ã¾ã™ã€‚[OUP Academic](https://academic.oup.com/rfs/article/38/6/1730/8101501)

ã•ã‚‰ã«ã€æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³ç³»åˆ—ã‚’è¦‹ã‚‹ã¨

*   month-to-month ã§æ¿€ã—ãæŒ¯å‹•ï¼ˆã‚ªãƒ¼ãƒˆã‚³ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã‚€ã—ã‚è² ï¼‰
*   T-bill 1ãƒ¶æœˆåˆ©å›ã‚Šã‚ˆã‚Šä½ã„æœˆãŒç´„ 1/3ã€æœŸå¾…è¶…éãƒªã‚¿ãƒ¼ãƒ³ãŒãƒã‚¤ãƒŠã‚¹ã®æœˆãŒç´„ 1/5
*   ã‚ˆã£ã¦ã€**æ ªå¼ãŒ T-bill ã‚ˆã‚Šå®‰å…¨ï¼ˆæœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³ãŒä½ã„ï¼‰æœˆãŒé »ç¹ã«å­˜åœ¨ã™ã‚‹**

ã¨ã„ã†ã€ãƒªã‚¹ã‚¯ãƒ™ãƒ¼ã‚¹ã®èª¬æ˜ã¨æ•´åˆçš„ã§ãªã„ç‰¹å¾´ã‚‚å¼·èª¿ã•ã‚Œã¦ã„ã¾ã™ã€‚[OUP Academic](https://academic.oup.com/rfs/article/38/6/1730/8101501)

* * *

4\. ç†è«–ãƒ¢ãƒ‡ãƒ«ï¼šEarnings extrapolation ã¨ã€Œéšæ®µå‹ã€æ¸›è¡°
-----------------------------------------

### 4.1 åŸºæœ¬ã®ã‚¢ã‚¤ãƒ‡ã‚¢

ãƒ¢ãƒ‡ãƒ«éƒ¨åˆ†ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯

*   **earnings extrapolationï¼ˆã‚¢ãƒ¼ãƒ‹ãƒ³ã‚°ã®å˜ç´”å¤–æŒ¿ï¼‰**
*   **time-varying decay rateï¼ˆæƒ…å ±ã®æ¸›è¡°é€Ÿåº¦ãŒä¸€å®šã§ãªã„ï¼‰**
*   **step-function patternï¼ˆstep å‹ã®æœ‰åŠ¹æ€§ï¼‰**

ã§ã™ã€‚[OUP Academic](https://academic.oup.com/rfs/article/38/6/1730/8101501)

è¨­å®šã¯ã–ã£ãã‚Šï¼š

1.  æŠ•è³‡å®¶ã¯ã€å°†æ¥ã® aggregate earningsï¼ˆé›†è¨ˆåˆ©ç›Šï¼‰ã‚’äºˆæ¸¬ã™ã‚‹ã¨ãã€
    *   ä¸»ã« **newsy æœˆã®ç™ºè¡¨ earnings** ã«åŸºã¥ã„ã¦äºˆæ¸¬ã‚’è¡Œã†
    *   non-newsy æœˆã®æƒ…å ±ã¯ã‚ã¾ã‚Šä½¿ã‚ãªã„ï¼ˆearnings season ã«æ³¨æ„ãŒé›†ä¸­ã™ã‚‹ï¼‰
2.  **ç¾å®Ÿä¸–ç•Œã§ã¯**
    *   ã‚ã‚‹ newsy æœˆã® earnings ãŒã€æ¬¡ã®æ•°ãƒ¶æœˆã® earnings ã«å¯¾ã—ã¦æŒã¤ã€Œäºˆæ¸¬åŠ›ã€ã¯
        *   non-newsy æœˆã‚’äºˆæ¸¬ã™ã‚‹ã¨ãã«ã¯å¼·ãæ®‹ã‚‹
        *   æ¬¡ã® newsy æœˆã® earnings ã‚’äºˆæ¸¬ã™ã‚‹ã¨ãã«ã€ä¸€æ°—ã«å¼±ããªã‚‹  
            â†’ ã¤ã¾ã‚Šã€ã€Œæƒ…å ±ã®æœ‰åŠ¹æ€§ã¯æ™‚é–“ã¨ã¨ã‚‚ã«å¾ã€…ã«æ¸›è¡°ã™ã‚‹ã€ã®ã§ã¯ãªãã€  
            **newsy æœˆã®ã¨ã“ã‚ã§éšæ®µçŠ¶ã« drop ã™ã‚‹**ï¼ˆstep functionï¼‰[OUP Academic](https://academic.oup.com/rfs/article/38/6/1730/8101501)
3.  ã—ã‹ã—æŠ•è³‡å®¶ã¯ã€ã“ã®æ¸›è¡°ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’èª¤èªã—ã€
    *   **å¸¸ã«ä¸€å®šé€Ÿåº¦ã§æ¸›è¡°ã™ã‚‹ã¨ä»®å®š**ã—ã¦ extrapolation ã—ã¦ã—ã¾ã†

### 4.2 ãã“ã‹ã‚‰ç”Ÿã˜ã‚‹ mispricing ã®æ–¹å‘

ã“ã®èª¤èªã‹ã‚‰ã€æ¬¡ã®ã‚ˆã†ãªäºˆæ¸¬èª¤å·®ãŒç™ºç”Ÿã—ã¾ã™ï¼š[OUP Academic](https://academic.oup.com/rfs/article/38/6/1730/8101501)

*   good newsy æœˆï¼ˆé«˜ã„ earnings, é«˜ã„ stock returnï¼‰ãŒã‚ã£ãŸã¨ã
    *   å°†æ¥ **newsy æœˆã® earnings** ã«å¯¾ã—ã¦ã¯ã€  
        æœ¬å½“ã¯æƒ…å ±ã®æœ‰åŠ¹æ€§ãŒå¤§ããè½ã¡ã‚‹ã®ã«ã€æŠ•è³‡å®¶ã¯ãã‚Œã‚’ç†è§£ã—ã¦ã„ãªã„  
        â†’ **å°†æ¥ã® newsy earnings ã‚’éå¤§ã«äºˆæ¸¬ï¼ˆoverreactionï¼‰**  
        â†’ ã‚¢ãƒŠã‚¦ãƒ³ã‚¹æ™‚ã«ã¯å¤±æœ›ãŒç”Ÿã˜ã¦**ãƒªã‚¿ãƒ¼ãƒ³ãƒªãƒãƒ¼ã‚µãƒ«ï¼ˆè² ã®äºˆæ¸¬ï¼‰**
    *   å°†æ¥ **non-newsy æœˆã® earnings** ã«å¯¾ã—ã¦ã¯ã€  
        æƒ…å ±ã®æœ‰åŠ¹æ€§ãŒé«˜ãç¶­æŒã•ã‚Œã‚‹ã®ã«ã€æŠ•è³‡å®¶ã¯æ¸›è¡°ã™ã‚‹ã¨è€ƒãˆã¦ã—ã¾ã†  
        â†’ **å°†æ¥ã® non-newsy earnings ã‚’éå°ã«äºˆæ¸¬ï¼ˆunderreactionï¼‰**  
        â†’ å¾Œã‹ã‚‰æƒ…å ±ãŒç¹”ã‚Šè¾¼ã¾ã‚Œ**ãƒªã‚¿ãƒ¼ãƒ³ã‚³ãƒ³ãƒ†ã‚£ãƒ‹ãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆæ­£ã®äºˆæ¸¬ï¼‰**

ã“ã‚ŒãŒ

> ã€Œnewsy æœˆã®ãƒªã‚¿ãƒ¼ãƒ³ã¯å°†æ¥ newsy æœˆãƒªã‚¿ãƒ¼ãƒ³ã®è² ã®äºˆæ¸¬å­ãƒ»non-newsy æœˆãƒªã‚¿ãƒ¼ãƒ³ã®æ­£ã®äºˆæ¸¬å­ã«ãªã‚‹ã€

ã¨ã„ã†å®Ÿè¨¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ä¸€è‡´ã—ã¾ã™ã€‚[OUP Academic](https://academic.oup.com/rfs/article/38/6/1730/8101501)

* * *

5\. ã‚µãƒ¼ãƒ™ã‚¤ãƒ»ã‚¢ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã§ã®æ¤œè¨¼
---------------------

Guo ã¯å¸‚å ´ãƒªã‚¿ãƒ¼ãƒ³ã ã‘ã§ãªãã€

*   ã‚¢ãƒŠãƒªã‚¹ãƒˆ/æŠ•è³‡å®¶ã® **earnings expectation**ï¼ˆEPS äºˆæƒ³ï¼‰
*   çµæœã¨ã—ã¦ã® **earnings surprise**

ã‚’ç”¨ã„ã¦ã€ã€Œextrapolation ãƒŸã‚¹ã€ãŒæœ¬å½“ã«èµ·ãã¦ã„ã‚‹ã‹ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚[OUP Academic](https://academic.oup.com/rfs/article/38/6/1730/8101501)

### 5.1 aggregate earnings surprises

ä»£è¡¨çš„ãªå›å¸°ã¯

$$
\text{AggSurprise}_t = \alpha + \beta_1 \sum_{j=1}^4 \text{AggSurprise}_{nm(t,j)} + \beta_2 \Big( \sum_{j=1}^4 \text{AggSurprise}_{nm(t,j)} \times I_t^{nm} \Big) + \gamma I_t^{nm} + \epsilon_t
$$

ã®ã‚ˆã†ãªå½¢ã§ã€

*   newsy æœˆ / non-newsy æœˆã§ã€Œéå»ã®ã‚µãƒ—ãƒ©ã‚¤ã‚ºã®åŠ¹ãæ–¹ï¼ˆÎ²ï¼‰ã€ãŒé•ã†ã‹ã‚’æ¤œè¨¼ã€‚
*   çµæœã¯ã€**newsy æœˆã§ã¯éå»ã‚µãƒ—ãƒ©ã‚¤ã‚ºã¸ã®åå¿œãŒã‚ˆã‚Š â€œoverreaction æ°—å‘³â€**ã€  
    **non-newsy æœˆã§ã¯ã‚ˆã‚Š â€œunderreaction æ°—å‘³â€** ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚[OUP Academic](https://academic.oup.com/rfs/article/38/6/1730/8101501)

### 5.2 revision ãƒ‡ãƒ¼ã‚¿

ã•ã‚‰ã«ã€ã‚¢ãƒŠãƒªã‚¹ãƒˆã® earnings forecast revisionï¼ˆIBES ç³»ï¼‰ã‚’ç”¨ã„ã¦ã€

*   äºˆæƒ³ã®ä¿®æ­£ãŒ newsy vs non-newsy ã§ã©ã†é•ã†ã‹
*   ã©ã¡ã‚‰ã§ over / under extrapolation ãŒå¼·ã„ã‹

ã‚’ç¢ºèªã—ã€ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã¨æ•´åˆçš„ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚[OUP Academic](https://academic.oup.com/rfs/article/38/6/1730/8101501)

* * *

6\. ã‚¯ãƒ­ã‚¹ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¨æµ·å¤–å¸‚å ´
-----------------

### 6.1 æ¥­ç¨®ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ 

Moskowitz & Grinblatt (1999) å‹ã® industry momentum ã« newsy / non-newsy ã®åŒºåˆ¥ã‚’å°å…¥ã™ã‚‹ã¨ï¼š[OUP Academic](https://academic.oup.com/rfs/article/38/6/1730/8101501)

*   å¹³å‡çš„ã«ã¯æ¥­ç¨®ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ã¯å¼·ã„ãŒã€
    *   **non-newsy æœˆã«é›†ä¸­**ï¼ˆã‚³ãƒ³ãƒ†ã‚£ãƒ‹ãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ãŒå¼·ã„ï¼‰
    *   **newsy æœˆã§ã¯ã»ã¼æ¶ˆãˆã‚‹**ï¼ˆãƒªãƒãƒ¼ã‚µãƒ«æˆåˆ†ãŒå¼·ãæ‰“ã¡æ¶ˆã™ï¼‰

ã¨ã„ã†çµæœãŒå¾—ã‚‰ã‚Œã‚‹ã€‚

### 6.2 æµ·å¤–å¸‚å ´

åŒæ§˜ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒ

*   ä¸»è¦æµ·å¤–æ ªå¼å¸‚å ´ã® aggregate index
*   å„å›½ã®æ¥­ç¨®ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª

ã§ã‚‚è¦³æ¸¬ã•ã‚Œã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã€ã€Œç±³å›½å›ºæœ‰ã®ç¾è±¡ã§ã¯ãªã„ã€ã¨ä¸»å¼µã—ã¦ã„ã¾ã™ã€‚[OUP Academic](https://academic.oup.com/rfs/article/38/6/1730/8101501)

* * *

7\. ãƒªã‚¹ã‚¯ãƒ™ãƒ¼ã‚¹èª¬æ˜ã®å›°é›£æ€§ã¨ç†è«–çš„å«æ„
----------------------

Guo ã¯ã€ã“ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’**æ¨™æº–çš„ãªãƒªã‚¹ã‚¯ãƒ—ãƒ¬ãƒŸã‚¢ãƒ å¤‰å‹•ãƒ¢ãƒ‡ãƒ«**ã§èª¬æ˜ã™ã‚‹ã®ã¯å›°é›£ã ã¨å¼·èª¿ã—ã¾ã™ã€‚ä¸»ãªç†ç”±ã¯ï¼š[OUP Academic+1](https://academic.oup.com/rfs/article/38/6/1730/8101501)

1.  æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³ãŒæœˆæ¬¡ã§å¤§ããæŒ¯å‹•ã™ã‚‹ï¼ˆã‚ªãƒ¼ãƒˆã‚³ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒè² ï¼‰ã€‚
2.  æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³ãŒ T-bill ã‚’1/3ã®æœˆã§ä¸‹å›ã‚Šã€1/5ã®æœˆã§ã¯æœŸå¾…è¶…éãƒªã‚¿ãƒ¼ãƒ³ãŒãƒã‚¤ãƒŠã‚¹ã€‚
3.  ã‚‚ã—ãƒªã‚¹ã‚¯ãƒ¢ãƒ‡ãƒ«ã§èª¬æ˜ã™ã‚‹ãªã‚‰ã€
    *   good newsy å¾Œã¯ã€å°†æ¥ã® newsy æœˆãŒã€Œå®‰å…¨ã€ã€non-newsy æœˆãŒã€Œå±é™ºã€ã«ãªã‚‰ãªã‘ã‚Œã°ãªã‚‰ãªã„ãŒã€  
        ãã†ã—ãŸãƒªã‚¹ã‚¯æ§‹é€ ã‚’è‡ªç„¶ã«ç”Ÿã¿å‡ºã™ãƒã‚¯ãƒ­ãƒ¢ãƒ‡ãƒ«ã¯ã‹ãªã‚Šç‰¹æ®Šã«ãªã‚‹ã€‚

ãã®ãŸã‚ã€Guo ã¯

> ã“ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ **earnings extrapolation ã¨ã„ã†è¡Œå‹•ãƒã‚¤ã‚¢ã‚¹** ãŒæœ€ã‚‚ç´ ç›´ãªèª¬æ˜ã§ã‚ã‚Šã€  
> æ ªå¼å¸‚å ´ã®ã€Œäºˆæ¸¬å¯èƒ½æ€§ã€ã¨ã€ŒåŠ¹ç‡æ€§ã€ã«é–¢ã™ã‚‹å¾“æ¥ã®å‰æã‚’è¦‹ç›´ã™å¿…è¦ãŒã‚ã‚‹

ã¨çµè«–ã¥ã‘ã¦ã„ã¾ã™ã€‚[OUP Academic+1](https://academic.oup.com/rfs/article/38/6/1730/8101501)

* * *

8\. ã‚ãªãŸã®å®Ÿè£…ã¨ã®é–¢ä¿‚ï¼ˆnr, P4\_j mktnm, z\*\_tï¼‰
---------------------------------------

ã‚ãªãŸãŒå®Ÿè£…ã—ã¦ã„ã‚‹

*   **nr(t)**ï¼šnewsyâ†’repetitive, repetitiveâ†’newsy ã®ã€Œç¶™ç¶šï¼‹åè»¢ã€æ§‹é€ 
*   **P4\_j mktnm(t,j)**ï¼šéå»4ã¤ã® newsy æœˆãƒªã‚¿ãƒ¼ãƒ³ã®åˆè¨ˆï¼ˆã‚ã‚‹ã„ã¯å¹³å‡ï¼‰
*   **z\*\_t**ï¼šnr + P4 ã‚’ç·šå½¢çµåˆã—ãŸã‚ªãƒ³ãƒ©ã‚¤ãƒ³äºˆæ¸¬å­

ã¯ã€ **ã™ã¹ã¦ã“ã® Guo (2025) ã®ã‚·ã‚°ãƒŠãƒ«è¨­è¨ˆã¨ä¿‚æ•°æ¨å®šæ‰‹é †ï¼ˆMethods 1â€“7ï¼‰ã‚’ã€  
é‹ç”¨ã«ä½¿ã„ã‚„ã™ã„å½¢ã«è½ã¨ã—è¾¼ã‚“ã ã‚‚ã®** ã¨ç†è§£ã—ã¦ã‚ˆã„ã§ã™ã€‚

ç‰¹ã«

*    $mkt_{nm}(t,j)$ 
*    $\sum_{j=1}^4 mkt_{nm}(t,j)$ ï¼ˆP4 å‹ï¼‰
*   expanding mean ã‚’å¼•ã„ã¦ã€newsy æœˆã§ç¬¦å·ã‚’åè»¢ã•ã›ã‚‹ã‚·ã‚°ãƒŠãƒ«

ã¯ã€ãã®ã¾ã¾ã‚ãªãŸã®ã‚³ãƒ¼ãƒ‰å†…ã®

*   `mkt_nm(t,j)`
*   `nm4` / `P4`
*   `nr` + `P4` ã‚’çµ„ã¿åˆã‚ã›ãŸ `z*_t`

ã¨ 1 å¯¾ 1 å¯¾å¿œã—ã¾ã™ã€‚

* * *

ã‚‚ã—æ¬¡ã®ã‚ˆã†ãªç‚¹ã‚’ã•ã‚‰ã«è©°ã‚ãŸã„å ´åˆã¯ã€ãã“ã ã‘åˆ‡ã‚Šå‡ºã—ã¦æ·±æ˜ã‚Šã‚‚å¯èƒ½ã§ã™ï¼š

*   Table 4ï¼ˆMethods 1â€“7ï¼‰ã®ãã‚Œãã‚Œã®å®šç¾©ã¨ã€Python å®Ÿè£…ã¸ã®å®Œå…¨ãƒãƒƒãƒ”ãƒ³ã‚°
*   ä¿‚æ•°æ¨å®šã®å®Ÿå‹™çš„ç´°éƒ¨ï¼ˆexpanding / rollingã€ã‚µãƒ³ãƒ—ãƒ«åˆ†å‰²ã®ä»•æ–¹ã€constraint ã®æ‰±ã„ï¼‰
*   Earnings extrapolation ãƒ¢ãƒ‡ãƒ«ã®æ•°å¼ãƒ¬ãƒ™ãƒ«ã§ã®å®Œå…¨ãªå°å‡º
*   ã‚ãªãŸã® `z_t`, `z*_t` å®Ÿè£…ãŒ Table 4 ã®ã©ã® Method ã«æœ€ã‚‚è¿‘ã„ã‹ã®ãƒãƒƒãƒ”ãƒ³ã‚°

ã©ã“ã‹ã‚‰æ˜ã‚Šä¸‹ã’ãŸã„ã‹æŒ‡å®šã—ã¦ã„ãŸã ã‘ã‚Œã°ã€ãã“ã‚’æ•°å¼ï¼‹ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«ã¾ã§è½ã¨ã—è¾¼ã¿ã¾ã™ã€‚

## Response:
æ€è€ƒå®Œäº†

æ€è€ƒå®Œäº†

æ€è€ƒæ™‚é–“: 2m 34s

ã§ã¯é †ç•ªã«æ•´ç†ã—ã¾ã™ã€‚

1.  Guo (2025) Table 4 ã® Methods 0ã€œ7 ã®å®šç¾©ã¨ Python ã¸ã®ãƒãƒƒãƒ”ãƒ³ã‚°
2.  ä¿‚æ•°æ¨å®šï¼ˆexpanding / rolling, ã‚µãƒ³ãƒ—ãƒ«åˆ†å‰², constraintï¼‰ã®å®Ÿå‹™çš„ãƒ‡ã‚£ãƒ†ãƒ¼ãƒ«
3.  Earnings extrapolation ãƒ¢ãƒ‡ãƒ«ã®æ•°å¼ãƒ¬ãƒ™ãƒ«ã§ã®å°å‡ºã‚¤ãƒ¡ãƒ¼ã‚¸
4.  ã‚ãªãŸã® `z_t` / `z*_t` å®Ÿè£…ã¨ Table 4 ã®ã©ã® Method ãŒä¸€ç•ªè¿‘ã„ã‹

å¿…è¦ãªã¨ã“ã‚ã¯ RFS è«–æ–‡æœ¬æ–‡ã¨ãƒ¯ãƒ¼ã‚­ãƒ³ã‚°ãƒšãƒ¼ãƒ‘ãƒ¼ç‰ˆã‹ã‚‰ç¢ºèªã—ã¦ã„ã¾ã™ã€‚[OUP Academic+2Finance Department+2](https://academic.oup.com/rfs/article/38/6/1730/8101501?utm_source=chatgpt.com)

* * *

1\. Table 4ï¼ˆMethods 0ã€œ7ï¼‰ã®å®šç¾©ã¨ Python å®Ÿè£…ã¸ã®å¯¾å¿œ
------------------------------------------

### 1.0 å…±é€šã®å‰æ

*   ä¾å­˜å¤‰æ•°ï¼šç±³å›½æ ªå¼å¸‚å ´ã®æœˆæ¬¡è¶…éãƒªã‚¿ãƒ¼ãƒ³  $r_t$ ï¼ˆCRSP value-weighted minus T-billï¼‰ã€‚[OUP Academic](https://academic.oup.com/rfs/article/38/6/1730/8101501?utm_source=chatgpt.com)
*   ã€Œnewsy monthã€ï¼å››åŠæœŸç¬¬1æœˆï¼ˆ1,4,7,10æœˆãªã©ï¼‰ã€ãã‚Œä»¥å¤–ãŒ non-newsyã€‚
*    $mkt_{nm}(t,j)$ ï¼šæœˆ  $t$  ã‹ã‚‰é¡ã£ã¦ **j ç•ªç›®ã® newsy æœˆã®å¸‚å ´è¶…éãƒªã‚¿ãƒ¼ãƒ³**ã€‚[Finance Department](https://fnce.wharton.upenn.edu/wp-content/uploads/2022/07/Paper4_Guo.pdf?utm_source=chatgpt.com)
*   åŸºæœ¬ã‚·ã‚°ãƒŠãƒ«ï¼ˆrawï¼‰
    $$
    S_t \equiv \sum_{j=1}^4 mkt_{nm}(t,j)
    $$
    éå»4ã¤ã® newsy æœˆãƒªã‚¿ãƒ¼ãƒ³ã®åˆè¨ˆï¼ˆã‚‚ã—ãã¯å¹³å‡ã«æ¯”ä¾‹ï¼‰ã€‚[OUP Academic+1](https://academic.oup.com/rfs/article/38/6/1730/8101501?utm_source=chatgpt.com)
*   OOS  $R^2$  ã®å®šç¾©ï¼š
    $$
    R^2_{\text{OOS}} = 1 - \frac{\sum_{t=1}^{n}(r_t - \hat r_t)^2}{\sum_{t=1}^{n} (r_t - \bar r_t)^2}
    $$
    ã“ã“ã§  $\bar r_t$  ã¯ã€Œãã®æ™‚ç‚¹ã¾ã§ã®å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆexpanding windowï¼‰ã€ã§ã€  
    ã“ã‚Œã‚’ä¸Šå›ã‚ŒãŸã‚‰  $R^2 > 0$ ã€‚[OUP Academic](https://academic.oup.com/rfs/article/38/6/1730/8101501?utm_source=chatgpt.com)

#### Python ã§ã®åŸºæœ¬çš„ãª S\_t ã®æ§‹ç¯‰ã‚¤ãƒ¡ãƒ¼ã‚¸

```python
def build_newsy_signal(mkt_excess: pd.Series, is_newsy: pd.Series) -> pd.Series:
    """
    mkt_excess : æœˆæ¬¡å¸‚å ´è¶…éãƒªã‚¿ãƒ¼ãƒ³ (index=DatetimeIndex)
    is_newsy   : newsy ãƒ€ãƒŸãƒ¼ (True/False)
    æˆ»ã‚Šå€¤     : S_t = éå»4ã¤ã® newsy æœˆãƒªã‚¿ãƒ¼ãƒ³ã®åˆè¨ˆ
    """
    dates = mkt_excess.index
    S = pd.Series(index=dates, dtype=float)

    # éå»ã® newsy æœˆã® index ã‚’é †æ¬¡è“„ç©
    past_newsy_idx = []

    for i, t in enumerate(dates):
        if is_newsy.iloc[i]:
            past_newsy_idx.append(i)

        # t æ™‚ç‚¹ã‹ã‚‰ã¿ã¦ã€Œéå»ã€ã® newsy æœˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        cand = [k for k in past_newsy_idx if k < i]
        cand = sorted(cand, reverse=True)[:4]

        if len(cand) == 0:
            S[t] = np.nan
        else:
            S[t] = mkt_excess.iloc[cand].sum()

    return S
```

* * *

### Method 0ï¼šCampbell & Thompson (2008) å‹ã® valuation benchmark

*   **ã‚·ã‚°ãƒŠãƒ«**ï¼šnewsiness ã«é–¢ä¿‚ãªãã€ä¼çµ±çš„ãªãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»ã‚·ã‚°ãƒŠãƒ«ï¼ˆD/P, E/P, B/Mï¼‰ã€‚[OUP Academic+1](https://academic.oup.com/rfs/article/38/6/1730/8101501?utm_source=chatgpt.com)
*   äºˆæ¸¬å¼ï¼š  
    Campbell & Thompson (2008) ã®ã€Œvaluation + growthã€ä»•æ§˜ã‚’å„æ¯”ç‡ã«å¯¾ã—ã¦æ¨å®šã—ã€  
    ãã® **3 ã¤ã®äºˆæ¸¬ã‚’å¹³å‡ã—ãŸã‚‚ã®**ã‚’ Method 0 ã®äºˆæ¸¬  $\hat r_t^{(0)}$  ã¨ã™ã‚‹ã€‚
*   CT 2008 ã® sign constraintsï¼ˆä¿‚æ•° â‰¥ 0ã€äºˆæ¸¬ãƒªã‚¿ãƒ¼ãƒ³ â‰¥ 0 ç­‰ï¼‰ã‚’ãã®ã¾ã¾æ¡ç”¨ã€‚[OUP Academic](https://academic.oup.com/rfs/article/38/6/1730/8101501?utm_source=chatgpt.com)

Python ã§å®Œå…¨å†ç¾ã—ã‚ˆã†ã¨ã™ã‚‹ã¨ã€D/P, E/P, B/M ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ãªã®ã§ã€ã“ã“ã§ã¯éª¨æ ¼ã ã‘ï¼š

```python
def forecast_method0_ct(dp, ep, bm, r):
    """
    dp, ep, bm : valuation ratios
    r          : market excess return

    ã“ã“ã§ã¯ç–‘ä¼¼ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«ï¼š
      - å„ãƒ¬ã‚·ã‚ªã”ã¨ã« CT(2008) ä»•æ§˜ã§å›å¸°ã—ã€
      - ä¿‚æ•°ã« sign constraint ã‚’èª²ã—ã¦æ¨å®šã€
      - 3ã¤ã®äºˆæ¸¬å€¤ã®å¹³å‡ã‚’ Method 0 forecast ã¨ã™ã‚‹ã€‚
    """
    # TODO: CT(2008) ã® sign constrained regression ã‚’å®Ÿè£…
    pass
```

* * *

### Method 1ï¼šå˜ç´”ãª S\_tï¼ˆsum of 4 newsy returnsï¼‰ã‚’ä½¿ã†

*   **ã‚·ã‚°ãƒŠãƒ«**ï¼š
    $$
    s_t^{(1)} = S_t = \sum_{j=1}^4 mkt_{nm}(t,j)
    $$
*   å›å¸°ã®ä»•æ–¹ï¼š
    *   newsy æœˆã ã‘ã‚’é›†ã‚ã¦
        $$
        r_t = a_N + b_N s_t^{(1)} + \varepsilon_t,\quad t\in \text{newsy}
        $$
    *   non-newsy æœˆã ã‘ã‚’é›†ã‚ã¦
        $$
        r_t = a_{NN} + b_{NN} s_t^{(1)} + \varepsilon_t,\quad t\notin \text{newsy}
        $$
    *   **expanding window OLS**ï¼šæœˆ  $t$  ã®äºˆæ¸¬ã«ã¯å¿…ãš  $t-1$  ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ä½¿ç”¨ã€‚[OUP Academic+1](https://academic.oup.com/rfs/article/38/6/1730/8101501?utm_source=chatgpt.com)
*   äºˆæ¸¬å€¤ï¼ˆä¾‹ï¼šnewsy æœˆã®å ´åˆï¼‰
    $$
    \hat r_t^{(1)} = \hat a_N(t-1) + \hat b_N(t-1) s_t^{(1)}.
    $$

Python ã®æ“¬ä¼¼å®Ÿè£…ï¼š

```python
def forecast_method1(mkt_excess: pd.Series, S: pd.Series, is_newsy: pd.Series,
                     min_obs=60):
    dates = mkt_excess.index
    fcast = pd.Series(index=dates, dtype=float)

    for i, t in enumerate(dates):
        mask_past = (dates < t) & S.notna()
        if mask_past.sum() < min_obs:
            fcast[t] = np.nan
            continue

        if is_newsy.loc[t]:
            # newsy æœˆã®å›å¸°
            past = (mask_past & is_newsy)
        else:
            # non-newsy æœˆã®å›å¸°
            past = (mask_past & ~is_newsy)

        X = sm.add_constant(S.loc[past])
        y = mkt_excess.loc[past]

        model = sm.OLS(y, X).fit()
        a, b = model.params["const"], model.params[S.name]
        fcast[t] = a + b * S.loc[t]

    return fcast
```

* * *

### Methods 2ã€œ4ï¼šç¬¦å·èª¿æ•´ + demeaned ã‚·ã‚°ãƒŠãƒ«

ã¾ãš **å…±é€šã®ã‚·ã‚°ãƒŠãƒ«å®šç¾©**ï¼š[OUP Academic+1](https://academic.oup.com/rfs/article/38/6/1730/8101501?utm_source=chatgpt.com)

1.  éå»4ã¤ã® newsy ãƒªã‚¿ãƒ¼ãƒ³ã®åˆè¨ˆ  $S_t$  ã‚’ä½œã‚‹
2.  ãã® **expanding-window å¹³å‡** ã‚’å·®ã—å¼•ã
    $$
    \tilde S_t = S_t - \bar S_{t-1}, \quad \bar S_{t-1} = \frac{1}{t-1}\sum_{s\le t-1} S_s
    $$
3.  å¾“å±å¤‰æ•°ãŒ **newsy æœˆ** ã®ã¨ãã¯ç¬¦å·ã‚’åè»¢ï¼š
    $$
    s_t^{(*)} = \begin{cases} -\tilde S_t, & t \text{ ãŒ newsy} \\ \tilde S_t, & t \text{ ãŒ non-newsy} \end{cases}
    $$

```python
def build_signed_demeaned_signal(S: pd.Series, is_newsy: pd.Series) -> pd.Series:
    S_mean = S.expanding().mean().shift(1)  # t æ™‚ç‚¹ã§ t-1 ã¾ã§ã®å¹³å‡
    S_dm   = S - S_mean
    s_star = S_dm.copy()
    s_star[is_newsy] = -S_dm[is_newsy]  # newsyæœˆã¯ç¬¦å·åè»¢
    return s_star
```

#### Method 2

*   ã‚·ã‚°ãƒŠãƒ«ï¼šä¸Šã®  $s_t^{(*)}$ 
*   å›å¸°ï¼šMethod 1 åŒæ§˜ã€newsy / non-newsy ã§ã‚µãƒ³ãƒ—ãƒ«ã‚’åˆ†ã‘ã¦ expanding-window OLSã€‚
*   äºˆæ¸¬ï¼š
    $$
    \hat r_t^{(2)} = \begin{cases} \hat a_N(t-1) + \hat b_N(t-1) s_t^{(*)}, & t\text{ newsy} \\ \hat a_{NN}(t-1) + \hat b_{NN}(t-1) s_t^{(*)}, & t\text{ non-newsy} \end{cases}
    $$

Python ã¯ `forecast_method1` ã® `S` ã‚’ `s_star` ã«ç½®ãæ›ãˆã‚‹ã ã‘ã§ã™ã€‚

#### Method 3

*   ã‚·ã‚°ãƒŠãƒ«ã¯ Method 2 ã¨åŒã˜  $s_t^{(*)}$ ã€‚
*   é•ã„ã¯ **å®šæ•°é …ã®æ‰±ã„**ï¼š
    *   å®šæ•°ä¿‚æ•°  $a_N, a_{NN}$  ã‚’ãã®ã¾ã¾ä½¿ã‚ãšã€
    *   ä»£ã‚ã‚Šã«ã€Œ**expanding-window ã®å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³**ã€ã§ç½®ãæ›ãˆã‚‹ã€‚[OUP Academic+1](https://academic.oup.com/rfs/article/38/6/1730/8101501?utm_source=chatgpt.com)

å…·ä½“çš„ã«ã¯ï¼š

$$
\hat r_t^{(3)} = \begin{cases} \bar r_N(t-1) + \hat b_N(t-1)\, s_t^{(*)}, & t\text{ newsy}\\ \bar r_{NN}(t-1) + \hat b_{NN}(t-1)\, s_t^{(*)}, & t\text{ non-newsy} \end{cases}
$$

ã“ã“ã§  $\bar r_N(t-1)$  ã¯ã€Œéå»ã® newsy æœˆã®å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³ã€ã€  
 $\bar r_{NN}(t-1)$  ã¯ã€Œéå»ã® non-newsy æœˆã®å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³ã€ã€‚

```python
def forecast_method3(mkt_excess, s_star, is_newsy, min_obs=60):
    dates = mkt_excess.index
    fcast = pd.Series(index=dates, dtype=float)

    for i, t in enumerate(dates):
        mask_past = (dates < t) & s_star.notna()
        if mask_past.sum() < min_obs:
            fcast[t] = np.nan
            continue

        if is_newsy.loc[t]:
            past = (mask_past & is_newsy)
        else:
            past = (mask_past & ~is_newsy)

        X = sm.add_constant(s_star.loc[past])
        y = mkt_excess.loc[past]
        model = sm.OLS(y, X).fit()
        b = model.params[s_star.name]

        # newsy / non-newsy åˆ¥å¹³å‡ã‚’ intercept ã®ä»£ã‚ã‚Šã«ä½¿ã†
        mu = y.mean()
        fcast[t] = mu + b * s_star.loc[t]

    return fcast
```

#### Method 4

*   ã‚·ã‚°ãƒŠãƒ«ã¯ Method 2 ã¨åŒã˜  $s_t^{(*)}$ ã€‚
*   å®šæ•°é …ã‚’ã€ŒMethod 0 ã®äºˆæ¸¬ã€ã§ç½®ãæ›ãˆã‚‹ï¼š[OUP Academic+1](https://academic.oup.com/rfs/article/38/6/1730/8101501?utm_source=chatgpt.com)
    
$$
\hat r_t^{(4)} = \hat r_t^{(0)} + \hat b_{\text{grp}(t)}(t-1)\,s_t^{(*)},
$$

ã“ã“ã§  $\text{grp}(t)$  ã¯ newsy / non-newsy ã®åŒºåˆ¥ã€‚

ã¤ã¾ã‚Šï¼š

*   ã€Œvaluation-based äºˆæ¸¬ï¼ˆMethod 0ï¼‰ã€ï¼‹ã€Œextrapolation ãƒ™ãƒ¼ã‚¹ã®è¿½åŠ æˆåˆ†ã€ã¨ã„ã†æ§‹é€ ã€‚

Python ã§ã¯ Method 3 ã® `mu` éƒ¨åˆ†ã‚’ `fcast_method0[t]` ã«å¤‰ãˆã‚‹ã ã‘ã§ã™ã€‚

* * *

### Methods 5ã€œ7ï¼šä¿‚æ•°ã‚’ pooled sample ã‹ã‚‰æ¨å®š

Methods 5ã€œ7 ã¯ **Method 2ã€œ4 ã¨ã‚·ã‚°ãƒŠãƒ«ã¯åŒã˜**ã§ã€  
é•ã„ã¯ã€Œä¿‚æ•°ã‚’ newsy/non-newsy åˆ¥ã§ã¯ãªã **å…¨ã‚µãƒ³ãƒ—ãƒ« pooled** ã§æ¨å®šã™ã‚‹ã€ç‚¹ã€‚[OUP Academic+1](https://academic.oup.com/rfs/article/38/6/1730/8101501?utm_source=chatgpt.com)

*   Method 5ï¼šMethod 2 ã® pooled ç‰ˆ
*   Method 6ï¼šMethod 3 ã® pooled ç‰ˆ
*   Method 7ï¼šMethod 4 ã® pooled ç‰ˆ

ä¾‹ï¼šMethod 6 ã®äºˆæ¸¬å¼ã¯

$$
\hat r_t^{(6)} = \bar r(t-1) + \hat b(t-1)\, s_t^{(*)},
$$
*    $\bar r(t-1)$ ï¼šå…¨ã‚µãƒ³ãƒ—ãƒ«ï¼ˆnewsy + non-newsyï¼‰ã® expanding å¹³å‡
*    $\hat b(t-1)$ ï¼šå…¨ã‚µãƒ³ãƒ—ãƒ«ã§å›å¸°ã—ãŸå‚¾ãã€‚

Python çš„ã«ã¯ã€Method 3 ã® `past` ã‚’ `mask_past`ï¼ˆnewsy/non-newsy å…±é€šï¼‰ã«ã™ã‚‹ã ã‘ã§ã™ã€‚

```python
def forecast_method6(mkt_excess, s_star, min_obs=60):
    dates = mkt_excess.index
    fcast = pd.Series(index=dates, dtype=float)

    for i, t in enumerate(dates):
        mask_past = (dates < t) & s_star.notna()
        if mask_past.sum() < min_obs:
            fcast[t] = np.nan
            continue

        X = sm.add_constant(s_star.loc[mask_past])
        y = mkt_excess.loc[mask_past]
        model = sm.OLS(y, X).fit()
        b = model.params[s_star.name]

        mu = y.mean()
        fcast[t] = mu + b * s_star.loc[t]

    return fcast
```

* * *

2\. ä¿‚æ•°æ¨å®šã®å®Ÿå‹™çš„ãƒ‡ã‚£ãƒ†ãƒ¼ãƒ«
-----------------

### 2.1 Expanding window vs Rolling

*   Guo ã¯**expanding window** ã‚’æ˜ç¤ºçš„ã«æ¡ç”¨ã—ã¦ã„ã¾ã™ï¼š  
    ã€Œå„æœˆ t ã«ã¤ã„ã¦ã€tâˆ’1 ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã§ OLS â†’ ä¿‚æ•°ã§ t ã‚’äºˆæ¸¬ã€ã€‚[OUP Academic+1](https://academic.oup.com/rfs/article/38/6/1730/8101501?utm_source=chatgpt.com)
*   Rolling ã«ã—ãªã„ç†ç”±ï¼š
    *   ãƒ¢ãƒ‡ãƒ«ã¯ã€Œé•·æœŸå®‰å®šãªæ§‹é€ ã€ã«åŸºã¥ã„ã¦ã„ã‚‹
    *   ãŸã ã— Table 3/4 ã§ã¯ã‚µãƒ–ã‚µãƒ³ãƒ—ãƒ«ï¼ˆ1926â€“1973, 1974â€“2023 ç­‰ï¼‰ã‚‚åˆ†æã—ã¦æ§‹é€ å¤‰åŒ–ã‚’åˆ¥æ ã§ç¢ºèªã€‚[Finance Department](https://fnce.wharton.upenn.edu/wp-content/uploads/2022/07/Paper4_Guo.pdf)

å®Ÿè£…ä¸Šã¯ã€ã‚ãªãŸãŒä»Šæ›¸ã„ã¦ã„ã‚‹ã€Œfor ãƒ«ãƒ¼ãƒ—ã§ t ã‚’å›ã—ã¦ã€`dates < t` ã§éå»ã‚’åˆ‡ã‚‹ã€ã‚„ã‚Šæ–¹ã§å®Œå…¨ã« OK ã§ã™ã€‚

### 2.2 ã‚µãƒ³ãƒ—ãƒ«åˆ†å‰²ï¼šnewsy vs non-newsy vs pooled

*   Methods 1ã€œ4ï¼š**newsy ã¨ non-newsy ã‚’åˆ¥ã€…ã«å›å¸°**ã€‚
*   Methods 5ã€œ7ï¼š**å…¨ã‚µãƒ³ãƒ—ãƒ« pooled ã§ä¸€ã¤ã®å›å¸°**ã€‚[OUP Academic+1](https://academic.oup.com/rfs/article/38/6/1730/8101501?utm_source=chatgpt.com)

ã“ã®ã€Œåˆ†å‰² or pooledã€ã¯

*   newsy / non-newsy ã§æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³ã®æ°´æº–ã‚’åˆ¥ã«æŒãŸã›ã‚‹ã‹
*   ã‚·ã‚°ãƒŠãƒ«ã®å‚¾ãã ã‘ã‚’ä½¿ã†ã‹

ã®é•ã„ã¨ç†è§£ã§ãã¾ã™ã€‚

### 2.3 constraint ã®æ‰±ã„

*   Method 0 ã®ã¿ã€Campbell & Thompson (2008) å‹ã® sign constraints ã‚’åˆ©ç”¨  
    ï¼ˆä¿‚æ•° â‰¥ 0ã€äºˆæ¸¬ãƒªã‚¿ãƒ¼ãƒ³ã‚’ 0 ã¨ rf ã¨ã®é–“ã« truncate ã™ã‚‹ç­‰ï¼‰ã€‚[OUP Academic](https://academic.oup.com/rfs/article/38/6/1730/8101501?utm_source=chatgpt.com)
*   Methods 1ã€œ7 ã®ã€Œnr / P4 ã‚·ã‚°ãƒŠãƒ«ã«ã‚ˆã‚‹äºˆæ¸¬ã€ã®éƒ¨åˆ†ã«ã¯ã€**ç‰¹åˆ¥ãª sign constraint ã¯èª²ã—ã¦ã„ã¾ã›ã‚“**ã€‚é€šå¸¸ã® OLS ã«ã‚ˆã‚‹ä¿‚æ•°ã‚’ãã®ã¾ã¾ä½¿ã†è¨­è¨ˆã§ã™ã€‚[OUP Academic](https://academic.oup.com/rfs/article/38/6/1730/8101501?utm_source=chatgpt.com)

å®Ÿå‹™ä¸Šã‚ãªãŸã®å®Ÿè£…ã§ã‚‚

*   Method 0 ç›¸å½“ï¼šCT ä»•æ§˜ã‚’ãã®ã¾ã¾æ¨¡å€£ï¼ˆsign constrained regressionï¼‰
*   Methods 1ã€œ7 ç›¸å½“ï¼šæ™®é€šã® `sm.OLS` ã§ã‚ˆã„

ã¨è€ƒãˆã¦å•é¡Œã‚ã‚Šã¾ã›ã‚“ã€‚

### 2.4 OOS ã‚µãƒ³ãƒ—ãƒ«é–‹å§‹æ™‚ç‚¹

è«–æ–‡ã§ã¯ 1926â€“2021 å…¨æœŸã‚’ä½¿ã„ã€OOS RÂ² ã®è¨ˆç®—ã‚‚å…¨æœŸé–“ã§è¡Œã„ã¾ã™ãŒã€  
å®Ÿéš›ã«ã¯

*   æœ€ä½è¦³æ¸¬æ•°ï¼ˆä¾‹ãˆã° 60 ãƒ¶æœˆä»¥ä¸Šï¼‰ã‚’ç¢ºä¿ã—ã¦ã‹ã‚‰ OOS ã‚’é–‹å§‹
*   ãã‚Œä»¥å‰ã¯ forecast ã‚’ NaN ã«ã—ã¦ RÂ² é›†è¨ˆã‹ã‚‰å¤–ã™

ã¨ã„ã†å®Ÿå‹™çš„ãªå–ã‚Šæ‰±ã„ã§ååˆ†ã§ã™ï¼ˆã‚ãªãŸã® `min_obs` å¼•æ•°ã®è€ƒãˆæ–¹ã§è‰¯ã„ï¼‰ã€‚

* * *

3\. Earnings Extrapolation ãƒ¢ãƒ‡ãƒ«ã®æ•°å¼ãƒ¬ãƒ™ãƒ«å°å‡ºï¼ˆéª¨æ ¼ï¼‰
------------------------------------------

ã“ã“ã¯ RFS æœ¬æ–‡ã® Section 5ã€œ6 ã‚’è¸ã¾ãˆãŸã€ŒåŒå€¤ãªç°¡ç´„ãƒ¢ãƒ‡ãƒ«ã€ã§èª¬æ˜ã—ã¾ã™ã€‚[Finance Department](https://fnce.wharton.upenn.edu/wp-content/uploads/2022/07/Paper4_Guo.pdf)

### 3.1 çœŸã®é…å½“ãƒ»ã‚¢ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ—ãƒ­ã‚»ã‚¹

*   æ™‚é–“ã¯æœˆ t=0,1,2,â€¦
*   é…å½“  $D_t$ ã€ãã®å¯¾æ•°  $d_t = \log D_t$ 
*   ã€ŒROE çš„ãª earningsã€
    $$
    \Delta d_t = d_t - b_{t-1},
    $$
    ã“ã“ã§  $b_{t-1}$  ã¯ **æŒ‡æ•°åŠ é‡ç§»å‹•å¹³å‡ï¼ˆEWMAï¼‰** å‹ã® book value proxyï¼š
    $$
    b_{t-1} = (1-\rho)\sum_{i=0}^{\infty}\rho^i d_{t-1-i}
    $$
    â†’  $\Delta d_t$  ã¯ã€Œå½“æœŸ earnings âˆ’ éå»ã®è“„ç© earningsã€ â‰ˆ ROEã€‚[Finance Department](https://fnce.wharton.upenn.edu/wp-content/uploads/2022/07/Paper4_Guo.pdf)

**çœŸã®ãƒ—ãƒ­ã‚»ã‚¹**ã¨ã—ã¦ã€

$$
\Delta d_t = \begin{cases} \mu_N + \phi_N \Delta d_{t-1} + u_t, & t\text{ ãŒ newsy} \\ \mu_{NN} + \phi_{NN} \Delta d_{t-1} + u_t, & t\text{ ãŒ non-newsy} \end{cases}
$$

ã‹ã¤

$$
0 < \phi_N < \phi_{NN} < 1
$$

ã¨ã—ã¾ã™ã€‚

*   newsy æœˆã® earnings ã¯ã€Œéå» earnings ã¨ã®è‡ªå·±ç›¸é–¢ãŒä½ã„ã€
*   non-newsy æœˆã® earnings ã¯ã€Œè‡ªå·±ç›¸é–¢ãŒé«˜ã„ã€

ã¨ã„ã†å®Ÿè¨¼çµæœã‚’åæ˜ ã—ãŸå½¢ã§ã™ã€‚[Finance Department+1](https://fnce.wharton.upenn.edu/wp-content/uploads/2022/07/Paper4_Guo.pdf)

### 3.2 æŠ•è³‡å®¶ã®èª¤ã£ãŸä¿¡å¿µï¼šä»£è¡¨ AR ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ Ï†

æŠ•è³‡å®¶ã¯ã€Œãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã«ã‚ˆã£ã¦è‡ªå·±ç›¸é–¢ãŒå¤‰ã‚ã‚‹ã€ã¨ã„ã†äº‹å®Ÿã‚’ç†è§£ã—ã¦ãŠã‚‰ãšã€  
ç°¡ç•¥åŒ–ã•ã‚ŒãŸ **å˜ä¸€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ Ï†** ãƒ¢ãƒ‡ãƒ«ã‚’ä¿¡ã˜ã¦ã„ã‚‹ã¨ã—ã¾ã™ï¼š

$$
\Delta d_t = \mu + \phi \Delta d_{t-1} + \varepsilon_t
$$
*    $\phi$  ã¯ã€news y ã‚„ non-newsy ã®é•ã„ã‚’å¹³å‡åŒ–ã—ãŸ â€œä»£è¡¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿â€
*   å®Ÿéš›ã®  $\phi_N, \phi_{NN}$  ã¨ã®ä¹–é›¢ãŒ mis-extrapolation ã®åŸå› ã€‚[Finance Department](https://fnce.wharton.upenn.edu/wp-content/uploads/2022/07/Paper4_Guo.pdf)

### 3.3 æ ªä¾¡ã¨æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³

*   æŠ•è³‡å®¶ã¯ **ãƒªã‚¹ã‚¯ä¸­ç«‹**ãƒ»ä¸€å®šã®å‰²å¼•ç‡  $R_f$  ã‚’æŒã¤ã¨ã—ã¾ã™ã€‚[Finance Department](https://fnce.wharton.upenn.edu/wp-content/uploads/2022/07/Paper4_Guo.pdf)
*   ä¾¡æ ¼ã¯å°†æ¥é…å½“ã®å‰²å¼•ç¾åœ¨ä¾¡å€¤ï¼š
    $$
    P_t = \sum_{k=1}^\infty \frac{1}{R_f^k} \mathbb{E}_t[D_{t+k}]
    $$
    â†’ log-linear åŒ–ã™ã‚‹ã¨ Campbellâ€“Shiller å‹ã®è¿‘ä¼¼ã§
    $$
    p_t \approx \kappa_0 + \kappa_1 b_t + \kappa_2 \Delta d_t
    $$
    ã®ã‚ˆã†ãªå½¢ã«ã¾ã¨ã‚ã‚‰ã‚Œã¾ã™ï¼ˆè«–æ–‡ã§ã¯ã‚ˆã‚Šå³å¯†ã«æ•´ç†ï¼‰ã€‚[Finance Department](https://fnce.wharton.upenn.edu/wp-content/uploads/2022/07/Paper4_Guo.pdf)
*   ã‚·ãƒ³ãƒ—ãƒ«ã«ã¯ã€**äºˆæƒ³é…å½“æˆé•·ç‡ã‚’å¤–æŒ¿ã—ãŸã‚‚ã®ãŒä¾¡æ ¼ã«å…¥ã‚‹**ã®ã§ã€  
    æŠ•è³‡å®¶ã®äºˆæƒ³
    $$
    \mathbb{E}_t^{\text{(investor)}}[\Delta d_{t+1}] = \mu + \phi \Delta d_t
    $$
    ãŒä¾¡æ ¼ã«å½±éŸ¿ã—ã€çµæœã¨ã—ã¦äºˆæƒ³ãƒªã‚¿ãƒ¼ãƒ³
    $$
    \mathbb{E}_t^{\text{(investor)}}[R_{t+1}]
    $$
    ã«ã‚‚ä¾å­˜ã—ã¾ã™ã€‚

### 3.4 èª¤ä¿¡å¿µãŒä½œã‚‹äºˆæ¸¬ãƒ‘ã‚¿ãƒ¼ãƒ³

çœŸã®ãƒ—ãƒ­ã‚»ã‚¹ã«å¯¾ã™ã‚‹ 1-step å…ˆäºˆæ¸¬èª¤å·®ã‚’è¨ˆç®—ã™ã‚‹ã¨ï¼š

*   çœŸã® 1-step ahead æœŸå¾…å€¤
    $$
    \mathbb{E}_t^{\text{(true)}}[\Delta d_{t+1}] = \begin{cases} \mu_N + \phi_N \Delta d_t, & t+1\text{ ãŒ newsy}\\ \mu_{NN} + \phi_{NN} \Delta d_t, & t+1\text{ ãŒ non-newsy} \end{cases}
    $$
*   æŠ•è³‡å®¶ã®æœŸå¾…å€¤ï¼ˆèª¤ã£ãŸãƒ¢ãƒ‡ãƒ«ï¼‰
    $$
    \mathbb{E}_t^{\text{(inv)}}[\Delta d_{t+1}] = \mu + \phi \Delta d_t
    $$

ã—ãŸãŒã£ã¦ã€**èª¤å·®**ã¯

$$
\text{Bias}_{t+1} = \mathbb{E}_t^{\text{(inv)}}[\Delta d_{t+1}]- \mathbb{E}_t^{\text{(true)}}[\Delta d_{t+1}] = \begin{cases} (\mu - \mu_N) + (\phi - \phi_N)\Delta d_t, & t+1\text{ newsy}\\ (\mu - \mu_{NN}) + (\phi - \phi_{NN})\Delta d_t, & t+1\text{ non-newsy} \end{cases}
$$

ã“ã“ã§

*   good earnings â†’  $\Delta d_t > 0$  ã®ã¨ã
*   ã‚‚ã—  $\phi$  ãŒã€Œå¹³å‡çš„ã€ï¼ˆ $\phi_N < \phi < \phi_{NN}$ ï¼‰ã ã¨ã™ã‚‹ã¨[Finance Department](https://fnce.wharton.upenn.edu/wp-content/uploads/2022/07/Paper4_Guo.pdf)
    
$$
\phi - \phi_N > 0,\quad\phi - \phi_{NN} < 0
$$
*   **t+1 ãŒ newsy ã®å ´åˆ**ï¼šBias $_{t+1} > 0$  ã¨ãªã‚Šã€
    *   æŠ•è³‡å®¶ã¯ earnings ã‚’ **éå¤§è©•ä¾¡**ï¼ˆoverreactionï¼‰
    *   å®Ÿç¾æ™‚ã«å¤±æœ› â†’ **ãƒªã‚¿ãƒ¼ãƒ³ã®ãƒªãƒãƒ¼ã‚µãƒ«ï¼ˆè² ã®äºˆæ¸¬ï¼‰**
*   **t+1 ãŒ non-newsy ã®å ´åˆ**ï¼šBias $_{t+1} < 0$  ã¨ãªã‚Šã€
    *   æŠ•è³‡å®¶ã¯ earnings ã‚’ **éå°è©•ä¾¡**ï¼ˆunderreactionï¼‰
    *   å¾Œã‹ã‚‰è¿½ã„ä¸Šã’ â†’ **ãƒªã‚¿ãƒ¼ãƒ³ã®ã‚³ãƒ³ãƒ†ã‚£ãƒ‹ãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆæ­£ã®äºˆæ¸¬ï¼‰**

ã“ã® Bias ãŒä¾¡æ ¼ã¨ãƒªã‚¿ãƒ¼ãƒ³ã«åæ˜ ã•ã‚Œã‚‹ã®ã§ã€

*   newsy æœˆã®ãƒªã‚¿ãƒ¼ãƒ³ã¯ã€Œéå»ã® newsy ãƒªã‚¿ãƒ¼ãƒ³ã® **è² ã®äºˆæ¸¬å­**ã€
*   non-newsy æœˆã®ãƒªã‚¿ãƒ¼ãƒ³ã¯ã€Œéå»ã® newsy ãƒªã‚¿ãƒ¼ãƒ³ã® **æ­£ã®äºˆæ¸¬å­**ã€

ã¨ã„ã†ã€å®Ÿè¨¼ã§è¦‹ã¦ã„ã‚‹ç›¸é–¢ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒå°ã‹ã‚Œã¾ã™ã€‚[Finance Department](https://fnce.wharton.upenn.edu/wp-content/uploads/2022/07/Paper4_Guo.pdf)

è«–æ–‡ã§ã¯ã“ã‚Œã‚’ã•ã‚‰ã«ä¸€èˆ¬åŒ–ã—ã€multi-step ahead forecastï¼ˆ6ãƒ¶æœˆå…ˆãªã©ï¼‰ã‚’è€ƒãˆã‚‹ã“ã¨ã§ã€  
ã€Œéå» 4 ã¤ç¨‹åº¦ã® newsy ãƒªã‚¿ãƒ¼ãƒ³ã«ã‚ãŸã£ã¦æœ‰æ„ãªä¿‚æ•°ãŒå‡ºã‚‹ã€ã“ã¨ã‚’å†ç¾ã—ã¦ã„ã¾ã™ã€‚

* * *

4\. ã‚ãªãŸã® `z_t` / `z*_t` ã¨ Table 4 Methods ã¨ã®å¯¾å¿œ
----------------------------------------------

æœ€å¾Œã«ã€ã‚ãªãŸã®å®Ÿè£…ã¨è«–æ–‡ã®æ–¹æ³•ã‚’çµã³ã¤ã‘ã¾ã™ã€‚

### 4.1 ã‚ãªãŸã®å…ƒã® `build_predictor_z`ï¼ˆnr-only ç‰ˆï¼‰

å…ƒã‚³ãƒ¼ãƒ‰ï¼ˆè¦ç´„ï¼‰ï¼š

*   æœˆã‚¿ã‚¤ãƒ—ï¼š N, R, 3
*   `mkt_mean_lag`ï¼šå¸‚å ´è¶…éãƒªã‚¿ãƒ¼ãƒ³ã® expanding å¹³å‡ï¼ˆtâˆ’1ã¾ã§ï¼‰
*   `base = mkt_lag - mkt_mean_lag`
*   ãƒ«ãƒ¼ãƒ«ï¼š
    *   **R æœˆ**ï¼š`z = base`ï¼ˆ1ãƒ¶æœˆå‰ã®ãƒªã‚¿ãƒ¼ãƒ³ âˆ’ å¹³å‡ï¼‰
    *   **N æœˆ**ï¼šç›´è¿‘ã® R æœˆã® `base` ã®ç¬¦å·ã‚’åè»¢ã—ã¦ä½¿ç”¨
    *   **3 æœˆ**ï¼š0  
        ï¼ˆï¼‹å®Ÿè£…ã®ç´°éƒ¨ã¯ã“ã‚Œã«æº–æ‹ ï¼‰

ã“ã‚Œã¯

*   Guo 2025 ã®ã€Œéå»4ã¤ã® newsy ãƒªã‚¿ãƒ¼ãƒ³åˆè¨ˆã€ã‚’ **ã€Œéå»1ã¤ã€ã«ç¸®ã‚ãŸãƒãƒ¼ã‚¸ãƒ§ãƒ³**
*   ã•ã‚‰ã«ã€ã€Œdemeanï¼ˆå¹³å‡ã‚’å¼•ãï¼‰ã€ï¼‹ã€Œnewsy æœˆã§ç¬¦å·åè»¢ã€ã¨ã„ã†æ§‹é€ ã¯  
    Methods 2ã€œ7 ã®å…±é€šã‚·ã‚°ãƒŠãƒ«è¨­è¨ˆã¨æœ¬è³ªçš„ã«åŒã˜ã§ã™ã€‚[OUP Academic+1](https://academic.oup.com/rfs/article/38/6/1730/8101501?utm_source=chatgpt.com)

ãŸã ã—é•ã„ã¯ï¼š

*   Guoï¼š
    *   ã‚·ã‚°ãƒŠãƒ«  $s_t$  â†’ **OLS ã§  $\hat r_t$  ã‚’æ¨å®š**
    *   ãã®  $\hat r_t$  ã‚’ä½¿ã£ã¦æˆ¦ç•¥ã‚’çµ„ã‚€ï¼ˆåˆ¥é€”ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼‰
*   ã‚ãªãŸï¼š
    *   `z_t` è‡ªä½“ã‚’ã€Œã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å‰ã® weight ç”¨ã‚·ã‚°ãƒŠãƒ«ã€ã¨ã—ã¦ä½¿ç”¨ã—ã€
    *   `w_t = z_t * target_vol / Ïƒ_z` ã«ç›´æ¥å…¥ã‚Œã¦ã„ã‚‹

ã¨ã„ã†ç‚¹ã§ã™ã€‚  
æ§‹é€ çš„ã«ä¸€ç•ªè¿‘ã„ã®ã¯ **ã€ŒK=1 ã® Method 6ã€** ã¨è€ƒãˆã‚‹ã®ãŒè‡ªç„¶ã§ã™ï¼š

*   K=4 â†’ K=1 ã«å¤‰æ›´
*   pooledï¼ˆnewsy+non-newsyï¼‰æ‰±ã„
*   demeaned ï¼‹ sign flip ã¯ Method 2ã€œ7 ã¨åŒã˜
*   intercept ä»£æ›¿ = expanding mean ã«è¿‘ã„æ‰±ã„

### 4.2 ã‚ãªãŸã® `z*_t`ï¼ˆnr + P4 ã® 2å¤‰æ•°ç‰ˆï¼‰

ã‚ãªãŸãŒå¾Œã§å®Ÿè£…ã—ãŸ `build_z_star_online` ã¯ï¼š

*   äºˆæ¸¬å­ï¼š
    *    $x_{1,t} = mkt\_nr(t)$ 
    *    $x_{2,t} = P4(t)$ ï¼ˆéå»4ã¤ã® newsy æœˆå¹³å‡ï¼‰
*   ä¿‚æ•°æ¨å®šï¼š
    *    $r_s = \alpha + \beta_1 x_{1,s} + \beta_2 x_{2,s} + \varepsilon_s$ 
    *   t ã«å¯¾ã™ã‚‹äºˆæ¸¬ã«ã¯ **tâˆ’1 ã¾ã§ã® expanding window** ã‚’ä½¿ç”¨
*   äºˆæ¸¬å­ï¼š
    $$
    z^*_t = \hat\beta_1(t-1) x_{1,t} + \hat\beta_2(t-1) x_{2,t}
    $$
*   ã“ã‚Œã‚’ `z` ã¨ã—ã¦ `apply_timing_strategy` ã«æ¸¡ã—ã¦ã„ã‚‹ã€‚

ã“ã‚Œã¯

*   signal = sum\_{4} mkt\_nm(t,j)ï¼ˆP4ï¼‰ã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ãŸ **Method 6** ã‚’
*   **2æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«ï¼ˆnr + P4ï¼‰ã«æ‹¡å¼µã—ãŸ multivariate ç‰ˆ**
*   æ¨å®šã¯ pooled sampleï¼ˆnewsy + non-newsyï¼‰ã§ã‚„ã£ã¦ã„ã‚‹ã®ã§ã€  
    æ­£ç¢ºã«ã¯ã€Œ**Method 6 ã®å¤šå¤‰é‡æ‹¡å¼µ**ã€ã¨è¨€ãˆã¾ã™ã€‚[OUP Academic+1](https://academic.oup.com/rfs/article/38/6/1730/8101501?utm_source=chatgpt.com)

### 4.3 ãã£ã¡ã‚Š Method 2 / 6 ã«åˆã‚ã›ãŸã„å ´åˆã®ä¿®æ­£ãƒã‚¤ãƒ³ãƒˆ

ã‚‚ã—ã€

> ã€Œè«–æ–‡ Table 4 ã® Method 2 / 6 ã¨**å®Œå…¨ã«åŒã˜**æ§‹é€ ã§å®Ÿè£…ã—ãŸã„ã€

ã®ã§ã‚ã‚Œã°ã€å¿…è¦ãªä¿®æ­£ã¯ï¼š

1.  **ã‚·ã‚°ãƒŠãƒ«å®šç¾©ã‚’çµ±ä¸€**
    *   ã‚ãªãŸã® `P4` ã‚’
        $$
        S_t = \sum_{j=1}^4 mkt_{nm}(t,j)
        $$
        ã«ã—ã¦ã€ãã®å¾Œã«ã€Œexpanding-mean ã‚’å¼•ãã€ã€Œnewsy æœˆã§ sign flipã€ã‚’å¿…ãšå…¥ã‚Œã‚‹ã€‚
2.  **äºˆæ¸¬å€¤  $\hat r_t$  ã‚’ã¾ãšä½œã‚‹**
    *   `z_t` ã‚’ç›´æ¥ weight ã«ä½¿ã†ã®ã§ã¯ãªãã€
    *   `forecast_methodX` ã®ã‚ˆã†ã«ã—ã¦ `hat_r_t` ã‚’åˆ¥ Series ã§ç®¡ç†ã™ã‚‹ã€‚
3.  **weight ã¯  $\hat r_t$  ã‹ã‚‰ä½œã‚‹**
    *   Guo ã¯ Method 6 ã®äºˆæ¸¬åˆ—ã‚’ Figure 2 ã§æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³ã¨ã—ã¦ãƒ—ãƒ­ãƒƒãƒˆã—ã€ãã®ã¾ã¾çµŒæ¸ˆçš„ãªè§£é‡ˆã‚’ã—ã¦ã„ã‚‹ã€‚[OUP Academic](https://academic.oup.com/rfs/article/38/6/1730/8101501?utm_source=chatgpt.com)
    *   æˆ¦ç•¥å®Ÿè£…ã§ã¯ã€
        $$
        w_t = \frac{\hat r_t}{\hat\sigma_{\hat r}} \cdot \text{target\_vol}
        $$
        ã®ã‚ˆã†ãª scaling ã«ã™ã‚Œã°ã€ã‚ãªãŸã®ç¾è¡Œã® `apply_timing_strategy` ã¨å®Œå…¨ã«æ•´åˆã™ã‚‹ã€‚

ã‚ãªãŸã®ç¾è¡Œã‚³ãƒ¼ãƒ‰ã¯ \*\*Guo ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ã‹ãªã‚Šå¿ å®Ÿã«å–ã‚Šå…¥ã‚ŒãŸã€Œã‚„ã‚„ç°¡ç´„ç‰ˆã€\*\*ã«ãªã£ã¦ã„ã‚‹ã®ã§ã€  
ä¸Šè¨˜ã®å¾®ä¿®æ­£ã‚’å…¥ã‚Œã‚Œã°ã€ŒTable 4 ã®ç‰¹å®š Method ã¨ 1:1 ãƒãƒƒãƒã€ã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

* * *

ã‚‚ã—æ¬¡ã«ã‚„ã‚‹ã¨ã—ãŸã‚‰ï¼š

*   ã€ŒMethod 2 / 6 ã‚’**ãã®ã¾ã¾**å®Ÿè£…ã—ã¦ã€ç¾è¡Œã® `z_t`, `z*_t` ã¨ OOS RÂ²ãƒ»æˆ¦ç•¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ¯”è¼ƒã™ã‚‹ã€
*   ã€ŒÎ²\_News(t), Î²\_NonNews(t) ã®æ™‚ç³»åˆ—ã‚’å¯è¦–åŒ–ã—ã¦ã€2020 å¹´ä»¥é™ã§æ§‹é€ å¤‰åŒ–ã‚’æ¤œå‡ºã™ã‚‹ã€

ã¨ã„ã£ãŸåˆ†æãŒè‡ªç„¶ã ã¨æ€ã„ã¾ã™ã€‚  
å¿…è¦ã§ã‚ã‚Œã°ã€ãã®æ¯”è¼ƒç”¨ã® Python ã‚’ä¸¸ã”ã¨æ›¸ãä¸‹ã‚ã—ã¾ã™ã€‚

## Response:
æ€è€ƒå®Œäº†

æ€è€ƒå®Œäº†

æ€è€ƒå®Œäº†

æ€è€ƒå®Œäº†

æ€è€ƒæ™‚é–“: 4m 44s

Guo (2025) ã®ã€Œç­†è€…ã‚¤ãƒæŠ¼ã—ã€ã®é‹ç”¨ãƒ«ãƒ¼ãƒ«ã¯ã€Table 4 ã® Method 6 ã‚’ç”¨ã„ãŸ time-series strategy ã§ã™ã€‚å®Ÿéš›ã« Figure 2 ã®æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³ç³»åˆ—ã‚‚ Method 6 ã§æã‹ã‚Œã¦ãŠã‚Šã€Appendix A.3 ã§ã‚‚ã€Œthe forecast from method 6 of Table 4ã€ã€ŒThe portfolio weight in my strategy is c\_t x\_tã€ã¨æ˜è¨˜ã•ã‚Œã¦ã„ã¾ã™ã€‚[OUP Academic+1](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf)

ä»¥ä¸‹ã§ã€ã‚ãªãŸã® `load_ff_monthly_from_ken_french` ã‚’å‰æã«ã€Method 6 ãƒ™ãƒ¼ã‚¹ã®æˆ¦ç•¥ã‚’ã€Œãã®ã¾ã¾ã€å®Ÿè£…ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’ãƒ•ãƒ«ã§ç¤ºã—ã¾ã™ã€‚

* * *

1\. å‰æï¼šFF ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨æœˆã‚¿ã‚¤ãƒ—
----------------------

ã™ã§ã«ãŠæŒã¡ã®é–¢æ•°ã‚’ãã®ã¾ã¾ä½¿ã„ã¾ã™ã€‚

```python
import pandas as pd
import numpy as np
import math
import matplotlib.pyplot as plt

# æ—¢å­˜ï¼šKen French ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æœˆæ¬¡éƒ¨åˆ†ã ã‘æŠ½å‡º
def load_ff_monthly_from_ken_french(csv_path: str) -> pd.DataFrame:
    raw = pd.read_csv(csv_path, skiprows=4)

    num = pd.to_numeric(raw['Unnamed: 0'], errors='coerce')
    mask_monthly = num > 10000
    monthly = raw[mask_monthly].copy()

    monthly = monthly.rename(columns={'Unnamed: 0': 'date'})
    monthly['date'] = pd.to_datetime(monthly['date'].astype(int), format="%Y%m")
    monthly = monthly.set_index('date').sort_index()

    for col in ['Mkt-RF', 'RF']:
        monthly[col] = pd.to_numeric(monthly[col], errors='coerce')

    ff = monthly[['Mkt-RF', 'RF']].copy()
    ff['mkt_excess'] = ff['Mkt-RF'] / 100.0
    ff['rf'] = ff['RF'] / 100.0

    return ff[['mkt_excess', 'rf']].dropna()

# æ—¢å­˜ï¼šGuo ã® newsy / non-newsyï¼ˆå››åŠæœŸ1ãƒ¶æœˆç›®ãŒ newsyï¼‰
def classify_month_type(index):
    mt = pd.Series(index=index, dtype="object")
    for t in index:
        m = t.month % 3
        if m == 1:
            mt[t] = 'N'   # newsy (Jan, Apr, Jul, Oct)
        elif m == 2:
            mt[t] = 'R'   # repetitive
        else:
            mt[t] = '3'   # 3rd month
    return mt
```

* * *

2\. Method 6 ã®ã‚·ã‚°ãƒŠãƒ« xâ‚œï¼ˆè«–æ–‡ã® x\_tï¼‰
-------------------------------

### è«–æ–‡ã®å®šç¾©ï¼ˆè¦ç´„ï¼‰

Appendix A.3 ã«ã‚ˆã‚‹ã¨ã€Method 6 ç”¨ã® time-series strategy ã¯ä»¥ä¸‹ã§ã™ã€‚[OUP Academic](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf)

*   å„æœˆ tâˆ’1 ã®çµ‚ã‚ã‚Šã«ã€
    1.  ã€Œç›´è¿‘ 4 ã¤ã® newsy æœˆã®å¸‚å ´ãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆé…å½“è¾¼ã¿ã€Excess ã§ã¯ãªã„ï¼‰ã€ã®åˆè¨ˆã‚’å–ã‚‹  
        â†’ è«–æ–‡ä¸­ã® `âˆ‘_{j=1}^4 mktnm(tâˆ’1, j)` ã«ç›¸å½“
    2.  ãã®ã€Œ4ãƒ‹ãƒ¥ãƒ¼ã‚¹yåˆè¨ˆã€ã® expanding meanï¼ˆã‚µãƒ³ãƒ—ãƒ«é–‹å§‹ã€œtâˆ’1 ã¾ã§ã®å¹³å‡ï¼‰ã‚’å¼•ã
    3.  ç¿Œæœˆ t ãŒ newsy ãªã‚‰ç¬¦å·ã‚’åè»¢ã€non-newsy ãªã‚‰ãã®ã¾ã¾  
        â†’ ã“ã‚ŒãŒã€Œdemeaned & sign-flipped signalã€x\_{tâˆ’1}
*   å›å¸°ã¯  
    `mkt_t = Î² x_{tâˆ’1} + 1 * mktÌ„_{tâˆ’1} + Îµ_t`  
    ï¼ˆmktÌ„\_{tâˆ’1} ã¯ tâˆ’1 ã¾ã§ã®å¸‚å ´ãƒªã‚¿ãƒ¼ãƒ³ã® expanding meanã€‚ä¿‚æ•° 1 ã«å›ºå®šï¼‰
*   ã‚ã‚‹æœˆ t ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã§ Î² ã‚’ expanding OLS ã§æ¨å®šã—ã€ãã® Î²\_t ã‚’ä½¿ã£ã¦  
    `E_t[mkt_{t+1}] = Î²_t x_t + mktÌ„_t`  
    ã‚’äºˆæ¸¬ã€‚ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚¦ã‚§ã‚¤ãƒˆã¯ `w_t = Î²_t x_t`ã€‚

ã“ã‚Œã«å³å¯†ã«å¯¾å¿œã™ã‚‹ Python å®Ÿè£…ã‚’ä½œã‚Šã¾ã™ã€‚

### (1) ã€Œç›´è¿‘ 4 ã¤ã® newsy æœˆãƒªã‚¿ãƒ¼ãƒ³ã€ã®åˆè¨ˆ Sâ‚œ

```python
def compute_news_sum_series(mkt_total: pd.Series,
                            month_type: pd.Series) -> pd.Series:
    """
    mkt_total: å¸‚å ´ãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ (é…å½“è¾¼ã¿, æœˆæ¬¡, ãƒ¬ãƒ™ãƒ«: 0.01 = 1%)
    month_type: 'N','R','3' ã‹ã‚‰ãªã‚‹ Series (index ã¯ mkt_total ã¨åŒã˜)

    æˆ»ã‚Šå€¤:
        S_t = ã€Œt ã¾ã§ã«å‡ºç¾ã—ãŸç›´è¿‘ 4 ã¤ã® newsy æœˆã® total return ã®åˆè¨ˆã€
    """
    is_newsy = (month_type == "N")
    news_series = mkt_total[is_newsy]

    res = pd.Series(index=mkt_total.index, dtype=float)
    for t in mkt_total.index:
        past_news = news_series[news_series.index <= t]
        if len(past_news) >= 4:
            res[t] = past_news.iloc[-4:].sum()
        else:
            res[t] = np.nan
    return res
```

### (2) xâ‚œ ã®æ§‹ç¯‰ï¼ˆè«–æ–‡ã® x\_{tâˆ’1} ã‚’ index t ã«æŒãŸã›ã‚‹ï¼‰

```python
def build_method6_signal(mkt_total: pd.Series):
    """
    Guo (2025) Appendix A.3 ã® x_{t-1} ã‚’ index t ã«è¼‰ã›ãŸ Series x_t ã‚’è¿”ã™ã€‚

    mkt_total: æœˆæ¬¡ã®å¸‚å ´ãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ (mkt_excess + rf)
    """
    idx = mkt_total.index
    month_type = classify_month_type(idx)
    is_newsy = (month_type == "N")

    # ç›´è¿‘4ã¤ã® newsy æœˆã® total return åˆè¨ˆ S_t
    S = compute_news_sum_series(mkt_total, month_type)

    # x_t: ã€Œt ã®ãƒªã‚¿ãƒ¼ãƒ³ã‚’äºˆæ¸¬ã™ã‚‹ãŸã‚ã® x_{t-1}ã€ã‚’ t ã® index ã«ä¿å­˜
    x = pd.Series(index=idx, dtype=float)

    # S ã® expanding mean ã‚’ t-1 æ™‚ç‚¹ã¾ã§ã§è¨ˆç®—ï¼ˆNaN ã¯é™¤å¤–ï¼‰
    S_hist = []
    for i in range(1, len(idx)):
        prev_date = idx[i-1]   # t-1
        curr_date = idx[i]     # t

        s_prev = S.loc[prev_date]
        if np.isnan(s_prev):
            x[curr_date] = np.nan
            continue

        # ã‚µãƒ³ãƒ—ãƒ«é–‹å§‹ã€œt-1 ã¾ã§ã® S ã®å¹³å‡
        S_hist.append(s_prev)
        s_bar = float(np.mean(S_hist))

        # ç¿Œæœˆ t ãŒ newsy ãªã‚‰ç¬¦å·åè»¢
        sign = -1.0 if is_newsy[curr_date] else 1.0
        x[curr_date] = sign * (s_prev - s_bar)

    return x, month_type
```

* * *

3\. Method 6 ã® time-series æˆ¦ç•¥ã®å®Œå…¨å®Ÿè£…
----------------------------------

è«–æ–‡ã®å›å¸°å¼  
`mkt_t = Î² x_{tâˆ’1} + 1 * mktÌ„_{tâˆ’1} + Îµ_t`  
ã¯ã€  
`(mkt_t âˆ’ mktÌ„_{tâˆ’1}) = Î² x_{tâˆ’1} + Îµ_t`  
ã¨æ›¸ãæ›ãˆã‚‰ã‚Œã‚‹ã®ã§ã€Œå®šæ•°é …ãªã— 1 å¤‰æ•°å›å¸°ã€ã¨ã—ã¦å®Ÿè£…ã§ãã¾ã™ã€‚

ã•ã‚‰ã«ã€Appendix A.3 ã§ã¯ Sharpe æ¯”æ¯”è¼ƒã®ãŸã‚ã«ã€Œæœ€çµ‚çš„ãªã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’å¸‚å ´ã®ãƒœãƒ©ã¨åŒã˜ 5.34% ã«ã‚¹ã‚±ãƒ¼ãƒ«ã€ã—ã¦ã„ã¾ã™ã€‚[OUP Academic](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf)

ä»¥ä¸‹ã®é–¢æ•°ã§ã¯

*   `min_obs`ï¼šÎ² æ¨å®šã«å¿…è¦ãªæœ€ä½ã‚µãƒ³ãƒ—ãƒ«æ•°ï¼ˆä¾‹ï¼š120ãƒ¶æœˆï¼‰
*   `target_vol`ï¼šãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’åˆã‚ã›ãŸã„æ°´æº–ï¼ˆNone ã®å ´åˆã€å¸‚å ´ãƒœãƒ©ã«åˆã‚ã›ã‚‹ â†’ è«–æ–‡ä»•æ§˜ï¼‰
*   `max_leverage`ï¼šæœ›ã‚€ãªã‚‰ãƒªã‚¢ãƒ«é‹ç”¨ç”¨ã« w\_t ã‚’ã‚¯ãƒªãƒƒãƒ—ï¼ˆè«–æ–‡ã¯ã“ã“ã‚’åˆ¶ç´„ã—ã¦ã„ãªã„ã®ã§ã€None ãªã‚‰ç„¡åˆ¶ç´„ï¼‰

ã¨ã„ã†å½¢ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã—ã¦ã‚ã‚Šã¾ã™ã€‚

```python
def backtest_method6_strategy(ff: pd.DataFrame,
                              min_obs: int = 120,
                              target_vol: float = None,
                              max_leverage: float = None) -> pd.DataFrame:
    """
    Guo (2025) ãŒ Appendix A.3 ã§èª¬æ˜ã—ã¦ã„ã‚‹
    Method 6 ãƒ™ãƒ¼ã‚¹ã® time-series strategy ã‚’å®Ÿè£…ã—ã€ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã‚’è¿”ã™ã€‚

    ff: load_ff_monthly_from_ken_french ã®å‡ºåŠ›
        å¿…é ˆåˆ—: 'mkt_excess', 'rf' (å˜ä½ã¯ãƒªã‚¿ãƒ¼ãƒ³ãƒ¬ãƒ™ãƒ«, 0.01=1%)

    æˆ»ã‚Šå€¤:
        DataFrame:
          - mkt_excess, rf, mkt_total
          - month_type ('N','R','3')
          - x: Method 6 ã® signal x_t
          - mkt_mean: mktÌ„_{t-1} (t index ã«ãšã‚‰ã—ãŸã‚‚ã®)
          - beta: å„ t æ™‚ç‚¹ã¾ã§ã® expanding OLS ã§æ¨å®šã—ãŸ Î²_t
          - w_raw: Î²_t x_t ã‚’ 1ãƒ¶æœˆå…ˆã«é©ç”¨ã—ãŸ weightï¼ˆoverlay éƒ¨åˆ†ï¼‰
          - exp_ret: äºˆæ¸¬ã•ã‚ŒãŸå¸‚å ´ãƒªã‚¿ãƒ¼ãƒ³ E_t[mkt_{t+1}]
          - strat_excess_raw: overlay ã®ç”Ÿã®è¶…éãƒªã‚¿ãƒ¼ãƒ³
          - strat_excess_scaled: ãƒœãƒ©èª¿æ•´å¾Œã®è¶…éãƒªã‚¿ãƒ¼ãƒ³
          - strat_total: ç·ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆrf + strat_excess_scaledï¼‰
    """
    mkt_excess = ff["mkt_excess"].copy()
    rf = ff["rf"].copy()

    # å¸‚å ´ãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ (CRSP value-weighted ã«ç›¸å½“ã™ã‚‹è¿‘ä¼¼)
    mkt_total = mkt_excess + rf
    idx = mkt_total.index

    # 1) ã‚·ã‚°ãƒŠãƒ« x_tï¼ˆindex tï¼‰ã¨ month_type
    x, month_type = build_method6_signal(mkt_total)

    # 2) mktÌ„_{t-1} ï¼ˆexpanding mean ã‚’ 1 æœŸã‚·ãƒ•ãƒˆï¼‰
    mkt_mean = mkt_total.expanding().mean().shift(1)

    # 3) å›å¸° (mkt_t - mktÌ„_{t-1}) = Î² x_{t-1} + Îµ_t
    y_adj = mkt_total - mkt_mean
    beta = pd.Series(index=idx, dtype=float)

    for i, t in enumerate(idx):
        # t ã¾ã§ã«åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã ã‘ã§ Î² ã‚’æ¨å®šï¼ˆexpandingï¼‰
        mask = (idx <= t) & x.notna() & y_adj.notna()
        n = mask.sum()
        if n < min_obs:
            beta[t] = np.nan
            continue

        xi = x[mask].values
        yi = y_adj[mask].values
        denom = (xi ** 2).sum()
        beta[t] = (xi * yi).sum() / denom if denom > 0 else np.nan

    # 4) 1ãƒ¶æœˆå…ˆã®äºˆæ¸¬ã¨ weight
    exp_ret = pd.Series(index=idx, dtype=float)
    w_raw = pd.Series(index=idx, dtype=float)

    for i in range(len(idx) - 1):
        t = idx[i]
        t_next = idx[i + 1]

        if any(np.isnan([beta[t], x[t], mkt_mean[t]])):
            exp_ret[t_next] = np.nan
            w = 0.0
        else:
            # è«–æ–‡ä¸Šã¯ w_t = Î²_t x_t
            w = beta[t] * x[t]
            if max_leverage is not None:
                w = float(np.clip(w, -max_leverage, max_leverage))

            # äºˆæ¸¬å¸‚å ´ãƒªã‚¿ãƒ¼ãƒ³ E_t[mkt_{t+1}] = Î²_t x_t + mktÌ„_t
            exp_ret[t_next] = w + mkt_mean[t]

        w_raw[t_next] = w

    # 5) overlay ã®è¶…éãƒªã‚¿ãƒ¼ãƒ³: w_t * mkt_excess_{t}
    strat_excess_raw = w_raw * mkt_excess

    # 6) ãƒœãƒ©èª¿æ•´ï¼ˆSharpe æ¯”æ¯”è¼ƒã®ãŸã‚ï¼‰
    common_mask = strat_excess_raw.notna() & mkt_excess.notna()
    strat_vol = strat_excess_raw[common_mask].std(ddof=1)
    mkt_vol = mkt_excess[common_mask].std(ddof=1)

    if target_vol is None:
        # è«–æ–‡ã¨åŒæ§˜ã€Œå¸‚å ´ãƒœãƒ©ã¨æƒãˆã‚‹ã€
        target_vol = float(mkt_vol)

    if strat_vol is not None and strat_vol > 0:
        scale = target_vol / strat_vol
    else:
        scale = 1.0

    strat_excess_scaled = strat_excess_raw * scale
    strat_total = rf + strat_excess_scaled

    out = pd.DataFrame({
        "mkt_excess": mkt_excess,
        "rf": rf,
        "mkt_total": mkt_total,
        "month_type": month_type,
        "x": x,
        "mkt_mean": mkt_mean,
        "beta": beta,
        "w_raw": w_raw,
        "exp_ret": exp_ret,
        "strat_excess_raw": strat_excess_raw,
        "strat_excess_scaled": strat_excess_scaled,
        "strat_total": strat_total,
    })
    out.attrs["scale"] = scale
    out.attrs["target_vol"] = target_vol
    out.attrs["min_obs"] = min_obs
    out.attrs["max_leverage"] = max_leverage

    return out
```

* * *

4\. ä½¿ã„æ–¹ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç¢ºèªã®ä¾‹
-------------------

### (1) ãƒ•ãƒ«ã‚µãƒ³ãƒ—ãƒ«ã§ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ

```python
# 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
ff = load_ff_monthly_from_ken_french("F-F_Research_Data_Factors.csv")

# 2. Method 6 æˆ¦ç•¥ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
res_m6 = backtest_method6_strategy(
    ff,
    min_obs=120,      # 1926 ä»¥é™ãªã‚‰ 10 å¹´ãã‚‰ã„ã‚’åˆæœŸæ¨å®šçª“ã«
    target_vol=None,  # None â†’ å¸‚å ´ãƒœãƒ©ã«åˆã‚ã›ã‚‹ï¼ˆè«–æ–‡ä»•æ§˜ï¼‰
    max_leverage=None # None â†’ Î²_t x_t ã‚’ãã®ã¾ã¾ä½¿ã†ï¼ˆè«–æ–‡ä»•æ§˜ï¼‰
)

print("scale (vol match):", res_m6.attrs["scale"])
print("target_vol (monthly):", res_m6.attrs["target_vol"])
```

### (2) ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³ã®ãƒ—ãƒ­ãƒƒãƒˆ

```python
def plot_method6_performance(res):
    strat_wealth = (1.0 + res["strat_total"]).dropna().cumprod()
    mkt_wealth = (1.0 + res["mkt_total"]).reindex(strat_wealth.index).cumprod()

    plt.figure(figsize=(14, 5))
    plt.plot(strat_wealth, label="Method 6 Strategy (vol-matched)", linewidth=2)
    plt.plot(mkt_wealth, label="Market", linestyle="--", linewidth=1.5)
    plt.title("Cumulative Return: Guo (2025) Method 6 vs Market")
    plt.legend()
    plt.grid(True)
    plt.show()

plot_method6_performance(res_m6)
```

### (3) ã‚µãƒãƒªçµ±è¨ˆï¼ˆSharpe ç­‰ï¼‰

```python
def summarize_performance(res, start=None, end=None, rf_col="rf"):
    if start is not None or end is not None:
        sub = res.loc[start:end].copy()
    else:
        sub = res.copy()

    strat = sub["strat_total"].dropna()
    mkt = sub["mkt_total"].reindex(strat.index)

    # å¹´ç‡åŒ–ï¼ˆæœˆæ¬¡â†’12å€ï¼‰
    def ann_stats(r):
        mu_m = r.mean()
        sd_m = r.std(ddof=1)
        mu_a = mu_m * 12
        sd_a = sd_m * math.sqrt(12)
        sharpe = mu_a / sd_a if sd_a > 0 else np.nan
        return mu_a, sd_a, sharpe

    mu_s, sd_s, sh_s = ann_stats(strat)
    mu_mkt, sd_mkt, sh_mkt = ann_stats(mkt)

    print("Period:", strat.index[0].strftime("%Y-%m"), "ã€œ", strat.index[-1].strftime("%Y-%m"))
    print(" Strategy:  mu={:.2%}, sigma={:.2%}, Sharpe={:.2f}".format(mu_s, sd_s, sh_s))
    print(" Market  :  mu={:.2%}, sigma={:.2%}, Sharpe={:.2f}".format(mu_mkt, sd_mkt, sh_mkt))

# ãƒ•ãƒ«ã‚µãƒ³ãƒ—ãƒ«
summarize_performance(res_m6)

# 2020å¹´ä»¥é™ã ã‘
summarize_performance(res_m6, start="2020-01-01")
```

* * *

5\. ã‚³ãƒ¡ãƒ³ãƒˆï¼šå°†æ¥æƒ…å ±ãƒªãƒ¼ã‚¯ã¨ Guo è«–æ–‡ã¨ã®æ•´åˆæ€§
-----------------------------

*   x\_t ã®æ§‹ç¯‰ã§ã¯
    *   ã€Œç›´è¿‘ 4 newsyã€ã®åˆè¨ˆ S\_{tâˆ’1}ã€
    *   ãã® expanding meanï¼ˆã‚µãƒ³ãƒ—ãƒ«é–‹å§‹ã€œtâˆ’1 ã¾ã§ï¼‰ã€
    *   ç¿Œæœˆ t ãŒ newsy ã‹ã©ã†ã‹ï¼ˆã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼æƒ…å ±ãªã®ã§å…ˆå–ã‚Šã§ã¯ãªã„ï¼‰  
        ã ã‘ã‚’ä½¿ã£ã¦ã„ã¾ã™ã€‚
*   Î²\_t ã®æ¨å®šã‚‚ã€Œãã®æ™‚ç‚¹ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ (â‰¤ t)ã€ã ã‘ã§è¡Œã£ã¦ãŠã‚Šã€Appendix A.2 / A.3 ã®è¶£æ—¨ã©ãŠã‚Šã€æ¨å®šä¿‚æ•°ã« look-ahead bias ã¯å…¥ã‚Šã¾ã›ã‚“ã€‚[OUP Academic+1](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf)
*   ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’å¸‚å ´ãƒœãƒ©ã«åˆã‚ã›ã‚‹ãŸã‚ã®ã‚¹ã‚±ãƒ¼ãƒ«ä¿‚æ•°ã¯ã€è«–æ–‡ã‚‚ ex-post ã«è¨ˆç®—ã—ã¦ãŠã‚Šã€ã“ã‚Œã¯ã€Œå±¥æ­´ã‚’æŒ¯ã‚Šè¿”ã£ãŸè©•ä¾¡ã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´ã€ã§ã‚ã£ã¦ã€ã‚·ã‚°ãƒŠãƒ«ã‚„ãƒã‚¸ã‚·ãƒ§ãƒ³æ§‹ç¯‰ãã®ã‚‚ã®ã«ã¯å½±éŸ¿ã—ã¾ã›ã‚“ã€‚

ã“ã®ã‚³ãƒ¼ãƒ‰ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€æ—¢ã«è¨ˆç®—æ¸ˆã¿ã® `nr` ã‚„ P4\_j ã‚’çµ„ã¿åˆã‚ã›ãŸ z\*_t ç‰ˆï¼ˆ2 å¤‰æ•°å›å¸°ï¼‰ã‚’åŒã˜ã€Œexpanding OLS + mktÌ„_{t-1} ã«ä¿‚æ•° 1 å›ºå®šã€ã®æ çµ„ã¿ã§æ‹¡å¼µã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ãŒã€ã¾ãšã¯è«–æ–‡ãŒå®Ÿéš›ã« time-series strategy ã¨ã—ã¦æ¡ç”¨ã—ã¦ã„ã‚‹ Method 6 ã‚’ã“ã®å½¢ã§ä¸€åº¦å©ã„ã¦ã¿ã‚‹ã®ãŒã‚ˆã„ã¨æ€ã„ã¾ã™ã€‚

## Response:
æ€è€ƒæ™‚é–“: 44s

äº†è§£ã—ã¾ã—ãŸã€‚  
å…ˆã»ã©ã® **Method 6 å®Ÿè£…**ã‚’ãã®ã¾ã¾ãƒ™ãƒ¼ã‚¹ã«ã—ã¦ã€

> nrï¼ˆmkt\_nrï¼‰ã¨ P4\_jï¼ˆmkt\_nm4\_avgï¼‰ã‚’çµ„ã¿åˆã‚ã›ãŸ 2 å¤‰æ•°å›å¸°ç‰ˆ z\*\_t

ã‚’ã€**åŒã˜ã€Œ(mkt\_t âˆ’ mktÌ„\_{tâˆ’1}) = Î²â‚ xâ‚ + Î²â‚‚ xâ‚‚ã€å½¢å¼ã§å®Ÿè£…ã™ã‚‹**ã‚³ãƒ¼ãƒ‰ã‚’ç¤ºã—ã¾ã™ã€‚

*   1å¤‰æ•°ç‰ˆï¼ˆGuo æ¨å¥¨ã® Method 6ï¼‰ã®å®Œå…¨å®Ÿè£…ã¯ã™ã§ã«ã‚ã‚Šã¾ã™ã€‚
*   ã“ã“ã§ã¯ã€Œ2å¤‰æ•°ç‰ˆ Method 6ï¼ˆmultivariate æ‹¡å¼µï¼‰ã€ã¨ã—ã¦ã€
    *   xâ‚\_tï¼šnrï¼ˆmkt\_nrï¼‰ã‹ã‚‰ä½œã‚‹ã‚·ã‚°ãƒŠãƒ«
    *   xâ‚‚\_tï¼šP4ï¼ˆmkt\_nm4\_avgï¼‰ã‹ã‚‰ä½œã‚‹ã‚·ã‚°ãƒŠãƒ«
*   ã©ã¡ã‚‰ã‚‚
    *   tâˆ’1 æ™‚ç‚¹ã¾ã§ã®å€¤ã§ expanding mean ã‚’å¼•ã„ã¦
    *   ç¿Œæœˆ t ãŒ newsy ãªã‚‰ç¬¦å·åè»¢  
        ã¨ã„ã†ã€ŒMethod 6 ã®ãƒ­ã‚¸ãƒƒã‚¯ã€ã‚’è¸è¥²ã—ã¾ã™ã€‚

* * *

1\. å‰æï¼š`add_nr_and_nm4` ã§ nr ã¨ P4 ã‚’ä½œã‚‹
-------------------------------------

ä»¥å‰å‡ºã—ãŸ nr / nm4 ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚’å†æ²ã—ã¾ã™ã€‚  
ï¼ˆã™ã§ã«åŒæ§˜ã®é–¢æ•°ã‚’æŒã£ã¦ã„ã‚Œã°ã€ãã“ã ã‘å·®ã—æ›¿ãˆã¦ã‚‚å•é¡Œã‚ã‚Šã¾ã›ã‚“ï¼‰

```python
import pandas as pd
import numpy as np
import math
import matplotlib.pyplot as plt
import statsmodels.api as sm

# æ—¢å­˜ï¼šKen French å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æœˆæ¬¡éƒ¨åˆ†ã ã‘æŠ½å‡º
def load_ff_monthly_from_ken_french(csv_path: str) -> pd.DataFrame:
    raw = pd.read_csv(csv_path, skiprows=4)

    num = pd.to_numeric(raw['Unnamed: 0'], errors='coerce')
    mask_monthly = num > 10000
    monthly = raw[mask_monthly].copy()

    monthly = monthly.rename(columns={'Unnamed: 0': 'date'})
    monthly['date'] = pd.to_datetime(monthly['date'].astype(int), format="%Y%m")
    monthly = monthly.set_index('date').sort_index()

    for col in ['Mkt-RF', 'RF']:
        monthly[col] = pd.to_numeric(monthly[col], errors='coerce')

    ff = monthly[['Mkt-RF', 'RF']].copy()
    ff['mkt_excess'] = ff['Mkt-RF'] / 100.0
    ff['rf']         = ff['RF'] / 100.0

    return ff[['mkt_excess', 'rf']].dropna()

# æ—¢å­˜ï¼šGuo ã®æœˆã‚¿ã‚¤ãƒ—åˆ†é¡
def classify_month_type(index):
    mt = pd.Series(index=index, dtype="object")
    for t in index:
        m = t.month % 3
        if m == 1:
            mt[t] = 'N'   # newsy
        elif m == 2:
            mt[t] = 'R'   # repetitive
        else:
            mt[t] = '3'   # 3rd month
    return mt

# nr(t) ã¨ nm4 (P4) ã‚’è¨ˆç®—
def add_nr_and_nm4(ff: pd.DataFrame) -> pd.DataFrame:
    """
    ff: load_ff_monthly_from_ken_french ã®å‡ºåŠ›
        å¿…é ˆåˆ—: ['mkt_excess', 'rf']

    æˆ»ã‚Šå€¤:
        ff ã«ä»¥ä¸‹ã®åˆ—ã‚’è¿½åŠ ã—ãŸ DataFrame:
          - 'month_type' : 'N', 'R', '3'
          - 'mkt_nr'     : nr(t) ç”¨ã®å¸‚å ´è¶…éãƒªã‚¿ãƒ¼ãƒ³
          - 'mkt_nm1'..'mkt_nm4'
          - 'mkt_nm4_avg': éå»4ã¤ newsy æœˆãƒªã‚¿ãƒ¼ãƒ³ã®å¹³å‡ (P4)
    """
    df = ff.copy()
    df["month_type"] = classify_month_type(df.index)

    dates = list(df.index)
    mt = df["month_type"].values
    mkt = df["mkt_excess"].values

    nr_dates = []
    mkt_nr_list = []

    past_newsy_indices = []
    mkt_nm1 = []
    mkt_nm2 = []
    mkt_nm3 = []
    mkt_nm4 = []

    for i, t in enumerate(dates):
        # nr(t): t ã‚ˆã‚Šå‰ã§æœ€ã‚‚è¿‘ã„ N or R
        nr_idx = None
        j = i - 1
        while j >= 0:
            if mt[j] in ("N", "R"):
                nr_idx = j
                break
            j -= 1
        if nr_idx is None:
            nr_dates.append(None)
            mkt_nr_list.append(np.nan)
        else:
            nr_dates.append(dates[nr_idx])
            mkt_nr_list.append(mkt[nr_idx])

        # newsy æœˆã®å±¥æ­´æ›´æ–°
        if mt[i] == "N":
            past_newsy_indices.append(i)

        # nm(t,j): ç›´è¿‘ã® newsy æœˆãŸã¡
        cand = [k for k in past_newsy_indices if k < i]
        cand = sorted(cand, reverse=True)

        vals = []
        for jj in range(4):
            if jj < len(cand):
                vals.append(mkt[cand[jj]])
            else:
                vals.append(np.nan)

        mkt_nm1.append(vals[0])
        mkt_nm2.append(vals[1])
        mkt_nm3.append(vals[2])
        mkt_nm4.append(vals[3])

    df["nr_date"]   = nr_dates
    df["mkt_nr"]    = mkt_nr_list
    df["mkt_nm1"]   = mkt_nm1
    df["mkt_nm2"]   = mkt_nm2
    df["mkt_nm3"]   = mkt_nm3
    df["mkt_nm4"]   = mkt_nm4
    df["mkt_nm4_avg"] = df[["mkt_nm1", "mkt_nm2", "mkt_nm3", "mkt_nm4"]].mean(axis=1)

    return df
```

* * *

2\. nr + P4 ã® 2å¤‰æ•°ç‰ˆã‚·ã‚°ãƒŠãƒ« xâ‚â‚œ, xâ‚‚â‚œï¼ˆMethod 6 æ‹¡å¼µï¼‰
--------------------------------------------

Guo ã® 1å¤‰æ•° x\_tï¼ˆS ã® demean & sign flipï¼‰ã¨åŒã˜æ§‹é€ ã§ã€

*   xâ‚â‚œï¼šnrï¼ˆmkt\_nrï¼‰ã‚’ expanding mean ã§ demean ã—ã€  
    ç¿Œæœˆ t ãŒ newsy ãªã‚‰ç¬¦å·åè»¢
*   xâ‚‚â‚œï¼šP4ï¼ˆmkt\_nm4\_avgï¼‰ã‚‚åŒæ§˜

ã«ãªã‚‹ã‚ˆã†ã«ä½œã‚Šã¾ã™ã€‚

```python
def build_nr_p4_signals(df_nr_p4: pd.DataFrame):
    """
    df_nr_p4: add_nr_and_nm4(ff) ã‚’é€šã—ãŸ DataFrame
              å¿…é ˆåˆ—: 'mkt_nr', 'mkt_nm4_avg', 'month_type'

    æˆ»ã‚Šå€¤:
        x1, x2, month_type
        x1_t, x2_t ã¯ã€Œt ã®ãƒªã‚¿ãƒ¼ãƒ³ã‚’äºˆæ¸¬ã™ã‚‹ãŸã‚ã« t-1 ã¾ã§ã®æƒ…å ±ã‹ã‚‰æ§‹æˆã—ãŸã‚·ã‚°ãƒŠãƒ«ã€
    """
    df = df_nr_p4.copy()
    idx = df.index
    month_type = df["month_type"]
    is_newsy = (month_type == "N")

    mkt_nr = df["mkt_nr"]
    P4     = df["mkt_nm4_avg"]

    x1 = pd.Series(index=idx, dtype=float)  # nr ç”¨
    x2 = pd.Series(index=idx, dtype=float)  # P4 ç”¨

    hist_nr = []
    hist_P4 = []

    # t=1 ä»¥é™ã«ã¤ã„ã¦ã€t-1 ã®æƒ…å ±ã§ x_t ã‚’æ§‹ç¯‰
    for i in range(1, len(idx)):
        prev_date = idx[i-1]   # t-1
        curr_date = idx[i]     # t

        nr_prev = mkt_nr.loc[prev_date]
        P4_prev = P4.loc[prev_date]

        # nr/P4 ã®ã©ã¡ã‚‰ã‹ãŒ NaN ãªã‚‰ã‚·ã‚°ãƒŠãƒ«ã¯ NaN
        if np.isnan(nr_prev) or np.isnan(P4_prev):
            x1[curr_date] = np.nan
            x2[curr_date] = np.nan
            continue

        # ã“ã‚Œã¾ã§ã®å±¥æ­´ï¼‹ç›´è¿‘å€¤ã¾ã§ã§å¹³å‡ã‚’è¨ˆç®—
        hist_nr.append(nr_prev)
        hist_P4.append(P4_prev)
        nr_bar = float(np.mean(hist_nr))
        P4_bar = float(np.mean(hist_P4))

        nr_dm = nr_prev - nr_bar
        P4_dm = P4_prev - P4_bar

        # ç¿Œæœˆ t ãŒ newsy ãªã‚‰ç¬¦å·åè»¢
        sign = -1.0 if is_newsy[curr_date] else 1.0

        x1[curr_date] = sign * nr_dm
        x2[curr_date] = sign * P4_dm

    return x1, x2, month_type
```

* * *

3\. 2å¤‰æ•°å›å¸°ç‰ˆ z\*\_t æˆ¦ç•¥ï¼š`backtest_method6_zstar_strategy`
------------------------------------------------------

æ§‹é€ ã¯ Method 6 ã¨åŒã˜ã§ã™ï¼š

*   å›å¸°ï¼š
    $$
    mkt_t - \bar mkt_{t-1} = \beta_1 x1_t + \beta_2 x2_t + \varepsilon_t
    $$
    ï¼ˆå®šæ•°é …ãªã—ã€ä¿‚æ•° 1 ã¯ mktÌ„\_{tâˆ’1} ã«å›ºå®šï¼‰
*   å„ t ã§ expanding OLS ã«ã‚ˆã‚Š Î²â‚(t), Î²â‚‚(t) ã‚’æ¨å®š
*   ã‚¦ã‚§ã‚¤ãƒˆï¼š
    $$
    w_t = \beta_1(t-1) x1_t + \beta_2(t-1) x2_t
    $$
*   äºˆæ¸¬ãƒªã‚¿ãƒ¼ãƒ³ï¼š
    $$
    \hat r_t = w_t + \bar mkt_{t-1}
    $$
*   è¶…éãƒªã‚¿ãƒ¼ãƒ³ï¼š`w_t * mkt_excess_t`
*   æœ€å¾Œã«ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’å¸‚å ´ã¨ä¸€è‡´ã•ã›ã‚‹ã‚ˆã†ã«ã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆGuo ã¨åŒæ§˜ï¼‰

```python
def backtest_method6_zstar_strategy(
    ff: pd.DataFrame,
    min_obs: int = 120,
    target_vol: float = None,
    max_leverage: float = None,
) -> pd.DataFrame:
    """
    Guo (2025) Method 6 ã‚’ nr + P4 ã® 2å¤‰æ•°ç‰ˆã«æ‹¡å¼µã—ãŸæˆ¦ç•¥ã€‚

    ff: load_ff_monthly_from_ken_french ã®å‡ºåŠ›
        å¿…é ˆåˆ—: 'mkt_excess', 'rf'

    æˆ»ã‚Šå€¤:
        DataFrame:
          - mkt_excess, rf, mkt_total
          - month_type
          - x1_nr, x2_P4
          - mkt_mean
          - beta1, beta2
          - w_raw, exp_ret
          - strat_excess_raw, strat_excess_scaled, strat_total
    """
    # 0) åŸºæœ¬ã®å¸‚å ´ãƒªã‚¿ãƒ¼ãƒ³
    mkt_excess = ff["mkt_excess"].copy()
    rf         = ff["rf"].copy()
    mkt_total  = mkt_excess + rf
    idx        = mkt_total.index

    # 1) nr, P4 ã‚’è¨ˆç®—
    df_nr_p4 = add_nr_and_nm4(ff)

    # 2) nr, P4 ã‹ã‚‰ x1_t, x2_t ã‚’æ§‹ç¯‰ï¼ˆMethod 6 ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
    x1, x2, month_type = build_nr_p4_signals(df_nr_p4)

    # 3) mktÌ„_{t-1}ï¼ˆexpanding mean ã‚’1æœŸã‚·ãƒ•ãƒˆï¼‰
    mkt_mean = mkt_total.expanding().mean().shift(1)

    # 4) å›å¸° (mkt_t - mktÌ„_{t-1}) = Î²1 x1_t + Î²2 x2_t
    y_adj = mkt_total - mkt_mean
    beta1 = pd.Series(index=idx, dtype=float)
    beta2 = pd.Series(index=idx, dtype=float)

    for i, t in enumerate(idx):
        mask = (idx <= t) & x1.notna() & x2.notna() & y_adj.notna()
        n = mask.sum()
        if n < min_obs:
            beta1[t] = np.nan
            beta2[t] = np.nan
            continue

        X = np.column_stack([x1[mask].values, x2[mask].values])
        y = y_adj[mask].values

        # OLS: Î² = (X'X)^(-1) X'y ï¼ˆ2å¤‰æ•°ãªã®ã§è‡ªå‰å®Ÿè£…ã§ã‚‚OKï¼‰
        XtX = X.T @ X
        XtY = X.T @ y
        try:
            beta_vec = np.linalg.solve(XtX, XtY)
            beta1[t], beta2[t] = beta_vec[0], beta_vec[1]
        except np.linalg.LinAlgError:
            beta1[t], beta2[t] = np.nan, np.nan

    # 5) 1ãƒ¶æœˆå…ˆã®äºˆæ¸¬ã¨ weightï¼ˆÎ²_t ã‚’ t->t+1 ã«ä½¿ã†ï¼‰
    exp_ret = pd.Series(index=idx, dtype=float)
    w_raw   = pd.Series(index=idx, dtype=float)

    for i in range(len(idx) - 1):
        t      = idx[i]
        t_next = idx[i + 1]

        b1 = beta1[t]
        b2 = beta2[t]
        xt1 = x1[t]
        xt2 = x2[t]
        mt_bar = mkt_mean[t]

        if any(np.isnan([b1, b2, xt1, xt2, mt_bar])):
            exp_ret[t_next] = np.nan
            w = 0.0
        else:
            w = b1 * xt1 + b2 * xt2
            if max_leverage is not None:
                w = float(np.clip(w, -max_leverage, max_leverage))

            exp_ret[t_next] = w + mt_bar

        w_raw[t_next] = w

    # 6) overlay ã®è¶…éãƒªã‚¿ãƒ¼ãƒ³
    strat_excess_raw = w_raw * mkt_excess

    # 7) ãƒœãƒ©èª¿æ•´ï¼ˆSharpe æ¯”æ¯”è¼ƒã®ãŸã‚ï¼‰
    common_mask = strat_excess_raw.notna() & mkt_excess.notna()
    strat_vol   = strat_excess_raw[common_mask].std(ddof=1)
    mkt_vol     = mkt_excess[common_mask].std(ddof=1)

    if target_vol is None:
        target_vol = float(mkt_vol)  # å¸‚å ´ãƒœãƒ©ã«åˆã‚ã›ã‚‹

    if strat_vol is not None and strat_vol > 0:
        scale = target_vol / strat_vol
    else:
        scale = 1.0

    strat_excess_scaled = strat_excess_raw * scale
    strat_total         = rf + strat_excess_scaled

    out = pd.DataFrame({
        "mkt_excess": mkt_excess,
        "rf": rf,
        "mkt_total": mkt_total,
        "month_type": month_type,
        "x1_nr": x1,
        "x2_P4": x2,
        "mkt_mean": mkt_mean,
        "beta1": beta1,
        "beta2": beta2,
        "w_raw": w_raw,
        "exp_ret": exp_ret,
        "strat_excess_raw": strat_excess_raw,
        "strat_excess_scaled": strat_excess_scaled,
        "strat_total": strat_total,
    })
    out.attrs["scale"]       = scale
    out.attrs["target_vol"]  = target_vol
    out.attrs["min_obs"]     = min_obs
    out.attrs["max_leverage"] = max_leverage

    return out
```

* * *

4\. æ¯”è¼ƒã®å®Ÿè¡Œä¾‹ï¼ˆMethod 6 vs 2å¤‰æ•° z\*\_tï¼‰
----------------------------------

```python
def plot_cumret(res, label, ax=None):
    strat_wealth = (1.0 + res["strat_total"]).dropna().cumprod()
    mkt_wealth   = (1.0 + res["mkt_total"]).reindex(strat_wealth.index).cumprod()

    if ax is None:
        fig, ax = plt.subplots(figsize=(14,5))

    ax.plot(strat_wealth, label=label, linewidth=2)
    ax.plot(mkt_wealth,   label="Market", linestyle="--", linewidth=1.5)
    ax.grid(True)
    ax.legend()
    return ax

def summarize(res, label, start=None, end=None):
    if start is not None or end is not None:
        sub = res.loc[start:end].copy()
    else:
        sub = res.copy()

    strat = sub["strat_total"].dropna()
    mkt   = sub["mkt_total"].reindex(strat.index)

    def ann_stats(r):
        mu_m = r.mean()
        sd_m = r.std(ddof=1)
        mu_a = mu_m * 12
        sd_a = sd_m * math.sqrt(12)
        sharpe = mu_a / sd_a if sd_a > 0 else np.nan
        return mu_a, sd_a, sharpe

    mu_s, sd_s, sh_s     = ann_stats(strat)
    mu_mkt, sd_mkt, sh_m = ann_stats(mkt)

    print(f"[{label}]")
    print("Period:", strat.index[0].strftime("%Y-%m"), "ã€œ", strat.index[-1].strftime("%Y-%m"))
    print(" Strategy:  mu={:.2%}, sigma={:.2%}, Sharpe={:.2f}".format(mu_s, sd_s, sh_s))
    print(" Market  :  mu={:.2%}, sigma={:.2%}, Sharpe={:.2f}".format(mu_mkt, sd_mkt, sh_m))
    print()

if __name__ == "__main__":
    ff = load_ff_monthly_from_ken_french("F-F_Research_Data_Factors.csv")

    # 1) Guo æ¨å¥¨ã® Method 6 1å¤‰æ•°ç‰ˆï¼ˆå‰å›ã® backtest_method6_strategy ãŒã‚ã‚‹å‰æï¼‰
    res_m6_1 = backtest_method6_strategy(ff, min_obs=120, target_vol=None, max_leverage=None)

    # 2) nr + P4 ã® 2å¤‰æ•°ç‰ˆ z*_t
    res_m6_2 = backtest_method6_zstar_strategy(ff, min_obs=120, target_vol=None, max_leverage=None)

    # 3) ãƒ•ãƒ«ã‚µãƒ³ãƒ—ãƒ«ã®ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³æ¯”è¼ƒ
    fig, ax = plt.subplots(figsize=(14,5))
    plot_cumret(res_m6_1, "Method 6 (1-var S)", ax=ax)
    plot_cumret(res_m6_2, "Method 6 (2-var nr+P4)", ax=ax)
    ax.set_title("Cumulative Return: Method 6 vs 2-var z*_t")
    plt.show()

    # 4) ã‚µãƒãƒªçµ±è¨ˆï¼ˆå…¨æœŸé–“ & 2020å¹´ä»¥é™ï¼‰
    summarize(res_m6_1, "Method 6 (1-var S)")
    summarize(res_m6_2, "Method 6 (2-var nr+P4)")
    summarize(res_m6_1, "Method 6 (1-var S, 2020+)", start="2020-01-01")
    summarize(res_m6_2, "Method 6 (2-var nr+P4, 2020+)", start="2020-01-01")
```

* * *

5\. ä½ç½®ã¥ã‘ãƒ»è§£é‡ˆ
-----------

*   ã“ã® 2å¤‰æ•°ç‰ˆã¯ã€Guo ã® **Method 6ï¼ˆS ã® signed-deviationï¼‰** ã‚’
    *   **nr**ï¼šç›´è¿‘ N/R ã®ãƒªã‚¿ãƒ¼ãƒ³æ§‹é€ ï¼ˆcorrelation neglectï¼‰
    *   **P4**ï¼šéå»4ã¤ newsy ã®å¹³å‡ï¼ˆparameter compressionï¼‰  
        ã¨ã„ã† **2 ã¤ã®èª¤èªãƒ¡ã‚«ãƒ‹ã‚ºãƒ **ã«åˆ†è§£ã—ã¦ jointly å­¦ç¿’ã™ã‚‹æ‹¡å¼µç‰ˆã§ã™ã€‚
*   ä¸¡æ–¹ã® Î² ãŒæœ‰æ„ã§ã‚ã‚Œã°ã€
    *   ã€Œnr-only ã®æˆ¦ç•¥ã€ã¨
    *   ã€ŒP4-only ã® Method 6ã€  
        ãã‚Œãã‚Œã¨ã¯ç•°ãªã‚‹æŒ™å‹•ãŒå‡ºã¦ãã‚‹ã¯ãšã§ã€ç‰¹ã«  
        ã€Œã©ã¡ã‚‰ã‹ç‰‡æ–¹ã®äºˆæ¸¬åŠ›ãŒå¼±ã¾ã£ãŸå±€é¢ï¼ˆä¾‹ï¼š2020å¹´ä»¥é™ï¼‰ã€ã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å·®ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã®ãŒãƒã‚¤ãƒ³ãƒˆã«ãªã‚Šã¾ã™ã€‚

ã“ã®ã¾ã¾å‹•ã‹ã—ã¦ã¿ã¦ã€

*   ãƒ•ãƒ«æœŸé–“
*   1980+ / 2000+ / 2010+ / 2020+

ãªã©ã€ã„ãã¤ã‹ã®ã‚µãƒ–ã‚µãƒ³ãƒ—ãƒ«ã§ Sharpeãƒ»ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³ã‚’æ¯”è¼ƒã™ã‚‹ã¨ã€è«–æ–‡æœ¬ä½“ï¼‹Guo 2025 æ‹¡å¼µã‚’ã€Œã‹ãªã‚Šå¿ å®Ÿã«å®Ÿè£…ã—ãŸä¸Šã§ã®ã€å®Ÿå‹™çš„è©•ä¾¡ãŒã§ãã‚‹ã¨æ€ã„ã¾ã™ã€‚

## Response:
æ€è€ƒæ™‚é–“: 22s

ä¸€è¨€ã§ã„ã†ã¨ã€

> ä»¥å‰ã® `build_z_star_online` ç‰ˆã¯  
> **ã€Œz\*\_t ã‚’ãã®ã¾ã¾ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”¨ã‚·ã‚°ãƒŠãƒ«ã¨ã—ã¦ä½¿ã†æˆ¦ç•¥ã€**  
> ä»Šå›ã® Method 6 æ‹¡å¼µç‰ˆã¯  
> **ã€Œexpanding OLS ã§æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³ã‚’æ¨å®šã—ã¦ã€ãã®æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³ã‹ã‚‰æœ€é©ã‚¦ã‚§ã‚¤ãƒˆã‚’ä½œã‚‹æˆ¦ç•¥ã€**

ãªã®ã§ã€  
**äºˆæ¸¬å­ã®å‰å‡¦ç†ãƒ»å›å¸°ä»•æ§˜ãƒ»ã‚¦ã‚§ã‚¤ãƒˆã®ä½œã‚Šæ–¹ãŒã‹ãªã‚Šé•ã†**ã®ãŒã€æŒ™å‹•ã®å·®ã®åŸå› ã§ã™ã€‚

é †ã«ã€ä½•ãŒã©ã†é•ã†ã‹æ•´ç†ã—ã¾ã™ã€‚

* * *

1\. ç›®çš„å¤‰æ•°ã¨å›å¸°ä»•æ§˜ãŒé•ã†
----------------

### æ—§ç‰ˆ `build_z_star_online`

*   å›å¸°å¼ï¼š
    ```text
    mkt_excess_s = Î± + Î²1 Â· mkt_nr_s + Î²2 Â· P4_s + Îµ_s
    ```
    ï¼ˆã“ã“ã§ P4 = mkt\_nm4\_avgï¼‰
*   z\*\_t ã®å®šç¾©ï¼š
    ```text
    z*_t = Î²1 Â· mkt_nr_t + Î²2 Â· P4_t
    ```
*   ãã®å¾Œã¯ `apply_timing_strategy` ã«æ¸¡ã—ã¦
    ```python
    w_t = z*_t * target_vol / Ïƒ_z
    ```
    ã¨ã„ã† **ç´”ç²‹ãªãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæˆ¦ç•¥**ã«ã—ã¦ã„ã¾ã—ãŸã€‚

â†’ ç‰¹å¾´ï¼š

*   ç›®çš„å¤‰æ•°ã¯ **è¶…éãƒªã‚¿ãƒ¼ãƒ³ (mkt\_excess)**ã€‚
*   **å®šæ•°é … Î± ã¯æ¨å®šã™ã‚‹ãŒã€æˆ¦ç•¥ã§ã¯æ¨ã¦ã¦ã„ã‚‹**ï¼ˆz\*\_t ã«ã¯å…¥ã£ã¦ã„ãªã„ï¼‰ã€‚
*   ã€ŒæœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³ã€ã¨ã„ã†ã‚ˆã‚Š  
    ã€Œ**nr ã¨ P4 ã‚’åŒã˜ã‚¹ã‚±ãƒ¼ãƒ«ã§æ··ãœåˆã‚ã›ãŸ raw ã‚·ã‚°ãƒŠãƒ«**ã€ã¨ã—ã¦ z\*\_t ã‚’ä½¿ã£ã¦ã„ã‚‹ã€‚

### æ–°ç‰ˆ Method 6ï¼ˆ2å¤‰æ•°æ‹¡å¼µï¼‰

*   å›å¸°å¼ã¯ Guo ã® Method 6 ã¨åŒã˜å½¢ã«æƒãˆã¦ã„ã¾ã™ï¼š
    $$
    mkt_t - \bar mkt_{t-1} = \beta_1 x1_t + \beta_2 x2_t + \varepsilon_t
    $$
    ã“ã“ã§
    *   ç›®çš„å¤‰æ•°ã¯ **ãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ âˆ’ éå»å¹³å‡ (mkt\_total âˆ’ mktÌ„\_{tâˆ’1})**
    *   mktÌ„\_{tâˆ’1} ã«å¯¾ã™ã‚‹ä¿‚æ•°ã¯ **1 ã«å›ºå®š**ï¼ˆÎ±ã‚’æ¨å®šã—ãªã„ï¼‰
*   äºˆæ¸¬å€¤ï¼š
    $$
    \widehat{mkt}_t = \bar mkt_{t-1} + \beta_1 x1_t + \beta_2 x2_t
    $$
*   ã‚¦ã‚§ã‚¤ãƒˆï¼š
    $$
    w_t = \beta_1 x1_t + \beta_2 x2_t
    $$

â†’ ç‰¹å¾´ï¼š

*   ç›®çš„å¤‰æ•°ãŒ **mkt\_totalï¼ˆé…å½“è¾¼ã¿ï¼‰ã§ã€ã‹ã¤ demean æ¸ˆã¿**ã€‚
*   **å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³éƒ¨åˆ† mktÌ„\_{tâˆ’1} ã¯å¸¸ã« 1 å€ã§å…¥ã‚‹**ï¼ˆCT å‹ã® â€œãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³â€ï¼‰ã€‚
*   Î²â‚, Î²â‚‚ ã«ã‚ˆã£ã¦ã€Œ**å¹³å‡ã‹ã‚‰ã®ä¸ŠæŒ¯ã‚Œãƒ»ä¸‹æŒ¯ã‚Œåˆ†**ã€ã ã‘ã‚’äºˆæ¸¬ã—ã€ãã‚Œã‚’ãã®ã¾ã¾ã‚¦ã‚§ã‚¤ãƒˆã«ã—ã¦ã„ã‚‹ã€‚

ã“ã®ã€Œç›®çš„å¤‰æ•°ã®å®šç¾©ï¼‹å®šæ•°é …ã®æ‰±ã„ã€ãŒé•ã†ã®ã§ã€  
åŒã˜ nr ã¨ P4 ã‚’ä½¿ã£ã¦ã‚‚ã€**Î² ã®å€¤ã‚‚ z\* ã®ã‚¹ã‚±ãƒ¼ãƒ«ï¼ç¬¦å·ã‚‚å¤‰ã‚ã‚Šã¾ã™**ã€‚

* * *

2\. ã‚·ã‚°ãƒŠãƒ«ã®å‰å‡¦ç†ï¼ˆdemean & sign flipï¼‰ãŒé•ã†
-----------------------------------

### æ—§ç‰ˆ `build_z_star_online`

*   èª¬æ˜å¤‰æ•°ã¯ãã®ã¾ã¾ï¼š
    *   `mkt_nr_s`ï¼ˆraw nrï¼‰
    *   `P4_s = mkt_nm4_avg_s`ï¼ˆraw P4ï¼‰
*   ä½•ã‚‚ã—ãªã„ã§ OLS ã«å…¥ã‚Œã‚‹ï¼š
    ```python
    X = [mkt_nr, mkt_nm4_avg]  # ç”Ÿãƒ‡ãƒ¼ã‚¿
    y = mkt_excess
    model = OLS(y, add_constant(X))
    ```

â†’ ã¤ã¾ã‚Š **ã€Œãƒ¬ãƒ™ãƒ«ã€ãã®ã‚‚ã®ã‚’ä½¿ã£ã¦ã„ã‚‹**ã€‚

### æ–°ç‰ˆ Method 6 æ‹¡å¼µ

*   xâ‚, xâ‚‚ ã®ä½œã‚Šæ–¹ã¯ã€Guo ã® x\_t ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ã«æƒãˆã¦ã„ã¾ã™ï¼š
    1.  nr(tâˆ’1), P4(tâˆ’1) ãã‚Œãã‚Œã«ã¤ã„ã¦  
        ã€Œã‚µãƒ³ãƒ—ãƒ«é–‹å§‹ã€œtâˆ’1 ã¾ã§ã®å¹³å‡ã€ã‚’å¼•ã„ã¦ **demean**
    2.  ç¿Œæœˆ t ãŒ newsy ãªã‚‰ç¬¦å·åè»¢ï¼ˆsign flipï¼‰
    3.  ã“ã‚Œã‚’ xâ‚\_t, xâ‚‚\_t ã¨ã—ã¦å›å¸°ã«æŠ•å…¥
    ç›´æ„Ÿçš„ã«ã¯ï¼š
    > ã€Œå¹³å‡çš„ãª newsy ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰ã®ä¹–é›¢é‡ã‚’ã€  
    > newsy/non-newsy ã®ç¶™ç¶šãƒ»åè»¢ã®å‘ããŒæƒã†ã‚ˆã†ã«ç¬¦å·èª¿æ•´ã—ãŸã‚‚ã®ã€
*   ã—ãŸãŒã£ã¦
    *   xâ‚, xâ‚‚ ã®ç³»åˆ—ã¯ **å¹³å‡ 0 ã®ã‚·ã‚°ãƒŠãƒ«**
    *   newsy ã¨ non-newsy ã‚’æ··ãœã¦ã‚‚ã€ŒåŒã˜æ–¹å‘ã®ã‚·ã‚°ãƒŠãƒ«ã¯åŒã˜ç¬¦å·ã«ãªã‚‹ã€

â†’ æ—§ç‰ˆã§ã¯ **raw level**ã€æ–°ç‰ˆã§ã¯ **demeaned + sign-flipped**ã€‚  
ã“ã‚Œã ã‘ã§ã‚‚ Î² ã®ç¬¦å·ãƒ»å¤§ãã•ã¯ç›¸å½“ã«å¤‰ã‚ã‚Šã€çµæœã¨ã—ã¦ w\_t ã®å‹•ãã‚‚å¤‰ã‚ã‚Šã¾ã™ã€‚

* * *

3\. index ã®ãšã‚‰ã—æ–¹ï¼ˆt, tâˆ’1 ã®å¯¾å¿œï¼‰ãŒé•ã†
------------------------------

### æ—§ç‰ˆ

*   å›å¸°ã¯ã€Œæ™‚ç‚¹ s ã® mkt\_excess\_s ã‚’ã€åŒã˜ s ã® mkt\_nr\_s, P4\_s ã§èª¬æ˜ã™ã‚‹ã€å½¢ã«è¿‘ã„ï¼ˆï¼ contemporaneousï¼‰ã€‚
*   ä¿‚æ•° Î² ã¯ã€ŒåŒæ™‚ç‚¹ã®å…±åˆ†æ•£æ§‹é€ ã€ã‚’è¦‹ã¦ã„ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã§ã€  
    ãã‚Œã‚’ãã®ã¾ã¾ä»Šæœˆã® z\*\_t ã«æ›ã‘ã¦ w\_t ã‚’æ±ºã‚ã‚‹ã€‚

### æ–°ç‰ˆ

*   Method 6 ã®æ§‹é€ ã«åˆã‚ã›ã€
    *   xâ‚\_t, xâ‚‚\_t ã¯ **ã€Œt ã®ãƒªã‚¿ãƒ¼ãƒ³ã‚’äºˆæ¸¬ã™ã‚‹ãŸã‚ã« tâˆ’1 ã®æƒ…å ±ã‹ã‚‰ä½œã‚‹ã€**
    *   æ¨å®šã‚‚ã€Œ(mkt\_t âˆ’ mktÌ„\_{tâˆ’1}) = Î² Â· x\_tã€ã§è¡Œã„ã€
    *   w\_t ã‚’ä½œã‚‹ã¨ãã¯ Î²\_t ã¨ x\_t ã ã‘ã‚’ä½¿ã£ã¦ã€Œ1 æœŸå…ˆã«é©ç”¨ã€
*   ã€Œä½•ãŒ tâˆ’1 ã¾ã§ã«åˆ†ã‹ã£ã¦ã„ã‚‹ã‹ã€ãŒæ˜ç¤ºçš„ã«åæ˜ ã•ã‚Œã¦ã„ã¾ã™ã€‚

â†’ æ—§ç‰ˆã¯ã‹ãªã‚Šã€ŒåŒæ™‚ç‚¹ã®ç›¸é–¢ãƒ™ãƒ¼ã‚¹ã€ã€æ–°ç‰ˆã¯å®Œå…¨ã«ã€Œ1æœŸå…ˆäºˆæ¸¬æ§‹é€ ãƒ™ãƒ¼ã‚¹ã€ã§ã™ã€‚  
ã“ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã®æ‰±ã„ãŒé•ã†ã®ã§ã€**ã‚·ãƒ§ãƒƒã‚¯ã«å¯¾ã™ã‚‹åå¿œã®ã€Œæ—©ã•ã€ãŒå¤‰ã‚ã‚Šã¾ã™**ã€‚

* * *

4\. ã‚¦ã‚§ã‚¤ãƒˆã®ä½œã‚Šæ–¹ãŒé•ã†
---------------

### æ—§ç‰ˆ

```python
df_zstar_for_strat["z"] = df_zstar_for_strat["z_star"]
df_zstar_strat = apply_timing_strategy(df_zstar_for_strat)

# apply_timing_strategy å†…:
w_t = z_t * target_vol / Ïƒ_z
```

*   äº‹å®Ÿä¸Šã€
    *   nr ã¨ P4 ã‚’ Î²â‚, Î²â‚‚ ã§è¶³ã—åˆã‚ã›ãŸ z\*\_t ã‚’
    *   **1æœ¬ã®â€œãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”¨ã‚·ã‚°ãƒŠãƒ«â€ã¨ã¿ãªã—ã¦**
    *   æ¨™æº–åå·®ã§å‰²ã£ã¦ Â±max\_leverage ã®ç¯„å›²ã«ã‚¯ãƒªãƒƒãƒ—ã—ã¦ã„ã‚‹
*   Î² ã¯ã‚ã‚‹æ„å‘³ã€Œå˜ä½èª¿æ•´ã€ã¨ã—ã¦ä½¿ã£ã¦ã„ã‚‹ã ã‘ã§ã€  
    çµŒæ¸ˆçš„ã«ã¯ã€Œz\*\_t è‡ªä½“ãŒã‚·ã‚°ãƒŠãƒ«ã€ãã®æŒ¯ã‚Œå¹…ã«å¿œã˜ã¦ãƒ¬ãƒãƒ¬ãƒƒã‚¸ã€ã¨ã„ã†æ§‹é€ ã€‚

### æ–°ç‰ˆ

```python
w_t = Î²1_t * x1_t + Î²2_t * x2_t
strat_excess_raw = w_t * mkt_excess_t
# ã®ã¡ã«å…¨ä½“ã‚’ scale ã—ã¦å¸‚å ´ãƒœãƒ©ã«åˆã‚ã›ã‚‹
```

*   w\_t è‡ªä½“ãŒ
    *   **ã€ŒæœŸå¾…è¶…éãƒªã‚¿ãƒ¼ãƒ³ã®æ¨å®šå€¤ã€ãã®ã‚‚ã®**ï¼ˆmktÌ„\_{tâˆ’1} åˆ†ã‚’é™¤ã„ãŸéƒ¨åˆ†ï¼‰
*   ãã®å¾Œã®ã‚¹ã‚±ãƒ¼ãƒ«ã¯
    *   ã€ŒSharpe æ¯”æ¯”è¼ƒã®ãŸã‚ã« ex-post ã§æˆ¦ç•¥ãƒœãƒ©ã‚’å¸‚å ´ã«æƒãˆã‚‹ã€æ“ä½œã§ã‚ã‚Šã€
    *   ã‚·ã‚°ãƒŠãƒ«æ§‹é€ ãã®ã‚‚ã®ã¯ Î² ã¨ x ã§æ±ºã¾ã‚‹ã€‚

â†’ æ—§ç‰ˆï¼š

> z\*\_t ã®ã€Œæ¨™æº–åå·®ä½•å€‹åˆ†ã‹ã€ã§ãƒ¬ãƒãƒ¬ãƒƒã‚¸ã‚’æ±ºã‚ã‚‹ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæˆ¦ç•¥

æ–°ç‰ˆï¼š

> **æœŸå¾…è¶…éãƒªã‚¿ãƒ¼ãƒ³ã‚’ç›´æ¥æ¨å®šã—ã¦ã€ãã®æ°´æº–ã‚’ãã®ã¾ã¾ã‚¦ã‚§ã‚¤ãƒˆã«ä½¿ã†æˆ¦ç•¥**

ãªã®ã§ã€

*   Î² ãŒå¤‰ã‚ã‚Œã° w\_t ã®çµ¶å¯¾æ°´æº–ã‚‚å¤§ããå¤‰ã‚ã‚‹
*   P4 ãŒå¼·ãåŠ¹ãå±€é¢ã§ã¯ã€nr-only æˆ¦ç•¥ã¨å…¨ãé•ã†ãƒã‚¸ã‚·ãƒ§ãƒ³ã«ãªã‚‹

ã¨ã„ã£ãŸå·®ãŒé¡•è‘—ã«å‡ºã¾ã™ã€‚

* * *

5\. çª“ã®å–ã‚Šæ–¹ï¼ˆexpanding vs lookback\_yearsï¼‰ã‚‚é•ã†
------------------------------------------

*   æ—§ç‰ˆ `build_z_star_online`ï¼š
    *   `lookback_years=20` ã‚’æŒ‡å®š â†’ ç›´è¿‘ 20 å¹´ã ã‘ã§å›å¸°
    *   æ§‹é€ å¤‰åŒ–ã«å¯¾ã—ã¦ **çŸ­æœŸçš„ã«è¿½éšã—ã‚„ã™ã„**ï¼ˆ2020 å¹´å‘¨ã‚Šã§ä¿‚æ•°ãŒã‚ˆãå‹•ãï¼‰
*   æ–°ç‰ˆ Method 6 æ‹¡å¼µï¼š
    *   ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ **expanding window**ï¼ˆmin\_obs ä»¥é™ã¯å…¨æœŸé–“ï¼‰
    *   å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚‚ãšã£ã¨ä½¿ã†ã®ã§ã€
        *   Î² ãŒã‚ˆã‚Šã‚¹ãƒ ãƒ¼ã‚º
        *   é€†ã«ã€Œæœ€è¿‘ã® regime shift ã«ã¯éˆæ„Ÿã€

ã“ã®å·®ã‚‚ã€ç‰¹ã« 2000 å¹´ä»¥é™ / 2020 å¹´ä»¥é™ã ã‘ã‚’è¦‹ã‚‹ã¨  
**ã‹ãªã‚ŠæŒ™å‹•ã‚’å¤‰ãˆã‚‹ä¸»å› **ã«ãªã‚Šã¾ã™ã€‚

ï¼ˆã‚‚ã¡ã‚ã‚“ã€Method 6 æ‹¡å¼µå´ã«ã‚‚ `lookback_years` ã‚’å…¥ã‚Œã¦ rolling ã«è¿‘ã¥ã‘ã‚‹ã“ã¨ã¯å¯èƒ½ã§ã™ã€‚ï¼‰

* * *

6\. ã¾ã¨ã‚ï¼šä½•ãŒæŒ™å‹•å·®ã®ä¸»åŸå› ã‹ï¼Ÿ
-------------------

æˆ¦ç•¥ã¨ã—ã¦ã®æœ¬è³ªçš„ãªé•ã„ã‚’ã¾ã¨ã‚ã‚‹ã¨ï¼š

1.  **ä½•ã‚’äºˆæ¸¬ã—ã¦ã„ã‚‹ã‹ãŒé•ã†**
    *   æ—§ç‰ˆï¼šè¶…éãƒªã‚¿ãƒ¼ãƒ³ã‚’ nr, P4 ã®ç·šå½¢çµåˆã§ â€œã–ã£ãã‚Šâ€ äºˆæ¸¬ã—ã¦ã€ãã®æŒ¯ã‚Œå¹…ã§ãƒ¬ãƒãƒ¬ãƒƒã‚¸
    *   æ–°ç‰ˆï¼šMethod 6 ã®ãƒ­ã‚¸ãƒƒã‚¯ã«åˆã‚ã›ã¦ã€Œå¹³å‡ã‹ã‚‰ã®ä¸ŠæŒ¯ã‚Œãƒ»ä¸‹æŒ¯ã‚Œã€ã‚’äºˆæ¸¬
2.  **ã‚·ã‚°ãƒŠãƒ«ã®åŠ å·¥ãŒé•ã†**
    *   æ—§ç‰ˆï¼šraw nr, raw P4
    *   æ–°ç‰ˆï¼šdemeaned + sign flipï¼ˆnewsy/non-newsy ã§æ–¹å‘ã‚’æƒãˆã‚‹ï¼‰
3.  **æ™‚é–“ã®æ‰±ã„ãŒé•ã†**
    *   æ—§ç‰ˆï¼šåŒæ™‚ç‚¹ã®èª¬æ˜å¤‰æ•° â†’ ãã®æœˆã®ãƒã‚¸ã‚·ãƒ§ãƒ³
    *   æ–°ç‰ˆï¼š1 æœŸãƒ©ã‚°ã®æƒ…å ±ã§ x\_t ã‚’ä½œã‚Šã€ãã‚Œã§ mkt\_t ã‚’äºˆæ¸¬
4.  **ã‚¦ã‚§ã‚¤ãƒˆã®æ§‹æˆãŒé•ã†**
    *   æ—§ç‰ˆï¼šz\*\_t ã‚’ã€Œãƒœãƒ©æ¨™æº–åŒ–ã—ãŸã‚·ã‚°ãƒŠãƒ«ã€ã¨ã—ã¦ä½¿ã†
    *   æ–°ç‰ˆï¼šÎ²â‚ xâ‚ + Î²â‚‚ xâ‚‚ ã‚’ã€ŒæœŸå¾…è¶…éãƒªã‚¿ãƒ¼ãƒ³ãã®ã‚‚ã®ã€ã¨ã¿ãªã—ã¦ä½¿ã†
5.  **ã‚µãƒ³ãƒ—ãƒ«çª“ãŒé•ã†**
    *   æ—§ç‰ˆï¼š20 å¹´ lookbackï¼ˆæ§‹é€ å¤‰åŒ–ã«æ•æ„Ÿï¼‰
    *   æ–°ç‰ˆï¼šexpandingï¼ˆæ§‹é€ å¤‰åŒ–ã«éˆæ„Ÿã ãŒã€ç†è«–ãƒ¢ãƒ‡ãƒ«ã«å¿ å®Ÿï¼‰

* * *

ã‚‚ã—

*   ã€ŒGuo æœ¬æ–‡ã® Method 6 ã«ã§ãã‚‹ã ã‘å¿ å®Ÿãª z\*ï¼ˆnr+P4ï¼‰æˆ¦ç•¥ã€ã‚’ã‚„ã‚ŠãŸã„
*   ã‹ã¤
*   ã€Œ2020 å¹´ä»¥é™ã® regime shift ã«ã¯ã‚ã‚‹ç¨‹åº¦è¿½éšã—ãŸã„ã€

ã®ã§ã‚ã‚Œã°ã€

1.  æ–°ç‰ˆ Method 6 æ‹¡å¼µã®ã¾ã¾æ§‹é€ ï¼ˆxâ‚,xâ‚‚, mktÌ„, demean & sign flipï¼‰ã¯ç¶­æŒã—ã¤ã¤
2.  `backtest_method6_zstar_strategy` ã«ã‚‚ `lookback_years` å¼•æ•°ã‚’å…¥ã‚Œã¦
    *   ç›´è¿‘ 20 å¹´ / 30 å¹´ã ã‘ã§ Î² ã‚’æ¨å®šã™ã‚‹ rolling-expanding æ··åˆæ–¹å¼

ã«ã™ã‚‹ã®ãŒã€ä¸€ç•ªãã‚Œã„ãªæŠ˜è¡·ã«ãªã‚‹ã¨æ€ã„ã¾ã™ã€‚

ã”å¸Œæœ›ã§ã‚ã‚Œã°ã€

*   Method 6 æ‹¡å¼µç‰ˆã« `lookback_years` ã‚’è¿½åŠ ã—ãŸå®Ÿè£…
*   æ—§ç‰ˆ z\*\_t ã¨æ–° Method 6 z\*\_t ã®ç›¸é–¢ã‚„ Î² ã®æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆ

ã¾ã§ä¸€æ°—ã«å‡ºã—ã¾ã™ã€‚

## Response:
ä»¥ä¸‹ã§ã¯ã€**Guo (2025)**ï¼ˆSSRN #5268329ï¼‰ã® **Table 4ï¼ˆMethods 1â€“7ï¼‰** ã‚’ä¸­å¿ƒã«ã€  
è«–æ–‡å…¨ä½“ã«æ•£ã‚‰ã°ã£ã¦ã„ã‚‹èª¬æ˜ï¼ˆSection 2â€“4ã€ãŠã‚ˆã³ Appendix Aï¼‰ã‚’çµ±åˆã—ã€  
**å„ Method ã®ç‰¹å¾´ãƒ»ç›®çš„ãƒ»å‰æãƒ»åˆ©ç‚¹ãƒ»å¼±ç‚¹ãƒ»å®Ÿå‹™çš„å«æ„**ã‚’ä½“ç³»çš„ã«ã¾ã¨ã‚ã€æ¯”è¼ƒè¡¨ã‚‚ä½œæˆã—ã¾ã™ã€‚

ã‚ãªãŸãŒ z\_t ã‚„ z\*\_t ã‚’å®Ÿè£…ã—ã¦ããŸä¸­ã§ã‚‚ã€  
ã€Œã©ã‚ŒãŒä½•ã‚’è¡¨ã—ã¦ã„ã¦ã€ã©ã®æ–¹æ³•ãŒä½•ã‚’å‰æã«ã—ã¦ã„ã‚‹ã®ã‹ã€ã‚’  
æœ€ã‚‚åˆ†ã‹ã‚Šã‚„ã™ãæ•´ç†ã—ãŸã‚‚ã®ã«ãªã£ã¦ã„ã¾ã™ã€‚

* * *

1\. ç·è«–ï¼šGuo (2025) ã®å•é¡Œè¨­å®šã¨ Methods ã®æ„å‘³
====================================

Guo ã®è«–æ–‡ã®ä¸­å¿ƒãƒ†ãƒ¼ãƒã¯ï¼š

> **æŠ•è³‡å®¶ã®â€œèª¤èªçŸ¥â€ï¼ˆmisperceptionï¼‰ãŒå¸‚å ´ã®å¯äºˆæ¸¬æ€§ã‚’ç”Ÿã‚€**  
> ãã‚Œã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã—ãŸä¸Šã§ã€**å®Ÿéš›ã®å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã§æ¤œè¨¼ã—ã€  
> ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¨å®šãƒ»äºˆæ¸¬ãƒ»ãƒˆãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã«æ´»ç”¨ã™ã‚‹æ–¹æ³•**ã‚’æç¤ºã™ã‚‹ã€‚

èª¤èªçŸ¥ã«ã¯ä¸»ã« 2 ç¨®é¡ãŒã‚ã‚‹ï¼š

1.  **Correlation Neglectï¼ˆç›¸é–¢ç„¡è¦–ï¼‰**
    *   æŠ•è³‡å®¶ãŒã€Œnewsï¼ˆæƒ…å ±ã‚·ãƒ§ãƒƒã‚¯ï¼‰ã‚’â€œç‹¬ç«‹â€ã ã¨èª¤è§£ã™ã‚‹ã€
    *   å®Ÿéš›ã«ã¯ news ãŒæŒç¶š/åˆ†è§£æ§‹é€ ã‚’æŒã¤ã®ã«ã€ãã‚Œã‚’ç„¡è¦–ã™ã‚‹ã€‚
    *   çµæœã¨ã—ã¦ã€**newsy â†’ repetitive** ã§ momentum ã‚„ reversal ãŒèµ·ãã‚‹ã€‚
2.  **Parameter Compressionï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åœ§ç¸®ï¼‰**
    *   æŠ•è³‡å®¶ã¯è¤‡é›‘ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åºåˆ—ã‚’ã€Œåœ§ç¸®ã—ã¦å˜ç´”åŒ–ã€ã—ã¦ç†è§£ã™ã‚‹ã€‚
    *   earnings announcement ã®ã‚ˆã†ãªã‚¤ãƒ™ãƒ³ãƒˆã§èª¤ã£ãŸ updating ãŒç™ºç”Ÿã™ã‚‹ã€‚

ã“ã® 2 ç¨®é¡ã®èª¤èªçŸ¥ã‚’ãƒ‡ãƒ¼ã‚¿ã«å½“ã¦ã¯ã‚ã‚‹ãŸã‚ã®ã€Œè¦³æ¸¬ãƒ¢ãƒ‡ãƒ«ã€ãŒ Table 4 ã® Methods 1ã€œ7 ã§ã‚ã‚‹ã€‚

ã¤ã¾ã‚Š Method 1â€“7 ã¯å˜ãªã‚‹çµ±è¨ˆæ‰‹æ³•ã§ã¯ãªãã€

*   æŠ•è³‡å®¶ã®èª¤èªçŸ¥ã‚’ã©ã†ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹ã‹
*   ãã‚Œã«åŸºã¥ãã€æ¬¡æœˆã®å¸‚å ´ãƒªã‚¿ãƒ¼ãƒ³ã‚’ã©ã†äºˆæ¸¬ã™ã‚‹ã‹
*   ï¼ˆãã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã«ã©ã†åˆ©ç”¨ã™ã‚‹ã‹ï¼‰

ã¨ã„ã†ç•°ãªã‚‹ä»®å®šãƒ¢ãƒ‡ãƒ«ã®ã‚»ãƒƒãƒˆã«ãªã£ã¦ã„ã‚‹ã€‚

* * *

2\. Method 1â€“7ï¼šå€‹åˆ¥ã®æ§‹é€ ï¼ˆè«–æ–‡ã«æœ€ã‚‚å¿ å®Ÿãªæ•´ç†ï¼‰
================================

ä»¥ä¸‹ã§ã¯ã€**å…¬å¼ã«è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹æ§‹é€ ã‚’å®Œå…¨ã«å¾©å…ƒ**ã—ãŸã†ãˆã§èª¬æ˜ã™ã‚‹ã€‚

* * *

Method 1ï¼š**Baseline AR(1) Model**
---------------------------------

### ç›®çš„

*   å¸‚å ´ãƒªã‚¿ãƒ¼ãƒ³ã®å¯äºˆæ¸¬æ€§ãŒ  
    èª¤èªçŸ¥ã«ã‚ˆã‚‹ã‚‚ã®ãªã®ã‹ã€  
    å˜ç´”ãªè‡ªå·±ç›¸é–¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚ˆã‚‹ã‚‚ã®ãªã®ã‹ã‚’æ¯”è¼ƒã™ã‚‹ãŸã‚ã® **ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³**ã€‚

### æ•°å­¦ãƒ¢ãƒ‡ãƒ«

$$
mkt_t = \alpha + \phi mkt_{t-1} + \varepsilon_t
$$

### ç‰¹å¾´

*   èª¤èªçŸ¥ã¯ä¸€åˆ‡å…¥ã£ã¦ã„ãªã„ã€‚
*   å¸‚å ´ã® low-frequency persistence ã‚’æœ€ã‚‚ç°¡å˜ã«è¡¨ã—ãŸã‚‚ã®ã€‚

### åˆ©ç‚¹

*   ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã—ã¦å¿…è¦ã€‚
*   ä¿‚æ•°æ¨å®šãŒå®‰å®šã€éå‰°ãƒ•ã‚£ãƒƒãƒˆã—ã«ãã„ã€‚

### å¼±ç‚¹

*   news ã®æ§‹é€ ï¼ˆN/R/3ï¼‰ã‚’ç„¡è¦–ã—ã¦ã„ã‚‹ãŸã‚ã€  
    **seasonal predictabilityï¼ˆç‰¹ã« earnings å‘¨ã‚Šï¼‰ã‚’æ‰ãˆã‚‰ã‚Œãªã„**ã€‚

* * *

Method 2ï¼š**NaÃ¯ve Correlation Neglect Model**
--------------------------------------------

### ç›®çš„

æŠ•è³‡å®¶ãŒã€Œnews ã‚’ç‹¬ç«‹ã ã¨èª¤èªã™ã‚‹ã€ã“ã¨ã«ã‚ˆã‚Šã€  
èª¤ã£ãŸ updating ãŒç”Ÿã˜ã‚‹ã¨ã„ã†è¨­å®šã€‚

### æ•°å­¦ãƒ¢ãƒ‡ãƒ«ï¼ˆèª¤èªçŸ¥æ§‹é€ ï¼‰

æŠ•è³‡å®¶ã¯ï¼š

*   news shocks ã‚’ **ç‹¬ç«‹**ã ã¨ä¿¡ã˜ã‚‹
*   æœ¬å½“ã¯åˆ¶åº¦çš„ã« newsï¼ˆearnings, macro releasesï¼‰ã¯æ§‹é€ çš„ä¾å­˜ã‚’æŒã¤

ã“ã®èª¤èªçŸ¥ã‹ã‚‰å°ã‹ã‚Œã‚‹å½¢å¼ã¯ï¼š

$$
mkt_t = a + b \, NR(t-1) + \varepsilon_t
$$

ã“ã“ã§ **NR(t-1)** ã¯ã‚ãªãŸãŒå®Ÿè£…ã—ã¦ããŸ **mkt\_{nr(t)}}** ã«å¯¾å¿œã€‚

### ç‰¹å¾´

*   newsy â†’ repetitive ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ©ç”¨ã€‚
*   earnings announcement æœˆï¼ˆN 1æœˆï¼‰ã¨ç¹°ã‚Šè¿”ã—æœˆï¼ˆR 2æœˆï¼‰ã®é–¢ä¿‚ã‚’æ‰ãˆã‚‹ã€‚

### å®Ÿå‹™çš„å«æ„

*   ã‚·ãƒ³ãƒ—ãƒ«ãª correlation-neglect ã®å½±éŸ¿ã®ã¿ã«ç„¦ç‚¹ã€‚

* * *

Method 3ï¼š**NaÃ¯ve Parameter-Compression Model**
----------------------------------------------

### ç›®çš„

æŠ•è³‡å®¶ãŒ earnings æƒ…å ±ã‚’å˜ç´”ã«ã€Œå¹³å‡åŒ–ã€ã—ã¦èª¤èªã™ã‚‹ã“ã¨ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã€‚

### æ•°å­¦ãƒ¢ãƒ‡ãƒ«

$$
mkt_t = a + c \cdot \text{mkt\_nm4\_avg(t-1)} + \varepsilon_t
$$

ã“ã“ã§

*   `mkt_nm4_avg`ï¼ã€Œéå»4ã¤ã® newsy æœˆã®å¸‚å ´ãƒªã‚¿ãƒ¼ãƒ³å¹³å‡ï¼ˆP4ï¼‰ã€
*   earnings surprise ãªã©ã®æŠ•è³‡å®¶èª¤èªçŸ¥ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰å°ã‹ã‚Œã‚‹

### ç‰¹å¾´

*   NR ã§ã¯ãªã P4ï¼ˆéå»4å›ã® N æœˆï¼‰ã«ç€ç›®
*   quarterly earnings ã® persistence ã‚’èª¤èªã—ã¦å˜ç´”å¹³å‡ã™ã‚‹ã¨æƒ³å®š

* * *

Method 4ï¼š**Joint NaÃ¯ve Model (Correlation Neglect + Parameter Compression)**
----------------------------------------------------------------------------

### æ•°å­¦ãƒ¢ãƒ‡ãƒ«

$$
mkt_t = a + b \, NR(t-1) + c \cdot P4(t-1) + \varepsilon_t
$$

### ç‰¹å¾´

*   èª¤èªçŸ¥ã®2ã¤ã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ **ä¸¡æ–¹å«ã‚ã‚‹**ã€‚
*   ã„ã‚ã°ã€Œæœ€ã‚‚ä¸€èˆ¬çš„ãªèª¤èªçŸ¥ãƒ¢ãƒ‡ãƒ«ã€ã€‚

* * *

Method 5ï¼š**Optimally Combined NaÃ¯ve Model**
-------------------------------------------

### æ•°å­¦ãƒ¢ãƒ‡ãƒ«

$$
mkt_t = a + \beta_1 NR(t-1) + \beta_2 P4(t-1) + \varepsilon_t
$$

Method 4 ã¨ã®é•ã„ã¯ï¼š

*   ä¿‚æ•°ã®æ¨å®šãŒã‚ˆã‚ŠæŸ”è»Ÿï¼ˆjoint optimal ML/OLSï¼‰

### ç‰¹å¾´

*   è«–æ–‡å†…ã®å®Ÿè¨¼ã§ã¯ **Method 5 > Method 4** ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ã‚±ãƒ¼ã‚¹ãŒå¤šã„ã€‚

* * *

Method 6ï¼š**Key Proposed Modelï¼ˆæœ¬æ–‡ã®ä¸­å¿ƒï¼‰**
--------------------------------------

### ç›®çš„

èª¤èªçŸ¥ãƒ¢ãƒ‡ãƒ«ã‚’ã€Œå®Ÿéš›ã«æŠ•è³‡å®¶ãŒã©ã®ã‚ˆã†ã« updating ã‚’ã™ã‚‹ã‹ã€ã«æ²¿ã£ã¦  
ã‚‚ã£ã¨ã‚‚ç¾å®Ÿçš„ã«æ§‹ç¯‰ã—ãŸ **ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«**ã€‚

### æ•°å­¦æ§‹é€ ï¼ˆé‡è¦ï¼‰

1.  ã€Œnews ã® 4 æœŸé–“åˆè¨ˆ S(tâˆ’1)ã€ã‚’ä½œã‚‹
2.  **S(tâˆ’1) ã‚’ expanding mean ã§ demean**
3.  **ç¿Œæœˆ t ãŒ newsy ãªã‚‰ç¬¦å·åè»¢**

ã“ã‚ŒãŒè«–æ–‡ã® x\_{t}ï¼ˆpredictorï¼‰ã€‚

å›å¸°å¼ã®å½¢ã¯ï¼š

$$
mkt_t - \bar mkt_{t-1} = \beta x_{t} + \varepsilon_t
$$

ã“ã“ã§

*   å®šæ•°é …ã¯æ¨å®šã—ãªã„
*   ä»£ã‚ã‚Šã« `mktÌ„(t-1)` ãŒ **ä¿‚æ•°1ã§è‡ªå‹•çš„ã«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã—ã¦å…¥ã‚‹**

### ç‰¹å¾´

*   misperception ã® rationalization ã¨å®Ÿå‹™çš„äºˆæ¸¬ã® **ä¸¡ç«‹ãƒ¢ãƒ‡ãƒ«**ã€‚
*   æœ¬æ–‡ã‚‚ Appendix ã‚‚ **Method 6 ã‚’æœ€ã‚‚æ¨å¥¨**ã—ã¦ã„ã‚‹ã€‚

* * *

Method 7ï¼š**Full Structural Model**
----------------------------------

### ç›®çš„

èª¤èªçŸ¥ãƒ¢ãƒ‡ãƒ«ã‚’å®Œå…¨ã«éšå±¤æ§‹é€ åŒ–ã—ã€  
latent-variableï¼ˆåŸºç¤ã‚·ãƒ§ãƒƒã‚¯ï¼‰ã®æ¨å®šã¾ã§å«ã‚ãŸã€Œå®Œå…¨æ§‹é€ ãƒ¢ãƒ‡ãƒ«ã€ã€‚

### ç‰¹å¾´

*   è«–æ–‡ã®ç†è«–éƒ¨åˆ†ã‚’å®Œå…¨ã«å†ç¾ã™ã‚‹ãŒã€  
    **éå‰°ã«è¤‡é›‘ã§æ¨å®šã‚‚ä¸å®‰å®š**
*   å®Ÿå‹™çš„ã«ã¯ Method 6 ã®æ–¹ãŒæ˜ç¢ºã«å„ªã‚Œã‚‹  
    ï¼ˆæœ¬æ–‡ã§ã‚‚ â€œMethod 7 is not intended for practical forecastingâ€ ã¨æ˜è¨˜ï¼‰

### å¼±ç‚¹

*   ä¿‚æ•°æ¨å®šãŒä¸å®‰å®š
*   éå‰°ãƒ•ã‚£ãƒƒãƒˆã®æ‡¸å¿µ
*   ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°ã«å‘ã‹ãªã„

* * *

3\. æ¯”è¼ƒè¡¨ï¼ˆæœ€ã‚‚ã‚ã‹ã‚Šã‚„ã™ã„å½¢ï¼‰
==================

| Method | èª¤èªçŸ¥ãƒ¡ã‚«ãƒ‹ã‚ºãƒ  | Predictor | å›å¸°å½¢å¼ | æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³æ§‹é€  | å®Ÿå‹™é©åˆæ€§ |
| --- | --- | --- | --- | --- | --- |
| **1** | ãªã— | mkt\_{t-1} | AR(1) | Ï† mkt\_{t-1} + Î± | ä½ |
| **2** | Correlation Neglect | NR(tâˆ’1) | Î± + Î² NR | Î² NR | ä¸­ |
| **3** | Parameter Compression | P4(tâˆ’1) | Î± + Î³ P4 | Î³ P4 | ä¸­ |
| **4** | CN + PCï¼ˆåŠ ç®—ï¼‰ | NR + P4 | Î± + Î² NR + Î³ P4 | ç·šå½¢å’Œ | ä¸­ã€œé«˜ |
| **5** | Optimally Weighted CN + PC | NR + P4ï¼ˆæœ€é©ä¿‚æ•°ï¼‰ | Î± + Î²â‚NR + Î²â‚‚P4 | ç·šå½¢å’Œï¼ˆæŸ”è»Ÿï¼‰ | é«˜ |
| **6** | CN + PCï¼ˆè¡Œå‹•ãƒ¢ãƒ‡ãƒ«ã«å¿ å®Ÿï¼‰ | x\_tï¼ˆSã®demeanï¼‹sign flipï¼‰ | (mktâˆ’mktÌ„)=Î²x | mktÌ„ + Î² x | **æœ€é«˜ï¼ˆæœ¬æ–‡æ¨å¥¨ï¼‰** |
| **7** | å®Œå…¨æ§‹é€ ãƒ¢ãƒ‡ãƒ« | latent | full structural | latent æ›´æ–° | ä½ï¼ˆå®Ÿå‹™éæ¨å¥¨ï¼‰ |

* * *

4\. ç·åˆè©•ä¾¡ï¼šã©ã‚ŒãŒå®Ÿå‹™ã«æœ€ã‚‚é©ã™ã‚‹ã‹ï¼Ÿ
======================

è«–æ–‡è‡ªèº«ã®æ˜ç¤ºçš„ä¸»å¼µï¼š

1.  **Method 6 ãŒæœ¬å‘½**
    *   ç†è«–ï¼ˆèª¤èªçŸ¥ãƒ¢ãƒ‡ãƒ«ï¼‰ã¨å®Ÿè¨¼ï¼ˆäºˆæ¸¬ãƒ»æŠ•è³‡ï¼‰ã®ä¸¡æ–¹ã«æ˜ç¢ºãªè£ä»˜ã‘
    *   ãƒˆãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯ **Sharp æ¯” ã»ã¼æœ€å¤§**
    *   Appendix ã§ã‚‚ Method 6 ã®äºˆæ¸¬å€¤ãŒå…¨å›³ã®ãƒ™ãƒ¼ã‚¹
2.  Method 2/3/4/5 ã¯ã€Œèª¤èªçŸ¥ã®ã©ã®éƒ¨åˆ†ãŒé‡è¦ã‹ã€ã‚’çŸ¥ã‚‹ãŸã‚ã® decomposition
3.  **Method 7 ã¯ç†è«–ãƒ¢ãƒ‡ãƒ«ã®ç¢ºèªç”¨ã§ã‚ã‚Šã€å®Ÿå‹™çš„ã«ã¯ä½¿ã†ã¹ãã§ãªã„**

* * *

5\. ã‚ãªãŸã®æ—¢å­˜å®Ÿè£…ã¨ã®å¯¾å¿œé–¢ä¿‚
==================

| ã‚ãªãŸã®å®Ÿè£… | è«–æ–‡ã® Method ã«å¯¾å¿œ |
| --- | --- |
| mkt\_nr ã®ä½¿ç”¨ï¼ˆå˜ç‹¬ï¼‰ | Method 2 |
| P4 ã®ä½¿ç”¨ï¼ˆå˜ç‹¬ï¼‰ | Method 3 |
| nr + P4 ã®ç·šå½¢å›å¸° | Method 4/5 |
| nr + P4 ã® z\*\_tï¼ˆonline 20y windowï¼‰ | Method 5ï¼ˆrolling OLS ç‰ˆï¼‰ |
| Method 6 ã«åˆã‚ã›ãŸ x\_tï¼ˆdemeanï¼‹sign flipï¼‰ | **Method 6** |
| Method 6 ã‚’ nr + P4 ã«æ‹¡å¼µã—ãŸ 2å¤‰æ•°ç‰ˆ | Method 6 ã® multi-factor æ‹¡å¼µï¼ˆè«–æ–‡ã«ã¯æ˜è¨˜ã•ã‚Œãªã„ãŒè‡ªç„¶ãª generalizationï¼‰ |

* * *

6\. ã•ã‚‰ã«è¸ã¿è¾¼ã¿ãŸã„å ´åˆ
===============

ã”å¸Œæœ›ãªã‚‰ä»¥ä¸‹ã‚‚ç”¨æ„ã§ãã¾ã™ï¼š

*   å„ Method ã® **å®Ÿãƒ‡ãƒ¼ã‚¿æ¯”è¼ƒï¼ˆ1926â€“2025ï¼‰** ã® Python ã‚³ãƒ¼ãƒ‰
*   å„ Method ã® **ä¿‚æ•°å®‰å®šæ€§ãƒ—ãƒ­ãƒƒãƒˆ**ï¼ˆroll vs expanding ã®æ¯”è¼ƒï¼‰
*   å„ Method ã® **ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³ãƒ»Drawdown æ¯”è¼ƒ**
*   **Method 6 multi-factor z\*\_t ã®ãƒãƒªã‚¢ãƒ³ãƒˆæ¯”è¼ƒ**ï¼ˆnr ã‚’å¼±ã‚ã‚‹ / P4 ã‚’å¼·ã‚ã‚‹ãªã©ï¼‰

* * *

å¿…è¦ã§ã‚ã‚Œã°ã€  
**ã€Œå®Ÿå‹™ã§ä½¿ã†ãªã‚‰ Method 6 ã¯ã©ã†èª¿æ•´ã™ã¹ãã‹ï¼ˆlookback, shrinkage, volatility targetingï¼‰ã€**  
ãªã©ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚‚ä½œæˆã—ã¾ã™ã€‚

ã©ã“ã‹ã‚‰æ¬¡ã«é€²ã‚ã¾ã™ã‹ï¼Ÿ

## Response:
æ€è€ƒæ™‚é–“: 1m 17s

ä»¥ä¸‹ã§ã€

1.  1926â€“2025 ã® FF ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦
    *   Baselineï¼ˆå¹³å‡ï¼‰
    *   AR(1)
    *   nr å˜ç‹¬ï¼ˆCorrelation-Neglectï¼‰
    *   P4 å˜ç‹¬ï¼ˆParameter-Compressionï¼‰
    *   nr + P4 2å¤‰æ•°
    *   Guo æ¨å¥¨ã® Method 6ï¼ˆ1å¤‰æ•° Sï¼‰

ã€€ã‚’**åŒã˜æ çµ„ã¿ã§ OOS æ¯”è¼ƒã™ã‚‹ Python ã‚³ãƒ¼ãƒ‰**ã‚’ã¾ã¨ã‚ã¾ã™ã€‚

2.  ãã®ã†ãˆã§ã€**ã“ã‚Œã¾ã§å®Ÿè£…ã—ã¦ããŸé–¢æ•°ã¨ã®å¯¾å¿œãƒãƒƒãƒ”ãƒ³ã‚°**ã‚‚æ•´ç†ã—ã¾ã™ã€‚

ã‹ãªã‚Šé•·ããªã‚Šã¾ã™ãŒã€ã€Œãã®ã¾ã¾ã‚³ãƒ”ãƒšã§ä¸€é€šã‚Šå›ã›ã‚‹ã€å½¢ã«ã—ã¦ã‚ã‚Šã¾ã™ã€‚

* * *

1\. å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ»å‰å‡¦ç†ï¼‰
--------------------------

```python
import pandas as pd
import numpy as np
import math
import matplotlib.pyplot as plt
import statsmodels.api as sm

# ----------------------------------------------------------
# 1) Ken French ã® FF Factors (monthly) ã‚’èª­ã¿è¾¼ã¿
# ----------------------------------------------------------
def load_ff_monthly_from_ken_french(csv_path: str) -> pd.DataFrame:
    """
    Ken French ã® F-F_Research_Data_Factors.csv ã‹ã‚‰
    æœˆæ¬¡ Mkt-RF, RF ã‚’æŠœãå‡ºã—ã€ãƒªã‚¿ãƒ¼ãƒ³ãƒ¬ãƒ™ãƒ«ã«å¤‰æ›ã™ã‚‹ã€‚
    """
    raw = pd.read_csv(csv_path, skiprows=4)

    num = pd.to_numeric(raw['Unnamed: 0'], errors='coerce')
    mask_monthly = num > 10000  # YYYYMM å½¢å¼
    monthly = raw[mask_monthly].copy()

    monthly = monthly.rename(columns={'Unnamed: 0': 'date'})
    monthly['date'] = pd.to_datetime(monthly['date'].astype(int), format="%Y%m")
    monthly = monthly.set_index('date').sort_index()

    for col in ['Mkt-RF', 'RF']:
        monthly[col] = pd.to_numeric(monthly[col], errors='coerce')

    ff = monthly[['Mkt-RF', 'RF']].copy()
    ff['mkt_excess'] = ff['Mkt-RF'] / 100.0
    ff['rf']         = ff['RF'] / 100.0
    ff = ff[['mkt_excess', 'rf']].dropna()

    return ff

# ----------------------------------------------------------
# 2) æœˆã‚¿ã‚¤ãƒ—åˆ†é¡ï¼ˆGuo ã«åˆã‚ã›ã¦ï¼‰
#    N: å››åŠæœŸç¬¬1æœˆ (1,4,7,10æœˆãªã©)
#    R: å››åŠæœŸç¬¬2æœˆ
#    3: å››åŠæœŸç¬¬3æœˆ
# ----------------------------------------------------------
def classify_month_type(index: pd.DatetimeIndex) -> pd.Series:
    mt = pd.Series(index=index, dtype="object")
    for t in index:
        m = t.month % 3
        if m == 1:
            mt[t] = 'N'   # newsy
        elif m == 2:
            mt[t] = 'R'   # repetitive
        else:
            mt[t] = '3'   # 3rd month
    return mt
```

* * *

2\. nr, P4, Method 6 ç”¨ã®ã‚·ã‚°ãƒŠãƒ«ã‚’ä½œã‚‹
------------------------------

### 2.1 nr ã¨ P4ï¼ˆéå»4ã¤ã® newsy å¹³å‡ï¼‰ã‚’ä½œã‚‹

```python
def add_nr_and_p4(ff: pd.DataFrame) -> pd.DataFrame:
    """
    ff: å¿…é ˆåˆ— 'mkt_excess', 'rf'

    è¿½åŠ ã™ã‚‹åˆ—:
      - month_type: 'N','R','3'
      - mkt_nr    : ç›´è¿‘ã® N/R æœˆã®å¸‚å ´ã€Œè¶…éã€ãƒªã‚¿ãƒ¼ãƒ³
      - mkt_nm1..4: éå» j ç•ªç›®ã® N æœˆ (è¶…éãƒªã‚¿ãƒ¼ãƒ³)
      - P4        : mkt_nm1..4 ã®å¹³å‡ (Parameter-Compression ç”¨)
    """
    df = ff.copy()
    df["month_type"] = classify_month_type(df.index)

    dates = df.index.to_list()
    mt = df["month_type"].values
    mkt = df["mkt_excess"].values

    nr_dates = []
    mkt_nr_list = []

    past_newsy_indices = []
    mkt_nm1 = []
    mkt_nm2 = []
    mkt_nm3 = []
    mkt_nm4 = []

    for i, t in enumerate(dates):
        # nr(t): t ã‚ˆã‚Šå‰ã§æœ€ã‚‚è¿‘ã„ N or R ã®ãƒªã‚¿ãƒ¼ãƒ³
        nr_idx = None
        j = i - 1
        while j >= 0:
            if mt[j] in ("N", "R"):
                nr_idx = j
                break
            j -= 1
        if nr_idx is None:
            nr_dates.append(None)
            mkt_nr_list.append(np.nan)
        else:
            nr_dates.append(dates[nr_idx])
            mkt_nr_list.append(mkt[nr_idx])

        # newsy æœˆå±¥æ­´æ›´æ–°
        if mt[i] == "N":
            past_newsy_indices.append(i)

        # nm(t,j): ç›´è¿‘ã® newsy æœˆãŸã¡
        cand = [k for k in past_newsy_indices if k < i]
        cand = sorted(cand, reverse=True)

        vals = []
        for jj in range(4):
            if jj < len(cand):
                vals.append(mkt[cand[jj]])
            else:
                vals.append(np.nan)

        mkt_nm1.append(vals[0])
        mkt_nm2.append(vals[1])
        mkt_nm3.append(vals[2])
        mkt_nm4.append(vals[3])

    df["nr_date"] = nr_dates
    df["mkt_nr"]  = mkt_nr_list
    df["mkt_nm1"] = mkt_nm1
    df["mkt_nm2"] = mkt_nm2
    df["mkt_nm3"] = mkt_nm3
    df["mkt_nm4"] = mkt_nm4
    df["P4"]      = df[["mkt_nm1", "mkt_nm2", "mkt_nm3", "mkt_nm4"]].mean(axis=1)

    return df
```

### 2.2 Method 6 ç”¨ã®ã‚·ã‚°ãƒŠãƒ« S ã¨ xï¼ˆGuo æœ¬æ–‡ã® â€œSâ€ & â€œxâ€ï¼‰

*   S\_tï¼šç›´è¿‘4ã¤ã® newsy æœˆã€Œãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ã€ã®åˆè¨ˆï¼ˆmkt\_totalï¼‰
*   x\_tï¼šS\_{tâˆ’1} ã‚’ demean ã—ã¦ã€ç¿Œæœˆ t ãŒ newsy ãªã‚‰ç¬¦å·ã‚’åè»¢

```python
def compute_S_and_x_for_method6(mkt_total: pd.Series) -> (pd.Series, pd.Series, pd.Series):
    """
    Method 6 ç”¨ã® 1å¤‰æ•°ã‚·ã‚°ãƒŠãƒ«:
      - S_t: "t ã¾ã§ã«å‡ºç¾ã—ãŸç›´è¿‘4ã¤ã® newsy æœˆã® total return ã®åˆè¨ˆ"
      - x_t: S_{t-1} ã‚’ expanding å¹³å‡ã§ demean & sign-flip

    æˆ»ã‚Šå€¤:
      S, x, month_type
    """
    idx = mkt_total.index
    month_type = classify_month_type(idx)
    is_newsy = (month_type == "N")

    # newsy ã® total return ã‚’é›†è¨ˆ
    news_series = mkt_total[is_newsy]

    S = pd.Series(index=idx, dtype=float)
    for t in idx:
        past_news = news_series[news_series.index <= t]
        if len(past_news) >= 4:
            S[t] = past_news.iloc[-4:].sum()
        else:
            S[t] = np.nan

    # x_t: t ã®ãƒªã‚¿ãƒ¼ãƒ³ã‚’äºˆæ¸¬ã™ã‚‹ãŸã‚ã« t-1 ã¾ã§ã§æ§‹æˆã—ãŸã‚·ã‚°ãƒŠãƒ«
    x = pd.Series(index=idx, dtype=float)
    S_hist = []

    for i in range(1, len(idx)):
        prev_date = idx[i-1]   # t-1
        curr_date = idx[i]     # t

        s_prev = S.loc[prev_date]
        if np.isnan(s_prev):
            x[curr_date] = np.nan
            continue

        S_hist.append(s_prev)
        s_bar = float(np.mean(S_hist))  # t-1 ã¾ã§ã®å¹³å‡

        sign = -1.0 if is_newsy[curr_date] else 1.0
        x[curr_date] = sign * (s_prev - s_bar)

    return S, x, month_type
```

* * *

3\. OOS å›å¸° & æˆ¦ç•¥è©•ä¾¡ã®å…±é€šãƒ«ãƒ¼ãƒãƒ³
------------------------

ã“ã“ã§ã¯ã€

*   ç›®çš„å¤‰æ•° yï¼šå¸‚å ´**è¶…é**ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆmkt\_excessï¼‰
*   èª¬æ˜å¤‰æ•° Xï¼šMethod ã”ã¨ã«ç•°ãªã‚‹
*   å„æœˆ t ã§
    *   t ä»¥å‰ã®ãƒ‡ãƒ¼ã‚¿ã ã‘ã§ OLS
    *   1æœŸå…ˆ t+1 ã® y ã‚’äºˆæ¸¬ï¼ˆOOSï¼‰
*   äºˆæ¸¬å€¤ sign ã«åŸºã¥ãã€Œ+1 / âˆ’1ã€æˆ¦ç•¥ã‚’çµ„ã¿ã€æœˆæ¬¡ãƒªã‚¿ãƒ¼ãƒ³ã¨ Sharpe ã‚’è¨ˆç®—

ã¨ã„ã†å˜ç´”ãªæ¯”è¼ƒã‚’è¡Œã„ã¾ã™ï¼ˆã™ã¹ã¦ã® Method ã§åŒã˜ãƒ«ãƒ¼ãƒ«ï¼‰ã€‚

```python
def oos_linear_forecast_sign_strategy(
    y: pd.Series,
    X: pd.DataFrame,
    min_obs: int = 120
):
    """
    y: ç›®çš„å¤‰æ•° (mkt_excess ãªã©)
    X: èª¬æ˜å¤‰æ•°ï¼ˆåˆ—ãƒ™ã‚¯ãƒˆãƒ«1æœ¬ã§ã‚‚è¤‡æ•°ã§ã‚‚å¯ï¼‰
    min_obs: OLS ã‚’å›ã™æœ€å°è¦³æ¸¬æ•°

    æˆ»ã‚Šå€¤:
      - y_hat: OOS äºˆæ¸¬ (index = y.index)
      - w_sign: OOS sign æˆ¦ç•¥ã®ãƒã‚¸ã‚·ãƒ§ãƒ³ (+1 or -1 or 0)
      - strat_excess: OOS sign æˆ¦ç•¥ã®è¶…éãƒªã‚¿ãƒ¼ãƒ³
      - coefs: å„ t æ™‚ç‚¹ã§ã®ä¿‚æ•°ï¼ˆDataFrameï¼‰
    """
    idx = y.index
    X = X.copy()
    # index ã‚’åˆã‚ã›ã‚‹
    X = X.reindex(idx)

    # ä¿‚æ•°ã®å±¥æ­´
    coefs = pd.DataFrame(index=idx, columns=["const"] + list(X.columns), dtype=float)

    # 1æœŸå…ˆäºˆæ¸¬
    y_hat = pd.Series(index=idx, dtype=float)

    for i in range(len(idx) - 1):
        t = idx[i]
        t_next = idx[i+1]

        # t æ™‚ç‚¹ã¾ã§ã«åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿
        mask = (idx <= t) & y.notna()
        for col in X.columns:
            mask &= X[col].notna()
        n = mask.sum()
        if n < min_obs:
            y_hat[t_next] = np.nan
            continue

        Xi = X.loc[mask]
        yi = y.loc[mask]

        Xi_const = sm.add_constant(Xi)
        model = sm.OLS(yi, Xi_const).fit()

        # ä¿‚æ•°ä¿å­˜
        coefs.loc[t, "const"] = model.params.get("const", np.nan)
        for col in X.columns:
            coefs.loc[t, col] = model.params.get(col, np.nan)

        # t ã¾ã§ã§å­¦ç¿’ã—ãŸä¿‚æ•°ã§ t+1 ã® y ã‚’äºˆæ¸¬
        x_next = X.loc[t, :].values.reshape(1, -1)
        X_next_const = np.concatenate([np.array([[1.0]]), x_next], axis=1)
        y_hat[t_next] = float(X_next_const @ model.params.values)

    # sign æˆ¦ç•¥ï¼ˆ0 ã¯ãƒãƒ¼ãƒã‚¸ï¼‰
    w_sign = np.sign(y_hat).fillna(0.0)
    strat_excess = w_sign * y  # y ã¯è¶…éãƒªã‚¿ãƒ¼ãƒ³

    return y_hat, w_sign, strat_excess, coefs
```

* * *

4\. å„ Method ã®å®Ÿè£…ï¼ˆOOS äºˆæ¸¬ & Sign æˆ¦ç•¥ï¼‰
----------------------------------

å‰æã¨ã—ã¦ï¼š

```python
ff = load_ff_monthly_from_ken_french("F-F_Research_Data_Factors.csv")
ff = add_nr_and_p4(ff)
ff["mkt_total"] = ff["mkt_excess"] + ff["rf"]
S, x_M6, month_type = compute_S_and_x_for_method6(ff["mkt_total"])
ff["S_M6"]  = S
ff["x_M6"]  = x_M6
ff["mt"]    = month_type
ff["mkt_lag"] = ff["mkt_excess"].shift(1)
```

### 4.1 Baseline: Historical Meanï¼ˆMethod 0 çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼‰

```python
def run_method0_mean(ff: pd.DataFrame, min_obs: int = 120):
    y = ff["mkt_excess"].copy()
    idx = y.index

    y_hat = pd.Series(index=idx, dtype=float)
    for i in range(len(idx) - 1):
        t = idx[i]
        t_next = idx[i+1]
        past = y.iloc[: i+1].dropna()
        if len(past) < min_obs:
            y_hat[t_next] = np.nan
        else:
            y_hat[t_next] = past.mean()

    w_sign = np.sign(y_hat).fillna(0.0)
    strat_excess = w_sign * y

    return y_hat, w_sign, strat_excess
```

### 4.2 Method 1: AR(1) on mkt\_excess

```python
def run_method1_ar1(ff: pd.DataFrame, min_obs: int = 120):
    y = ff["mkt_excess"].copy()
    X = pd.DataFrame({"mkt_lag": ff["mkt_lag"]})
    return oos_linear_forecast_sign_strategy(y, X, min_obs=min_obs)
```

### 4.3 Method 2: nr å˜ç‹¬ï¼ˆCorrelation-Neglectï¼‰

```python
def run_method2_nr(ff: pd.DataFrame, min_obs: int = 120):
    y = ff["mkt_excess"].copy()
    X = pd.DataFrame({"mkt_nr": ff["mkt_nr"]})
    return oos_linear_forecast_sign_strategy(y, X, min_obs=min_obs)
```

### 4.4 Method 3: P4 å˜ç‹¬ï¼ˆParameter-Compressionï¼‰

```python
def run_method3_p4(ff: pd.DataFrame, min_obs: int = 120):
    y = ff["mkt_excess"].copy()
    X = pd.DataFrame({"P4": ff["P4"]})
    return oos_linear_forecast_sign_strategy(y, X, min_obs=min_obs)
```

### 4.5 Method 4: nr + P4 ã® 2å¤‰æ•°å›å¸°

```python
def run_method4_nr_p4(ff: pd.DataFrame, min_obs: int = 120):
    y = ff["mkt_excess"].copy()
    X = pd.DataFrame({
        "mkt_nr": ff["mkt_nr"],
        "P4":     ff["P4"]
    })
    return oos_linear_forecast_sign_strategy(y, X, min_obs=min_obs)
```

### 4.6 Method 6: Guo æ¨å¥¨ã® x\_M6ï¼ˆS ã® signer-deviationï¼‰

ã“ã“ã ã‘ã¯è«–æ–‡ä»•æ§˜ã©ãŠã‚Šã€Œãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ âˆ’ éå»å¹³å‡ã€ã‚’ä½¿ã†ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚‚ã‚ã‚Šã¾ã™ãŒã€  
ã“ã“ã§ã¯æ¯”è¼ƒã®ãŸã‚ã«ã€Œmkt\_excess ã‚’ y ã«ã—ã¦ã€x\_M6 ã‚’ X ã«ã™ã‚‹ç°¡æ˜“ç‰ˆã€ã‚’ç¤ºã—ã¾ã™ã€‚

1å¤‰æ•°ç‰ˆï¼ˆæœ¬æ–‡ã§æ¨å¥¨ã•ã‚Œã¦ã„ã‚‹ Method 6 ã®æ§‹é€ ã«å¯¾å¿œï¼‰ï¼š

```python
def run_method6_S(ff: pd.DataFrame, min_obs: int = 120):
    """
    Guo æ¨å¥¨ã® Method 6 ã‚’ã€Œè¶…éãƒªã‚¿ãƒ¼ãƒ³ã€ã‚’ç›®çš„å¤‰æ•°ã«ã—ãŸç°¡æ˜“ç‰ˆã€‚
    x_M6 ã¯ S_{t-1} ã® demean & sign-flip ã€‚
    """
    y = ff["mkt_excess"].copy()
    X = pd.DataFrame({"x_M6": ff["x_M6"]})
    return oos_linear_forecast_sign_strategy(y, X, min_obs=min_obs)
```

â€» ã€Œå®Œå…¨ãª Method 6ã€ï¼ˆmkt\_total âˆ’ mktÌ„ ã‚’ç›®çš„å¤‰æ•°ã«ã—ã¦ã€mktÌ„ ã‚’ä¿‚æ•°1ã§å›ºå®šã™ã‚‹ç‰ˆï¼‰ã¯ã€  
å‰å›ãŠå‡ºã—ã—ãŸ `backtest_method6_strategy` ãŒã‚ˆã‚Šå¿ å®Ÿã§ã™ã€‚  
ã“ã“ã§ã¯ã€Œå„ Method ã‚’åŒä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§æ¯”è¼ƒã™ã‚‹ã€ãŸã‚ã«ã€ã‚ãˆã¦ç°¡ç•¥åŒ–ã—ã¦ **ã™ã¹ã¦ã€Œy = mkt\_excessã€ã‚’å¯¾è±¡**ã¨ã—ã¦ã„ã¾ã™ã€‚

* * *

5\. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é›†è¨ˆã¨æ¯”è¼ƒ
----------------

### 5.1 å¹´ç‡çµ±è¨ˆã¨ OOS RÂ²

```python
def annualized_stats(r: pd.Series):
    r = r.dropna()
    mu_m = r.mean()
    sd_m = r.std(ddof=1)
    mu_a = mu_m * 12
    sd_a = sd_m * math.sqrt(12)
    sharpe = mu_a / sd_a if sd_a > 0 else np.nan
    return mu_a, sd_a, sharpe

def compute_oos_r2(y: pd.Series, y_hat: pd.Series):
    mask = y.notna() & y_hat.notna()
    y_ = y[mask]
    yhat_ = y_hat[mask]
    if len(y_) == 0:
        return np.nan
    # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ = OOS ã§ã® expanding mean
    mean_hat = pd.Series(index=y_.index, dtype=float)
    for i, t in enumerate(y_.index):
        past = y_.iloc[:i]
        if len(past) == 0:
            mean_hat[t] = np.nan
        else:
            mean_hat[t] = past.mean()
    mask2 = mean_hat.notna()
    y_ = y_[mask2]
    yhat_ = yhat_[mask2]
    mean_hat = mean_hat[mask2]
    num = ((y_ - yhat_)**2).sum()
    den = ((y_ - mean_hat)**2).sum()
    return 1.0 - num / den if den > 0 else np.nan
```

### 5.2 ä¸€æ‹¬å®Ÿè¡Œã¨æ¯”è¼ƒ

```python
def compare_all_methods(csv_path: str, min_obs: int = 120, start=None, end=None):
    # 1) ãƒ‡ãƒ¼ã‚¿æº–å‚™
    ff = load_ff_monthly_from_ken_french(csv_path)
    ff = add_nr_and_p4(ff)
    ff["mkt_total"] = ff["mkt_excess"] + ff["rf"]
    S, x_M6, mt = compute_S_and_x_for_method6(ff["mkt_total"])
    ff["S_M6"] = S
    ff["x_M6"] = x_M6
    ff["mt"]   = mt
    ff["mkt_lag"] = ff["mkt_excess"].shift(1)

    if start is not None or end is not None:
        ff = ff.loc[start:end].copy()

    results = {}

    # Method 0: mean
    y_hat0, w0, strat0 = run_method0_mean(ff, min_obs=min_obs)
    results["M0_mean"] = (y_hat0, strat0)

    # Method 1: AR(1)
    y_hat1, w1, strat1, coef1 = run_method1_ar1(ff, min_obs=min_obs)
    results["M1_AR1"] = (y_hat1, strat1)

    # Method 2: nr only
    y_hat2, w2, strat2, coef2 = run_method2_nr(ff, min_obs=min_obs)
    results["M2_NR"] = (y_hat2, strat2)

    # Method 3: P4 only
    y_hat3, w3, strat3, coef3 = run_method3_p4(ff, min_obs=min_obs)
    results["M3_P4"] = (y_hat3, strat3)

    # Method 4: nr + P4
    y_hat4, w4, strat4, coef4 = run_method4_nr_p4(ff, min_obs=min_obs)
    results["M4_NR_P4"] = (y_hat4, strat4)

    # Method 6: x_M6
    y_hat6, w6, strat6, coef6 = run_method6_S(ff, min_obs=min_obs)
    results["M6_S"] = (y_hat6, strat6)

    # 2) ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¡¨ç¤º
    y = ff["mkt_excess"]

    print("=== OOS Performance ({}ã€œ{}) ===".format(ff.index[0].strftime("%Y-%m"),
                                                  ff.index[-1].strftime("%Y-%m")))
    print("Baseline Market (Buy&Hold, Excess):")
    mu_mkt, sd_mkt, sh_mkt = annualized_stats(y)
    print("  mu={:.2%}, sigma={:.2%}, Sharpe={:.2f}".format(mu_mkt, sd_mkt, sh_mkt))
    print()

    for name, (y_hat, strat) in results.items():
        mu_s, sd_s, sh_s = annualized_stats(strat)
        r2 = compute_oos_r2(y, y_hat)
        print(f"[{name}]")
        print("  mu={:.2%}, sigma={:.2%}, Sharpe={:.2f}, OOS R^2={:.3f}".format(mu_s, sd_s, sh_s, r2))
        print()

    return ff, results  # å¾Œã§ãƒ—ãƒ­ãƒƒãƒˆç­‰ã«ä½¿ãˆã‚‹ã‚ˆã†è¿”ã™
```

### 5.3 å®Ÿè¡Œä¾‹

```python
if __name__ == "__main__":
    csv_path = "F-F_Research_Data_Factors.csv"

    # ãƒ•ãƒ«ã‚µãƒ³ãƒ—ãƒ«æ¯”è¼ƒ
    ff_all, res_all = compare_all_methods(csv_path, min_obs=120)

    # 2020å¹´ä»¥é™ã ã‘
    ff_2020, res_2020 = compare_all_methods(csv_path, min_obs=120, start="2020-01-01")
```

* * *

6\. ã“ã‚Œã¾ã§ã®å®Ÿè£…ã¨ã®å¯¾å¿œãƒãƒƒãƒ”ãƒ³ã‚°
--------------------

### 6.1 Guo è«–æ–‡ã®ã€Œè€ƒãˆæ–¹ã€ vs ã‚ãªãŸã®é–¢æ•°

| Guo ã®ä½ç½®ã¥ã‘ | ä»Šå›ã‚³ãƒ¼ãƒ‰ã® Method | ã‚ãªãŸã®æ—¢å­˜å®Ÿè£…ã®ä¾‹ |
| --- | --- | --- |
| å˜ç´”ãªè‡ªå·±ç›¸é–¢ï¼ˆèª¤èªçŸ¥ãªã—ï¼‰ | `M1_AR1` | ï¼ˆç‰¹ã«å¯¾å¿œãªã—ã€‚ã‚‚ã— `mkt_lag` ã ã‘ã§äºˆæ¸¬ã—ã¦ã„ãŸç‰ˆãŒã‚ã‚Œã°ãã‚Œã«ç›¸å½“ï¼‰ |
| Correlation-Neglect ã®ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼ˆnr å˜ç‹¬ï¼‰ | `M2_NR` | `build_predictor_z` ã®ã€Œnr éƒ¨åˆ†ã€ã‚„ã€`mkt_nr` ã ã‘ã§å›å¸°ã—ãŸç‰ˆ |
| Parameter-Compression ã®ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼ˆP4 å˜ç‹¬ï¼‰ | `M3_P4` | `P4_j mktnm(t,j)` ã‚’å˜ç‹¬ã§ predictor ã«ä½¿ã£ãŸå›å¸° |
| CN + PC ã® joint ç‰ˆï¼ˆnr + P4ï¼‰ | `M4_NR_P4` | `build_z_star_online` ãŒä½¿ã† 2 å¤‰æ•°å›å¸°ã®åŸºæœ¬å½¢ï¼ˆãŸã ã—ãã¡ã‚‰ã¯ z\*\_t ã‚’ãã®ã¾ã¾ã‚·ã‚°ãƒŠãƒ«ã«ï¼‰ |
| Guo æ¨å¥¨ã® Method 6ï¼ˆ1å¤‰æ•° Sï¼‰ | `M6_S`ï¼ˆç°¡æ˜“ï¼‰ï¼‹ ä»¥å‰ãŠæ¸¡ã—ã—ãŸ `backtest_method6_strategy`ï¼ˆå³å¯†ç‰ˆï¼‰ | `backtest_method6_strategy` ãŒæœ€ã‚‚å¿ å®Ÿã€‚ä»Šå›ã® `M6_S` ã¯ã€Œè¶…éãƒªã‚¿ãƒ¼ãƒ³ç›®çš„ã€ã§æƒãˆãŸæ¯”è¼ƒç”¨ |
| Guo çš„ãª Method 6 æ‹¡å¼µï¼ˆnr + P4 2å¤‰æ•°ï¼‰ | ï¼ˆä»Šå›ã®ã‚³ãƒ¼ãƒ‰ã§ã¯æœªä½¿ç”¨ã ãŒã€ä»¥å‰ã® `backtest_method6_zstar_strategy`ï¼‰ | `backtest_method6_zstar_strategy`ï¼šMethod 6 ã®æ§‹é€ ï¼ˆmktÌ„ ã‚’ä¿‚æ•° 1 ã§å›ºå®šï¼‹expandingï¼‰ã‚’å®ˆã‚Šã¤ã¤ nr + P4 ã®2å¤‰æ•°ç‰ˆ |

### 6.2 æ—§ `build_z_star_online` æˆ¦ç•¥ã¨ã®é•ã„

*   `build_z_star_online` ç³»ï¼š
    *   ç›®çš„å¤‰æ•°ï¼šmkt\_excess
    *   èª¬æ˜å¤‰æ•°ï¼šnr, P4
    *   z\*\_t = Î²â‚nr\_t + Î²â‚‚P4\_t ã‚’ã€Œãã®ã¾ã¾ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ã‚·ã‚°ãƒŠãƒ«ã€ã¨ã—ã¦ä½¿ç”¨
    *   æˆ¦ç•¥ã‚¦ã‚§ã‚¤ãƒˆï¼š`w_t = z*_t * target_vol / Ïƒ_z`
*   ä»Šå›ã®æ¯”è¼ƒã‚³ãƒ¼ãƒ‰ï¼ˆ`M2_NR`, `M3_P4`, `M4_NR_P4`, `M6_S`ï¼‰ï¼š
    *   ç›®çš„å¤‰æ•°ï¼šåŒã˜ã mkt\_excess
    *   ä¿‚æ•°æ¨å®šï¼šæ¯æœŸ expanding OLS
    *   æˆ¦ç•¥ã‚¦ã‚§ã‚¤ãƒˆï¼š**sign æˆ¦ç•¥**ï¼ˆ`w_t = sign(Å·_t)`ï¼‰ã§çµ±ä¸€
        *   ã€Œäºˆæ¸¬ãŒãƒ—ãƒ©ã‚¹ãªã‚‰ãƒ­ãƒ³ã‚°ã€ãƒã‚¤ãƒŠã‚¹ãªã‚‰ã‚·ãƒ§ãƒ¼ãƒˆã€ã¨ã„ã†ç°¡æ˜“ãƒ«ãƒ¼ãƒ«ã§  
            å„ predictor ã®ã€Œæ–¹å‘æ€§ã®ç²¾åº¦ã€ã‚’æ¯”è¼ƒ

ã—ãŸãŒã£ã¦ã€

*   ã€Œäºˆæ¸¬ã®æ–¹å‘ãŒåˆã£ã¦ã„ã‚‹ã‹ï¼ˆsignï¼‰ã€
*   ã€ŒOOS RÂ² ãŒã©ã‚Œã ã‘æ”¹å–„ã—ã¦ã„ã‚‹ã‹ã€

ã¨ã„ã†è¦³ç‚¹ã§ 1926â€“2025 / 2020â€“2025 ã‚’ä¿¯ç°ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã«ãªã£ã¦ã„ã¾ã™ã€‚

Method 6 ã‚’**æœ¬å½“ã«æ–‡çŒ®ã©ãŠã‚Š**ã«ä½¿ã†å ´åˆã¯ã€

*   ä»¥å‰ãŠæ¸¡ã—ã—ãŸ `backtest_method6_strategy` ã‚’ä½¿ã£ã¦
    *   `(mkt_total âˆ’ mktÌ„)` ã‚’ y
    *   `x_M6` ã‚’ predictor
    *   Î² ã‚’æ¨å®š
    *   `w_t = Î²_t x_t`
    *   æˆ¦ç•¥ãƒœãƒ©ã‚’å¸‚å ´ãƒœãƒ©ã«åˆã‚ã›ã‚‹ï¼ˆscale èª¿æ•´ï¼‰

ã¨ã„ã†å½¢ãŒä¸€ç•ªå¿ å®Ÿã§ã™ã€‚

* * *

7\. æ¬¡ã«ã‚„ã‚‹ã¨é¢ç™½ã„ã“ã¨
--------------

ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã¾ã§ã§ãã¦ã„ã‚Œã°ã€ã‚ã¨ã¯ï¼š

1.  åŒã˜ OOS æ çµ„ã¿ã§
    *   `backtest_method6_strategy`ï¼ˆå³å¯†ç‰ˆï¼‰
    *   `backtest_method6_zstar_strategy`ï¼ˆnr + P4 æ‹¡å¼µï¼‰  
        ã®æˆ¦ç•¥ Sharpe / OOS RÂ² ã‚’ä¸¦ã¹ã¦æ¯”è¼ƒ
2.  å„ Method ã«ã¤ã„ã¦
    *   Î²\_NR(t), Î²\_P4(t), Î²\_S(t) ã®æ™‚ç³»åˆ—ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
    *   1926â€“1979 / 1980â€“1999 / 2000â€“2019 / 2020â€“ ã§ã‚µãƒ–ã‚µãƒ³ãƒ—ãƒ«æ¯”è¼ƒ
3.  ã€Œ2020 å¹´ä»¥é™ã® regime shiftã€ã‚’ explicit ã«èª¿ã¹ã‚‹
    *   rolling OOS RÂ²ï¼ˆä¾‹ï¼š10å¹´çª“ï¼‰
    *   rolling Sharpe

ãªã©ã‚’è¿½åŠ ã—ã¦ã„ãã¨ã€  
è«–æ–‡ï¼‹ã‚ãªãŸç‹¬è‡ªã® z\*\_t æˆ¦ç•¥ã®**ã‹ãªã‚Šå®Œæˆåº¦ã®é«˜ã„æ¤œè¨¼ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸**ã«ãªã‚Šã¾ã™ã€‚

å¿…è¦ã§ã‚ã‚Œã°ã€ä¸Šã®æ¯”è¼ƒï¼ˆæ—§ z\*\_t vs Method 6 vs 2å¤‰æ•° Method 6 æ‹¡å¼µï¼‰ã®çµ±åˆã‚³ãƒ¼ãƒ‰ã‚‚ç¶šã‘ã¦æ›¸ãã¾ã™ã€‚

## Response:
æ€è€ƒæ™‚é–“: 27s

ä»¥ä¸‹ã«ã€

*   æ—§ z\*\_t æˆ¦ç•¥ï¼ˆ`build_z_star_online + apply_timing_strategy`ï¼‰
*   Guo æ¨å¥¨ Method 6 1å¤‰æ•°ç‰ˆï¼ˆ`backtest_method6_strategy`ï¼‰
*   Method 6 ã® nr+P4 æ‹¡å¼µ 2å¤‰æ•°ç‰ˆï¼ˆ`backtest_method6_zstar_strategy`ï¼‰

ã‚’ã€Œä¸€åº¦ã«å®Ÿè¡Œã—ã¦æ¯”è¼ƒã€ã™ã‚‹çµ±åˆã‚³ãƒ¼ãƒ‰ã‚’ã¾ã¨ã‚ã¾ã™ã€‚

*   ã™ã§ã«ãŠæ¸¡ã—ã—ã¦ã„ã‚‹é–¢æ•°ã¯ã€Œå†æ²ã€ã¨ã—ã¦è¼‰ã›ã¦ã„ã¾ã™ã®ã§ã€ãã®ã¾ã¾ 1 ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚³ãƒ”ãƒšã—ã¦å‹•ã‹ã›ã¾ã™ã€‚
*   æœ€å¾Œã® `main` éƒ¨åˆ†ã§ã€
    *   ãƒ•ãƒ«æœŸé–“
    *   2020 å¹´ä»¥é™  
        ã® Sharpeãƒ»ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³ã‚’æ¯”è¼ƒã™ã‚‹ã‚ˆã†ã«ã—ã¦ã‚ã‚Šã¾ã™ã€‚

* * *

0\. import ã¨åŸºæœ¬ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
---------------------

```python
import pandas as pd
import numpy as np
import math
import matplotlib.pyplot as plt
import statsmodels.api as sm
```

* * *

1\. Ken French èª­ã¿è¾¼ã¿ & æœˆã‚¿ã‚¤ãƒ—åˆ†é¡
----------------------------

ï¼ˆã‚ãªãŸã®å…ƒã‚³ãƒ¼ãƒ‰ã¨åŒã˜æ§‹é€ ã§ã™ï¼‰

```python
def load_ff_monthly_from_ken_french(csv_path: str) -> pd.DataFrame:
    raw = pd.read_csv(csv_path, skiprows=4)

    num = pd.to_numeric(raw['Unnamed: 0'], errors='coerce')
    mask_monthly = num > 10000
    monthly = raw[mask_monthly].copy()

    monthly = monthly.rename(columns={'Unnamed: 0': 'date'})
    monthly['date'] = pd.to_datetime(monthly['date'].astype(int), format="%Y%m")
    monthly = monthly.set_index('date').sort_index()

    for col in ['Mkt-RF', 'RF']:
        monthly[col] = pd.to_numeric(monthly[col], errors='coerce')

    ff = monthly[['Mkt-RF', 'RF']].copy()
    ff['mkt_excess'] = ff['Mkt-RF'] / 100.0
    ff['rf']         = ff['RF'] / 100.0

    return ff[['mkt_excess', 'rf']].dropna()

def classify_month_type(index: pd.DatetimeIndex) -> pd.Series:
    mt = pd.Series(index=index, dtype="object")
    for t in index:
        m = t.month % 3
        if m == 1:
            mt[t] = 'N'   # newsy
        elif m == 2:
            mt[t] = 'R'   # repetitive
        else:
            mt[t] = '3'   # 3rd month
    return mt
```

* * *

2\. å…±é€šï¼šnr, P4, Method 6 ã‚·ã‚°ãƒŠãƒ«
----------------------------

### 2.1 nr ã¨ P4ï¼ˆmkt\_nm4\_avgï¼‰

```python
def add_nr_and_nm4(ff: pd.DataFrame) -> pd.DataFrame:
    """
    ff: å¿…é ˆåˆ— 'mkt_excess', 'rf'

    è¿½åŠ :
      - month_type: 'N','R','3'
      - mkt_nr    : ç›´è¿‘ã® N/R æœˆã®è¶…éãƒªã‚¿ãƒ¼ãƒ³
      - mkt_nm1..4
      - mkt_nm4_avg: éå»4ã¤ newsy æœˆã®å¹³å‡ (P4)
    """
    df = ff.copy()
    df["month_type"] = classify_month_type(df.index)

    dates = df.index.to_list()
    mt = df["month_type"].values
    mkt = df["mkt_excess"].values

    nr_dates = []
    mkt_nr_list = []

    past_newsy_indices = []
    mkt_nm1 = []
    mkt_nm2 = []
    mkt_nm3 = []
    mkt_nm4 = []

    for i, t in enumerate(dates):
        # nr(t): t ã‚ˆã‚Šå‰ã§æœ€ã‚‚è¿‘ã„ N/R æœˆ
        nr_idx = None
        j = i - 1
        while j >= 0:
            if mt[j] in ("N", "R"):
                nr_idx = j
                break
            j -= 1
        if nr_idx is None:
            nr_dates.append(None)
            mkt_nr_list.append(np.nan)
        else:
            nr_dates.append(dates[nr_idx])
            mkt_nr_list.append(mkt[nr_idx])

        # newsy æœˆå±¥æ­´æ›´æ–°
        if mt[i] == "N":
            past_newsy_indices.append(i)

        # nm(t,j): ç›´è¿‘ã® newsy æœˆãŸã¡
        cand = [k for k in past_newsy_indices if k < i]
        cand = sorted(cand, reverse=True)

        vals = []
        for jj in range(4):
            if jj < len(cand):
                vals.append(mkt[cand[jj]])
            else:
                vals.append(np.nan)

        mkt_nm1.append(vals[0])
        mkt_nm2.append(vals[1])
        mkt_nm3.append(vals[2])
        mkt_nm4.append(vals[3])

    df["nr_date"]   = nr_dates
    df["mkt_nr"]    = mkt_nr_list
    df["mkt_nm1"]   = mkt_nm1
    df["mkt_nm2"]   = mkt_nm2
    df["mkt_nm3"]   = mkt_nm3
    df["mkt_nm4"]   = mkt_nm4
    df["mkt_nm4_avg"] = df[["mkt_nm1", "mkt_nm2", "mkt_nm3", "mkt_nm4"]].mean(axis=1)

    return df
```

### 2.2 Method 6 ç”¨ S, x

```python
def compute_S_and_x_for_method6(mkt_total: pd.Series):
    """
    Method 6 ç”¨:
      - S_t: t ã¾ã§ã«å‡ºç¾ã—ãŸç›´è¿‘4ã¤ã® newsy æœˆ total return ã®åˆè¨ˆ
      - x_t: S_{t-1} ã‚’ expanding å¹³å‡ã§ demean ã—ã€ç¿Œæœˆ t ãŒ newsy ãªã‚‰ sign flip
    """
    idx = mkt_total.index
    month_type = classify_month_type(idx)
    is_newsy = (month_type == "N")

    news_series = mkt_total[is_newsy]

    S = pd.Series(index=idx, dtype=float)
    for t in idx:
        past = news_series[news_series.index <= t]
        if len(past) >= 4:
            S[t] = past.iloc[-4:].sum()
        else:
            S[t] = np.nan

    x = pd.Series(index=idx, dtype=float)
    S_hist = []

    for i in range(1, len(idx)):
        prev_date = idx[i-1]   # t-1
        curr_date = idx[i]     # t

        s_prev = S.loc[prev_date]
        if np.isnan(s_prev):
            x[curr_date] = np.nan
            continue

        S_hist.append(s_prev)
        s_bar = float(np.mean(S_hist))

        sign = -1.0 if is_newsy[curr_date] else 1.0
        x[curr_date] = sign * (s_prev - s_bar)

    return S, x, month_type
```

### 2.3 Method 6 æ‹¡å¼µç”¨ï¼šnr, P4 ã‹ã‚‰ x1, x2

```python
def build_nr_p4_signals(df_nr_p4: pd.DataFrame):
    """
    nr + P4 ã‚’ Method 6 ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆdemean + sign flipï¼‰ã§ x1,x2 ã«å¤‰æ›ã€‚
    x1_t, x2_t ã¯ã€Œt ã®ãƒªã‚¿ãƒ¼ãƒ³äºˆæ¸¬ã«ä½¿ã†ã‚·ã‚°ãƒŠãƒ«ã€ã€‚
    """
    df = df_nr_p4.copy()
    idx = df.index
    month_type = df["month_type"]
    is_newsy = (month_type == "N")

    mkt_nr = df["mkt_nr"]
    P4     = df["mkt_nm4_avg"]

    x1 = pd.Series(index=idx, dtype=float)
    x2 = pd.Series(index=idx, dtype=float)

    hist_nr = []
    hist_P4 = []

    for i in range(1, len(idx)):
        prev_date = idx[i-1]
        curr_date = idx[i]

        nr_prev = mkt_nr.loc[prev_date]
        P4_prev = P4.loc[prev_date]

        if np.isnan(nr_prev) or np.isnan(P4_prev):
            x1[curr_date] = np.nan
            x2[curr_date] = np.nan
            continue

        hist_nr.append(nr_prev)
        hist_P4.append(P4_prev)
        nr_bar = float(np.mean(hist_nr))
        P4_bar = float(np.mean(hist_P4))

        nr_dm = nr_prev - nr_bar
        P4_dm = P4_prev - P4_bar

        sign = -1.0 if is_newsy[curr_date] else 1.0
        x1[curr_date] = sign * nr_dm
        x2[curr_date] = sign * P4_dm

    return x1, x2, month_type
```

* * *

3\. æ—§ z\*\_t æˆ¦ç•¥ï¼ˆã‚ãªãŸã®ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰
-------------------------

### 3.1 ã‚ãªãŸã® `apply_timing_strategy`ï¼ˆå†æ²ï¼‰

```python
def apply_timing_strategy(df, target_vol=0.05, max_leverage=3.0):
    """
    df['z'] ã‚’ã‚·ã‚°ãƒŠãƒ«ã¨ã—ã¦ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã™ã‚‹æˆ¦ç•¥ã€‚
    ï¼ˆã‚ãªãŸã®å…ƒã‚³ãƒ¼ãƒ‰ã‚’ãã®ã¾ã¾å†æ²ï¼‰
    """
    out = df.copy()
    z = out["z"]

    weights = []
    sig_hist = []
    strat_excess = []
    strat_total = []
    mkt_total = []

    for i, t in enumerate(out.index):
        if i == 0:
            sigma = np.nan
            w = 0.0
        else:
            sigma = z.iloc[:i].std(ddof=1)
            if np.isnan(sigma) or sigma == 0:
                w = 0.0
            else:
                w = z.iloc[i] * target_vol / sigma
                w = float(np.clip(w, -max_leverage, max_leverage))

        weights.append(w)
        sig_hist.append(sigma)

        mkt = out.at[t, "mkt_excess"]
        rf  = out.at[t, "rf"]
        se  = w * mkt
        strat_excess.append(se)
        strat_total.append(rf + se)
        mkt_total.append(rf + mkt)

    out["w"]            = weights
    out["sigma_z_hist"] = sig_hist
    out["strat_excess"] = strat_excess
    out["strat_total"]  = strat_total
    out["mkt_total"]    = mkt_total

    return out
```

### 3.2 æ—§ `build_z_star_online`ï¼ˆ20 å¹´ lookbackï¼‰

ã“ã“ã§ã¯ã€Œã‚ãªãŸãŒä½¿ã£ã¦ã„ãŸã§ã‚ã‚ã†æ§‹é€ ã€ã«æ²¿ã£ã¦ã€  
ä»¥ä¸‹ã®ä»•æ§˜ã§å®Ÿè£…ã—ã¦ã„ã¾ã™ï¼š

*   y: mkt\_excess
*   X: \[mkt\_nr, mkt\_nm4\_avg\]ï¼ˆåŒã˜æ™‚ç‚¹ sï¼‰
*   å„ t ã«ã¤ã„ã¦
    *   tâˆ’1 æ™‚ç‚¹ã¾ã§ã®ã€Œç›´è¿‘ lookback\_years å¹´ã€ã®ãƒ‡ãƒ¼ã‚¿ã§ OLS
    *   Î²â‚(t), Î²â‚‚(t) ã‚’æ¨å®š
    *   z\*\_t = Î²â‚(t) mkt\_nr\_t + Î²â‚‚(t) mkt\_nm4\_avg\_t

```python
def build_z_star_online(
    ff: pd.DataFrame,
    lookback_years: int = 20,
    min_obs: int = 120,
) -> pd.DataFrame:
    """
    æ—§ z*_t æˆ¦ç•¥ç”¨ã®ã‚·ã‚°ãƒŠãƒ«æ§‹ç¯‰ã€‚
    - y: mkt_excess
    - X: [mkt_nr, mkt_nm4_avg]ï¼ˆåŒæ™‚ç‚¹ï¼‰
    - ç›´è¿‘ lookback_years å¹´ã®ãƒ‡ãƒ¼ã‚¿ã§ expanding-like OLS
    """
    df = add_nr_and_nm4(ff)
    df["mkt_total"] = df["mkt_excess"] + df["rf"]

    idx = df.index
    beta1 = pd.Series(index=idx, dtype=float)
    beta2 = pd.Series(index=idx, dtype=float)

    for i, t in enumerate(idx):
        # å›å¸°ã«ä½¿ã†æœŸé–“: t-1 ã¾ã§ & ç›´è¿‘ lookback_years å¹´
        if i == 0:
            continue
        end_date = idx[i-1]
        start_date = end_date - pd.DateOffset(years=lookback_years)

        mask = (idx >= start_date) & (idx <= end_date)
        sub = df.loc[mask, ["mkt_excess", "mkt_nr", "mkt_nm4_avg"]].dropna()

        if len(sub) < min_obs:
            continue

        y = sub["mkt_excess"]
        X = sub[["mkt_nr", "mkt_nm4_avg"]]
        X_const = sm.add_constant(X)

        model = sm.OLS(y, X_const).fit()

        beta1[t] = model.params.get("mkt_nr", np.nan)
        beta2[t] = model.params.get("mkt_nm4_avg", np.nan)

    df["beta_nr"]  = beta1
    df["beta_P4"]  = beta2
    df["z_star"]   = df["beta_nr"] * df["mkt_nr"] + df["beta_P4"] * df["mkt_nm4_avg"]

    return df
```

* * *

4\. Method 6ï¼ˆGuo æœ¬æ–‡ï¼‰1å¤‰æ•°æˆ¦ç•¥
-------------------------

ï¼ˆä»¥å‰ãŠæ¸¡ã—ã—ãŸ `backtest_method6_strategy` ã‚’å†æ²ï¼‰

```python
def backtest_method6_strategy(ff: pd.DataFrame,
                              min_obs: int = 120,
                              target_vol: float = None,
                              max_leverage: float = None) -> pd.DataFrame:
    """
    Guo (2025) Method 6: S (4 newsy sum) â†’ x_t â†’ Î²_t x_t ã«ã‚ˆã‚‹ time-series strategy
    mkt_total, mkt_mean ã‚’ä½¿ã£ãŸå¿ å®Ÿç‰ˆã€‚
    """
    mkt_excess = ff["mkt_excess"].copy()
    rf         = ff["rf"].copy()
    mkt_total  = mkt_excess + rf
    idx        = mkt_total.index

    # S_t, x_t, month_type
    S, x, month_type = compute_S_and_x_for_method6(mkt_total)

    # mktÌ„_{t-1}
    mkt_mean = mkt_total.expanding().mean().shift(1)

    y_adj = mkt_total - mkt_mean
    beta = pd.Series(index=idx, dtype=float)

    for i, t in enumerate(idx):
        mask = (idx <= t) & x.notna() & y_adj.notna()
        n = mask.sum()
        if n < min_obs:
            beta[t] = np.nan
            continue

        xi = x[mask].values
        yi = y_adj[mask].values
        denom = (xi ** 2).sum()
        beta[t] = (xi * yi).sum() / denom if denom > 0 else np.nan

    exp_ret = pd.Series(index=idx, dtype=float)
    w_raw   = pd.Series(index=idx, dtype=float)

    for i in range(len(idx) - 1):
        t      = idx[i]
        t_next = idx[i + 1]

        if any(np.isnan([beta[t], x[t], mkt_mean[t]])):
            exp_ret[t_next] = np.nan
            w = 0.0
        else:
            w = beta[t] * x[t]
            if max_leverage is not None:
                w = float(np.clip(w, -max_leverage, max_leverage))
            exp_ret[t_next] = w + mkt_mean[t]

        w_raw[t_next] = w

    strat_excess_raw = w_raw * mkt_excess

    common_mask = strat_excess_raw.notna() & mkt_excess.notna()
    strat_vol = strat_excess_raw[common_mask].std(ddof=1)
    mkt_vol   = mkt_excess[common_mask].std(ddof=1)

    if target_vol is None:
        target_vol = float(mkt_vol)

    if strat_vol is not None and strat_vol > 0:
        scale = target_vol / strat_vol
    else:
        scale = 1.0

    strat_excess_scaled = strat_excess_raw * scale
    strat_total         = rf + strat_excess_scaled

    out = pd.DataFrame({
        "mkt_excess": mkt_excess,
        "rf": rf,
        "mkt_total": mkt_total,
        "month_type": month_type,
        "x": x,
        "mkt_mean": mkt_mean,
        "beta": beta,
        "w_raw": w_raw,
        "exp_ret": exp_ret,
        "strat_excess_raw": strat_excess_raw,
        "strat_excess_scaled": strat_excess_scaled,
        "strat_total": strat_total,
    })
    out.attrs["scale"]       = scale
    out.attrs["target_vol"]  = target_vol
    out.attrs["min_obs"]     = min_obs
    out.attrs["max_leverage"] = max_leverage

    return out
```

* * *

5\. Method 6 nr+P4 2å¤‰æ•°æ‹¡å¼µæˆ¦ç•¥
--------------------------

ï¼ˆä»¥å‰ã® `backtest_method6_zstar_strategy` ã‚’å†æ²ï¼‰

```python
def backtest_method6_zstar_strategy(
    ff: pd.DataFrame,
    min_obs: int = 120,
    target_vol: float = None,
    max_leverage: float = None,
) -> pd.DataFrame:
    """
    Method 6 ã‚’ nr + P4 (mkt_nr, mkt_nm4_avg) ã®2å¤‰æ•°ç‰ˆã«æ‹¡å¼µã—ãŸæˆ¦ç•¥ã€‚
    """
    mkt_excess = ff["mkt_excess"].copy()
    rf         = ff["rf"].copy()
    mkt_total  = mkt_excess + rf
    idx        = mkt_total.index

    df_nr_p4 = add_nr_and_nm4(ff)
    x1, x2, month_type = build_nr_p4_signals(df_nr_p4)

    mkt_mean = mkt_total.expanding().mean().shift(1)
    y_adj = mkt_total - mkt_mean

    beta1 = pd.Series(index=idx, dtype=float)
    beta2 = pd.Series(index=idx, dtype=float)

    for i, t in enumerate(idx):
        mask = (idx <= t) & x1.notna() & x2.notna() & y_adj.notna()
        n = mask.sum()
        if n < min_obs:
            beta1[t] = np.nan
            beta2[t] = np.nan
            continue

        X = np.column_stack([x1[mask].values, x2[mask].values])
        y = y_adj[mask].values

        XtX = X.T @ X
        XtY = X.T @ y
        try:
            beta_vec = np.linalg.solve(XtX, XtY)
            beta1[t], beta2[t] = beta_vec[0], beta_vec[1]
        except np.linalg.LinAlgError:
            beta1[t], beta2[t] = np.nan, np.nan

    exp_ret = pd.Series(index=idx, dtype=float)
    w_raw   = pd.Series(index=idx, dtype=float)

    for i in range(len(idx) - 1):
        t      = idx[i]
        t_next = idx[i + 1]

        b1 = beta1[t]
        b2 = beta2[t]
        xt1 = x1[t]
        xt2 = x2[t]
        mt_bar = mkt_mean[t]

        if any(np.isnan([b1, b2, xt1, xt2, mt_bar])):
            exp_ret[t_next] = np.nan
            w = 0.0
        else:
            w = b1 * xt1 + b2 * xt2
            if max_leverage is not None:
                w = float(np.clip(w, -max_leverage, max_leverage))
            exp_ret[t_next] = w + mt_bar

        w_raw[t_next] = w

    strat_excess_raw = w_raw * mkt_excess

    common_mask = strat_excess_raw.notna() & mkt_excess.notna()
    strat_vol   = strat_excess_raw[common_mask].std(ddof=1)
    mkt_vol     = mkt_excess[common_mask].std(ddof=1)

    if target_vol is None:
        target_vol = float(mkt_vol)

    if strat_vol is not None and strat_vol > 0:
        scale = target_vol / strat_vol
    else:
        scale = 1.0

    strat_excess_scaled = strat_excess_raw * scale
    strat_total         = rf + strat_excess_scaled

    out = pd.DataFrame({
        "mkt_excess": mkt_excess,
        "rf": rf,
        "mkt_total": mkt_total,
        "month_type": month_type,
        "x1_nr": x1,
        "x2_P4": x2,
        "mkt_mean": mkt_mean,
        "beta1": beta1,
        "beta2": beta2,
        "w_raw": w_raw,
        "exp_ret": exp_ret,
        "strat_excess_raw": strat_excess_raw,
        "strat_excess_scaled": strat_excess_scaled,
        "strat_total": strat_total,
    })
    out.attrs["scale"]       = scale
    out.attrs["target_vol"]  = target_vol
    out.attrs["min_obs"]     = min_obs
    out.attrs["max_leverage"] = max_leverage

    return out
```

* * *

6\. å…±é€šã®è©•ä¾¡é–¢æ•° & æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆ
--------------------

```python
def annualized_stats(r: pd.Series):
    r = r.dropna()
    mu_m = r.mean()
    sd_m = r.std(ddof=1)
    mu_a = mu_m * 12
    sd_a = sd_m * math.sqrt(12)
    sharpe = mu_a / sd_a if sd_a > 0 else np.nan
    return mu_a, sd_a, sharpe

def summarize_strategy(df_strat: pd.DataFrame, label: str, start=None, end=None):
    sub = df_strat.copy()
    if start is not None or end is not None:
        sub = sub.loc[start:end].copy()

    strat = sub["strat_total"].dropna()
    mkt   = sub["mkt_total"].reindex(strat.index)

    mu_s, sd_s, sh_s = annualized_stats(strat)
    mu_m, sd_m, sh_m = annualized_stats(mkt)

    print(f"[{label}] Period: {strat.index[0].strftime('%Y-%m')} ã€œ {strat.index[-1].strftime('%Y-%m')}")
    print("  Strategy: mu={:.2%}, sigma={:.2%}, Sharpe={:.2f}".format(mu_s, sd_s, sh_s))
    print("  Market  : mu={:.2%}, sigma={:.2%}, Sharpe={:.2f}".format(mu_m, sd_m, sh_m))
    print()

def plot_three_strategies(df_old, df_m6, df_m6_2, title_suffix="Full Sample"):
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æƒãˆã‚‹
    common_index = df_old["strat_total"].dropna().index
    common_index = common_index.intersection(df_m6["strat_total"].dropna().index)
    common_index = common_index.intersection(df_m6_2["strat_total"].dropna().index)

    sw_old = (1.0 + df_old["strat_total"].reindex(common_index)).cumprod()
    sw_m6  = (1.0 + df_m6["strat_total"].reindex(common_index)).cumprod()
    sw_m6_2 = (1.0 + df_m6_2["strat_total"].reindex(common_index)).cumprod()
    mw     = (1.0 + df_old["mkt_total"].reindex(common_index)).cumprod()

    plt.figure(figsize=(14,5))
    plt.plot(sw_old,  label="Old z*_t (nr+P4, 20y rolling)", linewidth=2)
    plt.plot(sw_m6,   label="Method 6 (S, 1-var)", linewidth=2)
    plt.plot(sw_m6_2, label="Method 6 (nr+P4, 2-var)", linewidth=2)
    plt.plot(mw,      label="Market", linestyle="--", linewidth=1.5)
    plt.title(f"Cumulative Wealth: {title_suffix}")
    plt.legend()
    plt.grid(True)
    plt.show()
```

* * *

7\. çµ±åˆå®Ÿè¡Œï¼ˆãƒ•ãƒ«æœŸé–“ & 2020+ï¼‰
----------------------

```python
if __name__ == "__main__":
    csv_path = "F-F_Research_Data_Factors.csv"

    # 1) FF ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    ff = load_ff_monthly_from_ken_french(csv_path)

    # 2) æ—§ z*_t æˆ¦ç•¥
    df_zstar = build_z_star_online(
        ff,
        lookback_years=20,
        min_obs=120,
    )
    df_old = df_zstar.copy()
    df_old["z"] = df_old["z_star"]
    df_old = apply_timing_strategy(df_old, target_vol=0.05, max_leverage=3.0)

    # 3) Method 6 1å¤‰æ•°ç‰ˆï¼ˆè«–æ–‡æ¨å¥¨ï¼‰
    df_m6 = backtest_method6_strategy(ff, min_obs=120, target_vol=None, max_leverage=None)

    # 4) Method 6 nr+P4 2å¤‰æ•°æ‹¡å¼µ
    df_m6_2 = backtest_method6_zstar_strategy(ff, min_obs=120, target_vol=None, max_leverage=None)

    print("=== Full Sample ===")
    summarize_strategy(df_old,  "Old z*_t (nr+P4, 20y rolling)")
    summarize_strategy(df_m6,   "Method 6 (S, 1-var)")
    summarize_strategy(df_m6_2, "Method 6 (nr+P4, 2-var)")
    plot_three_strategies(df_old, df_m6, df_m6_2, title_suffix="Full Sample")

    print("=== 2020+ Subsample ===")
    summarize_strategy(df_old,  "Old z*_t (nr+P4, 20y rolling)", start="2020-01-01")
    summarize_strategy(df_m6,   "Method 6 (S, 1-var)",           start="2020-01-01")
    summarize_strategy(df_m6_2, "Method 6 (nr+P4, 2-var)",       start="2020-01-01")

    # ã‚µãƒ–ã‚µãƒ³ãƒ—ãƒ«ã®ãƒ—ãƒ­ãƒƒãƒˆã‚‚è¦‹ãŸã‘ã‚Œã°ï¼š
    df_old_2020  = df_old.loc["2020-01-01":].copy()
    df_m6_2020   = df_m6.loc["2020-01-01":].copy()
    df_m6_2_2020 = df_m6_2.loc["2020-01-01":].copy()
    plot_three_strategies(df_old_2020, df_m6_2020, df_m6_2_2020, title_suffix="2020+")
```

* * *

8\. å¯¾å¿œãƒãƒƒãƒ”ãƒ³ã‚°ã®ã¾ã¨ã‚
---------------

*   `df_old`  
    â†’ æ—§ `build_z_star_online + apply_timing_strategy`  
    â†’ Guo çš„ã«ã¯ **Method 5ï¼ˆnr+P4 jointï¼‰ã‚’ 20 å¹´ rolling OLS + ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã§ä½¿ã£ã¦ã„ã‚‹æˆ¦ç•¥**
*   `df_m6`  
    â†’ `backtest_method6_strategy`  
    â†’ Guo æœ¬æ–‡ã® **Method 6 1å¤‰æ•° Sï¼ˆ4 newsy sumï¼‰** ã«å¯¾å¿œã™ã‚‹ã€Œæœ¬å‘½ã€æˆ¦ç•¥
*   `df_m6_2`  
    â†’ `backtest_method6_zstar_strategy`  
    â†’ Method 6 ã®æ§‹é€ ï¼ˆmktÌ„ ã«ä¿‚æ•°1å›ºå®š + demean+sign flipï¼‰ã‚’ä¿ã£ãŸã¾ã¾  
    nr + P4 ã‚’ 2å¤‰æ•°ã«æ‹¡å¼µã—ãŸ **ã‚ãªãŸç‹¬è‡ªã® z\*\_t æ‹¡å¼µç‰ˆ**

ã“ã® 3 ã¤ã‚’åŒã˜æ çµ„ã¿ã§

*   ãƒ•ãƒ«ã‚µãƒ³ãƒ—ãƒ«
*   2020 å¹´ä»¥é™

ã«ã¤ã„ã¦ Sharpe / ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³ / shape ã®é•ã„ã‚’è¦‹ã‚‹ã¨ã€  
ã€Œæ—§ z\*\_t æˆ¦ç•¥ã¨ã€Guo æœ¬æ–‡ã® Method 6ï¼ˆï¼‹ãã®æ‹¡å¼µç‰ˆï¼‰ãŒã©ã“ã§ã©ã†æŒ™å‹•ãŒé•ã†ã‹ã€ãŒä¸€æ°—ã«å¯è¦–åŒ–ã§ãã‚‹ã¯ãšã§ã™ã€‚

## Response:
äº†è§£ã—ã¾ã—ãŸã€‚  
å‰ã«ãŠæ¸¡ã—ã—ãŸ

*   `compare_all_methods`ï¼ˆM0ã€œM6 ã® OOS äºˆæ¸¬ãƒ»Sign æˆ¦ç•¥æ¯”è¼ƒï¼‰
*   æ—§ `z*_t` æˆ¦ç•¥ vs Method 6 vs Method 6ï¼ˆnr+P4 æ‹¡å¼µï¼‰

ã‚’ **1 æœ¬ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã«çµ±åˆã—ãŸå®Œå…¨ç‰ˆã‚³ãƒ¼ãƒ‰**ã‚’ä¸‹ã«ã¾ã¨ã‚ã¾ã™ã€‚

Ken French ã® CSVï¼ˆ`F-F_Research_Data_Factors.csv`ï¼‰ã•ãˆã‚ã‚Œã°ã€ãã®ã¾ã¾å®Ÿè¡Œã§ãã¾ã™ã€‚

* * *

```python
import pandas as pd
import numpy as np
import math
import matplotlib.pyplot as plt
import statsmodels.api as sm

# ======================================================================
# 1. Ken French èª­ã¿è¾¼ã¿ & æœˆã‚¿ã‚¤ãƒ—åˆ†é¡
# ======================================================================

def load_ff_monthly_from_ken_french(csv_path: str) -> pd.DataFrame:
    """
    Ken French ã® F-F_Research_Data_Factors.csv ã‹ã‚‰
    æœˆæ¬¡ Mkt-RF, RF ã‚’æŠœãå‡ºã—ã€ãƒªã‚¿ãƒ¼ãƒ³ãƒ¬ãƒ™ãƒ«ã«å¤‰æ›ã™ã‚‹ã€‚
    """
    raw = pd.read_csv(csv_path, skiprows=4)

    num = pd.to_numeric(raw['Unnamed: 0'], errors='coerce')
    mask_monthly = num > 10000  # YYYYMM éƒ¨åˆ†ã ã‘æŠ½å‡º
    monthly = raw[mask_monthly].copy()

    monthly = monthly.rename(columns={'Unnamed: 0': 'date'})
    monthly['date'] = pd.to_datetime(monthly['date'].astype(int), format="%Y%m")
    monthly = monthly.set_index('date').sort_index()

    for col in ['Mkt-RF', 'RF']:
        monthly[col] = pd.to_numeric(monthly[col], errors='coerce')

    ff = monthly[['Mkt-RF', 'RF']].copy()
    ff['mkt_excess'] = ff['Mkt-RF'] / 100.0
    ff['rf']         = ff['RF'] / 100.0

    return ff[['mkt_excess', 'rf']].dropna()

def classify_month_type(index: pd.DatetimeIndex) -> pd.Series:
    """
    Guo ã«åˆã‚ã›ãŸæœˆã‚¿ã‚¤ãƒ—åˆ†é¡ï¼š
      - N: å››åŠæœŸ1ãƒ¶æœˆç›® (1,4,7,10æœˆãªã©)
      - R: å››åŠæœŸ2ãƒ¶æœˆç›®
      - 3: å››åŠæœŸ3ãƒ¶æœˆç›®
    """
    mt = pd.Series(index=index, dtype="object")
    for t in index:
        m = t.month % 3
        if m == 1:
            mt[t] = 'N'
        elif m == 2:
            mt[t] = 'R'
        else:
            mt[t] = '3'
    return mt

# ======================================================================
# 2. nr, P4, Method 6 ç”¨ã‚·ã‚°ãƒŠãƒ«
# ======================================================================

def add_nr_and_p4(ff: pd.DataFrame) -> pd.DataFrame:
    """
    ff: å¿…é ˆåˆ— 'mkt_excess', 'rf'

    è¿½åŠ åˆ—:
      - month_type   : 'N','R','3'
      - mkt_nr       : ç›´è¿‘ã® N/R æœˆã®è¶…éãƒªã‚¿ãƒ¼ãƒ³ (nr)
      - mkt_nm1..4   : éå» j ç•ªç›®ã® N æœˆ (è¶…éãƒªã‚¿ãƒ¼ãƒ³)
      - P4           : mkt_nm1..4 ã®å¹³å‡ (Parameter-Compression ç”¨)
      - mkt_nm4_avg  : P4 ã¨åŒã˜ (åˆ¥åã€‚z*_t æ—§å®Ÿè£…äº’æ›ç”¨)
    """
    df = ff.copy()
    df["month_type"] = classify_month_type(df.index)

    dates = df.index.to_list()
    mt = df["month_type"].values
    mkt = df["mkt_excess"].values

    nr_dates = []
    mkt_nr_list = []

    past_newsy_indices = []
    mkt_nm1 = []
    mkt_nm2 = []
    mkt_nm3 = []
    mkt_nm4 = []

    for i, t in enumerate(dates):
        # nr(t): t ã‚ˆã‚Šå‰ã§æœ€ã‚‚è¿‘ã„ N or R
        nr_idx = None
        j = i - 1
        while j >= 0:
            if mt[j] in ("N", "R"):
                nr_idx = j
                break
            j -= 1
        if nr_idx is None:
            nr_dates.append(None)
            mkt_nr_list.append(np.nan)
        else:
            nr_dates.append(dates[nr_idx])
            mkt_nr_list.append(mkt[nr_idx])

        # newsy æœˆå±¥æ­´æ›´æ–°
        if mt[i] == "N":
            past_newsy_indices.append(i)

        # nm(t,j): ç›´è¿‘ã® newsy æœˆãŸã¡
        cand = [k for k in past_newsy_indices if k < i]
        cand = sorted(cand, reverse=True)

        vals = []
        for jj in range(4):
            if jj < len(cand):
                vals.append(mkt[cand[jj]])
            else:
                vals.append(np.nan)

        mkt_nm1.append(vals[0])
        mkt_nm2.append(vals[1])
        mkt_nm3.append(vals[2])
        mkt_nm4.append(vals[3])

    df["nr_date"] = nr_dates
    df["mkt_nr"]  = mkt_nr_list
    df["mkt_nm1"] = mkt_nm1
    df["mkt_nm2"] = mkt_nm2
    df["mkt_nm3"] = mkt_nm3
    df["mkt_nm4"] = mkt_nm4

    df["P4"] = df[["mkt_nm1", "mkt_nm2", "mkt_nm3", "mkt_nm4"]].mean(axis=1)
    df["mkt_nm4_avg"] = df["P4"]  # æ—§å®Ÿè£…äº’æ›ç”¨

    return df

def compute_S_and_x_for_method6(mkt_total: pd.Series):
    """
    Method 6 ç”¨:
      - S_t: t ã¾ã§ã«å‡ºç¾ã—ãŸç›´è¿‘4ã¤ã® newsy æœˆ total return ã®åˆè¨ˆ
      - x_t: S_{t-1} ã‚’ expanding å¹³å‡ã§ demean ã—ã€ç¿Œæœˆ t ãŒ newsy ãªã‚‰ sign flip
    """
    idx = mkt_total.index
    month_type = classify_month_type(idx)
    is_newsy = (month_type == "N")

    news_series = mkt_total[is_newsy]

    S = pd.Series(index=idx, dtype=float)
    for t in idx:
        past = news_series[news_series.index <= t]
        if len(past) >= 4:
            S[t] = past.iloc[-4:].sum()
        else:
            S[t] = np.nan

    x = pd.Series(index=idx, dtype=float)
    S_hist = []

    for i in range(1, len(idx)):
        prev_date = idx[i-1]   # t-1
        curr_date = idx[i]     # t

        s_prev = S.loc[prev_date]
        if np.isnan(s_prev):
            x[curr_date] = np.nan
            continue

        S_hist.append(s_prev)
        s_bar = float(np.mean(S_hist))

        sign = -1.0 if is_newsy[curr_date] else 1.0
        x[curr_date] = sign * (s_prev - s_bar)

    return S, x, month_type

def build_nr_p4_signals(df_nr_p4: pd.DataFrame):
    """
    nr + P4 ã‚’ Method 6 ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆdemean + sign flipï¼‰ã§ x1,x2 ã«å¤‰æ›ã€‚
    x1_t, x2_t ã¯ã€Œt ã®ãƒªã‚¿ãƒ¼ãƒ³äºˆæ¸¬ã«ä½¿ã†ã‚·ã‚°ãƒŠãƒ«ã€ã€‚
    """
    df = df_nr_p4.copy()
    idx = df.index
    month_type = df["month_type"]
    is_newsy = (month_type == "N")

    mkt_nr = df["mkt_nr"]
    P4     = df["mkt_nm4_avg"]

    x1 = pd.Series(index=idx, dtype=float)
    x2 = pd.Series(index=idx, dtype=float)

    hist_nr = []
    hist_P4 = []

    for i in range(1, len(idx)):
        prev_date = idx[i-1]
        curr_date = idx[i]

        nr_prev = mkt_nr.loc[prev_date]
        P4_prev = P4.loc[prev_date]

        if np.isnan(nr_prev) or np.isnan(P4_prev):
            x1[curr_date] = np.nan
            x2[curr_date] = np.nan
            continue

        hist_nr.append(nr_prev)
        hist_P4.append(P4_prev)
        nr_bar = float(np.mean(hist_nr))
        P4_bar = float(np.mean(hist_P4))

        nr_dm = nr_prev - nr_bar
        P4_dm = P4_prev - P4_bar

        sign = -1.0 if is_newsy[curr_date] else 1.0
        x1[curr_date] = sign * nr_dm
        x2[curr_date] = sign * P4_dm

    return x1, x2, month_type

# ======================================================================
# 3. compare_all_methods ç”¨ï¼šOOS å›å¸° & Sign æˆ¦ç•¥
# ======================================================================

def oos_linear_forecast_sign_strategy(
    y: pd.Series,
    X: pd.DataFrame,
    min_obs: int = 120
):
    """
    y: ç›®çš„å¤‰æ•° (mkt_excess ãªã©)
    X: èª¬æ˜å¤‰æ•°ï¼ˆåˆ—ãƒ™ã‚¯ãƒˆãƒ«1æœ¬ã§ã‚‚è¤‡æ•°ã§ã‚‚å¯ï¼‰
    min_obs: OLS ã‚’å›ã™æœ€å°è¦³æ¸¬æ•°

    æˆ»ã‚Šå€¤:
      - y_hat: OOS äºˆæ¸¬
      - w_sign: sign æˆ¦ç•¥ã®ã‚¦ã‚§ã‚¤ãƒˆ (+1/ -1 / 0)
      - strat_excess: sign æˆ¦ç•¥ã®è¶…éãƒªã‚¿ãƒ¼ãƒ³
      - coefs: å„ t ã®ä¿‚æ•° (DataFrame)
    """
    idx = y.index
    X = X.copy().reindex(idx)

    coefs = pd.DataFrame(index=idx, columns=["const"] + list(X.columns), dtype=float)
    y_hat = pd.Series(index=idx, dtype=float)

    for i in range(len(idx) - 1):
        t = idx[i]
        t_next = idx[i+1]

        mask = (idx <= t) & y.notna()
        for col in X.columns:
            mask &= X[col].notna()
        n = mask.sum()
        if n < min_obs:
            y_hat[t_next] = np.nan
            continue

        Xi = X.loc[mask]
        yi = y.loc[mask]
        Xi_const = sm.add_constant(Xi)
        model = sm.OLS(yi, Xi_const).fit()

        coefs.loc[t, "const"] = model.params.get("const", np.nan)
        for col in X.columns:
            coefs.loc[t, col] = model.params.get(col, np.nan)

        x_next = X.loc[t, :].values.reshape(1, -1)
        X_next_const = np.concatenate([np.array([[1.0]]), x_next], axis=1)
        y_hat[t_next] = float(X_next_const @ model.params.values)

    w_sign = np.sign(y_hat).fillna(0.0)
    strat_excess = w_sign * y

    return y_hat, w_sign, strat_excess, coefs

def run_method0_mean(ff: pd.DataFrame, min_obs: int = 120):
    """
    Method 0 çš„ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼šéå»å¹³å‡ã§ OOS äºˆæ¸¬
    """
    y = ff["mkt_excess"].copy()
    idx = y.index

    y_hat = pd.Series(index=idx, dtype=float)
    for i in range(len(idx) - 1):
        t = idx[i]
        t_next = idx[i+1]
        past = y.iloc[: i+1].dropna()
        if len(past) < min_obs:
            y_hat[t_next] = np.nan
        else:
            y_hat[t_next] = past.mean()

    w_sign = np.sign(y_hat).fillna(0.0)
    strat_excess = w_sign * y

    return y_hat, w_sign, strat_excess

def run_method1_ar1(ff: pd.DataFrame, min_obs: int = 120):
    y = ff["mkt_excess"].copy()
    X = pd.DataFrame({"mkt_lag": ff["mkt_excess"].shift(1)})
    return oos_linear_forecast_sign_strategy(y, X, min_obs=min_obs)

def run_method2_nr(ff: pd.DataFrame, min_obs: int = 120):
    y = ff["mkt_excess"].copy()
    X = pd.DataFrame({"mkt_nr": ff["mkt_nr"]})
    return oos_linear_forecast_sign_strategy(y, X, min_obs=min_obs)

def run_method3_p4(ff: pd.DataFrame, min_obs: int = 120):
    y = ff["mkt_excess"].copy()
    X = pd.DataFrame({"P4": ff["P4"]})
    return oos_linear_forecast_sign_strategy(y, X, min_obs=min_obs)

def run_method4_nr_p4(ff: pd.DataFrame, min_obs: int = 120):
    y = ff["mkt_excess"].copy()
    X = pd.DataFrame({
        "mkt_nr": ff["mkt_nr"],
        "P4":     ff["P4"]
    })
    return oos_linear_forecast_sign_strategy(y, X, min_obs=min_obs)

def run_method6_S(ff: pd.DataFrame, min_obs: int = 120):
    """
    Method 6 ã® x_M6ï¼ˆS ã® demean+sign flipï¼‰ã‚’èª¬æ˜å¤‰æ•°ã«ã—ãŸç°¡æ˜“ç‰ˆã€‚
    ç›®çš„å¤‰æ•°ã¯ mkt_excess ã«çµ±ä¸€ã€‚
    """
    y = ff["mkt_excess"].copy()
    X = pd.DataFrame({"x_M6": ff["x_M6"]})
    return oos_linear_forecast_sign_strategy(y, X, min_obs=min_obs)

def annualized_stats(r: pd.Series):
    r = r.dropna()
    mu_m = r.mean()
    sd_m = r.std(ddof=1)
    mu_a = mu_m * 12
    sd_a = sd_m * math.sqrt(12)
    sharpe = mu_a / sd_a if sd_a > 0 else np.nan
    return mu_a, sd_a, sharpe

def compute_oos_r2(y: pd.Series, y_hat: pd.Series):
    """
    OOS R^2ï¼šOOS å¹³å‡äºˆæ¸¬ã«å¯¾ã™ã‚‹ç›¸å¯¾æ”¹å–„åº¦
    """
    mask = y.notna() & y_hat.notna()
    y_ = y[mask]
    yhat_ = y_hat[mask]
    if len(y_) == 0:
        return np.nan

    mean_hat = pd.Series(index=y_.index, dtype=float)
    for i, t in enumerate(y_.index):
        past = y_.iloc[:i]
        if len(past) == 0:
            mean_hat[t] = np.nan
        else:
            mean_hat[t] = past.mean()

    mask2 = mean_hat.notna()
    y_ = y_[mask2]
    yhat_ = yhat_[mask2]
    mean_hat = mean_hat[mask2]

    num = ((y_ - yhat_)**2).sum()
    den = ((y_ - mean_hat)**2).sum()
    return 1.0 - num / den if den > 0 else np.nan

def compare_all_methods(csv_path: str, min_obs: int = 120, start=None, end=None):
    """
    M0ã€œM6 ã® OOS äºˆæ¸¬ãƒ»Sign æˆ¦ç•¥ã‚’ä¸€æ‹¬æ¯”è¼ƒã€‚
    """
    ff = load_ff_monthly_from_ken_french(csv_path)
    ff = add_nr_and_p4(ff)
    ff["mkt_total"] = ff["mkt_excess"] + ff["rf"]
    S, x_M6, mt = compute_S_and_x_for_method6(ff["mkt_total"])
    ff["S_M6"] = S
    ff["x_M6"] = x_M6
    ff["mt"]   = mt

    if start is not None or end is not None:
        ff = ff.loc[start:end].copy()

    results = {}

    # M0: mean
    y_hat0, w0, strat0 = run_method0_mean(ff, min_obs=min_obs)
    results["M0_mean"] = (y_hat0, strat0)

    # M1: AR(1)
    y_hat1, w1, strat1, coef1 = run_method1_ar1(ff, min_obs=min_obs)
    results["M1_AR1"] = (y_hat1, strat1)

    # M2: nr only
    y_hat2, w2, strat2, coef2 = run_method2_nr(ff, min_obs=min_obs)
    results["M2_NR"] = (y_hat2, strat2)

    # M3: P4 only
    y_hat3, w3, strat3, coef3 = run_method3_p4(ff, min_obs=min_obs)
    results["M3_P4"] = (y_hat3, strat3)

    # M4: nr+P4
    y_hat4, w4, strat4, coef4 = run_method4_nr_p4(ff, min_obs=min_obs)
    results["M4_NR_P4"] = (y_hat4, strat4)

    # M6: S (x_M6)
    y_hat6, w6, strat6, coef6 = run_method6_S(ff, min_obs=min_obs)
    results["M6_S"] = (y_hat6, strat6)

    y = ff["mkt_excess"]

    print("=== OOS Performance ({}ã€œ{}) ===".format(ff.index[0].strftime("%Y-%m"),
                                                  ff.index[-1].strftime("%Y-%m")))
    print("Baseline Market (Buy&Hold, Excess):")
    mu_mkt, sd_mkt, sh_mkt = annualized_stats(y)
    print("  mu={:.2%}, sigma={:.2%}, Sharpe={:.2f}".format(mu_mkt, sd_mkt, sh_mkt))
    print()

    for name, (y_hat, strat) in results.items():
        mu_s, sd_s, sh_s = annualized_stats(strat)
        r2 = compute_oos_r2(y, y_hat)
        print(f"[{name}]")
        print("  mu={:.2%}, sigma={:.2%}, Sharpe={:.2f}, OOS R^2={:.3f}".format(mu_s, sd_s, sh_s, r2))
        print()

    return ff, results

# ======================================================================
# 4. æ—§ z*_t æˆ¦ç•¥ç”¨ï¼šapply_timing_strategy + build_z_star_online
# ======================================================================

def apply_timing_strategy(df, target_vol=0.05, max_leverage=3.0):
    """
    df['z'] ã‚’ã‚·ã‚°ãƒŠãƒ«ã¨ã—ã¦ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã™ã‚‹æˆ¦ç•¥ã€‚
    ï¼ˆã‚‚ã¨ã‚‚ã¨ãŠä½¿ã„ã ã£ãŸå®Ÿè£…ã‚’ãƒ™ãƒ¼ã‚¹ã«ï¼‰
    """
    out = df.copy()
    z = out["z"]

    weights = []
    sig_hist = []
    strat_excess = []
    strat_total = []
    mkt_total = []

    for i, t in enumerate(out.index):
        if i == 0:
            sigma = np.nan
            w = 0.0
        else:
            sigma = z.iloc[:i].std(ddof=1)
            if np.isnan(sigma) or sigma == 0:
                w = 0.0
            else:
                w = z.iloc[i] * target_vol / sigma
                w = float(np.clip(w, -max_leverage, max_leverage))

        weights.append(w)
        sig_hist.append(sigma)

        mkt = out.at[t, "mkt_excess"]
        rf  = out.at[t, "rf"]
        se  = w * mkt
        strat_excess.append(se)
        strat_total.append(rf + se)
        mkt_total.append(rf + mkt)

    out["w"]            = weights
    out["sigma_z_hist"] = sig_hist
    out["strat_excess"] = strat_excess
    out["strat_total"]  = strat_total
    out["mkt_total"]    = mkt_total

    return out

def build_z_star_online(
    ff: pd.DataFrame,
    lookback_years: int = 20,
    min_obs: int = 120,
) -> pd.DataFrame:
    """
    æ—§ z*_t æˆ¦ç•¥ç”¨ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ä¿‚æ•°æ¨å®šï¼š
    - y: mkt_excess
    - X: [mkt_nr, mkt_nm4_avg]ï¼ˆåŒæ™‚ç‚¹ï¼‰
    - t-1 æ™‚ç‚¹ã¾ã§ã®ç›´è¿‘ lookback_years å¹´ã§ OLS
    """
    df = add_nr_and_p4(ff)
    df["mkt_total"] = df["mkt_excess"] + df["rf"]

    idx = df.index
    beta1 = pd.Series(index=idx, dtype=float)
    beta2 = pd.Series(index=idx, dtype=float)

    for i, t in enumerate(idx):
        if i == 0:
            continue

        end_date = idx[i-1]
        start_date = end_date - pd.DateOffset(years=lookback_years)

        mask = (idx >= start_date) & (idx <= end_date)
        sub = df.loc[mask, ["mkt_excess", "mkt_nr", "mkt_nm4_avg"]].dropna()

        if len(sub) < min_obs:
            continue

        y = sub["mkt_excess"]
        X = sub[["mkt_nr", "mkt_nm4_avg"]]
        X_const = sm.add_constant(X)

        model = sm.OLS(y, X_const).fit()

        beta1[t] = model.params.get("mkt_nr", np.nan)
        beta2[t] = model.params.get("mkt_nm4_avg", np.nan)

    df["beta_nr"]  = beta1
    df["beta_P4"]  = beta2
    df["z_star"]   = df["beta_nr"] * df["mkt_nr"] + df["beta_P4"] * df["mkt_nm4_avg"]

    return df

# ======================================================================
# 5. Method 6ï¼ˆ1å¤‰æ•° & nr+P4 2å¤‰æ•°ï¼‰æˆ¦ç•¥
# ======================================================================

def backtest_method6_strategy(ff: pd.DataFrame,
                              min_obs: int = 120,
                              target_vol: float = None,
                              max_leverage: float = None) -> pd.DataFrame:
    """
    Guo (2025) Method 6: S (4 newsy sum) â†’ x_t â†’ Î²_t x_t ã«ã‚ˆã‚‹ time-series strategy
    mkt_total, mkt_mean ã‚’ä½¿ã£ãŸå¿ å®Ÿç‰ˆã€‚
    """
    mkt_excess = ff["mkt_excess"].copy()
    rf         = ff["rf"].copy()
    mkt_total  = mkt_excess + rf
    idx        = mkt_total.index

    S, x, month_type = compute_S_and_x_for_method6(mkt_total)
    mkt_mean = mkt_total.expanding().mean().shift(1)

    y_adj = mkt_total - mkt_mean
    beta = pd.Series(index=idx, dtype=float)

    for i, t in enumerate(idx):
        mask = (idx <= t) & x.notna() & y_adj.notna()
        n = mask.sum()
        if n < min_obs:
            beta[t] = np.nan
            continue

        xi = x[mask].values
        yi = y_adj[mask].values
        denom = (xi ** 2).sum()
        beta[t] = (xi * yi).sum() / denom if denom > 0 else np.nan

    exp_ret = pd.Series(index=idx, dtype=float)
    w_raw   = pd.Series(index=idx, dtype=float)

    for i in range(len(idx) - 1):
        t      = idx[i]
        t_next = idx[i + 1]

        if any(np.isnan([beta[t], x[t], mkt_mean[t]])):
            exp_ret[t_next] = np.nan
            w = 0.0
        else:
            w = beta[t] * x[t]
            if max_leverage is not None:
                w = float(np.clip(w, -max_leverage, max_leverage))
            exp_ret[t_next] = w + mkt_mean[t]

        w_raw[t_next] = w

    strat_excess_raw = w_raw * mkt_excess

    common_mask = strat_excess_raw.notna() & mkt_excess.notna()
    strat_vol = strat_excess_raw[common_mask].std(ddof=1)
    mkt_vol   = mkt_excess[common_mask].std(ddof=1)

    if target_vol is None:
        target_vol = float(mkt_vol)

    if strat_vol is not None and strat_vol > 0:
        scale = target_vol / strat_vol
    else:
        scale = 1.0

    strat_excess_scaled = strat_excess_raw * scale
    strat_total         = rf + strat_excess_scaled

    out = pd.DataFrame({
        "mkt_excess": mkt_excess,
        "rf": rf,
        "mkt_total": mkt_total,
        "month_type": month_type,
        "x": x,
        "mkt_mean": mkt_mean,
        "beta": beta,
        "w_raw": w_raw,
        "exp_ret": exp_ret,
        "strat_excess_raw": strat_excess_raw,
        "strat_excess_scaled": strat_excess_scaled,
        "strat_total": strat_total,
    })
    out.attrs["scale"]       = scale
    out.attrs["target_vol"]  = target_vol
    out.attrs["min_obs"]     = min_obs
    out.attrs["max_leverage"] = max_leverage

    return out

def backtest_method6_zstar_strategy(
    ff: pd.DataFrame,
    min_obs: int = 120,
    target_vol: float = None,
    max_leverage: float = None,
) -> pd.DataFrame:
    """
    Method 6 ã‚’ nr + P4 (mkt_nr, mkt_nm4_avg) ã®2å¤‰æ•°ç‰ˆã«æ‹¡å¼µã—ãŸæˆ¦ç•¥ã€‚
    """
    mkt_excess = ff["mkt_excess"].copy()
    rf         = ff["rf"].copy()
    mkt_total  = mkt_excess + rf
    idx        = mkt_total.index

    df_nr_p4 = add_nr_and_p4(ff)
    x1, x2, month_type = build_nr_p4_signals(df_nr_p4)

    mkt_mean = mkt_total.expanding().mean().shift(1)
    y_adj = mkt_total - mkt_mean

    beta1 = pd.Series(index=idx, dtype=float)
    beta2 = pd.Series(index=idx, dtype=float)

    for i, t in enumerate(idx):
        mask = (idx <= t) & x1.notna() & x2.notna() & y_adj.notna()
        n = mask.sum()
        if n < min_obs:
            beta1[t] = np.nan
            beta2[t] = np.nan
            continue

        X = np.column_stack([x1[mask].values, x2[mask].values])
        y = y_adj[mask].values

        XtX = X.T @ X
        XtY = X.T @ y
        try:
            beta_vec = np.linalg.solve(XtX, XtY)
            beta1[t], beta2[t] = beta_vec[0], beta_vec[1]
        except np.linalg.LinAlgError:
            beta1[t], beta2[t] = np.nan, np.nan

    exp_ret = pd.Series(index=idx, dtype=float)
    w_raw   = pd.Series(index=idx, dtype=float)

    for i in range(len(idx) - 1):
        t      = idx[i]
        t_next = idx[i + 1]

        b1 = beta1[t]
        b2 = beta2[t]
        xt1 = x1[t]
        xt2 = x2[t]
        mt_bar = mkt_mean[t]

        if any(np.isnan([b1, b2, xt1, xt2, mt_bar])):
            exp_ret[t_next] = np.nan
            w = 0.0
        else:
            w = b1 * xt1 + b2 * xt2
            if max_leverage is not None:
                w = float(np.clip(w, -max_leverage, max_leverage))
            exp_ret[t_next] = w + mt_bar

        w_raw[t_next] = w

    strat_excess_raw = w_raw * mkt_excess

    common_mask = strat_excess_raw.notna() & mkt_excess.notna()
    strat_vol   = strat_excess_raw[common_mask].std(ddof=1)
    mkt_vol     = mkt_excess[common_mask].std(ddof=1)

    if target_vol is None:
        target_vol = float(mkt_vol)

    if strat_vol is not None and strat_vol > 0:
        scale = target_vol / strat_vol
    else:
        scale = 1.0

    strat_excess_scaled = strat_excess_raw * scale
    strat_total         = rf + strat_excess_scaled

    out = pd.DataFrame({
        "mkt_excess": mkt_excess,
        "rf": rf,
        "mkt_total": mkt_total,
        "month_type": month_type,
        "x1_nr": x1,
        "x2_P4": x2,
        "mkt_mean": mkt_mean,
        "beta1": beta1,
        "beta2": beta2,
        "w_raw": w_raw,
        "exp_ret": exp_ret,
        "strat_excess_raw": strat_excess_raw,
        "strat_excess_scaled": strat_excess_scaled,
        "strat_total": strat_total,
    })
    out.attrs["scale"]       = scale
    out.attrs["target_vol"]  = target_vol
    out.attrs["min_obs"]     = min_obs
    out.attrs["max_leverage"] = max_leverage

    return out

# ======================================================================
# 6. å…±é€šã®è©•ä¾¡é–¢æ•° & 3æˆ¦ç•¥æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆ
# ======================================================================

def summarize_strategy(df_strat: pd.DataFrame, label: str, start=None, end=None):
    sub = df_strat.copy()
    if start is not None or end is not None:
        sub = sub.loc[start:end].copy()

    strat = sub["strat_total"].dropna()
    mkt   = sub["mkt_total"].reindex(strat.index)

    mu_s, sd_s, sh_s = annualized_stats(strat)
    mu_m, sd_m, sh_m = annualized_stats(mkt)

    print(f"[{label}] Period: {strat.index[0].strftime('%Y-%m')} ã€œ {strat.index[-1].strftime('%Y-%m')}")
    print("  Strategy: mu={:.2%}, sigma={:.2%}, Sharpe={:.2f}".format(mu_s, sd_s, sh_s))
    print("  Market  : mu={:.2%}, sigma={:.2%}, Sharpe={:.2f}".format(mu_m, sd_m, sh_m))
    print()

def plot_three_strategies(df_old, df_m6, df_m6_2, title_suffix="Full Sample"):
    common_index = df_old["strat_total"].dropna().index
    common_index = common_index.intersection(df_m6["strat_total"].dropna().index)
    common_index = common_index.intersection(df_m6_2["strat_total"].dropna().index)

    sw_old  = (1.0 + df_old["strat_total"].reindex(common_index)).cumprod()
    sw_m6   = (1.0 + df_m6["strat_total"].reindex(common_index)).cumprod()
    sw_m6_2 = (1.0 + df_m6_2["strat_total"].reindex(common_index)).cumprod()
    mw      = (1.0 + df_old["mkt_total"].reindex(common_index)).cumprod()

    plt.figure(figsize=(14,5))
    plt.plot(sw_old,  label="Old z*_t (nr+P4, 20y rolling)", linewidth=2)
    plt.plot(sw_m6,   label="Method 6 (S, 1-var)", linewidth=2)
    plt.plot(sw_m6_2, label="Method 6 (nr+P4, 2-var)", linewidth=2)
    plt.plot(mw,      label="Market", linestyle="--", linewidth=1.5)
    plt.title(f"Cumulative Wealth: {title_suffix}")
    plt.legend()
    plt.grid(True)
    plt.show()

# ======================================================================
# 7. mainï¼šcompare_all_methods + 3 æˆ¦ç•¥æ¯”è¼ƒ
# ======================================================================

if __name__ == "__main__":
    csv_path = "F-F_Research_Data_Factors.csv"

    # ------------------------------
    # A. Table 4 ã® Method æ¯”è¼ƒ
    # ------------------------------
    print("########## Table 4 Methods (M0ã€œM6) OOS æ¯”è¼ƒ: 1926â€“2025 ##########")
    ff_all, res_all = compare_all_methods(csv_path, min_obs=120)

    print("########## Table 4 Methods OOS æ¯”è¼ƒ: 2020+ ##########")
    ff_2020, res_2020 = compare_all_methods(csv_path, min_obs=120, start="2020-01-01")

    # ------------------------------
    # B. æ—§ z*_t vs Method 6 vs 2å¤‰æ•° Method 6
    # ------------------------------
    ff = load_ff_monthly_from_ken_french(csv_path)

    # æ—§ z*_t
    df_zstar = build_z_star_online(
        ff,
        lookback_years=20,
        min_obs=120,
    )
    df_old = df_zstar.copy()
    df_old["z"] = df_old["z_star"]
    df_old = apply_timing_strategy(df_old, target_vol=0.05, max_leverage=3.0)

    # Method 6 (1-var S)
    df_m6 = backtest_method6_strategy(ff, min_obs=120, target_vol=None, max_leverage=None)

    # Method 6 (nr+P4 2-var)
    df_m6_2 = backtest_method6_zstar_strategy(ff, min_obs=120, target_vol=None, max_leverage=None)

    print("########## 3æˆ¦ç•¥æ¯”è¼ƒ: Full Sample ##########")
    summarize_strategy(df_old,  "Old z*_t (nr+P4, 20y rolling)")
    summarize_strategy(df_m6,   "Method 6 (S, 1-var)")
    summarize_strategy(df_m6_2, "Method 6 (nr+P4, 2-var)")
    plot_three_strategies(df_old, df_m6, df_m6_2, title_suffix="Full Sample")

    print("########## 3æˆ¦ç•¥æ¯”è¼ƒ: 2020+ ##########")
    summarize_strategy(df_old,  "Old z*_t (nr+P4, 20y rolling)", start="2020-01-01")
    summarize_strategy(df_m6,   "Method 6 (S, 1-var)",           start="2020-01-01")
    summarize_strategy(df_m6_2, "Method 6 (nr+P4, 2-var)",       start="2020-01-01")

    df_old_2020  = df_old.loc["2020-01-01":].copy()
    df_m6_2020   = df_m6.loc["2020-01-01":].copy()
    df_m6_2_2020 = df_m6_2.loc["2020-01-01":].copy()
    plot_three_strategies(df_old_2020, df_m6_2020, df_m6_2_2020, title_suffix="2020+")
```

* * *

ã“ã‚Œã§ã€

*   `compare_all_methods` ã«ã‚ˆã‚‹ **Methods 0ã€œ6 ã® OOS Sign æˆ¦ç•¥æ¯”è¼ƒ**
*   æ—§ `z*_t` æˆ¦ç•¥ vs æ–‡çŒ®ã©ãŠã‚Š Method 6 vs nr+P4 æ‹¡å¼µ Method 6

ã‚’ä¸€åº¦ã«è©•ä¾¡ã§ãã¾ã™ã€‚

ã‚‚ã—å‹•ã‹ã—ã¦ã¿ã¦ã€

*   ä¿‚æ•°ã®æ™‚ç³»åˆ—ï¼ˆÎ²\_nr, Î²\_P4, Î²\_Sï¼‰
*   rolling Sharpe / rolling OOS RÂ²

ãªã©ã‚‚è¦‹ãŸããªã‚Œã°ã€ãã®éƒ¨åˆ†ã‚‚è¿½åŠ ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ãã¾ã™ã€‚

## Response:
æ€è€ƒå®Œäº†

æ€è€ƒæ™‚é–“: 41s

ä»¥ä¸‹ã§ã¯ã€

*   æ–‡çŒ® Guo (2025)ã€ŒEarnings Extrapolation and Predictable Stock Market Returnsã€
*   Guo & Wachter (2025)ã€ŒCorrelation Neglect in Asset Pricesã€  
    ã‚’ä¸»ãªå‚ç…§å…ƒã¨ã—ã¦ã€ã‚ãªãŸã®ã‚³ãƒ¼ãƒ‰ã§æ¯”è¼ƒã—ã¦ã„ã‚‹å„æˆ¦ç•¥ã‚’ã€Œå­¦è¡“çš„ãªä½ç½®ã¥ã‘ã€ã§æ•´ç†ã—ã¾ã™ã€‚[OUP Academic+2SSRN+2](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf?utm_source=chatgpt.com)

æœ€å¾Œã«ã€Œã©ã®æˆ¦ç•¥ãŒè«–æ–‡ã®ã©ã® Method ã«å¯¾å¿œã™ã‚‹ã‹ã€ã‚‚ã¾ã¨ã‚ã¾ã™ã€‚

* * *

1\. ç†è«–çš„ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã®æ•´ç†
------------------

### 1.1 Earnings extrapolation ã¨ newsy / non-newsy æœˆ

Guo (2025) ã¯ã€  
ã€Œå››åŠæœŸç¬¬1æœˆï¼ˆnewsy monthï¼š1,4,7,10 æœˆãªã©ï¼‰ã§ã®å¸‚å ´ãƒªã‚¿ãƒ¼ãƒ³ãŒã€ãã®å¾Œã®æœˆæ¬¡ãƒªã‚¿ãƒ¼ãƒ³ã‚’å¼·ãäºˆæ¸¬ã™ã‚‹ã€ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚  
å…·ä½“çš„ã«ã¯ã€

*   äºˆæ¸¬å¯¾è±¡æœˆãŒ **newsy** ã®ã¨ãï¼šéå»ã® newsy æœˆãƒªã‚¿ãƒ¼ãƒ³ã¨å¼·ã„**è² **ã®ç›¸é–¢
*   äºˆæ¸¬å¯¾è±¡æœˆãŒ **non-newsyï¼ˆç¬¬2ãƒ»3æœˆï¼‰** ã®ã¨ãï¼šéå»ã® newsy æœˆãƒªã‚¿ãƒ¼ãƒ³ã¨å¼·ã„**æ­£**ã®ç›¸é–¢

ã¨ã„ã†ã€Œç¬¦å·ã®åè»¢ã‚’ä¼´ã†ã€äºˆæ¸¬ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒå­˜åœ¨ã—ã€ã“ã‚ŒãŒå¾“æ¥ã®ã€Œæœˆæ¬¡å¸‚å ´ãƒªã‚¿ãƒ¼ãƒ³ã¯ã»ã¨ã‚“ã©äºˆæ¸¬ä¸èƒ½ã€ã¨ã„ã†çµæœã‚’ãƒã‚¹ã‚¯ã—ã¦ã„ã‚‹ã€ã¨ä¸»å¼µã—ã¾ã™ã€‚[OUP Academic](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf?utm_source=chatgpt.com)

ã“ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ã€æŠ•è³‡å®¶ãŒ

*   earningsï¼ˆç‰¹ã« newsy æœˆã®æ±ºç®—ç™ºè¡¨ï¼‰ã‚’**å°†æ¥ã«å‘ã‘ã¦å¤–æŒ¿**ã™ã‚‹ä¸€æ–¹ã§ã€
*   ã€Œnewsy æœˆã¨ non-newsy æœˆã§ earnings ã®è‡ªå·±ç›¸é–¢æ§‹é€ ãŒç•°ãªã‚‹ï¼ˆnewsy ã®ã»ã†ãŒäºˆæ¸¬ã—ã¥ã‚‰ã„ï¼‰ã€ã“ã¨ã‚’**ååˆ†ã«èªè­˜ã—ã¦ã„ãªã„**

ã¨ã„ã†ã€Œearnings extrapolation + correlation neglectï¼ˆç›¸é–¢æ§‹é€ ã®ç„¡è¦–ï¼‰ã€ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰å°å‡ºã•ã‚Œã¾ã™ã€‚[Finance Department+2repository.upenn.edu+2](https://fnce.wharton.upenn.edu/wp-content/uploads/2022/07/Paper4_Guo.pdf?utm_source=chatgpt.com)

### 1.2 Correlation neglect ã®å½¢å¼åŒ–

Guo & Wachter (2025)ã€ŒCorrelation Neglect in Asset Pricesã€ã¯ã€ã“ã®ä»•çµ„ã¿ã‚’ã‚ˆã‚Šä¸€èˆ¬çš„ãªã€Œç›¸é–¢æ§‹é€ ã®èª¤èªçŸ¥ã€ã¨ã—ã¦å®šå¼åŒ–ã—ã€

*   æŠ•è³‡å®¶ãŒã‚·ã‚°ãƒŠãƒ«é–“ã®ç›¸é–¢ã‚„ã€æ™‚ç³»åˆ—è‡ªå·±ç›¸é–¢ã®**ãƒ¬ã‚¸ãƒ¼ãƒ ä¾å­˜æ€§**ã‚’æ­£ã—ãæ‰±ã‚ãªã„ã¨ãã€
*   æœˆæ¬¡ãƒªã‚¿ãƒ¼ãƒ³ã®è‡ªå·±ç›¸é–¢ãŒã€Œæœˆã®ç¨®é¡ã«ã‚ˆã£ã¦å¼·ãå¤‰å‹•ã™ã‚‹ã€ã‚ˆã†ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãŒç”Ÿã˜ã‚‹

ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚[SSRN+2SSRN+2](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5268329&utm_source=chatgpt.com)

ã‚ãªãŸã® `nr`, `P4`, `S`, `x_M6`, `z*_t` ãªã©ã®ã‚·ã‚°ãƒŠãƒ«ã¯ã€ã¾ã•ã«ã“ã®ãƒ¢ãƒ‡ãƒ«ãŒç¤ºã™ã€Œèª¤ã£ãŸæœŸå¾…å½¢æˆã«ã‚ˆã‚‹äºˆæ¸¬å¯èƒ½æ€§ã€ã‚’æŠ½å‡ºã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚

* * *

2\. compare\_all\_methods ã®å„æˆ¦ç•¥ï¼ˆMethod 0ã€œ6ï¼‰
------------------------------------------

### 2.1 Method 0ï¼šå˜ç´”å¹³å‡ï¼ˆM0\_meanï¼‰

**ä»•æ§˜**

*   äºˆæ¸¬å¼ï¼š
    $$
     \hat r_{t+1}^{(0)} = \bar r_t = \frac{1}{t}\sum_{s\le t} r_s,
    $$
    ã“ã“ã§  $r_t$  ã¯å¸‚å ´è¶…éãƒªã‚¿ãƒ¼ãƒ³ã€‚
*   æˆ¦ç•¥ï¼š $\hat r_{t+1}^{(0)}$  ã®ç¬¦å·ã«å¿œã˜ã¦ãƒ­ãƒ³ã‚°/ã‚·ãƒ§ãƒ¼ãƒˆã™ã‚‹ sign æˆ¦ç•¥ã€‚

**å­¦è¡“çš„æ„å‘³**

*   ã€Œreturn predictability ãŒã»ã¼ã‚¼ãƒ­ã€ã¨ã„ã†å¾“æ¥ã®å®Ÿè¨¼çµæœã‚’èƒŒæ™¯ã«ã—ãŸ**å¸°ç„¡ãƒ¢ãƒ‡ãƒ«**ï¼ˆEMH çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼‰ã€‚[OUP Academic+1](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf?utm_source=chatgpt.com)
*   Campbell & Yogo (2003) ãªã©ã®äºˆæ¸¬å¯èƒ½æ€§ãƒ†ã‚¹ãƒˆã§ã‚‚ã€ç„¡æ¡ä»¶å¹³å‡ã¯ã€Œæœ€ã‚‚å˜ç´”ãªäºˆæ¸¬ãƒ«ãƒ¼ãƒ«ã€ã¨ã—ã¦ã—ã°ã—ã°æ¯”è¼ƒå¯¾è±¡ã«ãªã‚Šã¾ã™ã€‚[NBER](https://www.nber.org/system/files/working_papers/w10026/w10026.pdf?utm_source=chatgpt.com)

ã“ã“ã§ã¯ã€Guo ã®é«˜åº¦ãªã‚·ã‚°ãƒŠãƒ«ãŒã€Œå˜ç´”å¹³å‡ã‚’ã©ã‚Œã ã‘ä¸Šå›ã‚‹ã‹ã€ã‚’æ¸¬ã‚‹ãŸã‚ã®**æœ€ä½é™ã®æ¯”è¼ƒåŸºæº–**ã¨è§£é‡ˆã§ãã¾ã™ã€‚

* * *

### 2.2 Method 1ï¼šAR(1)ï¼ˆM1\_AR1ï¼‰

**ä»•æ§˜**

*   äºˆæ¸¬å¼ï¼š
    $$
     r_{t+1} = \alpha + \phi r_t + \varepsilon_{t+1}.
    $$
*   éå»ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã expanding OLS ã§  $\phi$  ã‚’æ¨å®šã—ã€1 æœŸå…ˆã‚’äºˆæ¸¬ã€‚
*   sign æˆ¦ç•¥ã«ã‚ˆã‚Šãƒ­ãƒ³ã‚°/ã‚·ãƒ§ãƒ¼ãƒˆã‚’æ±ºå®šã€‚

**å­¦è¡“çš„æ„å‘³**

*   ã‚‚ã£ã¨ã‚‚æ¨™æº–çš„ãªã€Œ**ãƒªã‚¿ãƒ¼ãƒ³å¤–æŒ¿**ã€ãƒ¢ãƒ‡ãƒ«ã€‚
*   ã—ã‹ã—ã€Guo (2025) ãŒç¤ºã™ã‚ˆã†ã«ã€**æœˆæ¬¡å¸‚å ´ãƒªã‚¿ãƒ¼ãƒ³ã®å˜ç´” AR(1) ã¯éå¸¸ã«å¼±ã„äºˆæ¸¬åŠ›ã—ã‹æŒãŸãªã„**ã€‚[OUP Academic](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf?utm_source=chatgpt.com)
*   ã—ãŸãŒã£ã¦ã€æœ¬æˆ¦ç•¥ã¯
    > ã€ŒæŠ•è³‡å®¶ãŒ newsy / non-newsy ã®åˆ¥ã‚„ earnings ã®æƒ…å ±æ§‹é€ ã‚’ä¸€åˆ‡è€ƒæ…®ã›ãšã€å˜ã«ç›´è¿‘ãƒªã‚¿ãƒ¼ãƒ³ã‚’å¤–æŒ¿ã—ã¦ã„ã‚‹ã€
    ã¨ã„ã†å¤å…¸çš„ãªè¡Œå‹•ä»®èª¬ã«å¯¾å¿œã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã™ã€‚

* * *

### 2.3 Method 2ï¼šnr å˜ç‹¬ï¼ˆM2\_NRï¼‰â€” Correlation-Neglect ã® core

**ä»•æ§˜**

*   `mkt_nr`ï¼š
    *   ç¾åœ¨æ™‚ç‚¹ã‚ˆã‚Šç›´è¿‘ã®ã€ŒN ã¾ãŸã¯ Rï¼ˆæœˆã®ç¬¬1 or 2 æœˆï¼‰ã€ã®å¸‚å ´è¶…éãƒªã‚¿ãƒ¼ãƒ³ã€‚
    *   Guo ã® notation ã§ã„ã†ã€Œç›´è¿‘ã® earnings-heavy æœˆã®ãƒªã‚¿ãƒ¼ãƒ³ã€ã®ç°¡ç•¥åŒ–ã€‚
*   äºˆæ¸¬å¼ï¼š
    $$
     r_{t+1} = \alpha + \beta_{\text{nr}} \,\text{nr}_t + \varepsilon_{t+1}.
    $$

**å­¦è¡“çš„æ„å‘³**

*   Guo (2025) ã®**æ™‚ç³»åˆ—åˆ†è§£**ã§ã¯ã€éå» 12 ãƒ¶æœˆã®ã†ã¡ã€Œnewsy æœˆãƒªã‚¿ãƒ¼ãƒ³ã€ãŒç‰¹ã«é‡è¦ãªå½¹å‰²ã‚’æœãŸã™ã“ã¨ãŒç¤ºã•ã‚Œã¾ã™ã€‚[OUP Academic+1](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf?utm_source=chatgpt.com)
*   `nr_t` ã¯ã€ãã†ã—ãŸã€Œearnings é›†ç´„æœˆï¼ˆnewsy / repetitiveï¼‰ã®ç›´è¿‘ã‚·ãƒ§ãƒƒã‚¯ã€ã‚’ 1 å€‹ã®ã‚¹ã‚«ãƒ©ãƒ¼ã§ä»£è¡¨ã•ã›ãŸã‚·ã‚°ãƒŠãƒ«ã§ã‚ã‚Šã€
    *   æŠ•è³‡å®¶ãŒ earnings ã‚·ãƒ§ãƒƒã‚¯ã‚’**å°†æ¥ã«å˜èª¿ã«å¤–æŒ¿ã—ã¦ã—ã¾ã†**ï¼ˆextrapolationï¼‰ã€
    *   ã—ã‹ã—ã€Œnewsy vs non-newsy ã§äºˆæ¸¬åŠ›ãŒç•°ãªã‚‹ã€ã¨ã„ã†**ç›¸é–¢æ§‹é€ ã®é•ã„ã‚’ç„¡è¦–**ã—ã¦ã„ã‚‹  
        ã“ã¨ã«ã‚ˆã‚‹ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«ã—ãŸ predictor ã¨è§£é‡ˆã§ãã¾ã™ã€‚[SSRN+2SSRN+2](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5268329&utm_source=chatgpt.com)

ã“ã®ã‚·ãƒ³ãƒ—ãƒ«ãª `nr` ãƒ¢ãƒ‡ãƒ«ã¯ã€Guo & Wachter (2025) ãŒä¸€èˆ¬åŒ–ã—ã¦ã„ã‚‹ã€Œcorrelation neglect ã«åŸºã¥ãæ™‚ç³»åˆ—è‡ªå·±ç›¸é–¢ã®å¤‰å‹•ã€ã®æœ€ã‚‚ç´ æœ´ãªè¿‘ä¼¼ç‰ˆã¨ä½ç½®ã¥ã‘ã‚‰ã‚Œã¾ã™ã€‚[SSRN+2SSRN+2](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5268329&utm_source=chatgpt.com)

* * *

### 2.4 Method 3ï¼šP4 å˜ç‹¬ï¼ˆM3\_P4ï¼‰â€” Parameter Compression

**ä»•æ§˜**

*   `mkt_nm1..4`ï¼šç›´è¿‘ 4 å›ã® newsy æœˆã®è¶…éãƒªã‚¿ãƒ¼ãƒ³ã€‚
*   `P4`ï¼ˆã‚³ãƒ¼ãƒ‰ã§ã¯ `mkt_nm4_avg` ã¨åŒä¸€ï¼‰ï¼š
    $$
     P4_t = \frac{1}{4}\sum_{j=1}^{4}\text{mkt\_nm}(t,j),
    $$
    ã¨ã„ã† **éå» 4 newsy æœˆã®å¹³å‡**ã€‚
*   äºˆæ¸¬å¼ï¼š
    $$
     r_{t+1} = \alpha + \beta_{P4} P4_t + \varepsilon_{t+1}.
    $$

**å­¦è¡“çš„æ„å‘³**

*   Guo ã® Table 3 ã§ã¯ã€
    $$
     r_t = \alpha + \sum_{j=1}^{4} \beta_j \, \text{mktnm}(t,j) + \varepsilon_t
    $$
    ã¨ã„ã†ã€Œ4 ã¤ã® newsy æœˆãƒªã‚¿ãƒ¼ãƒ³ã‚’åˆ¥ã€…ã®ä¿‚æ•°ã§å›å¸°ã™ã‚‹ã€ä»•æ§˜ãŒæç¤ºã•ã‚Œã¾ã™ã€‚[OUP Academic+1](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf?utm_source=chatgpt.com)
*   ã—ã‹ã—å®Ÿå‹™ä¸Šãƒ»è¨ˆé‡ä¸Šã¯ã€4 ã¤ã®ä¿‚æ•°ã‚’ 1 ã¤ã«ã¾ã¨ã‚ãŸã€Œparameter-compressionï¼ˆæ¬¡å…ƒåœ§ç¸®ï¼‰ã€ãŒã—ã°ã—ã°æœ‰åŠ¹ã§ã‚ã‚Šã€`P4` ã¯ãã®**å˜ç´”å¹³å‡ã«ã‚ˆã‚‹åœ§ç¸®**ã«ç›¸å½“ã—ã¾ã™ã€‚
*   è¡Œå‹•ãƒ•ã‚¡ã‚¤ãƒŠãƒ³ã‚¹çš„ã«ã¯ã€æŠ•è³‡å®¶ãŒéå»è¤‡æ•°ã® newsy æœˆã‚·ãƒ§ãƒƒã‚¯ã‚’ã€Œã ã„ãŸã„åŒã˜ã‚‚ã®ã€ã¨è¦‹ãªã—ã€å˜ç´”ãªå¹³å‡ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ã‚¯ã‚¹ã§åˆ¤æ–­ã—ã¦ã„ã‚‹ã€ã¨ã„ã†èªçŸ¥ãƒ¢ãƒ‡ãƒ«ã¨æ•´åˆçš„ã§ã™ã€‚[econstor.eu+1](https://www.econstor.eu/bitstream/10419/52523/1/66946063X.pdf?utm_source=chatgpt.com)

* * *

### 2.5 Method 4ï¼šnr + P4 ã® 2å¤‰æ•°å›å¸°ï¼ˆM4\_NR\_P4ï¼‰

**ä»•æ§˜**

*   äºˆæ¸¬å¼ï¼š
    $$
     r_{t+1} = \alpha + \beta_{\text{nr}} \,\text{nr}_t + \beta_{P4} \,P4_t + \varepsilon_{t+1}.
    $$

**å­¦è¡“çš„æ„å‘³**

*   `nr`ï¼šç›´è¿‘ 1 å›ã® earnings-heavy æœˆã‚·ãƒ§ãƒƒã‚¯
*   `P4`ï¼šã‚ˆã‚Šé•·ã„æœŸé–“ã«ã‚ãŸã‚‹ newsy æœˆã‚·ãƒ§ãƒƒã‚¯ã®å¹³å‡  
    ã¨ã„ã† 2 ã¤ã®å°ºåº¦ã‚’åŒæ™‚ã«ä½¿ã†ã“ã¨ã§ã€
    1.  **çŸ­æœŸçš„ãªéå‰°åå¿œ / åè»¢**ï¼ˆnrï¼‰
2.  **ä¸­æœŸçš„ãªãƒˆãƒ¬ãƒ³ãƒ‰å¤–æŒ¿**ï¼ˆP4ï¼‰

ã®ä¸¡æ–¹ã®æˆåˆ†ã‚’åˆ†é›¢ã—ã¦æ‰ãˆã‚‹è©¦ã¿ã¨è§£é‡ˆã§ãã¾ã™ã€‚

*   Guo ã® Table 4 ã«ãŠã‘ã‚‹ã€ŒMethod 5ï¼ˆjoint specificationï¼‰ã€ã«æœ€ã‚‚è¿‘ã„æ§‹é€ ã§ã‚ã‚Šã€
    *   correlation neglectï¼ˆéåº¦ã« news ã‚’é‡è¦–ã™ã‚‹ï¼‰
    *   earnings extrapolationï¼ˆéå» earnings ã‚’éå‰°ã«å¤–æŒ¿ã™ã‚‹ï¼‰  
        ã®2 ç¨®ã®è¡Œå‹•ãƒã‚¤ã‚¢ã‚¹ã‚’ 1 æœ¬ã®å›å¸°ã§æ•æ‰ã™ã‚‹è¨­è¨ˆã§ã™ã€‚[OUP Academic+2SSRN+2](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf?utm_source=chatgpt.com)

* * *

### 2.6 Method 6ï¼šS ãƒ™ãƒ¼ã‚¹ã® 1å¤‰æ•°ãƒ¢ãƒ‡ãƒ«ï¼ˆM6\_S, x\_M6ï¼‰

**ä»•æ§˜ï¼ˆç°¡æ˜“ç‰ˆ M6\_Sï¼‰**

*   `S_t`ï¼š  
    ã€Œ**ç›´è¿‘ 4 å›ã® newsy æœˆã®ãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³**ã®å’Œã€
*   `x_M6(t)`ï¼š
    *    $S_{t-1}$  ã‚’ expanding å¹³å‡ã§ demean
    *   äºˆæ¸¬å¯¾è±¡æœˆãŒ newsy ã®å ´åˆã¯ç¬¦å·åè»¢ï¼ˆnewsy vs non-newsy ã§ç¬¦å·ãŒå¤‰ã‚ã‚‹æ§‹é€ ã‚’æ¨¡å€£ï¼‰
*   äºˆæ¸¬å¼ï¼ˆç°¡æ˜“ç‰ˆï¼‰ï¼š
    $$
     r_{t+1} = \alpha + \beta_S x_{M6,t} + \varepsilon_{t+1}.
    $$

**æœ¬æ¥ã® Method 6ï¼ˆè«–æ–‡ä»•æ§˜ï¼‰**

*   Guo ã®æœ¬æ¥ã® Method 6 ã§ã¯ã€
    *   ç›®çš„å¤‰æ•°ã¯ã€Œãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ âˆ’ ç„¡æ¡ä»¶å¹³å‡ã€
    *    $\bar r$  ã«ä¿‚æ•° 1 ã‚’**ç†è«–çš„åˆ¶ç´„**ã¨ã—ã¦èª²ã—ã€ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°éƒ¨åˆ†ã®ã¿ã‚’  $\beta_S x_t$  ã§èª¬æ˜  
        ã¨ã„ã†å½¢ã«ãªã£ã¦ãŠã‚Šã€ã‚ãªãŸã® `backtest_method6_strategy` ã¯ã“ã‚Œã«ã‹ãªã‚Šå¿ å®Ÿã§ã™ã€‚[OUP Academic+2SSRN+2](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf?utm_source=chatgpt.com)

**å­¦è¡“çš„æ„å‘³**

*   `S` ã¯ã€éå»ã® newsy æœˆã‚·ãƒ§ãƒƒã‚¯ã‚’ **earnings extrapolation + correlation neglect ãƒ¢ãƒ‡ãƒ«ã§æœ€é©ã«è¦ç´„ã—ãŸ sufficient statistic** ã«è¿‘ã„å½¹å‰²ã‚’æœãŸã—ã¾ã™ã€‚[OUP Academic+2Finance Department+2](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf?utm_source=chatgpt.com)
*   å®Ÿéš›ã€Guo & Wachter (2025) ã¯ã€S å‹ã®ã‚·ã‚°ãƒŠãƒ«ã‚’ç”¨ã„ãŸã¨ãã® OOS  $R^2$  ãŒã€å¾“æ¥æ–‡çŒ®ã§å ±å‘Šã•ã‚Œã‚‹å€¤ã‚ˆã‚Šä¸€æ¡å¤§ãã„ã“ã¨ã‚’ç¤ºã—ã¦ãŠã‚Šã€return predictability æ–‡çŒ®ã®ã€Œpriorã€ã‚’æ›´æ–°ã™ã¹ãã ã¨ä¸»å¼µã—ã¦ã„ã¾ã™ã€‚[SSRN+1](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5268329&utm_source=chatgpt.com)

* * *

3\. æ—§ z\*\_t æˆ¦ç•¥ã¨ Method 6 æ‹¡å¼µç‰ˆ
-----------------------------

ã“ã“ã‹ã‚‰ã¯ã€ã‚ãªãŸç‹¬è‡ªã®æ‹¡å¼µï¼ˆæ—§ z\*\_tã€Method 6 nr+P4 2å¤‰æ•°ï¼‰ã‚’ã€ä¸Šè¨˜æ–‡çŒ®æ çµ„ã¿ã®ä¸­ã§ä½ç½®ã¥ã‘ã¾ã™ã€‚

### 3.1 æ—§ z\*\_t æˆ¦ç•¥ï¼ˆbuild\_z\_star\_online + apply\_timing\_strategyï¼‰

**ä»•æ§˜**

1.  `add_nr_and_p4` ã§ nr ã¨ P4ï¼ˆ`mkt_nm4_avg`ï¼‰ã‚’æ§‹ç¯‰ã€‚
2.  ãƒ­ãƒ¼ãƒªãƒ³ã‚° 20 å¹´ window ã® OLSï¼š
    $$
    r_t = \alpha_t + \beta_{\text{nr},t} \,\text{nr}_t + \beta_{P4,t}\,P4_t + \varepsilon_t,
    $$
    ï¼ˆãŸã ã—å›å¸°ã«ä½¿ã†ã®ã¯  $t$  ã®å‰ã¾ã§ï¼‰
3.  z\*\_t ã‚’
    $$
     z^*_t = \beta_{\text{nr},t}\,\text{nr}_t + \beta_{P4,t}\,P4_t
    $$
    ã¨å®šç¾©ã—ã€ã“ã‚Œã‚’ `apply_timing_strategy` ã§ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæˆ¦ç•¥ã«å¤‰æ›ã€‚

**å­¦è¡“çš„è§£é‡ˆ**

*   æ§‹é€ çš„ã«ã¯ã€Guo Table 4 ã® **Method 5ï¼ˆjoint nr + P4 ãƒ¢ãƒ‡ãƒ«ï¼‰** ã‚’ã€ã€Œrolling 20 å¹´ OLS + ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒ†ã‚£ãƒ³ã‚°ã€ã§å®Ÿè£…ã—ãŸã‚‚ã®ã¨è§£é‡ˆã§ãã¾ã™ã€‚
*   ãŸã ã—è«–æ–‡ã® Method 6 ã¨ç•°ãªã‚Šï¼š
    *   ç›®çš„å¤‰æ•°ãŒã€Œè¶…éãƒªã‚¿ãƒ¼ãƒ³ã€ã§ã‚ã‚Šã€ãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ã‚„å¹³å‡æˆåˆ†ã® decomposition ã‚’æ˜ç¤ºçš„ã«è¡Œã£ã¦ã„ãªã„ã€‚
    *    $\bar r$  ã«ä¿‚æ•° 1 ã‚’èª²ã™åˆ¶ç´„ãŒãªã„ãŸã‚ã€ã€Œãƒªã‚¹ã‚¯ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ã®å¤‰å‹•ã€ã¨ã€ŒãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°æˆåˆ†ã€ãŒæ··åœ¨ã—ã‚„ã™ã„ã€‚
*   ä¸€æ–¹ã§ã€20 å¹´ã¨ã„ã†æ¯”è¼ƒçš„çŸ­ã„çª“ã‚’ç”¨ã„ã¦ã„ã‚‹ãŸã‚ã€**æ§‹é€ å¤‰åŒ–ï¼ˆä¾‹ãˆã° 1980 å¹´ä»£ vs 2000 å¹´ä»£ vs 2020 å¹´ä»¥é™ï¼‰ã®å½±éŸ¿ã‚’ã‚ˆã‚Šé‹­æ•ã«åæ˜ **ã§ãã‚‹ã€ã¨ã„ã† practical ãªåˆ©ç‚¹ãŒã‚ã‚Šã¾ã™ã€‚

* * *

### 3.2 Method 6 å¿ å®Ÿç‰ˆï¼ˆbacktest\_method6\_strategyï¼‰

**ä»•æ§˜å†æ²**

*   ç›®çš„å¤‰æ•°ï¼š
    $$
     y_t = \text{mkt\_total}_t - \bar r_{t-1}
    $$
*   èª¬æ˜å¤‰æ•°ï¼šMethod 6 ã® `x_t`
*   åˆ¶ç´„ï¼š $\bar r_{t-1}$  ã®ä¿‚æ•°ã¯ 1 ã«å›ºå®šï¼ˆæ§‹é€ ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®ç†è«–çš„åˆ¶ç´„ï¼‰ã€‚
*    $\beta_t$  ã¯ expanding OLS ã§é€æ¬¡æ¨å®šã•ã‚Œã€ãƒã‚¸ã‚·ãƒ§ãƒ³ã¯  $w_t = \beta_t x_t$ ã€‚
*   æœ€å¾Œã«ã€**æˆ¦ç•¥ãƒœãƒ©ã‚’å¸‚å ´ãƒœãƒ©ã«åˆã‚ã›ã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°**ã‚’å®Ÿæ–½ã€‚

**å­¦è¡“çš„æ„å‘³**

*   Guo ã® earnings extrapolation ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰å°ã‹ã‚Œã‚‹ã€Œ**èª¤ã£ãŸæœŸå¾…ã®ã¿ã«èµ·å› ã™ã‚‹äºˆæ¸¬å¯èƒ½æ€§**ã€ã‚’ãƒ”ãƒ¥ã‚¢ã«æŠ½å‡ºã—ã‚ˆã†ã¨ã™ã‚‹è¨­è¨ˆã€‚[OUP Academic+2SSRN+2](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf?utm_source=chatgpt.com)
*   çµŒæ¸ˆçš„ã«ã¯ã€
    *   ãƒªã‚¹ã‚¯ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ã®æ™‚é–“å¤‰å‹•ï¼ˆåˆç†çš„ãª componentï¼‰ã¯  $\bar r_{t-1}$  ã§èª¬æ˜ã—ã€
    *   æ®‹å·®éƒ¨åˆ†  $y_t$  ã‚’ correlation neglect ãŒç”Ÿã‚€ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ã¨ã¿ãªã™  
        ã¨ã„ã† decomposition ã«åŸºã¥ãã¾ã™ã€‚

ã—ãŸãŒã£ã¦ã€ã“ã® Method 6 æˆ¦ç•¥ã¯ã€ã€ŒGuo ã®ç†è«–ãƒ¢ãƒ‡ãƒ«ã«æœ€ã‚‚å¿ å®Ÿãªå®Ÿè£…ã€ã¨è¨€ãˆã¾ã™ã€‚

* * *

### 3.3 Method 6 nr+P4 2å¤‰æ•°æ‹¡å¼µï¼ˆbacktest\_method6\_zstar\_strategyï¼‰

**ä»•æ§˜**

*   `x1_t, x2_t`ï¼š
    *   nr ã¨ P4 ã®ãã‚Œãã‚Œã‚’ã€Method 6 ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆexpanding demean + newsy ã§ sign flipï¼‰ã§å¤‰æ›ã—ãŸã‚‚ã®ã€‚
    *   ã¤ã¾ã‚Šã€`x1` ã¯ã€ŒçŸ­æœŸ nr ã‚·ãƒ§ãƒƒã‚¯ã® correlation-neglect æˆåˆ†ã€ã€`x2` ã¯ã€Œä¸­æœŸ P4 ã‚·ãƒ§ãƒƒã‚¯ã®æˆåˆ†ã€ã¨ã„ã†è§£é‡ˆã€‚
*   ç›®çš„å¤‰æ•°ï¼š
    $$
     y_t = \text{mkt\_total}_t - \bar r_{t-1}
    $$
*   å›å¸°å¼ï¼š
    $$
     y_t = \beta_{1,t} x1_t + \beta_{2,t} x2_t + \varepsilon_t,
    $$
    ã‚’ expanding äºŒå¤‰é‡ OLS ã§æ®µéšçš„ã«æ¨å®šã€‚
*   æˆ¦ç•¥ãƒã‚¸ã‚·ãƒ§ãƒ³ï¼š
    $$
     w_t = \beta_{1,t} x1_t + \beta_{2,t} x2_t,
    $$
    ã‚’å¸‚å ´ãƒœãƒ©ã«åˆã‚ã›ã‚‹ã‚ˆã†ã‚¹ã‚±ãƒ¼ãƒ«ã€‚

**å­¦è¡“çš„æ„å‘³**

*   Method 6 ã®ã€ŒSï¼ˆnews-sumï¼‰ã€ã¯ã€å®Ÿã¯**nr ã¨ P4 ã®ç·šå½¢çµåˆã®ã‚ˆã†ãªå½¹å‰²**ã‚’æœãŸã—ã¦ã„ã‚‹ã¨è§£é‡ˆã§ãã¾ã™ã€‚
*   ã‚ãªãŸã® 2 å¤‰æ•°ç‰ˆã¯ã€ã“ã® S ã‚’ã‚ãˆã¦ã€ŒçŸ­æœŸ nr æˆåˆ†ã€ã¨ã€Œä¸­æœŸ P4 æˆåˆ†ã€ã«åˆ†è§£ã—ã€ãã‚Œãã‚Œã®ä¿‚æ•°  $\beta_1,\beta_2$  ã‚’åˆ¥ã€…ã«æ¨å®šã™ã‚‹ã“ã¨ã§ï¼š
    1.  **ã”ãç›´è¿‘ã® newsy ã‚·ãƒ§ãƒƒã‚¯**ã«å¯¾ã™ã‚‹å¸‚å ´ã® overreaction / mean-reversion
    2.  \*\*æ•°å››åŠæœŸã«ã‚ãŸã‚‹ earnings ã®ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆP4ï¼‰\*\*ã«å¯¾ã™ã‚‹ extrapolation
    ã®å¼·ã•ã‚’æ™‚å¤‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã—ã¦è­˜åˆ¥ã—ã‚ˆã†ã¨ã™ã‚‹æ‹¡å¼µã§ã™ã€‚
*   æ–‡çŒ®ä¸Šã€Guo è‡ªèº«ã¯ã€Œå˜ä¸€ S ã‚·ã‚°ãƒŠãƒ«ã€ã‚’æ¨å¥¨ã—ã¦ã„ã¾ã™ãŒã€Guo & Wachter (2025) ã®ä¸€èˆ¬çš„ãª correlation-neglect ãƒ¢ãƒ‡ãƒ«ã‚’è¸ã¾ãˆã‚‹ã¨ã€ã“ã†ã—ãŸãƒãƒ«ãƒã‚·ã‚°ãƒŠãƒ«ã¸ã®æ‹¡å¼µã¯è‡ªç„¶ãªç ”ç©¶æ–¹å‘ã§ã™ã€‚[SSRN+2SSRN+2](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5268329&utm_source=chatgpt.com)

* * *

4\. ã¾ã¨ã‚ï¼šæ–‡çŒ®ã® Method ã¨ã‚ãªãŸã®æˆ¦ç•¥ã®å¯¾å¿œ
-----------------------------

æœ€å¾Œã«ã€Table 4ï¼ˆMethods 1â€“7ï¼‰ãŠã‚ˆã³ Guo & Wachter ã®è¨˜è¿°ã¨ã€ã‚ãªãŸã®å®Ÿè£…ã®å¯¾å¿œã‚’æ•´ç†ã™ã‚‹ã¨ï¼š

| ã‚ãªãŸã®ãƒ©ãƒ™ãƒ« / ã‚³ãƒ¼ãƒ‰ | å­¦è¡“çš„ãªä½ç½®ã¥ã‘ | Guo (2025) / Guo & Wachter (2025) ã¨ã®å¯¾å¿œ |
| --- | --- | --- |
| M0\_mean | ç„¡æ¡ä»¶å¹³å‡ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ | æ–‡çŒ®ä¸­ã®ã€Œå¼±ã„ predictabilityã€å‰æã® EMH ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆç›´æ¥ã® Method ã§ã¯ãªã„ï¼‰[OUP Academic+1](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf?utm_source=chatgpt.com) |
| M1\_AR1 | å˜ç´”ãªãƒªã‚¿ãƒ¼ãƒ³å¤–æŒ¿ | ã€Œpast 12m return â†’ next month returnã€ã®ç´ æœ´ç‰ˆã€‚æ–‡çŒ®ã§ã¯ã€Œã»ã¼äºˆæ¸¬åŠ›ãªã—ã€ã¨ã•ã‚Œã‚‹éƒ¨é¡ã€‚[OUP Academic](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf?utm_source=chatgpt.com) |
| M2\_NR | Correlation-neglect ã‚·ã‚°ãƒŠãƒ«ï¼ˆå˜å¤‰é‡ï¼‰ | Table 3 ã® newsy æœˆãƒªã‚¿ãƒ¼ãƒ³ã®å½¹å‰²ã«è¿‘ã„ã€Œnewsy ã‚·ãƒ§ãƒƒã‚¯å˜ç‹¬ predictorã€ |
| M3\_P4 | Parameter-compression ã‚·ã‚°ãƒŠãƒ« | Table 3 ã®  $\{\text{mktnm}(t,j)\}_{j=1}^4$  ã‚’å˜ç´”å¹³å‡ã§åœ§ç¸®ã—ãŸ predictor |
| M4\_NR\_P4 | nr + P4 joint model | Table 4 ã® multi-predictorï¼ˆMethod 4 ã¾ãŸã¯ 5ï¼‰ã«ç›¸å½“ã™ã‚‹ joint specification |
| M6\_S / backtest\_method6\_strategy | Guo æ¨å¥¨ Method 6 | Sï¼ˆéå»4 newsy ã®å’Œï¼‰ã‚’ sufficient statistic ã¨ã¿ãªã™ 1 å¤‰æ•°ãƒ¢ãƒ‡ãƒ«ã€‚è«–æ–‡ãŒæœ€ã‚‚æ¨å¥¨ã™ã‚‹ä»•æ§˜ã€‚[OUP Academic+2SSRN+2](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf?utm_source=chatgpt.com) |
| æ—§ z\*\_t + apply\_timing\_strategy | Method 5 ã‚’ rolling OLS + ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã§æ‹¡å¼µã—ãŸç‹¬è‡ªå®Ÿè£… | nr+P4 joint ã‚’è¶…éãƒªã‚¿ãƒ¼ãƒ³ã§ãƒ•ã‚£ãƒƒãƒˆã—ã€ãã®ç·šå½¢çµåˆã‚’ z\*\_t ã‚·ã‚°ãƒŠãƒ«ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹å®Ÿå‹™ç‰ˆ |
| Method 6 nr+P4 2-var æ‹¡å¼µ | correlation-neglect ãƒ¢ãƒ‡ãƒ«ã® multi-signal æ‹¡å¼µ | Guo ã® Method 6 ã®æ§‹é€ ï¼ˆmktÌ„ ä¿‚æ•°1ï¼‰ã‚’ä¿ã¡ã¤ã¤ã€S ã‚’ nr/P4 ã«åˆ†è§£ã—ãŸç ”ç©¶è€…ç‹¬è‡ªã®æ‹¡å¼µ |

* * *

ã‚‚ã—æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¨ã—ã¦ã€

*   å„æˆ¦ç•¥ã® **OOS RÂ², Sharpe, å‹ç‡**ã‚’å¹´ä»£ã”ã¨ã«åˆ†è§£ã—ã¦
*   ã€Œã©ã®è¡Œå‹•ãƒã‚¤ã‚¢ã‚¹ï¼ˆçŸ­æœŸ nr vs ä¸­æœŸ P4ï¼‰ãŒã€ã©ã®æ™‚ä»£ã«ã©ã‚Œã ã‘å¼·ãåŠ¹ã„ã¦ã„ã‚‹ã‹ã€

ã‚’å®šé‡çš„ã«æ•´ç†ã—ãŸã„å ´åˆã¯ã€ãã®ãŸã‚ã®åˆ†æã‚³ãƒ¼ãƒ‰ï¼ˆrolling OOS RÂ², regime-wise decompositionï¼‰ã‚‚ç”¨æ„ã§ãã¾ã™ã€‚

## Response:
æ€è€ƒæ™‚é–“: 25s

ä»¥ä¸‹ã§ã¯ã€ã™ã§ã«å®Ÿè£…æ¸ˆã¿ã®

*   `compare_all_methods(csv_path, ...)`ï¼ˆâ†’ `ff`, `results` ã‚’è¿”ã™ï¼‰
*   `df_old`, `df_m6`, `df_m6_2` ãªã©ã®æˆ¦ç•¥ DataFrameï¼ˆ`strat_total`, `mkt_total` åˆ—ã‚ã‚Šï¼‰

ã‚’å‰æã«ã€

1.  **Rolling OOS RÂ²** ã‚’æ™‚ç³»åˆ—ã§ãƒ—ãƒ­ãƒƒãƒˆã™ã‚‹ã‚³ãƒ¼ãƒ‰
2.  **Regime-wise decomposition**ï¼ˆN/R/3 ã‚„ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ»ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¥ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†è§£ï¼‰

ã®ãŸã‚ã®è¿½åŠ ã‚³ãƒ¼ãƒ‰ã‚’ã¾ã¨ã‚ã¾ã™ã€‚

ãã®ã¾ã¾æ—¢å­˜ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®æœ«å°¾ã«è¿½è¨˜ã—ã¦ä½¿ãˆã‚‹å½¢ã«ã—ã¦ã‚ã‚Šã¾ã™ã€‚

* * *

1\. Rolling OOS RÂ² ã®è¨ˆç®—ãƒ»å¯è¦–åŒ–
--------------------------

### 1.1 1 æˆ¦ç•¥åˆ†ã® rolling OOS RÂ² ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°

```python
def rolling_oos_r2_series(y: pd.Series,
                          y_hat: pd.Series,
                          window: int = 120) -> pd.Series:
    """
    y      : å®Ÿç¾ãƒªã‚¿ãƒ¼ãƒ³ (ä¾‹: mkt_excess)
    y_hat  : OOS äºˆæ¸¬å€¤ (compare_all_methods ã®æˆ»ã‚Šå€¤ãªã©)
    window : R^2 ã‚’è¨ˆç®—ã™ã‚‹ãƒ­ãƒ¼ãƒªãƒ³ã‚°çª“ã®é•·ã•ï¼ˆæœˆæ•°ï¼‰

    å®šç¾©:
      å„æ™‚ç‚¹ t ã«ã¤ã„ã¦ã€ç›´è¿‘ window æœŸé–“ã®
        SSR_model = Î£ (y - y_hat)^2
        SSR_mean  = Î£ (y - yÌ„)^2   ï¼ˆåŒã˜ window å†…ã§ã®å˜ç´”å¹³å‡ã‚’ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼‰
      ã¨ã—ã¦
        R^2_t = 1 - SSR_model / SSR_mean
      ã‚’è¨ˆç®—ã™ã‚‹ã€‚
    """
    # å…±é€šã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«æƒãˆã‚‹
    data = pd.concat([y.rename("y"), y_hat.rename("y_hat")], axis=1).dropna()
    y_ = data["y"]
    yhat_ = data["y_hat"]
    idx = y_.index

    r2 = pd.Series(index=idx, dtype=float)

    for i in range(len(idx)):
        end = idx[i]
        start_pos = max(0, i - window + 1)
        window_idx = idx[start_pos:i+1]

        yw = y_.loc[window_idx]
        yh = yhat_.loc[window_idx]

        if len(yw) < window:
            r2[end] = np.nan
            continue

        y_mean = yw.mean()
        ss_model = ((yw - yh) ** 2).sum()
        ss_mean  = ((yw - y_mean) ** 2).sum()

        if ss_mean > 0:
            r2[end] = 1.0 - ss_model / ss_mean
        else:
            r2[end] = np.nan

    return r2
```

### 1.2 compare\_all\_methods ã®çµæœã‹ã‚‰ã€å…¨ Method ã® rolling OOS RÂ² ã‚’ä½œã£ã¦ãƒ—ãƒ­ãƒƒãƒˆ

```python
def build_rolling_oos_r2_df(ff: pd.DataFrame,
                            results: dict,
                            window: int = 120) -> pd.DataFrame:
    """
    compare_all_methods ã®æˆ»ã‚Šå€¤:
      ff      : mkt_excess ãªã©ã‚’å«ã‚€ DF
      results : {method_name: (y_hat, strat_excess)}
    ã‚’å…¥åŠ›ã¨ã—ã¦ã€å„ Method ã® rolling OOS R^2 ã® DataFrame ã‚’è¿”ã™ã€‚
    """
    y = ff["mkt_excess"]

    r2_dict = {}
    for name, (y_hat, strat) in results.items():
        r2_series = rolling_oos_r2_series(y, y_hat, window=window)
        r2_dict[name] = r2_series

    r2_df = pd.DataFrame(r2_dict)
    return r2_df

def plot_rolling_oos_r2(r2_df: pd.DataFrame,
                        title: str = "Rolling OOS R^2",
                        highlight_methods: list = None):
    """
    r2_df: index = æ—¥ä»˜, columns = Method åï¼ˆbuild_rolling_oos_r2_df ã®å‡ºåŠ›ï¼‰
    highlight_methods: ç›®ç«‹ãŸã›ãŸã„ Method ã®ãƒªã‚¹ãƒˆï¼ˆä¾‹: ["M2_NR", "M3_P4", "M6_S"]ï¼‰
    """
    plt.figure(figsize=(14,5))

    if highlight_methods is None:
        highlight_methods = list(r2_df.columns)

    for col in r2_df.columns:
        if col in highlight_methods:
            plt.plot(r2_df.index, r2_df[col], label=col, linewidth=2)
        else:
            plt.plot(r2_df.index, r2_df[col], label=col, linewidth=1, alpha=0.4)

    plt.axhline(0.0, color="black", linestyle="--", linewidth=1)
    plt.title(title)
    plt.ylabel("OOS $R^2$ (rolling)")
    plt.legend()
    plt.grid(True)
    plt.show()
```

### 1.3 ä½¿ç”¨ä¾‹

```python
if __name__ == "__main__":
    csv_path = "F-F_Research_Data_Factors.csv"

    # ã™ã§ã«å®Ÿè¡Œæ¸ˆã¿ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¦OK
    ff_all, res_all = compare_all_methods(csv_path, min_obs=120)

    # 10å¹´çª“ (120 ãƒ¶æœˆ) ã® rolling OOS R^2
    r2_all = build_rolling_oos_r2_df(ff_all, res_all, window=120)

    # å…¨æœŸé–“ãƒ—ãƒ­ãƒƒãƒˆ
    plot_rolling_oos_r2(
        r2_all,
        title="Rolling 10-year OOS R^2 (Methods 0â€“6)",
        highlight_methods=["M2_NR", "M3_P4", "M4_NR_P4", "M6_S"]
    )

    # 2020å¹´ä»¥é™ã ã‘è¦‹ãŸã„å ´åˆ
    r2_2020 = r2_all.loc["2020-01-01":]
    plot_rolling_oos_r2(
        r2_2020,
        title="Rolling 10-year OOS R^2 (2020+)",
        highlight_methods=["M2_NR", "M3_P4", "M4_NR_P4", "M6_S"]
    )
```

* * *

2\. Regime-wise decompositionï¼ˆN/R/3 åˆ¥ãƒ»ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ¥ï¼‰
-----------------------------------------------

### 2.1 æ±ç”¨ï¼šãƒ¬ã‚¸ãƒ¼ãƒ ã”ã¨ã®å¹´ç‡çµ±è¨ˆã‚’å‡ºã™é–¢æ•°

```python
def regime_performance(
    returns: pd.Series,
    regime: pd.Series,
    name: str = "",
    dropna: bool = True
) -> pd.DataFrame:
    """
    returns : æœˆæ¬¡ãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ (strat_total ãªã©)
    regime  : ãƒ¬ã‚¸ãƒ¼ãƒ ãƒ©ãƒ™ãƒ«ï¼ˆ'N', 'R', '3' ã‚„ 'LowVol', 'HighVol' ç­‰ï¼‰
    name    : æˆ¦ç•¥åï¼ˆå‡ºåŠ›åˆ—åç”¨ï¼‰

    æˆ»ã‚Šå€¤:
      index  : ãƒ¬ã‚¸ãƒ¼ãƒ ï¼ˆunique(regime)ï¼‰
      columns: ['mu_ann', 'sigma_ann', 'Sharpe', 'n_obs']
    """
    if dropna:
        data = pd.concat([returns.rename("ret"), regime.rename("regime")], axis=1).dropna()
    else:
        data = pd.concat([returns.rename("ret"), regime.rename("regime")], axis=1)
    if data.empty:
        return pd.DataFrame()

    out = []
    for g, df_g in data.groupby("regime"):
        r = df_g["ret"]
        mu_m = r.mean()
        sd_m = r.std(ddof=1)
        mu_a = mu_m * 12
        sd_a = sd_m * math.sqrt(12)
        sharpe = mu_a / sd_a if sd_a > 0 else np.nan
        out.append({
            "regime": g,
            "mu_ann": mu_a,
            "sigma_ann": sd_a,
            "Sharpe": sharpe,
            "n_obs": len(r)
        })

    out_df = pd.DataFrame(out).set_index("regime").sort_index()
    if name:
        out_df.columns = [f"{c}_{name}" for c in out_df.columns]
    return out_df
```

* * *

### 2.2 N / R / 3 åˆ¥ã®åˆ†è§£ï¼ˆcompare\_all\_methods ã® sign æˆ¦ç•¥ï¼‰

```python
def regime_decomposition_by_month_type(
    ff: pd.DataFrame,
    results: dict,
    regime_col: str = "mt"
) -> pd.DataFrame:
    """
    ff      : compare_all_methods ãŒè¿”ã—ãŸ ffï¼ˆ'mt' ã« month_type='N','R','3' ãŒå…¥ã£ã¦ã„ã‚‹æƒ³å®šï¼‰
    results : compare_all_methods ã® resultsï¼ˆ{name: (y_hat, strat_excess)})
    regime_col: ãƒ¬ã‚¸ãƒ¼ãƒ åˆ—åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ 'mt'ï¼‰

    å„ Method ã® strat_excess ã«ã¤ã„ã¦ã€N/R/3 åˆ¥ã«å¹´ç‡çµ±è¨ˆã‚’ã¾ã¨ã‚ã¦è¿”ã™ã€‚
    ã¤ã„ã§ã« Market (mkt_excess) ã‚‚åŒæ§˜ã«å‡ºã™ã€‚
    """
    mt = ff[regime_col]

    # Market
    mkt_perf = regime_performance(ff["mkt_excess"], mt, name="MKT")

    all_perf = mkt_perf.copy()
    for name, (y_hat, strat) in results.items():
        perf = regime_performance(strat, mt, name=name)
        all_perf = all_perf.join(perf, how="outer")

    return all_perf
```

ä½¿ç”¨ä¾‹ï¼š

```python
if __name__ == "__main__":
    csv_path = "F-F_Research_Data_Factors.csv"
    ff_all, res_all = compare_all_methods(csv_path, min_obs=120)

    reg_perf = regime_decomposition_by_month_type(ff_all, res_all, regime_col="mt")
    print("=== Regime-wise performance by month_type (N/R/3) ===")
    print(reg_perf)
```

* * *

### 2.3 ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ»ãƒ¬ã‚¸ãƒ¼ãƒ ã®å®šç¾©ï¼ˆHighVol / LowVol ãªã©ï¼‰

ä¾‹ã¨ã—ã¦ã€36 ãƒ¶æœˆ rolling æ¨™æº–åå·®ã®ä¸­å¤®å€¤ã§ high / low ã‚’åˆ†ã‘ã‚‹ã‚³ãƒ¼ãƒ‰ã§ã™ã€‚

```python
def build_vol_regime(ff: pd.DataFrame,
                     window: int = 36,
                     quantile: float = 0.5,
                     col: str = "mkt_excess") -> pd.Series:
    """
    ff      : mkt_excess ã‚’å«ã‚€ DataFrame
    window  : rolling æ¨™æº–åå·®ã®çª“é•· (æœˆæ•°)
    quantile: ãƒœãƒ©é–¾å€¤ï¼ˆ0.5 = medianï¼‰
    col     : ãƒœãƒ©ã‚’è¨ˆç®—ã™ã‚‹ãƒªã‚¿ãƒ¼ãƒ³åˆ—å

    æˆ»ã‚Šå€¤:
      vol_regime: index=ff.index, values in {'LowVol','HighVol'}
    """
    rets = ff[col].dropna()
    rolling_vol = rets.rolling(window=window).std(ddof=1)
    thr = rolling_vol.quantile(quantile)

    vol_regime = pd.Series(index=ff.index, dtype=object)
    vol_regime.loc[rolling_vol.index] = np.where(
        rolling_vol <= thr, "LowVol", "HighVol"
    )
    return vol_regime
```

* * *

### 2.4 ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ»ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¥ã®åˆ†è§£ï¼ˆsign æˆ¦ç•¥ï¼‰

```python
def regime_decomposition_by_vol(
    ff: pd.DataFrame,
    results: dict,
    window: int = 36,
    quantile: float = 0.5,
    col: str = "mkt_excess"
) -> pd.DataFrame:
    """
    ff      : compare_all_methods ãŒè¿”ã—ãŸ ff
    results : compare_all_methods ã® resultsï¼ˆ{name: (y_hat, strat_excess)})
    window, quantile, col: build_vol_regime ã«å¼•ãæ¸¡ã—

    HighVol / LowVol ã”ã¨ã®å¹´ç‡çµ±è¨ˆã‚’ã¾ã¨ã‚ã‚‹ã€‚
    """
    vol_regime = build_vol_regime(ff, window=window, quantile=quantile, col=col)

    # Market
    mkt_perf = regime_performance(ff["mkt_excess"], vol_regime, name="MKT")

    all_perf = mkt_perf.copy()
    for name, (y_hat, strat) in results.items():
        perf = regime_performance(strat, vol_regime, name=name)
        all_perf = all_perf.join(perf, how="outer")

    return all_perf
```

ä½¿ç”¨ä¾‹ï¼š

```python
if __name__ == "__main__":
    csv_path = "F-F_Research_Data_Factors.csv"
    ff_all, res_all = compare_all_methods(csv_path, min_obs=120)

    vol_perf = regime_decomposition_by_vol(ff_all, res_all, window=36, quantile=0.5)
    print("=== Regime-wise performance by volatility regime (LowVol / HighVol) ===")
    print(vol_perf)
```

* * *

3\. df\_old / df\_m6 / df\_m6\_2ï¼ˆãƒ•ãƒ«æˆ¦ç•¥ï¼‰ã®ãƒ¬ã‚¸ãƒ¼ãƒ åˆ†è§£
---------------------------------------------

`df_old`, `df_m6`, `df_m6_2` ã¯ã™ã§ã«

*   `strat_total`ï¼ˆæˆ¦ç•¥ãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ï¼‰
*   `mkt_total`ï¼ˆå¸‚å ´ãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ï¼‰
*   `month_type`ï¼ˆN/R/3ï¼‰

ã‚’æŒã£ã¦ã„ã‚‹ã®ã§ã€åŒã˜ `regime_performance` ã‚’ä½¿ã£ã¦ç°¡å˜ã«åˆ†è§£ã§ãã¾ã™ã€‚

### 3.1 æˆ¦ç•¥ 3 æœ¬ã® N/R/3 åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹

```python
def three_strategy_regime_by_month_type(df_old, df_m6, df_m6_2):
    mt_old = df_old["month_type"]

    perf_mkt = regime_performance(df_old["mkt_total"], mt_old, name="MKT")
    perf_old = regime_performance(df_old["strat_total"], mt_old, name="Old")
    perf_m6  = regime_performance(df_m6["strat_total"],   df_m6["month_type"],  name="M6")
    perf_m6_2= regime_performance(df_m6_2["strat_total"], df_m6_2["month_type"], name="M6_2")

    out = perf_mkt.join(perf_old, how="outer").join(perf_m6, how="outer").join(perf_m6_2, how="outer")
    return out
```

ä½¿ç”¨ä¾‹ï¼š

```python
if __name__ == "__main__":
    csv_path = "F-F_Research_Data_Factors.csv"
    ff = load_ff_monthly_from_ken_french(csv_path)

    df_zstar = build_z_star_online(ff, lookback_years=20, min_obs=120)
    df_old = df_zstar.copy()
    df_old["z"] = df_old["z_star"]
    df_old = apply_timing_strategy(df_old, target_vol=0.05, max_leverage=3.0)

    df_m6   = backtest_method6_strategy(ff, min_obs=120, target_vol=None, max_leverage=None)
    df_m6_2 = backtest_method6_zstar_strategy(ff, min_obs=120, target_vol=None, max_leverage=None)

    reg_three = three_strategy_regime_by_month_type(df_old, df_m6, df_m6_2)
    print("=== N/R/3 regime performance for (Old z*, M6, M6_2) ===")
    print(reg_three)
```

### 3.2 æˆ¦ç•¥ 3 æœ¬ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ»ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹

```python
def three_strategy_regime_by_vol(df_old, df_m6, df_m6_2,
                                 window: int = 36,
                                 quantile: float = 0.5):
    """
    df_old, df_m6, df_m6_2 : ãã‚Œãã‚Œ strat_total, mkt_total åˆ—ã‚’æŒã¤ DF

    Market ã®ãƒœãƒ©ã‹ã‚‰ãƒ¬ã‚¸ãƒ¼ãƒ ã‚’ä½œã‚Šã€3 æˆ¦ç•¥ã‚’æ¯”è¼ƒã€‚
    """
    # vol regime ã¯å¸‚å ´ãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ã‹ã‚‰ä½œæˆ
    tmp = pd.DataFrame({"mkt_total": df_old["mkt_total"]})
    vol_regime = build_vol_regime(tmp, window=window, quantile=quantile, col="mkt_total")

    perf_mkt = regime_performance(df_old["mkt_total"], vol_regime, name="MKT")
    perf_old = regime_performance(df_old["strat_total"], vol_regime, name="Old")
    perf_m6  = regime_performance(df_m6["strat_total"],   vol_regime, name="M6")
    perf_m6_2= regime_performance(df_m6_2["strat_total"], vol_regime, name="M6_2")

    out = perf_mkt.join(perf_old, how="outer").join(perf_m6, how="outer").join(perf_m6_2, how="outer")
    return out
```

ä½¿ç”¨ä¾‹ï¼š

```python
if __name__ == "__main__":
    # ä¸Šã¨åŒã˜ã df_old, df_m6, df_m6_2 ãŒã‚ã‚‹å‰æ
    vol_three = three_strategy_regime_by_vol(df_old, df_m6, df_m6_2, window=36, quantile=0.5)
    print("=== Volatility regime performance for (Old z*, M6, M6_2) ===")
    print(vol_three)
```

* * *

ã“ã‚Œã‚‰ã®ã‚³ãƒ¼ãƒ‰ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€

*   **æ™‚é–“ã¨ã¨ã‚‚ã« OOS RÂ² ãŒã©ã†å¤‰åŒ–ã—ãŸã‹**ï¼ˆrolling 10 å¹´ RÂ²ï¼‰
*   **newsy / repetitive / 3rd month ã§ã©ã®æˆ¦ç•¥ãŒå¼·ã„ã‹**
*   **é«˜ãƒœãƒ©ç›¸å ´ / ä½ãƒœãƒ©ç›¸å ´ã§ã©ã®æˆ¦ç•¥ãŒå„ªä½ã‹**

ã‚’ä¸€æ‹¬ã§æ¤œè¨¼ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚

ã‚‚ã—ã€ã“ã‚Œã‚‰ã‚’ã€Œ1926â€“79 / 1980â€“99 / 2000â€“19 / 2020+ã€ãªã©ã®**ã‚µãƒ–ã‚µãƒ³ãƒ—ãƒ«Ã—ãƒ¬ã‚¸ãƒ¼ãƒ **ã®ãƒ‘ãƒãƒ«è¡¨ã«ã—ãŸã„å ´åˆã‚‚ã€ä¸Šã®é–¢æ•°ã‚’å°‘ã—ãƒ©ãƒƒãƒ—ã—ã¦æ›¸ã‘ã‚‹ã®ã§ã€å¿…è¦ã§ã‚ã‚Œã°ãã“ã‚‚ã¾ã¨ã‚ã¾ã™ã€‚

## Response:
æ€è€ƒå®Œäº†

ä»¥ä¸‹ã§ã¯ã€Guo ç³»ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®ä¸­ã§

*   Method 5ï¼ˆnr + P4 ã®ã€Œé™çš„ã€joint å›å¸°ï¼‰
*   Method 6ï¼ˆGuo ãŒæœ¬å‘½ã¨ã—ã¦æ¨å¥¨ã—ã¦ã„ã‚‹ S ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ï¼‰
*   ã‚ãªãŸã® `nr + P4` ã® z\*\_tï¼ˆonline 20y window ç‰ˆï¼šrolling OLSï¼‰

ã‚’ã€ã§ãã‚‹ã ã‘è«–æ–‡ã«è¿‘ã„å½¢ã®æ•°å¼ã§æ•´ç†ã—ã¤ã¤ã€é•ã„ã‚’æ˜ç¢ºã«æ¯”è¼ƒã—ã¾ã™ã€‚

â€» æ–‡çŒ®ã¯ä¸»ã« Guo (2025) â€œEarnings Extrapolation and Predictable Stock Market Returnsâ€ ã¨ã€Guo & Wachter (2025) â€œCorrelation Neglect in Asset Pricesâ€ ã‚’æ„è­˜ã—ã¦ã„ã¾ã™ã€‚

* * *

1\. å…±é€šã®è¨­å®šï¼ˆå¤‰æ•°ã¨ notationï¼‰
-----------------------

æœˆæ¬¡ã§è¦³æ¸¬ã•ã‚Œã‚‹å¤‰æ•°ã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«ç½®ãã¾ã™ã€‚

*    $r_t$ : æœˆæ¬¡ã®ã€Œå¸‚å ´è¶…éãƒªã‚¿ãƒ¼ãƒ³ã€ã‚‚ã—ãã¯ãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³
*    $\bar r_{t-1}$ : æ™‚ç‚¹  $t-1$  ã¾ã§ã®ã€Œç„¡æ¡ä»¶å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³ã€ï¼ˆexpanding å¹³å‡ï¼‰
*    $\text{nr}_t$ : ã€Œnr ã‚·ã‚°ãƒŠãƒ«ã€
    *   ä¾‹ï¼šæ™‚ç‚¹  $t$  ã‚ˆã‚Šç›´è¿‘ã® earnings-heavy æœˆï¼ˆnewsy or repetitiveï¼‰ã®å¸‚å ´è¶…éãƒªã‚¿ãƒ¼ãƒ³
*    $\text{P4}_t$ : ã€ŒP4 ã‚·ã‚°ãƒŠãƒ«ã€
    *   ä¾‹ï¼šç›´è¿‘ 4 å›ã® newsy æœˆè¶…éãƒªã‚¿ãƒ¼ãƒ³ã®å¹³å‡
    $$
     \text{P4}_t = \frac{1}{4}\sum_{j=1}^{4}\text{mktnm}(t,j)
    $$
*    $S_t$ : Method 6 ã§ç”¨ã„ã‚‹ã€Œéå» 4 newsy æœˆã®ãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ã®åˆè¨ˆã€
    $$
     S_t = \sum_{j=1}^{4} R_{n_j(t)},
    $$
    ã“ã“ã§  $R_{n_j(t)}$  ã¯ã€Œç›´è¿‘ j ç•ªç›®ã® newsy æœˆãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ã€ã€‚
*    $x_t$ : Method 6 ã§ä½¿ã† S ã®å¤‰æ›ç‰ˆï¼ˆdemean + sign flipï¼‰ã€‚  
    ã‚ãªãŸã®å®Ÿè£…ã§ã¯ã€
    $$
     S_{t-1} \text{ ã®å±¥æ­´ã«å¯¾ã™ã‚‹ } \bar S_{t-1} = \frac{1}{t-1}\sum_{s < t} S_s
    $$
    ã‚’ç”¨ã„ã¦
    $$
     x_t = \text{sign\_adj}(t)\, \bigl(S_{t-1} - \bar S_{t-1}\bigr),
    $$
    ã“ã“ã§  $\text{sign\_adj}(t)$  ã¯ newy æœˆã§ç¬¦å·åè»¢ã™ã‚‹ãŸã‚ã®ä¿‚æ•°ï¼ˆãŸã¨ãˆã° newsy æœˆãªã‚‰  $-1$ ã€ãã‚Œä»¥å¤–ãªã‚‰  $+1$ ï¼‰ã€‚

ã“ã®ã‚ˆã†ã«ã€nr, P4, S ã¯ã„ãšã‚Œã‚‚

*   æ±ºç®—æœŸï¼ˆnewsy monthï¼‰ã®ãƒªã‚¿ãƒ¼ãƒ³ã‚·ãƒ§ãƒƒã‚¯ã‚’ã©ã†é›†ç´„ã™ã‚‹ã‹
*   ã¾ãŸãã‚Œã‚’ã€Œnewsy ã¨ non-newsy ã§ç¬¦å·ãŒå¤‰ã‚ã‚‹ã€æ§‹é€ ã«ã©ã†åŸ‹ã‚è¾¼ã‚€ã‹

ã¨ã„ã†ç‚¹ã§è¨­è¨ˆã•ã‚ŒãŸ predictor ã§ã™ã€‚

* * *

2\. Method 5ï¼ˆnr + P4 ã®é™çš„ joint ãƒ¢ãƒ‡ãƒ«ï¼‰
-----------------------------------

### 2.1 åŸºæœ¬çš„ãªå›å¸°ä»•æ§˜ï¼ˆç†è«–çš„ãªå½¢ï¼‰

Guo ã® Table 4 ã§ã®ã€Œè¤‡æ•° predictor joint ãƒ¢ãƒ‡ãƒ«ã€ã«å¯¾å¿œã™ã‚‹ã®ãŒ Method 5 ã§ã™ã€‚å˜ç´”åŒ–ã™ã‚‹ã¨ã€æ¦‚ã­æ¬¡ã®ã‚ˆã†ãª time-series å›å¸°ã§ã™ï¼š

$$
 r_t \;=\; \alpha + \beta_{\text{nr}}\, \text{nr}_{t-1} + \beta_{P4}\,\text{P4}_{t-1} + \varepsilon_t. \tag{M5}
$$
*   è¢«èª¬æ˜å¤‰æ•°ï¼šæœˆæ¬¡ãƒªã‚¿ãƒ¼ãƒ³  $r_t$ ï¼ˆå¸‚å ´è¶…éãƒªã‚¿ãƒ¼ãƒ³ or ãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ï¼‰
*   èª¬æ˜å¤‰æ•°ï¼š1 æœŸãƒ©ã‚°ã® nr ã¨ P4
*   ä¿‚æ•°  $\beta_{\text{nr}}, \beta_{P4}$  ã¯ä¸€å®šï¼ˆé™çš„ï¼‰ã¨ä»®å®šã—ã€å…¨ã‚µãƒ³ãƒ—ãƒ«ã§ OLS æ¨å®š

### 2.2 çµŒæ¸ˆçš„ãªæ„å‘³

*    $\text{nr}$  ã¯ã€Œç›´è¿‘ã® earnings-heavy æœˆã‚·ãƒ§ãƒƒã‚¯ã€ã€ $\text{P4}$  ã¯ã€Œæ•°å››åŠæœŸã«ã‚ãŸã‚‹ earnings ãƒˆãƒ¬ãƒ³ãƒ‰ã€ã‚’è¡¨ç¾ã€‚
*   Method 5 ã¯ã€çŸ­æœŸã‚·ãƒ§ãƒƒã‚¯ã¨ä¸­æœŸãƒˆãƒ¬ãƒ³ãƒ‰ã®ä¸¡æ–¹ã‚’ 1 æœ¬ã®ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã«å…¥ã‚Œã‚‹ã“ã¨ã§ã€
    *   **çŸ­æœŸã®ã‚ªãƒ¼ãƒãƒ¼ã‚·ãƒ¥ãƒ¼ãƒˆ / mean reversion æˆåˆ†ï¼ˆnrï¼‰**
    *   **ä¸­æœŸçš„ãª earnings extrapolation æˆåˆ†ï¼ˆP4ï¼‰**  
        ã‚’åˆ‡ã‚Šåˆ†ã‘ã‚‹ã“ã¨ã‚’ç‹™ã£ã¦ã„ã¾ã™ã€‚
*   ãŸã ã—ã€Method 6 ã¨ã¯ç•°ãªã‚Šã€ã€Œç„¡æ¡ä»¶å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³  $\bar r$  ã«ä¿‚æ•° 1 ã‚’å›ºå®šã™ã‚‹ã€ã¨ã„ã£ãŸæ§‹é€ çš„åˆ¶ç´„ã¯ãªãã€å˜ç´”ãªæ™‚ç³»åˆ—å›å¸°ã¨ã—ã¦æ‰±ã‚ã‚Œã¾ã™ã€‚

### 2.3 ã‚ãªãŸã®ã‚³ãƒ¼ãƒ‰ã¨ã®å¯¾å¿œ

*   `compare_all_methods` å†…ã® `run_method4_nr_p4` ãŒã€ã»ã¼ã“ã® Method 5 ã«å¯¾å¿œã—ã¾ã™ã€‚
*   ãŸã ã—ã‚ãªãŸã®ã‚³ãƒ¼ãƒ‰ã¯ã€Œexpanding OLS + OOS äºˆæ¸¬ + sign æˆ¦ç•¥ã€ã¨ã„ã†å½¢ã§ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã—ã¦ãŠã‚Šã€  
    Guo ã® Table 4 ã®ã€Œé™çš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€ã‚µãƒ³ãƒ—ãƒ«åˆ†å‰²ã§ã® OOS ãƒ†ã‚¹ãƒˆã€ã¨ã¯å®Ÿå‹™çš„ã«å°‘ã—ç•°ãªã‚Šã¾ã™ã€‚

* * *

3\. Method 6ï¼ˆGuo æ¨å¥¨ã®æ§‹é€ åˆ¶ç´„ä»˜ããƒ¢ãƒ‡ãƒ«ï¼‰
------------------------------

Method 6 ã¯ Guo ãŒæœ€ã‚‚æ¨å¥¨ã™ã‚‹ã€Œæ§‹é€ ãƒ¢ãƒ‡ãƒ«ã«å¿ å®Ÿãªã€ä»•æ§˜ã§ã™ã€‚å¤§ããªãƒã‚¤ãƒ³ãƒˆã¯ï¼š

1.  **ç›®çš„å¤‰æ•°ã®å®šç¾©ã‚’å¤‰ãˆã¦ã„ã‚‹**
2.  ** $\bar r$ ï¼ˆç„¡æ¡ä»¶å¹³å‡ï¼‰ã«ä¿‚æ•° 1 ã‚’èª²ã—ã€ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ã ã‘ã‚’åˆ¥ã®æˆåˆ†ã§èª¬æ˜ã™ã‚‹**

ã¨ã„ã†æ§‹é€ åˆ¶ç´„ã«ã‚ã‚Šã¾ã™ã€‚

### 3.1 ç„¡æ¡ä»¶å¹³å‡ã¨ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ã®åˆ†è§£

ã¾ãšå¸‚å ´ãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³  $R_t$  ã‚’ã€

$$
 R_t \;=\; \bar R_{t-1} + \eta_t,
$$

ã¨åˆ†è§£ã—ã¾ã™ã€‚ã“ã“ã§

*    $\bar R_{t-1} = \frac{1}{t-1}\sum_{s < t} R_s$ : ç„¡æ¡ä»¶å¹³å‡
*    $\eta_t$ : ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ï¼ˆearnings extrapolation + correlation neglect ã«ã‚ˆã‚‹æˆåˆ†ï¼‰

Guo ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã¯ã€ã“ã®  $\eta_t$  ã‚’ earnings ã‚·ã‚°ãƒŠãƒ«ã®é–¢æ•°ã¨ã—ã¦ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã¾ã™ã€‚

### 3.2 S ã¨ x\_t ã®æ§‹æˆ

*    $S_{t}$ : éå» 4 å›ã® newsy æœˆãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ã®åˆè¨ˆã€‚
*   ãã®å±¥æ­´ã‹ã‚‰æ±‚ã‚ãŸå¹³å‡  $\bar S_{t-1}$  ã«å¯¾ã—ã¦
    $$
     S_{t-1} - \bar S_{t-1}
    $$
    ã‚’è¨ˆç®—ã—ã€ã•ã‚‰ã«ã€Œäºˆæ¸¬å¯¾è±¡æœˆãŒ newsy ã‹ã©ã†ã‹ã€ã§ç¬¦å·ã‚’å¤‰ãˆã‚‹å¤‰æ›ã‚’æ–½ã—ãŸã‚‚ã®ãŒ  $x_t$ ã€‚

ç›´æ„Ÿçš„ã«ã¯

*   newsyâ†’non-newsy ã§ã¯ã€Œé«˜ã„ newsy ã‚·ãƒ§ãƒƒã‚¯ã¯ç¿Œæœˆã®åè»¢ã«ã¤ãªãŒã‚‹ã€
*   non-newsyâ†’non-newsy ã§ã¯ã€Œé«˜ã„ newsy ã‚·ãƒ§ãƒƒã‚¯ã¯ç¶™ç¶šçš„ãªæ¥½è¦³ã¨ã—ã¦æŒç¶šã™ã‚‹ã€

ã¨ã„ã£ãŸæ§‹é€ ã‚’ã€ã€Œç¬¦å·åè»¢ + demeanã€ã¨ã„ã† simple rule ã§æ‰ãˆã¦ã„ã¾ã™ã€‚

### 3.3 Method 6 ã®å›å¸°å¼

ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°æˆåˆ†  $\eta_t$  ã‚’  $x_t$  ã§èª¬æ˜ã™ã‚‹ï¼š

$$
 \eta_t \;=\; \beta_S x_t + \varepsilon_t.
$$

ã—ãŸãŒã£ã¦ã€ãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ã¯

$$
 R_t = \bar R_{t-1} + \beta_S x_t + \varepsilon_t.
$$

ã‚ãªãŸã® implementï¼ˆ`backtest_method6_strategy`ï¼‰ã§ã¯ã€ã“ã‚Œã‚’**ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ OLS**ã«ã—ãŸå½¢ã§ã€

*   ç›®çš„å¤‰æ•°ï¼š
    $$
     y_t = R_t - \bar R_{t-1}
    $$
*   èª¬æ˜å¤‰æ•°ï¼š
    $$
     x_t
    $$
*   expanding OLS ã§é€æ¬¡  $\beta_t$  ã‚’æ¨å®šã—ã€
*   1 æœŸå…ˆ  $t+1$  ã«ã¤ã„ã¦æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³ã‚’
    $$
     \widehat R_{t+1} = \bar R_t + \beta_t x_{t+1}
    $$
    ã¨ã—ã¦æˆ¦ç•¥ãƒã‚¸ã‚·ãƒ§ãƒ³ï¼ˆãƒ¬ãƒãƒ¬ãƒƒã‚¸ï¼‰ã‚’æ±ºã‚ã¦ã„ã¾ã™ã€‚

### 3.4 Method 6 ã®æˆ¦ç•¥ä¸Šã®ç‰¹å¾´

*    $\bar R$  ã«ä¿‚æ•° 1 ã‚’èª²ã™ã“ã¨ã§ã€ã€Œåˆç†çš„ãªãƒªã‚¹ã‚¯ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ã®æ™‚é–“å¤‰å‹•ã€ã‚’  $\bar R$  ãŒæ‹…ã„ã€  
     $\beta_S x_t$  ãŒã€Œearnings extrapolation + correlation neglect ã«ã‚ˆã‚‹ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ã€ã‚’å˜ç‹¬ã§è¡¨ã™æ§‹é€ ã«ãªã‚Šã¾ã™ã€‚
*   ãã®ãŸã‚ã€Method 5 ã®ã‚ˆã†ãªã€Œå˜ç´”å›å¸°ã€ã‚ˆã‚Šã‚‚ã€**çµŒæ¸ˆãƒ¢ãƒ‡ãƒ«ã¨æ¨å®šå¼ã®å¯¾å¿œãŒæ˜ç¢º**ã§ã‚ã‚Šã€Guo ãŒæ¨å¥¨ã™ã‚‹ç†ç”±ã«ãªã£ã¦ã„ã¾ã™ã€‚

* * *

4\. nr + P4 ã® z\*\_tï¼ˆonline 20y window, rolling OLS ç‰ˆï¼‰
------------------------------------------------------

ã“ã‚Œã¯ã€ã‚ãªãŸãŒå®Ÿè£…ã—ã¦ã„ã‚‹ã€Œç‹¬è‡ªæ‹¡å¼µã€ã§ã€Method 5 ã‚’ç™ºå±•ã•ã›ãŸã‚‚ã®ã§ã™ã€‚

### 4.1 å›å¸°ä»•æ§˜

ã‚ãªãŸã® `build_z_star_online` ã§ã¯ã€å¤§ã¾ã‹ã«æ¬¡ã®ã‚ˆã†ãª rolling OLS ã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚

1.  ã¾ãšã€`add_nr_and_p4` ã§ nr ã¨ P4 ã‚’æ§‹æˆï¼ˆ`mkt_nr`, `mkt_nm4_avg`ï¼‰ã€‚
2.  å„æ™‚ç‚¹  $t$  ã«ã¤ã„ã¦ã€ç›´è¿‘ 20 å¹´ï¼ˆ= 240 ãƒ¶æœˆç¨‹åº¦ï¼‰ã‚’ window ã¨ã—ã€ãã®æœŸé–“ã«é™ã£ã¦ä»¥ä¸‹ã‚’æ¨å®šï¼š
    
$$
 r_s = \alpha_t + \beta_{\text{nr},t}\, \text{nr}_s + \beta_{P4,t}\,\text{P4}_s + \varepsilon_s, \quad s \in \{t - 20\text{y},\dots,t-1\}. \tag{R-M5}
$$

ã“ã“ã§

*    $r_s$  ã¯å¸‚å ´è¶…éãƒªã‚¿ãƒ¼ãƒ³ï¼ˆ`mkt_excess`ï¼‰
*    $\beta_{\text{nr},t}, \beta_{P4,t}$  ã¯ã€Œæ™‚ç‚¹ t ã«ãŠã‘ã‚‹ 20 å¹´ rolling OLS ã®ä¿‚æ•°ã€
    3.  ãã—ã¦ã€åŒæ™‚ç‚¹  $t$  ã® nr, P4 ã«ã“ã®ä¿‚æ•°ã‚’ã‹ã‘ãŸç·šå½¢çµåˆã‚’
    
$$
 z^*_t = \beta_{\text{nr},t}\, \text{nr}_t + \beta_{P4,t}\,\text{P4}_t \tag{zstar}
$$

ã¨ã—ã¦å®šç¾©ã—ã€ã“ã‚Œã‚’ã‚·ã‚°ãƒŠãƒ«ã¨ã—ã¦ `apply_timing_strategy`ï¼ˆãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼‰ã«æ¸¡ã—ã¦ã„ã¾ã™ã€‚

### 4.2 Method 5 ã¨ã®é•ã„

æ§‹é€ çš„ã«ã¯ Method 5 ã¨åŒã˜ joint ãƒ¢ãƒ‡ãƒ«ã§ã™ãŒã€ä»¥ä¸‹ãŒå¤§ããªé•ã„ã§ã™ã€‚

1.  **é™çš„ vs æ™‚å¤‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**
    *   Method 5:  $\beta_{\text{nr}}, \beta_{P4}$  ã¯å…¨ã‚µãƒ³ãƒ—ãƒ«å›ºå®šï¼ˆé™çš„ï¼‰
    *   z\*\_t:  $\beta_{\text{nr},t}, \beta_{P4,t}$  ã¯ 20 å¹´ rolling OLS ã§**æ™‚å¤‰**ï¼ˆlocal in timeï¼‰
2.  **çª“é•·ã«ã‚ˆã‚‹æ§‹é€ å¤‰åŒ–ã®åæ˜ **
    *   20 å¹´ã¨ã„ã† window ã‚’å–ã‚‹ã“ã¨ã§ã€ã€Œ1920â€“1950ã€ã€Œ1950â€“1970ã€ã€Œ2000â€“2020ã€ãªã©ã®æ§‹é€ å¤‰åŒ–ã‚’ã‚ˆã‚Šæ•æ„Ÿã«åæ˜ å¯èƒ½ã€‚
    *   ç‰¹ã« 2000 å¹´ä»¥é™ã‚„ 2020 å¹´ä»¥é™ã® regime shiftï¼ˆearnings ã®æƒ…å ±ç’°å¢ƒã€FOMC ã®ã‚¹ã‚¿ãƒ³ã‚¹ã€ãƒã‚¤ã‚¢ã‚¦ãƒˆã‚„ buyback ã®å¢—åŠ ãªã©ï¼‰ã«å¯¾ã—ã¦ã€  
        é™çš„ãª Method 5 ã‚ˆã‚ŠæŸ”è»Ÿã«è¿½éšã§ãã¾ã™ã€‚
3.  **ç›®çš„å¤‰æ•°ã¨æ§‹é€ åˆ¶ç´„**
    *   z\*\_t ã¯å˜ã«  $r_t$ ï¼ˆè¶…éãƒªã‚¿ãƒ¼ãƒ³ï¼‰ã‚’èª¬æ˜ã™ã‚‹å›å¸°ã§ã€  
         $\bar r$  ã«ä¿‚æ•° 1 ã‚’èª²ã™ã‚ˆã†ãªæ§‹é€ åˆ¶ç´„ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
    *   ã—ãŸãŒã£ã¦ã€Method 6 ã®ã‚ˆã†ã«ã€Œãƒªã‚¹ã‚¯ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ã€ã¨ã€ŒãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ã€ã‚’ãã‚Œã„ã«åˆ†è§£ã—ã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªãã€  
        ä¸¡è€…ãŒæ··åœ¨ã—ãŸã€Œæœ‰åŠ¹ãªäºˆæ¸¬æˆåˆ†ã€ã‚’ pragmatic ã«æŠ½å‡ºã™ã‚‹ã‚·ã‚°ãƒŠãƒ«ã¨è¨€ãˆã¾ã™ã€‚
4.  **æˆ¦ç•¥å®Ÿè£…ã®é•ã„**
    *   Method 5ï¼ˆè«–æ–‡ï¼‰ã¯å¤šãã®å ´åˆã€å˜ç´”ãª time-series å›å¸°ã®äºˆæ¸¬å€¤  $\hat r_{t+1}$  ã‚’ç”¨ã„ãŸ sign æˆ¦ç•¥ã‚„ç·šå½¢æˆ¦ç•¥ã®ãƒ†ã‚¹ãƒˆãƒ¬ãƒ™ãƒ«ã€‚
    *   ã‚ãªãŸã® z\*\_t ã¯ã€ã“ã® joint å›å¸°ã®ç·šå½¢çµåˆã‚’ã•ã‚‰ã«ã€Œãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæˆ¦ç•¥ã€ã«å¤‰æ›ã—ã€  
        ã‚¿ã‚¤ãƒŸãƒ³ã‚°æˆ¦ç•¥ã¨ã—ã¦ã‚ˆã‚Šå®Ÿå‹™çš„ãªå½¢ã§é‹ç”¨ã—ã¦ã„ã¾ã™ï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒœãƒ©ã«åˆã‚ã›ã¦ãƒ¬ãƒãƒ¬ãƒƒã‚¸ã‚’èª¿æ•´ï¼‰ã€‚

* * *

5\. Method 5 vs Method 6 vs z\*\_tï¼ˆonline 20yï¼‰ã®é•ã„ã¾ã¨ã‚
----------------------------------------------------

### 5.1 æ•°å¼ãƒ¬ãƒ™ãƒ«ã§ã®æ¯”è¼ƒè¡¨

| ãƒ¢ãƒ‡ãƒ« | ç›®çš„å¤‰æ•° | èª¬æ˜å¤‰æ•° | ä¿‚æ•°ã®æ‰±ã„ | æ§‹é€ åˆ¶ç´„ | çµŒæ¸ˆçš„è§£é‡ˆ |
| --- | --- | --- | --- | --- | --- |
| Method 5 |  $r_t$ ï¼ˆè¶…é or ãƒˆãƒ¼ã‚¿ãƒ«ï¼‰ |  $\text{nr}_{t-1}, \text{P4}_{t-1}$  | é™çš„  $\beta_{\text{nr}},\beta_{P4}$  | ãªã— | çŸ­æœŸã‚·ãƒ§ãƒƒã‚¯ï¼ˆnrï¼‰ã¨ä¸­æœŸãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆP4ï¼‰ã® joint ãƒ¢ãƒ‡ãƒ« |
| Method 6 |  $R_t - \bar R_{t-1}$  |  $x_t$ ï¼ˆS ã® demean + sign flipï¼‰ | 1å¤‰æ•°  $\beta_S$ ã€expanding OLS |  $\bar R_{t-1}$  ã®ä¿‚æ•° = 1 ã«å›ºå®š | ç„¡æ¡ä»¶å¹³å‡ï¼åˆç†çš„ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ã€ $x_t$ ï¼ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ã‚’åˆ†é›¢ã™ã‚‹æ§‹é€ ãƒ¢ãƒ‡ãƒ« |
| z\*\_t (online 20y) |  $r_t$  |  $\text{nr}_t, \text{P4}_t$  | æ™‚å¤‰  $\beta_{\text{nr},t}, \beta_{P4,t}$ ï¼ˆ20y rollingï¼‰ | ãªã— | Method 5 ã‚’æ™‚å¤‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã—ã€æ§‹é€ å¤‰åŒ–ã‚’åæ˜ ï¼‹ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæˆ¦ç•¥ã«å¿œç”¨ |

### 5.2 ç›´æ„Ÿçš„ãªé•ã„

1.  **ä½•ã‚’ã€Œå®‰å®šã€ã¨ã¿ãªã™ã‹**
    *   Method 5: ã€Œnr ã¨ P4 ã®åŠ¹æœã¯ã‚µãƒ³ãƒ—ãƒ«å…¨ä½“ã§ã»ã¼ä¸€å®šã€ã¨ã¿ãªã™ã€‚
    *   Method 6: ã€Œ $\bar R$  ã¯é•·æœŸçš„ã«å®‰å®šï¼ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°éƒ¨åˆ†ã ã‘ãŒ  $x_t$  ã§å‹•ãã€ã¨ã¿ãªã™ã€‚
    *   z\*\_t: ã€Œnr ã¨ P4 ã®åŠ¹æœè‡ªä½“ãŒæ™‚é–“ã¨ã¨ã‚‚ã«å¤‰ã‚ã‚Šã†ã‚‹ï¼ˆæ§‹é€ å¤‰åŒ–ãŒã‚ã‚‹ï¼‰ã€ã¨ã¿ãªã™ã€‚
2.  **ãƒ¢ãƒ‡ãƒ«ã¨çµŒæ¸ˆç†è«–ã®çµã³ã¤ã**
    *   Method 5: empirical ãª multi-predictor å›å¸°ã€‚è¡Œå‹•ãƒ¢ãƒ‡ãƒ«ã¨ã®å¯¾å¿œã¯ã‚ã‚‹ãŒã€ç›´æ¥çš„ãªåˆ¶ç´„ã¯å°‘ãªã„ã€‚
    *   Method 6: correlation neglect + earnings extrapolation ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã€ã‹ãªã‚Šç›´æ¥çš„ã«å°å‡ºã•ã‚Œã‚‹æ§‹é€ ã€‚
    *   z\*\_t: Method 5 ã®ã€Œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ã‚«ãƒ«åŒ–ã—ãŸå®Ÿå‹™ç‰ˆã€ã§ã‚ã‚Šã€ç†è«–ã‚ˆã‚Šã‚‚ã€Œæœ€è¿‘ 20 å¹´ã§ä½•ãŒåŠ¹ã„ã¦ããŸã‹ã€ã«é‡å¿ƒã€‚
3.  **2020 å¹´ä»¥é™ã®æŒ™å‹•**
    *   2020 å¹´ä»¥é™ã® regime shiftï¼ˆã‚³ãƒ­ãƒŠã‚·ãƒ§ãƒƒã‚¯ã€æ”¿ç­–ç’°å¢ƒã®å¤‰åŒ–ã€å€‹äººæŠ•è³‡å®¶ã®å‚åŠ å¢—ï¼‰ã«ã‚ˆã‚Šã€  
        **nr / P4 ã®ä¿‚æ•°ãŒã€Œæ–‡çŒ®ã‚µãƒ³ãƒ—ãƒ«æ™‚ä»£ï¼ˆ1926â€“2019ï¼‰ã€ã¨å¤§ããç•°ãªã‚‹å¯èƒ½æ€§**ãŒã‚ã‚Šã¾ã™ã€‚
    *   é™çš„ Method 5 ã ã¨ã€Œéå» 100 å¹´å¹³å‡ã®é–¢ä¿‚ã€ã‚’å‰æã«ã™ã‚‹ã“ã¨ã«ãªã‚Šã€2020+ ã®ã‚·ãƒ§ãƒƒã‚¯ã«å¯¾ã—ã¦ãƒŸã‚¹ãƒãƒƒãƒãŒèµ·ãã‚„ã™ã„ã€‚
    *   z\*\_tï¼ˆ20y rollingï¼‰ã¯ã€ãã®ç‚¹ã§ã€Œç›´è¿‘ 20 å¹´ã®æ§‹é€ ã€ã‚’å„ªå…ˆã™ã‚‹ã®ã§ã€2020 ä»¥é™ã«ãŠã„ã¦ã¯ Method 5 ã‚ˆã‚Šå®Ÿå‹™çš„ã«å¦¥å½“ãªå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
    *   ä¸€æ–¹ã€Method 6 ã¯ã€Œç†è«–ã®ã‚³ã‚¢æ§‹é€ ã¯å¤‰ã‚ã‚‰ãªã„ã€ã¨ä»®å®šã—ã¦ã„ã‚‹ãŸã‚ã€  
        ã‚‚ã— correlation neglect ã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ è‡ªä½“ãŒå®‰å®šã—ã¦ã„ã‚‹ãªã‚‰ã€æœŸé–“ã‚’ã¾ãŸã„ã§ã‚‚å®‰å®šã—ãŸ RÂ² / Sharpe ã‚’å‡ºã—ã†ã‚‹ã€ã¨ã„ã†ä½ç½®ã¥ã‘ã§ã™ã€‚

* * *

6\. å®Ÿå‹™çš„ãªä½¿ã„åˆ†ã‘ã®ã‚¤ãƒ¡ãƒ¼ã‚¸
-----------------

*   **ç†è«–ã«å¿ å®Ÿï¼‹é•·æœŸä¸€è²«æ€§ã‚’é‡è¦–ã™ã‚‹ãªã‚‰**  
    â†’ Method 6 ã‚’ãƒ™ãƒ¼ã‚¹ã«æ¤œè¨¼ã™ã‚‹ï¼ˆ $\bar R$  ã«ä¿‚æ•° 1 ã‚’èª²ã™æ§‹é€ ãƒ¢ãƒ‡ãƒ«ï¼‰ã€‚
*   **å˜ç´”ã§è§£é‡ˆã—ã‚„ã™ã„ multi-signal ãƒ¢ãƒ‡ãƒ«ã‚’è¦‹ãŸã„ãªã‚‰**  
    â†’ Method 5ï¼ˆnr + P4ï¼‰ã‚’é™çš„ã«æ¨å®šã—ã€ä¿‚æ•°ã®ç¬¦å·ãƒ»å¤§ãã•ã‚’è§£é‡ˆã™ã‚‹ã€‚
*   **ç›´è¿‘ 20 å¹´ãã‚‰ã„ã® regime ã«ãƒ•ã‚£ãƒƒãƒˆã—ãŸã€Œæˆ¦ç•¥ã€ã¨ã—ã¦ä½¿ã†ãªã‚‰**  
    â†’ z\*\_tï¼ˆnr + P4 ã® rolling OLSï¼‰ã‚’ã‚·ã‚°ãƒŠãƒ«ã¨ã—ã€ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæˆ¦ç•¥ã¨ã—ã¦é‹ç”¨ã€‚  
    ï¼ˆãŸã ã—ã€ã“ã‚Œã¯ Guo æœ¬äººã®æ¨å¥¨ä»•æ§˜ã§ã¯ãªãã€Œã‚ãªãŸç‹¬è‡ªã®æ‹¡å¼µã€ãªã®ã§ã€backtest ã§ã—ã£ã‹ã‚Šæ¤œè¨¼ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ï¼‰

ã‚‚ã—ã€ã€ŒMethod 6 ã®æ§‹é€ åˆ¶ç´„ï¼ˆ $\bar R$  ã«ä¿‚æ•° 1ï¼‰ã‚’ç¶­æŒã—ãŸã¾ã¾ nr + P4 ã® 2 å¤‰æ•°ç‰ˆã‚’ä½œã‚‹ï¼ˆï¼æ§‹é€ ãƒ¢ãƒ‡ãƒ«ã«å¿ å®Ÿãª 2å¤‰é‡ z\*\_tï¼‰ã€ã¨ã„ã†æ–¹å‘ã«ã•ã‚‰ã«æ•´ç†ã—ãŸã„å ´åˆã¯ã€ãã®æ•°å¼ã¨ã‚³ãƒ¼ãƒ‰ã‚‚æ•´ç†ã§ãã¾ã™ã€‚

## Response:
æ€è€ƒæ™‚é–“: 16s

ã¯ã„ã€Method 5 ã‚‚ Method 6 ã‚‚ã€ã©ã¡ã‚‰ã‚‚è‡ªç„¶ã«ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«æ‹¡å¼µã§ãã¾ã™ã€‚

å°‘ã—æ•´ç†ã™ã‚‹ã¨ï¼š

*   ã€Œä½•ã‚’äºˆæ¸¬ã—ã¦ã„ã‚‹ã‹ã€ï¼ˆãƒªã‚¿ãƒ¼ãƒ³ or ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ï¼‰
*   ã€Œã©ã“ã§ãƒœãƒ©ã‚’åˆã‚ã›ã‚‹ã‹ã€ï¼ˆ1å›ã ã‘ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ»ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚° or ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã§å‹•çš„ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼‰

ã ã‘ã®é•ã„ã§ã€æ çµ„ã¿ã¨ã—ã¦ã¯å®Œå…¨ã«ä¸¡ç«‹ã—ã¾ã™ã€‚

* * *

1\. Method 5 ã‚’ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«ã™ã‚‹
------------------------

### 1.1 Method 5 ã®åŸºæœ¬å½¢ï¼ˆãŠã•ã‚‰ã„ï¼‰

Method 5ï¼ˆnr + P4 ã® joint ãƒ¢ãƒ‡ãƒ«ï¼‰ã¯ã€ã–ã£ãã‚Š

$$
r_t = \alpha + \beta_{\text{nr}} \,\mathrm{nr}_{t-1} + \beta_{P4}\,\mathrm{P4}_{t-1} + \varepsilon_t
$$

ã‚’ time-series å›å¸°ã§æ¨å®šã—ã€  
1æœŸå…ˆã®äºˆæ¸¬å€¤  $\hat r_{t+1}$  ã‹ã‚‰æˆ¦ç•¥ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚’æ±ºã‚ã¦ã„ã¾ã—ãŸã€‚

ãƒ»sign æˆ¦ç•¥ãªã‚‰

$$
w_{t+1}^{\text{sign}} = \mathrm{sign}(\hat r_{t+1})
$$

ãƒ»ç·šå½¢æˆ¦ç•¥ãªã‚‰ï¼ˆä¾‹ãˆã°ãã®ã¾ã¾ï¼‰

$$
w_{t+1}^{\text{lin}} = \hat r_{t+1}
$$

### 1.2 ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®åŸºæœ¬ã‚¢ã‚¤ãƒ‡ã‚¢

ç›®æ¨™æœˆæ¬¡ãƒœãƒ©ã‚’  $\sigma^*$  ã¨ã™ã‚‹ã¨ã€

1.  ã¾ãšã€Œç”Ÿã®æˆ¦ç•¥ã€ã®è¶…éãƒªã‚¿ãƒ¼ãƒ³ç³»åˆ—ã‚’ä½œã‚‹
    $$
    r^{\text{strat}}_t = w_t \cdot r_t^{\text{mkt}}
    $$
2.  ãã®æ¨™æº–åå·®ã‚’  $\hat\sigma$  ã¨è¨ˆç®—ã™ã‚‹ï¼ˆå…¨æœŸé–“ or ä¸€éƒ¨åŒºé–“ï¼‰
3.  ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªã‚¹ã‚±ãƒ¼ãƒ«ä¿‚æ•°  $k$  ã‚’
    $$
    k = \frac{\sigma^*}{\hat\sigma}
    $$
    ã¨ç½®ãã€å®Ÿéš›ã®ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚’
    $$
    \tilde w_t = k \cdot w_t
    $$
    ã¨ã™ã‚‹ã€‚

ã“ã‚Œã§ã€Œæœ€çµ‚çš„ãªæˆ¦ç•¥ã®æ¨™æº–åå·® â‰’  $\sigma^*$ ã€ã«ãªã‚Šã¾ã™ï¼ˆäº‹å¾Œãƒ™ãƒ¼ã‚¹ã®ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼‰ã€‚

### 1.3 ã‚³ãƒ¼ãƒ‰ä¾‹ï¼ˆMethod 5 ã® sign æˆ¦ç•¥ã‚’ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼‰

`compare_all_methods` ã® `run_method4_nr_p4` ã§å¾—ãŸ sign æˆ¦ç•¥ã‚’ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã™ã‚‹é–¢æ•°ã‚’è¿½åŠ ã™ã‚‹ã¨ã“ã‚“ãªæ„Ÿã˜ã«ãªã‚Šã¾ã™ã€‚

```python
def vol_target_from_sign_strategy(
    mkt_excess: pd.Series,
    y_hat: pd.Series,
    target_vol: float = 0.05,
    min_obs: int = 120
) -> pd.DataFrame:
    """
    Method 5 ãªã©ã® sign æˆ¦ç•¥ã‚’ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã™ã‚‹ç°¡æ˜“ç‰ˆã€‚

    mkt_excess : å¸‚å ´è¶…éãƒªã‚¿ãƒ¼ãƒ³ r_t
    y_hat      : OOS äºˆæ¸¬å€¤ \hat r_t
    target_vol : ç›®æ¨™æœˆæ¬¡ãƒœãƒ©ï¼ˆä¾‹ 0.05 = 5%ï¼‰
    """

    # 1) sign æˆ¦ç•¥ã®ç”Ÿã‚¦ã‚§ã‚¤ãƒˆ
    w_sign = np.sign(y_hat).fillna(0.0)

    # 2) ç”Ÿã®æˆ¦ç•¥è¶…éãƒªã‚¿ãƒ¼ãƒ³
    strat_excess_raw = w_sign * mkt_excess

    # 3) å®Ÿç¾ãƒœãƒ©ã‚’è¨ˆç®—ï¼ˆæ¬ æã‚’é™¤ã„ãŸå…¨æœŸé–“ï¼‰
    mask = strat_excess_raw.notna()
    realized_vol = strat_excess_raw[mask].std(ddof=1)

    if realized_vol is None or realized_vol == 0 or np.isnan(realized_vol):
        scale = 1.0
    else:
        scale = target_vol / realized_vol

    # 4) ã‚¹ã‚±ãƒ¼ãƒ«å¾Œã®æˆ¦ç•¥
    strat_excess = strat_excess_raw * scale

    out = pd.DataFrame({
        "mkt_excess": mkt_excess,
        "w_sign": w_sign,
        "w_scaled": w_sign * scale,
        "strat_excess_raw": strat_excess_raw,
        "strat_excess": strat_excess,
    })
    out.attrs["scale"] = scale
    out.attrs["target_vol"] = target_vol

    return out
```

*   `run_method4_nr_p4` ã®çµæœï¼ˆ`y_hat4`ï¼‰ã‚’ã“ã®é–¢æ•°ã«æ¸¡ã›ã°ã€  
    ã€Œ**Method 5 ã® sign æˆ¦ç•¥ãƒ»ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç‰ˆ**ã€ãŒä½œã‚Œã¾ã™ã€‚

ç·šå½¢æˆ¦ç•¥ç‰ˆã«ã—ãŸã‘ã‚Œã°ã€`w_sign` ã®ä»£ã‚ã‚Šã« `w_raw = y_hat` ã‚’ä½¿ã†ã ã‘ã§ã™ã€‚

* * *

2\. Method 6 ã¯ã™ã§ã«ã€Œãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæˆ¦ç•¥ã€ã«ãªã£ã¦ã„ã‚‹
----------------------------------

### 2.1 ã‚ãªãŸã® `backtest_method6_strategy` ã®ä¸­èº«

ã™ã§ã«æ›¸ã„ã¦ã„ãŸã ã„ãŸ Method 6 ç”¨ã‚³ãƒ¼ãƒ‰ã¯ã€

1.  `w_raw_t = Î²_t x_t` ã¨ã„ã†ã€Œç†è«–ãƒ¢ãƒ‡ãƒ«ã«æ²¿ã£ãŸç”Ÿã®ãƒ¬ãƒãƒ¬ãƒƒã‚¸ã€ã‚’è¨ˆç®—
2.  `strat_excess_raw = w_raw * mkt_excess`
3.  ãã®å®Ÿç¾ãƒœãƒ© `strat_vol` ã‚’è¨ˆç®—
4.  `scale = target_vol / strat_vol` ã§ã‚¹ã‚±ãƒ¼ãƒ«ä¿‚æ•°ã‚’æ±‚ã‚ã‚‹
5.  `strat_excess_scaled = strat_excess_raw * scale` ã‚’æ¡ç”¨

ã¨ã„ã†æµã‚Œã«ãªã£ã¦ã„ã¾ã—ãŸã€‚

ã“ã‚Œã¯ã¾ã•ã«ã€ŒMethod 6 ã‚’ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã—ãŸæˆ¦ç•¥ã€ã«ãªã£ã¦ã„ã¾ã™ã€‚

*   `target_vol=None` ã®å ´åˆã¯ã€Œå¸‚å ´ãƒœãƒ©ã«åˆã‚ã›ã‚‹ã€ã‚ˆã†ã«æ›¸ã„ã¦ã‚ã‚‹ã®ã§ã€  
    ã€Œ**å¸‚å ´ã¨åŒã˜ãƒœãƒ©ã‚’æŒã¤ Method 6 æˆ¦ç•¥**ã€ã«ãªã£ã¦ã„ã¾ã™ã€‚
*   `target_vol=0.05` ãªã©ã«ã™ã‚Œã°ã€ã€Œ**å¥½ããªæ°´æº–ã®ãƒœãƒ©ã«åˆã‚ã›ãŸ Method 6**ã€ã«ãã®ã¾ã¾ãªã‚Šã¾ã™ã€‚

### 2.2 ã‚‚ã†å°‘ã—å‹•çš„ã«ã—ãŸã„å ´åˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

ä¸Šã®ã‚„ã‚Šæ–¹ã¯ã€Œå…¨æœŸé–“ã® realized vol ã§ä¸€æ‹¬ã‚¹ã‚±ãƒ¼ãƒ«ã€ãªã®ã§ã€

*   æ¨å®šé–‹å§‹ä»¥é™ãšã£ã¨åŒã˜ scale ã‚’ä½¿ã†
*   regime shift ãŒã‚ã£ã¦ã‚‚ scale ã¯å¤‰ã‚ã‚‰ãªã„

ã¨ã„ã†ä»•æ§˜ã§ã™ã€‚

ã‚‚ã—ã€Œãƒ­ãƒ¼ãƒªãƒ³ã‚° 36 ãƒ¶æœˆã®å®Ÿç¾ãƒœãƒ©ã‹ã‚‰ã€æ¯æœˆ scale ã‚’æ›´æ–°ã—ãŸã„ã€ã®ã§ã‚ã‚Œã°ã€ä¾‹ãˆã°ï¼š

$$
\text{scale}_t = \frac{\sigma^*}{\widehat\sigma_{t-1}}, \quad \widehat\sigma_{t-1} = \mathrm{std}\bigl(\{w_s r^{\text{mkt}}_s\}_{s=t-36}^{t-1}\bigr)
$$

ã¨ã„ã£ãŸå½¢ã§ã€time-varying ãª scale ã‚’ä½¿ã†ã“ã¨ã‚‚ã§ãã¾ã™ã€‚  
å®Ÿè£…ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ `apply_timing_strategy` ã¨åŒã˜ã§ã€`rolling().std()` ã‚’æŒŸã‚€ã ã‘ã§ã™ã€‚

* * *

3\. nr + P4 ã® z\*\_tï¼ˆ20å¹´ rolling OLSï¼‰ã‚’ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã™ã‚‹
-----------------------------------------------

ã“ã¡ã‚‰ã¯ã™ã§ã« `apply_timing_strategy` ã§ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã—ã¦ã„ã¾ã™ãŒã€  
ã€ŒMethod 5 / 6 ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ã§åˆã‚ã›ãŸã„ã€ã¨ã„ã†æ„å‘³ã§æ•´ç†ã™ã‚‹ã¨ï¼š

1.  rolling OLS ã§
    $$
    z^*_t = \beta_{\text{nr},t} \mathrm{nr}_t + \beta_{P4,t}\mathrm{P4}_t
    $$
    ã‚’ä½œã‚‹
2.  ã€Œãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå‰ã® raw weightã€ã‚’
    $$
    w_t^{\text{raw}} = z^*_t
    $$
    ã¨è¦‹ãªã™
3.  `strat_excess_raw = w_raw * mkt_excess` ã‹ã‚‰ realized\_vol ã‚’è¨ˆç®—ã—ã€
    $$
    scale = \frac{\sigma^*}{\widehat\sigma}
    $$
4.  `w_scaled = w_raw * scale`ã€`strat_excess = w_scaled * mkt_excess`

ã¨ã„ã†å½¢ã«ã™ã‚Œã°ã€Method 5 / 6 ã¨å®Œå…¨ã«åŒã˜ã€Œãƒ¬ã‚¤ãƒ¤ãƒ¼ã€ã§ãƒœãƒ©ã‚’åˆã‚ã›ã‚‰ã‚Œã¾ã™ã€‚

æ—¢ã«ã‚ã‚‹ `apply_timing_strategy` ã¯

*   å„æ™‚ç‚¹ã§ `z` ã®éå»æ¨™æº–åå·®ã§å‰²ã‚‹ â†’ ex ante ã« w\_t ã‚’ç¸®å°  
    ã¨ã„ã† **ã€Œäº‹å‰ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã€** ã«è¿‘ã„è¨­è¨ˆãªã®ã§ã€
*   Method 5 / 6 ã®ã‚ˆã†ã«ã€Œæˆ¦ç•¥ãƒªã‚¿ãƒ¼ãƒ³ã‚’ä½œã£ã¦ã‹ã‚‰ 1 å›ã‚¹ã‚±ãƒ¼ãƒ«ã€
*   z\*\_t ã®ã‚ˆã†ã«ã€Œã‚·ã‚°ãƒŠãƒ«ã®æ¨™æº–åå·®ã§ãã®éƒ½åº¦å‰²ã‚‹ã€

ã®2 å±¤ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã‹ã©ã†ã‹ã¯ã€å¥½ã¿ã¨å®‰å®šæ€§ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã«ãªã‚Šã¾ã™ã€‚

* * *

4\. çµè«–ã¨ãŠã™ã™ã‚ã®æ•´ç†
--------------

### 4.1 çµè«–

*   **Method 5**  
    â†’ äºˆæ¸¬å€¤  $\hat r_t$  ã‹ã‚‰ä½œã‚‹ sign æˆ¦ç•¥ã‚‚ç·šå½¢æˆ¦ç•¥ã‚‚ã€\*\*äº‹å¾Œãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼ˆå…¨æœŸé–“ or ãƒ­ãƒ¼ãƒªãƒ³ã‚°ï¼‰\*\*ã§ç°¡å˜ã«ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¯èƒ½ã€‚
*   **Method 6**  
    â†’ ã™ã§ã«ã‚ãªãŸã®å®Ÿè£…ã¯ã€Œscale ã‚’ã‹ã‘ã¦ target\_vol ã«åˆã‚ã›ã‚‹ã€æ§‹é€ ã«ãªã£ã¦ã„ã‚‹ã®ã§ã€  
    **Method 6ï¼ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæˆ¦ç•¥** ã¨è¦‹ãªã—ã¦ã‚ˆã„ã€‚
*   **nr + P4 ã® z\*\_tï¼ˆ20y rollingï¼‰**  
    â†’ ä»Šã¯ `apply_timing_strategy` ã®ã€Œäº‹å‰ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã€ã‚’ä½¿ã£ã¦ã„ã‚‹ãŒã€  
    Method 6 ã¨åŒæ§˜ã«ã€Œäº‹å¾Œãƒœãƒ©ã€ã§ã‚‚ã† 1 å›ã ã‘ã‚¹ã‚±ãƒ¼ãƒ«ã‚’ã‹ã‘ã‚‹ã“ã¨ã‚‚å¯èƒ½ã€‚

### 4.2 å®Ÿå‹™çš„ãªãŠã™ã™ã‚

*   ç†è«–çš„ãªã‚¯ãƒªãƒ¼ãƒ³ã•é‡è¦–ï¼š  
    â†’ Method 6ï¼ˆæ§‹é€ åˆ¶ç´„ä»˜ãï¼‰ã®ã€Œç¾åœ¨ã®å®Ÿè£… + äº‹å¾Œãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã€ã§ååˆ†ç­‹ãŒé€šã£ã¦ã„ã‚‹ã€‚
*   å®Ÿå‹™ã§ã€Œã©ã®æˆ¦ç•¥ã‚‚åŒã˜æœˆæ¬¡ãƒœãƒ© 5%ã€ã§æ¯”è¼ƒã—ãŸã„ï¼š  
    â†’
    1.  å„æˆ¦ç•¥ã«ã¤ã„ã¦ raw è¶…éãƒªã‚¿ãƒ¼ãƒ³ç³»åˆ—ã‚’ä½œã‚‹
    2.  ãã®æ¨™æº–åå·®ã§ scale ã‚’ã‹ã‘ã¦ target\_vol ã«åˆã‚ã›ã‚‹  
        ã¨ã„ã†çµ±ä¸€ã‚¹ã‚­ãƒ¼ãƒ ã§ã€Method 5 / 6 / z\*\_t ã‚’æ¯”è¼ƒã™ã‚‹ã®ãŒãã‚Œã„ã§ã™ã€‚

ã‚‚ã—ã€ŒMethod 5 ã® nr + P4 ç·šå½¢æˆ¦ç•¥ã€ã¨ã€ŒMethod 6ã€ã¨ã€Œz\*\_tã€ã‚’ã€  
ã¾ã£ãŸãåŒã˜ `vol_target_strategy()` ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã§å‡¦ç†ã™ã‚‹çµ±åˆã‚³ãƒ¼ãƒ‰ãŒæ¬²ã—ã‘ã‚Œã°ã€ãã“ã ã‘åˆ‡ã‚Šå‡ºã—ãŸå…±é€šé–¢æ•°ç¾¤ã¨ã—ã¦ã¾ã¨ã‚ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

## Response:
æ€è€ƒæ™‚é–“: 13s

äº†è§£ã—ã¾ã—ãŸã€‚  
Method 5ãƒ»Method 6ãƒ»z\*\_tï¼ˆnr+P4, 20y rollingï¼‰ã‚’ã€ŒåŒã˜ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ­ã‚¸ãƒƒã‚¯ã€ã§æ‰±ãˆã‚‹ã‚ˆã†ã«ã™ã‚‹çµ±åˆã‚³ãƒ¼ãƒ‰ã‚’ãŠå‡ºã—ã—ã¾ã™ã€‚

ãƒã‚¤ãƒ³ãƒˆã ã‘å…ˆã«ã¾ã¨ã‚ã‚‹ã¨ï¼š

1.  ã¾ãšå„æ‰‹æ³•ã‹ã‚‰ã€Œ**raw weightï¼ˆãƒ¬ãƒãƒ¬ãƒƒã‚¸ï¼‰åˆ— `w_raw`**ã€ã‚’ä½œã‚‹
2.  å…±é€šã® `vol_target_from_weights(...)` é–¢æ•°ã«
    *   `w_raw`
    *   `mkt_excess`
    *   `rf`
    *   `target_vol`  
        ã‚’æ¸¡ã—ã¦ã€  
        ã€Œãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ¸ˆã¿æˆ¦ç•¥ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆ`strat_excess`, `strat_total`ï¼‰ã€ã‚’å¾—ã‚‹
3.  ã“ã‚Œã§ Method5 / Method6 / z\*\_t ã‚’**å®Œå…¨ã«åŒã˜ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**ã§æ¯”è¼ƒå¯èƒ½

ã¨ã„ã†æµã‚Œã«ã—ã¦ã„ã¾ã™ã€‚

* * *

0\. å‰æï¼ˆnrãƒ»P4ãƒ»Sãƒ»x ã®æ§‹ç¯‰ï¼‰
---------------------

ã™ã§ã«ãŠä½¿ã„ã® `add_nr_and_p4` / `compute_S_and_x_for_method6` ã‚’å‰æã«ã—ã¾ã™ã€‚  
ã¾ã åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã«åˆ†ã‘ã¦ã„ãªã„å ´åˆã¯ã€ãã®ã¾ã¾åŒã˜ã‚¹ã‚¯ãƒªãƒ—ãƒˆã«ç½®ã„ã¦ãã ã•ã„ã€‚

```python
import pandas as pd
import numpy as np
import math
import matplotlib.pyplot as plt
import statsmodels.api as sm

# --------------------------------------------------
# Fama-French èª­ã¿è¾¼ã¿
# --------------------------------------------------
def load_ff_monthly_from_ken_french(csv_path: str) -> pd.DataFrame:
    raw = pd.read_csv(csv_path, skiprows=4)
    num = pd.to_numeric(raw['Unnamed: 0'], errors='coerce')
    mask_monthly = num > 10000
    monthly = raw[mask_monthly].copy()
    monthly = monthly.rename(columns={'Unnamed: 0': 'date'})
    monthly['date'] = pd.to_datetime(monthly['date'].astype(int), format="%Y%m")
    monthly = monthly.set_index('date').sort_index()

    for col in ['Mkt-RF', 'RF']:
        monthly[col] = pd.to_numeric(monthly[col], errors='coerce')

    ff = monthly[['Mkt-RF', 'RF']].copy()
    ff['mkt_excess'] = ff['Mkt-RF'] / 100.0
    ff['rf']         = ff['RF'] / 100.0
    return ff[['mkt_excess', 'rf']].dropna()

def classify_month_type(index: pd.DatetimeIndex) -> pd.Series:
    mt = pd.Series(index=index, dtype="object")
    for t in index:
        m = t.month % 3
        if m == 1:
            mt[t] = 'N'
        elif m == 2:
            mt[t] = 'R'
        else:
            mt[t] = '3'
    return mt

def add_nr_and_p4(ff: pd.DataFrame) -> pd.DataFrame:
    df = ff.copy()
    df["month_type"] = classify_month_type(df.index)

    dates = df.index.to_list()
    mt = df["month_type"].values
    mkt = df["mkt_excess"].values

    nr_dates = []
    mkt_nr_list = []
    past_newsy_indices = []
    mkt_nm1 = []
    mkt_nm2 = []
    mkt_nm3 = []
    mkt_nm4 = []

    for i, t in enumerate(dates):
        # nr(t): ç›´è¿‘ã® N or R
        nr_idx = None
        j = i - 1
        while j >= 0:
            if mt[j] in ("N", "R"):
                nr_idx = j
                break
            j -= 1
        if nr_idx is None:
            nr_dates.append(None)
            mkt_nr_list.append(np.nan)
        else:
            nr_dates.append(dates[nr_idx])
            mkt_nr_list.append(mkt[nr_idx])

        # N (newsy) ã®å±¥æ­´æ›´æ–°
        if mt[i] == "N":
            past_newsy_indices.append(i)

        # nm(t,j)
        cand = [k for k in past_newsy_indices if k < i]
        cand = sorted(cand, reverse=True)
        vals = []
        for jj in range(4):
            if jj < len(cand):
                vals.append(mkt[cand[jj]])
            else:
                vals.append(np.nan)

        mkt_nm1.append(vals[0])
        mkt_nm2.append(vals[1])
        mkt_nm3.append(vals[2])
        mkt_nm4.append(vals[3])

    df["nr_date"] = nr_dates
    df["mkt_nr"]  = mkt_nr_list
    df["mkt_nm1"] = mkt_nm1
    df["mkt_nm2"] = mkt_nm2
    df["mkt_nm3"] = mkt_nm3
    df["mkt_nm4"] = mkt_nm4
    df["P4"]      = df[["mkt_nm1", "mkt_nm2", "mkt_nm3", "mkt_nm4"]].mean(axis=1)
    df["mkt_nm4_avg"] = df["P4"]
    return df

def compute_S_and_x_for_method6(mkt_total: pd.Series):
    idx = mkt_total.index
    month_type = classify_month_type(idx)
    is_newsy = (month_type == "N")

    news_series = mkt_total[is_newsy]

    S = pd.Series(index=idx, dtype=float)
    for t in idx:
        past = news_series[news_series.index <= t]
        if len(past) >= 4:
            S[t] = past.iloc[-4:].sum()
        else:
            S[t] = np.nan

    x = pd.Series(index=idx, dtype=float)
    S_hist = []
    for i in range(1, len(idx)):
        prev_date = idx[i-1]
        curr_date = idx[i]
        s_prev = S.loc[prev_date]
        if np.isnan(s_prev):
            x[curr_date] = np.nan
            continue
        S_hist.append(s_prev)
        s_bar = float(np.mean(S_hist))
        sign = -1.0 if is_newsy[curr_date] else 1.0
        x[curr_date] = sign * (s_prev - s_bar)

    return S, x, month_type
```

* * *

1\. å…±é€šï¼šraw weight ã‚’ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã™ã‚‹é–¢æ•°
------------------------------

ã¾ãšã¯ã€Œã©ã®æˆ¦ç•¥ã§ã‚‚ä½¿ãˆã‚‹ã€ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé–¢æ•°ã§ã™ã€‚

```python
def vol_target_from_weights(
    mkt_excess: pd.Series,
    rf: pd.Series,
    w_raw: pd.Series,
    target_vol: float = 0.05,
) -> pd.DataFrame:
    """
    ä»»æ„ã® raw weight w_raw ã«å¯¾ã—ã¦ã€
    - strat_excess_raw = w_raw * mkt_excess
    - ãã®å®Ÿç¾ãƒœãƒ©ã‹ã‚‰ã‚¹ã‚±ãƒ¼ãƒ«ä¿‚æ•°ã‚’è¨ˆç®—
    - ç›®æ¨™ãƒœãƒ© target_vol ã«åˆã‚ã›ã‚‹

    æˆ»ã‚Šå€¤:
      DataFrame: ['mkt_excess','rf','w_raw','w_scaled',
                  'strat_excess_raw','strat_excess','strat_total']
    """
    # ã‚¢ãƒ©ã‚¤ãƒ³
    data = pd.concat(
        [mkt_excess.rename("mkt_excess"),
         rf.rename("rf"),
         w_raw.rename("w_raw")],
        axis=1
    ).dropna(subset=["mkt_excess", "rf"])

    strat_excess_raw = data["w_raw"] * data["mkt_excess"]
    realized_vol = strat_excess_raw.std(ddof=1)

    if realized_vol is None or realized_vol == 0 or np.isnan(realized_vol):
        scale = 1.0
    else:
        scale = target_vol / realized_vol

    w_scaled = data["w_raw"] * scale
    strat_excess = strat_excess_raw * scale
    strat_total  = data["rf"] + strat_excess

    out = pd.DataFrame({
        "mkt_excess": data["mkt_excess"],
        "rf": data["rf"],
        "w_raw": data["w_raw"],
        "w_scaled": w_scaled,
        "strat_excess_raw": strat_excess_raw,
        "strat_excess": strat_excess,
        "strat_total": strat_total,
    })
    out.attrs["scale"] = scale
    out.attrs["target_vol"] = target_vol
    return out
```

* * *

2\. Method 5 ç”¨ï¼šnr + P4 ã® rolling OLS â†’ raw weight
-------------------------------------------------

ã“ã“ã§ã¯ã€ŒMethod 5ï¼ˆnr+P4ï¼‰ã€ã‚’ rolling OLS ã§æ¨å®šã—ã€  
1 æœŸå…ˆè¶…éãƒªã‚¿ãƒ¼ãƒ³ã®äºˆæ¸¬å€¤ã‚’ãã®ã¾ã¾ weight ã«ä½¿ã†**ç·šå½¢æˆ¦ç•¥**ã‚’æƒ³å®šã—ã¾ã™ã€‚

```python
def build_method5_nr_p4_raw_weights(
    ff: pd.DataFrame,
    lookback_years: int = 20,
    min_obs: int = 120,
) -> pd.Series:
    """
    Method 5ï¼ˆnr + P4 jointï¼‰ã® rolling OLS ç‰ˆã€‚
    - ç›´è¿‘ lookback_years å¹´ã§ nr, P4 â†’ mkt_excess ã‚’å›å¸°
    - æ¬¡æœˆã®äºˆæ¸¬å€¤ \hat r_{t+1} ã‚’ raw weight ã¨ã—ã¦è¿”ã™

    æˆ»ã‚Šå€¤:
      w_raw: index=ff.index, values= raw weight
    """
    df = add_nr_and_p4(ff)
    idx = df.index

    beta_nr  = pd.Series(index=idx, dtype=float)
    beta_p4  = pd.Series(index=idx, dtype=float)
    alpha    = pd.Series(index=idx, dtype=float)

    for i, t in enumerate(idx):
        if i == 0:
            continue

        end_date = idx[i-1]
        start_date = end_date - pd.DateOffset(years=lookback_years)
        mask = (idx >= start_date) & (idx <= end_date)
        sub = df.loc[mask, ["mkt_excess", "mkt_nr", "P4"]].dropna()

        if len(sub) < min_obs:
            continue

        y = sub["mkt_excess"]
        X = sub[["mkt_nr", "P4"]]
        X_const = sm.add_constant(X)
        model = sm.OLS(y, X_const).fit()

        alpha[t]   = model.params.get("const", np.nan)
        beta_nr[t] = model.params.get("mkt_nr", np.nan)
        beta_p4[t] = model.params.get("P4", np.nan)

    # 1æœŸå…ˆã®äºˆæ¸¬å€¤ã‚’ raw weight ã«
    w_raw = pd.Series(index=idx, dtype=float)
    for i in range(len(idx)-1):
        t = idx[i]
        t_next = idx[i+1]

        if any(np.isnan([alpha[t], beta_nr[t], beta_p4[t], df.at[t, "mkt_nr"], df.at[t, "P4"]])):
            w_raw[t_next] = 0.0
            continue

        nr_t = df.at[t, "mkt_nr"]
        p4_t = df.at[t, "P4"]
        w_raw[t_next] = alpha[t] + beta_nr[t]*nr_t + beta_p4[t]*p4_t

    return w_raw
```

*   ã“ã‚ŒãŒã€ŒMethod 5ï¼ˆnr+P4, rolling 20y OLSï¼‰ã® raw weightã€ã§ã™ã€‚
*   sign æˆ¦ç•¥ã«ã—ãŸã‘ã‚Œã° `np.sign(w_raw)` ã‚’ä½¿ãˆã° OK ã§ã™ã€‚

* * *

3\. z\*\_tï¼ˆnr+P4, rolling OLSï¼‰ã® raw weight
------------------------------------------

ã™ã§ã«ãŠä½¿ã„ã® `build_z_star_online` ã‚’ã€Œraw weight `w_raw = z_star`ã€ã¨ã—ã¦ä½¿ã†ç‰ˆã§ã™ã€‚  
ï¼ˆä¿‚æ•°ã‚’ã‹ã‘ãŸç·šå½¢çµåˆã ã‘ã‚’ä½¿ã„ã€å®šæ•°é …ã¯å…¥ã‚Œãªã„å®Ÿè£…ã€‚ï¼‰

```python
def build_z_star_online(
    ff: pd.DataFrame,
    lookback_years: int = 20,
    min_obs: int = 120,
) -> pd.DataFrame:
    """
    nr + P4 joint rolling OLS ã‹ã‚‰ z*_t ã‚’ä½œã‚‹ï¼ˆæ—¢å‡ºã®é–¢æ•°ã‚’æ•´ç†ã—ãŸç‰ˆï¼‰ã€‚
    """
    df = add_nr_and_p4(ff)
    idx = df.index

    beta_nr = pd.Series(index=idx, dtype=float)
    beta_p4 = pd.Series(index=idx, dtype=float)

    for i, t in enumerate(idx):
        if i == 0:
            continue

        end_date = idx[i-1]
        start_date = end_date - pd.DateOffset(years=lookback_years)
        mask = (idx >= start_date) & (idx <= end_date)
        sub = df.loc[mask, ["mkt_excess", "mkt_nr", "P4"]].dropna()

        if len(sub) < min_obs:
            continue

        y = sub["mkt_excess"]
        X = sub[["mkt_nr", "P4"]]
        X_const = sm.add_constant(X)
        model = sm.OLS(y, X_const).fit()

        beta_nr[t] = model.params.get("mkt_nr", np.nan)
        beta_p4[t] = model.params.get("P4", np.nan)

    df["beta_nr"]  = beta_nr
    df["beta_P4"]  = beta_p4
    df["z_star"]   = df["beta_nr"] * df["mkt_nr"] + df["beta_P4"] * df["P4"]
    return df

def build_zstar_raw_weights(ff: pd.DataFrame,
                            lookback_years: int = 20,
                            min_obs: int = 120) -> pd.Series:
    """
    z*_t ã‚’ãã®ã¾ã¾ raw weight ã¨ã—ã¦ä½¿ã†ã€‚
    """
    df_z = build_z_star_online(ff, lookback_years=lookback_years, min_obs=min_obs)
    w_raw = df_z["z_star"].fillna(0.0)
    return w_raw
```

* * *

4\. Method 6 ã® raw weightï¼ˆÎ²\_t x\_tï¼‰
------------------------------------

Method 6 ã¯ã€Œæ§‹é€ ãƒ¢ãƒ‡ãƒ«ã«æ²¿ã£ã¦ Î²\_t x\_t ãŒãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ã€ã‚’è¡¨ã™ã®ã§ã€  
`w_raw = Î²_t x_t` ã‚’å–ã‚Šå‡ºã—ã€å¾Œã§ `vol_target_from_weights` ã«æ¸¡ã—ã¾ã™ã€‚

```python
def build_method6_raw_weights(
    ff: pd.DataFrame,
    min_obs: int = 120,
) -> (pd.Series, pd.Series, pd.Series):
    """
    Method 6 ã® raw weight ã‚’æ§‹æˆã™ã‚‹ã€‚
    æˆ»ã‚Šå€¤:
      x      : predictor x_t
      beta   : rolling Î²_t
      w_raw  : Î²_t * x_t
    """
    mkt_excess = ff["mkt_excess"].copy()
    rf         = ff["rf"].copy()
    mkt_total  = mkt_excess + rf
    idx        = mkt_total.index

    S, x, month_type = compute_S_and_x_for_method6(mkt_total)
    mkt_mean = mkt_total.expanding().mean().shift(1)
    y_adj    = mkt_total - mkt_mean

    beta = pd.Series(index=idx, dtype=float)

    for i, t in enumerate(idx):
        mask = (idx <= t) & x.notna() & y_adj.notna()
        n = mask.sum()
        if n < min_obs:
            beta[t] = np.nan
            continue

        xi = x[mask].values
        yi = y_adj[mask].values
        denom = (xi ** 2).sum()
        beta[t] = (xi * yi).sum() / denom if denom > 0 else np.nan

    w_raw = pd.Series(index=idx, dtype=float)
    for i in range(len(idx)):
        t = idx[i]
        if np.isnan(beta[t]) or np.isnan(x[t]):
            w_raw[t] = 0.0
        else:
            w_raw[t] = beta[t] * x[t]

    return x, beta, w_raw
```

* * *

5\. 3 ã¤ã®æˆ¦ç•¥ã‚’çµ±ä¸€ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã§æ¯”è¼ƒã™ã‚‹ä¾‹
--------------------------

æœ€å¾Œã«ã€Method5ï¼ˆnr+P4, rollingï¼‰ã€z\*\_tï¼ˆnr+P4 rollingï¼‰ã€Method6ï¼ˆæ§‹é€ ãƒ¢ãƒ‡ãƒ«ï¼‰ã‚’  
ã™ã¹ã¦ `vol_target_from_weights` ã«é€šã—ã¦æ¯”è¼ƒã™ã‚‹ä¾‹ã§ã™ã€‚

```python
if __name__ == "__main__":
    csv_path = "F-F_Research_Data_Factors.csv"
    ff = load_ff_monthly_from_ken_french(csv_path)

    target_vol = 0.05  # æœˆæ¬¡ 5% ãªã©

    # 1) Method 5 (nr + P4, rolling OLS)
    w_m5 = build_method5_nr_p4_raw_weights(ff, lookback_years=20, min_obs=120)
    strat_m5 = vol_target_from_weights(ff["mkt_excess"], ff["rf"], w_m5, target_vol=target_vol)

    # 2) z*_t (nr + P4, rolling OLS â†’ Î²_nr, Î²_P4 ã®ç·šå½¢çµåˆ)
    w_zstar = build_zstar_raw_weights(ff, lookback_years=20, min_obs=120)
    strat_zstar = vol_target_from_weights(ff["mkt_excess"], ff["rf"], w_zstar, target_vol=target_vol)

    # 3) Method 6 (Î²_t x_t)
    x_m6, beta_m6, w_m6 = build_method6_raw_weights(ff, min_obs=120)
    strat_m6 = vol_target_from_weights(ff["mkt_excess"], ff["rf"], w_m6, target_vol=target_vol)

    # ç°¡æ˜“æ¯”è¼ƒï¼ˆå¹´ç‡å¹³å‡ãƒ»ãƒœãƒ©ãƒ»ã‚·ãƒ£ãƒ¼ãƒ—ï¼‰
    def annualized_stats(r: pd.Series):
        r = r.dropna()
        mu_m = r.mean()
        sd_m = r.std(ddof=1)
        mu_a = mu_m * 12
        sd_a = sd_m * math.sqrt(12)
        sharpe = mu_a / sd_a if sd_a > 0 else np.nan
        return mu_a, sd_a, sharpe

    for label, df_strat in [
        ("Method5_nrP4_rolling", strat_m5),
        ("zstar_nrP4_rolling",   strat_zstar),
        ("Method6_S",            strat_m6),
    ]:
        mu, sd, sh = annualized_stats(df_strat["strat_total"])
        print(f"[{label}] mu={mu:.2%}, sigma={sd:.2%}, Sharpe={sh:.2f}")

    # ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³ã®æ¯”è¼ƒ
    common_index = strat_m5["strat_total"].dropna().index
    common_index = common_index.intersection(strat_zstar["strat_total"].dropna().index)
    common_index = common_index.intersection(strat_m6["strat_total"].dropna().index)

    sw_m5    = (1.0 + strat_m5["strat_total"].reindex(common_index)).cumprod()
    sw_zstar = (1.0 + strat_zstar["strat_total"].reindex(common_index)).cumprod()
    sw_m6    = (1.0 + strat_m6["strat_total"].reindex(common_index)).cumprod()
    mw       = (1.0 + (ff["mkt_excess"] + ff["rf"]).reindex(common_index)).cumprod()

    plt.figure(figsize=(14,5))
    plt.plot(sw_m5,    label="Method5 nr+P4 (rolling, vol-targeted)", linewidth=2)
    plt.plot(sw_zstar, label="z*_t nr+P4 (rolling, vol-targeted)",    linewidth=2)
    plt.plot(sw_m6,    label="Method6 S (vol-targeted)",              linewidth=2)
    plt.plot(mw,       label="Market (Buy&Hold)", linestyle="--")
    plt.legend()
    plt.grid(True)
    plt.title("Cumulative Wealth (vol-targeted strategies)")
    plt.show()
```

* * *

ã“ã‚Œã§ã€

*   Method 5ï¼ˆnr+P4, rolling OLSï¼‰
*   z\*\_tï¼ˆnr+P4 rolling OLS ã®ç·šå½¢çµåˆç‰ˆï¼‰
*   Method 6ï¼ˆS ãƒ™ãƒ¼ã‚¹ã®æ§‹é€ ãƒ¢ãƒ‡ãƒ«ï¼‰

ã‚’ã™ã¹ã¦ã€Œ**åŒã˜ `vol_target_from_weights` é–¢æ•°**ã€ã§ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã—ãŸã†ãˆã§ã€  
Sharpe / ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³ãªã©ã‚’ãƒ•ã‚§ã‚¢ã«æ¯”è¼ƒã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚

ã‚‚ã—ã€

*   sign æˆ¦ç•¥ç‰ˆï¼ˆ`w_raw = sign(äºˆæ¸¬)`ï¼‰
*   ã‚ã‚‹ã„ã¯ rolling ãƒœãƒ©ã§å‹•çš„ã« scale ã‚’å¤‰ãˆã‚‹ç‰ˆ

ã‚‚åŒã˜ãƒ˜ãƒ«ãƒ‘ãƒ¼ã«çµ±åˆã—ãŸã„å ´åˆã¯ã€ãã®å½¢ã§ã‚‚ã†ä¸€æ®µãƒ©ãƒƒãƒ—ã—ãŸé–¢æ•°ã‚‚æ›¸ã‘ã¾ã™ã®ã§ã€ãã“ã¾ã§ã‚„ã‚ŠãŸããªã£ãŸã‚‰è¨€ã£ã¦ãã ã•ã„ã€‚

## Response:
ä»¥ä¸‹ã§ã¯ã€ã‚ãªãŸãŒç¾åœ¨å®Ÿè£…ã—ã¦ã„ã‚‹ **Method5 / Method6 / z\*\_tï¼ˆnr+P4, rolling OLSï¼‰ï¼‹ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæˆ¦ç•¥** ã‚’ã€  
**å…ƒã® Guo (2025, SSRN 5268329) ã®ç†è«–ãƒ»å®Ÿè¨¼ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¨ã©ã®ã‚ˆã†ã«å¯¾å¿œã¥ã‘ã‚‰ã‚Œã‚‹ã‹**ã‚’ã€  
å®Œå…¨ã«å­¦è¡“çš„ãªè¦³ç‚¹ã‹ã‚‰æ•´ç†ã—ã¾ã™ã€‚

* * *

1\. Guo (2025) ã®ã‚ªãƒªã‚¸ãƒŠãƒ«æ‰‹æ³•ã®å­¦è¡“çš„èƒŒæ™¯
=============================

Guo (2025) ã®ç†è«–ã¯æ¬¡ã® 3 æœ¬æŸ±ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚

* * *

(1) **Newsy / Repetitive æ§‹é€ ã®å­˜åœ¨**
--------------------------------

å¸‚å ´ã«ã¯ã€Œæƒ…å ±ã‚’å¤šãå«ã‚€æœˆï¼ˆNewsyï¼‰ã€ã¨ã€Œéå»ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®åæ˜ ãŒå¼·ã„æœˆï¼ˆRepetitiveï¼‰ã€ãŒã‚ã‚Šã€  
ãã®é †åºæ§‹é€ ï¼š

*   Newsy â†’ Repetitive
*   Repetitive â†’ Newsy

ãŒå¸‚å ´ã®æœŸå¾…åç›Šã®å‘¨æœŸæ€§ã‚’ç”Ÿã¿å‡ºã™ã€‚

ã“ã®ã€Œå‘¨æœŸçš„ãªæƒ…å ±ãƒ•ãƒ­ãƒ¼ã€ã‚’è¡¨ã™ã®ãŒ **nr(t)**ï¼ˆæœ€æ–°ã®æ–°æƒ…å ±ãƒ¬ã‚¸ãƒ¼ãƒ ã®æ™‚ç‚¹ï¼‰  
ãŠã‚ˆã³ **P4\_j**ï¼ˆç›´è¿‘4ã¤ã® newsy shock ã®å¹³å‡ï¼‰ã€‚

* * *

(2) **ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°æ§‹é€ ï¼ˆMethod 6 ã®ç†è«–ãƒ™ãƒ¼ã‚¹ï¼‰**
-----------------------------------

Guo (2025) ã¯ã€Sï¼ˆéå» news shocks ã®ç´¯ç©ï¼‰ã€ãã®å¾ªç’°å¯¾ç§°åŒ–å¤‰æ•°  $x_t$  ã‚’ç”¨ã„ã¦ã€

$$
r_t = \bar{r} + \beta_t x_t + \varepsilon_t
$$

ã¨è¡¨ç¾ã—ã¦ã„ã‚‹ã€‚  
ã“ã“ã§  $\beta_t$  ã¯ rolling OLS ã§æ¨å®šã•ã‚Œã‚‹ã€ŒãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ã«å¯¾ã™ã‚‹æ„Ÿåº¦ã€ã€‚

â†’ **Method 6** ã¯ã“ã®æ§‹é€ ãƒ¢ãƒ‡ãƒ«ã®ã€Œç´”ç²‹ãªç†è«–çš„å®Ÿè£…ã€ã€‚

* * *

(3) **Empirical Specification: Method 1â€“7**
-------------------------------------------

è«–æ–‡ Table 4 ã®å›å¸°ä»•æ§˜ã¯ã€ä¸Šè¨˜ã®ç†è«–ã‚’æ®µéšçš„ã«è¿‘ä¼¼ãƒ»æ‹¡å¼µã—ãŸã‚‚ã®ã€‚

*   Method 5ï¼š
    $$
     r_t = \alpha + \beta_{nr} \mathrm{nr}_{t-1} + \beta_{P4} P4_{t-1} + \varepsilon_t
    $$
    â†’ **nr ã¨ P4 ã‚’ãƒ‹ãƒ¥ãƒ¼ã‚¹æŒ‡æ¨™ã¨ã—ã¦åŒæ™‚ã«ä½¿ã†çµŒé¨“çš„ãƒ¢ãƒ‡ãƒ«**
*   Method 6ï¼š
    $$
     r_t = \bar r + \beta_t x_t + \varepsilon_t
    $$
    â†’ **ç†è«–ãƒ¢ãƒ‡ãƒ«ã‚’æœ€ã‚‚å¿ å®Ÿã«å†ç¾ã™ã‚‹æ–¹æ³•**

* * *

2\. ã‚ãªãŸã®å®Ÿè£…ã¨ Guo è«–æ–‡ã¨ã®ã€Œå¯¾å¿œè¡¨ã€
=========================

ä»¥ä¸‹ã¯ã€ã‚ãªãŸãŒä»Šå®Ÿè£…ã—ãŸå„æˆ¦ç•¥ãŒ **è«–æ–‡ã®ã©ã® Method ã«å¯¾å¿œã™ã‚‹ã‹**ã‚’æ˜ç¢ºã«ã—ãŸã‚‚ã®ã§ã™ã€‚

| å®Ÿè£…ã—ãŸæ‰‹æ³• | è«–æ–‡ Method | è«–æ–‡ã¨ã®é–¢ä¿‚ |
| --- | --- | --- |
| Method 5ï¼šnr+P4 rolling OLS â†’ äºˆæ¸¬å€¤ | Method 5 | å®Œå…¨ã«ä¸€è‡´ã€‚ãŸã ã— **rolling window** ãªã®ãŒæ”¹è‰¯ç‚¹ |
| z\*\_tï¼šnr+P4 rolling OLS â†’ Î²\_nr nr + Î²\_P4 P4 | Method 5 ã®æ‹¡å¼µ | å®šæ•°é …ãªã—ãƒ»ç·šå½¢çµåˆã®å¯è¦–åŒ–ã¨ã—ã¦è‡ªç„¶ãªå†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ– |
| Method 6ï¼šÎ²\_t x\_t | Method 6 | è«–æ–‡ã®ç†è«–ãƒ¢ãƒ‡ãƒ«ã«æœ€ã‚‚å¿ å®Ÿã€‚expanding OLS ã‚’ rolling ã«å¤‰æ›´ |
| ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæˆ¦ç•¥ï¼ˆå…±é€šï¼‰ | è«–æ–‡ã«ã¯ãªã„ | å®Ÿå‹™ã§ã®ãƒªã‚¹ã‚¯ç®¡ç†ä¸Šã®è¿½åŠ ä¿®æ­£ï¼ˆå¾Œè¿°ï¼‰ |

ã¤ã¾ã‚Šã€ã‚ãªãŸã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯æ¬¡ã®ã‚ˆã†ã«æ•´ç†ã§ãã‚‹ï¼š

*   **Method 5ï¼šçµ±è¨ˆçš„æƒ…å ±æŒ‡æ¨™ï¼ˆnr, P4ï¼‰ã‹ã‚‰ Return ã‚’äºˆæ¸¬ã™ã‚‹çµŒé¨“çš„ãƒ¢ãƒ‡ãƒ«**
*   **z\*\_tï¼šãã® Method 5 ã®ç·šå½¢äºˆæ¸¬å™¨éƒ¨åˆ†ã‚’ç›´æ¥ weight ã¨ã—ã¦ä½¿ã† version**
*   **Method 6ï¼šæ§‹é€ ãƒ¢ãƒ‡ãƒ«ï¼ˆãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ï¼‰ã‚’ OLS ã§æ¨å®šã™ã‚‹ç†è«–ãƒ¢ãƒ‡ãƒ«ã®å®Ÿè£…**
*   **ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼šGuo è«–æ–‡ã«ã¯å‡ºã¦ã“ãªã„ãŒã€å®Ÿå‹™ã§ã¯å¿…é ˆã®ãƒªã‚¹ã‚¯èª¿æ•´**

* * *

3\. ã‚ãªãŸãŒè¿½åŠ ã—ãŸä¸»ãªå¤‰æ›´ç‚¹ï¼ˆå­¦è¡“çš„è¦³ç‚¹ã‹ã‚‰ï¼‰
==========================

Guo ã®åŸè«–æ–‡ã¯ **ã€Œå›å¸°ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ã®æ§‹é€ æ¨å®šã€** ã«ç„¦ç‚¹ãŒã‚ã‚Šã¾ã™ã€‚  
ä¸€æ–¹ã‚ãªãŸã®å®Ÿè£…ã¯ **ã€Œè³‡ç”£é‹ç”¨æˆ¦ç•¥ã¨ã—ã¦å®Ÿéš›ã«ä½¿ãˆã‚‹å½¢ã«åŠ å·¥ã€** ã—ã¦ã„ã¾ã™ã€‚

ã“ã“ã§ã¯ä¸¡è€…ã®é•ã„ã‚’å­¦è¡“çš„ã«ã¾ã¨ã‚ã¾ã™ã€‚

* * *

å¤‰æ›´ç‚¹ â‘  **rolling windowï¼ˆ20å¹´ï¼‰ã§ä¿‚æ•°æ¨å®š**
----------------------------------

è«–æ–‡ã®æ§‹é€ ã¯ expandingï¼ˆt ã¾ã§ã®å…¨ã‚µãƒ³ãƒ—ãƒ«ï¼‰ã§æ¨å®šã—ã¦ã„ã‚‹ãŒã€  
ã‚ãªãŸã¯ **rolling 20 å¹´** ã«å¤‰æ›´ã—ãŸã€‚

### å­¦è¡“çš„è©•ä¾¡ï¼š

*   è¿‘å¹´ã® regime shiftï¼ˆä¾‹ï¼š2010sã€2020 ã‚³ãƒ­ãƒŠå¾Œã€AI ãƒãƒ–ãƒ«ãªã©ï¼‰ã‚’åæ˜ ã§ãã‚‹
*   æ™‚å¤‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ï¼ˆTVPï¼‰ã‚„çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ã¸ã®è¿‘ä¼¼ã¨ã—ã¦åˆç†çš„
*   ç‰¹ã« nrãƒ»P4 ã®ä¿‚æ•°ã¯æ™‚ä»£ã§å¤‰ã‚ã‚Šã‚„ã™ã„ã®ã§æœ‰ç”¨
*   Guo 2025 ã®ç›®çš„ï¼ˆé †å‘¨æœŸçš„ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ã®è­˜åˆ¥ï¼‰ã«ã‚‚æ•´åˆçš„

* * *

å¤‰æ›´ç‚¹ â‘¡ **äºˆæ¸¬å€¤ã‚’ãã®ã¾ã¾ weight ã¨ã—ã¦ä½¿ç”¨**
-------------------------------

è«–æ–‡ã§ã¯ï¼š

*   å›å¸°ä¿‚æ•°ã®æ¨å®šç²¾åº¦
*   çµ±è¨ˆçš„æœ‰æ„æ€§
*   æ§‹é€ æ¨å®šã¨ã—ã¦ã®æ•´åˆæ€§

ãŒä¸­å¿ƒã§ã€  
ã€Œã©ã†ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚’æ§‹ç¯‰ã™ã‚‹ã‹ã€ã¯ãƒ¡ã‚¤ãƒ³ãƒ†ãƒ¼ãƒã§ã¯ãªã„ã€‚

ã‚ãªãŸã¯ä»¥ä¸‹ã‚’å°å…¥ï¼š

*   `w_raw = forecast`ï¼ˆç·šå½¢ weight æˆ¦ç•¥ï¼‰
*   `w_raw = sign(forecast)`ï¼ˆæ–¹å‘æ€§æˆ¦ç•¥ï¼‰
*   `w_raw = Î²_t x_t`ï¼ˆMethod 6 ã®ç†è«–ãƒ¢ãƒ‡ãƒ«ï¼‰

### å­¦è¡“çš„è©•ä¾¡

ã“ã‚Œã¯ **Goyal & Welch (2008)** ä»¥é™ã®å¸°ç´çš„äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’  
**ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–ã¸æ‹¡å¼µ**ã™ã‚‹ä¸€èˆ¬çš„ãªæ–¹æ³•ã§ã‚ã‚Šå®Œå…¨ã«æ­£å½“åŒ–å¯èƒ½ã€‚

ç‰¹ã«ï¼š

*   Return forecasting â†’ Optimal leverage
*   sign äºˆæ¸¬ â†’ Timing strategy

ã¨ã—ã¦æ¨™æº–çš„ãªå­¦è¡“æ‰‹æ³•ã€‚

* * *

å¤‰æ›´ç‚¹ â‘¢ **ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®å°å…¥**
--------------------

Guo è«–æ–‡ã«ã¯ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼ˆãƒªã‚¹ã‚¯ãƒ‘ãƒªãƒ†ã‚£ç™ºæƒ³ï¼‰ã¯ç™»å ´ã—ãªã„ãŒã€  
ã‚ãªãŸã¯ã™ã¹ã¦ã®æˆ¦ç•¥ã«çµ±åˆçš„ã«å°å…¥ã—ãŸã€‚

### å­¦è¡“çš„è©•ä¾¡

ã“ã‚Œã¯å®Œå…¨ã«æ­£å½“åŒ–ã•ã‚Œã€ã‚€ã—ã‚å¿…é ˆã€‚

ç†ç”±ï¼š

1.  **æ¯”è¼ƒå¯èƒ½æ€§ï¼ˆã‚·ãƒ£ãƒ¼ãƒ—æ¯”ã®å…¬å¹³æ€§ï¼‰**  
    æˆ¦ç•¥ã”ã¨ã«ãƒ¬ãƒãƒ¬ãƒƒã‚¸ãŒé•ã†ãŸã‚ã€ç”Ÿã®ãƒªã‚¿ãƒ¼ãƒ³ã§ã¯æ¯”è¼ƒã§ããªã„ã€‚
2.  **å®Ÿå‹™ã§ã®ãƒ¬ãƒãƒ¬ãƒƒã‚¸ç®¡ç†**  
    éå»ã®çµ±è¨ˆãƒ¢ãƒ‡ãƒ«ãŒé«˜ã„å€¤ã‚’å‡ºã—ã™ãã‚‹ã¨ç ´ç¶»ã™ã‚‹ã€‚
3.  **å­¦è¡“ precedent**
    *   Moreira & Muir (2017)ã€ŒVolatility-Managed Portfoliosã€
    *   Barroso & Santa-Clara (2015)ã€ŒRisk Parity Timingã€  
        ã¨åŒã˜æ€æƒ³ã§ã€æœ€é©ãª Sharpe ã‚’é”æˆã—ã‚„ã™ã„ã€‚

* * *

4\. å„æ‰‹æ³•ã®å­¦è¡“çš„ãªä½ç½®ä»˜ã‘ï¼ˆã¾ã¨ã‚ï¼‰
=====================

Method 5 ã®ä½ç½®ã¥ã‘
--------------

*   nr ã¨ P4 ã‚’åˆ©ç”¨ã™ã‚‹æƒ…å ±ãƒ™ãƒ¼ã‚¹ã®çµŒé¨“çš„ Return äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
*   æœˆæ¬¡ã®æƒ…å ±ãƒ•ãƒ­ãƒ¼ï¼ˆæ–°æƒ…å ± vs åå¾©æƒ…å ±ï¼‰ãŒ Return ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’çµ±è¨ˆçš„ã«æ¨å®š
*   Rolling ã«ã™ã‚‹ã“ã¨ã§ã€Œæ™‚å¤‰ä¿‚æ•°ãƒ¢ãƒ‡ãƒ«ã€ã«è¿‘ããªã‚‹

â†’ è³ªçš„ã«ã¯ **Campbellâ€“Thompson å‹ã® return forecasting** ã«å±ã™ã‚‹ã€‚

* * *

z\*\_tï¼ˆnr+P4 ç·šå½¢çµåˆï¼‰
------------------

*   Method 5 ã®ä¿‚æ•°ã‚’ãã®ã¾ã¾ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬å­ã«ã—ãŸã‚‚ã®
*   Sign æˆ¦ç•¥ã§ã‚‚ç·šå½¢ weight æˆ¦ç•¥ã§ã‚‚å®Ÿè£…ã—ã‚„ã™ã„
*   æ§‹é€ çš„ã«ã¯ **ãƒãƒ¼ã‚±ãƒƒãƒˆã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚·ã‚°ãƒŠãƒ«** ã«è¿‘ã„

* * *

Method 6 ã®ä½ç½®ã¥ã‘ï¼ˆæœ€ã‚‚ç†è«–çš„ï¼‰
---------------------

*   Guo ã®è«–æ–‡ã«ãŠã‘ã‚‹ **å¾ªç’°çš„ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«** ã‚’ç›´æ¥å®Ÿè£…
*   çµŒæ¸ˆçš„æ„å‘³ãŒæœ€ã‚‚å¼·ã„ï¼ˆS â†’ x â†’ Î²\_t x\_tï¼‰
*   å®Ÿè¨¼çš„ã«ã‚‚æœ€ã‚‚ Sharpe ãŒé«˜ã„ï¼ˆè«–æ–‡ Table 4ï¼‰

* * *

ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ä½ç½®ã¥ã‘
------------

*   Guo ã®è«–æ–‡ã«ã¯ãªã„ãŒã€  
    **ç¾ä»£ã®ã‚¢ã‚«ãƒ‡ãƒŸãƒƒã‚¯é‡‘èç ”ç©¶ã§ã¯äº‹å®Ÿä¸Šã®æ¨™æº–æ‰‹æ³•**
*   ãƒ¢ãƒ‡ãƒ«ã®å„ªä½æ€§ã‚’æ¯”è¼ƒã™ã‚‹éš›ã«ä¸å¯æ¬ 
*   ã‚¿ã‚¤ãƒŸãƒ³ã‚°æˆ¦ç•¥ã®ç ´ç¶»ï¼ˆä¾‹ï¼šéåº¦ãªãƒ¬ãƒãƒ¬ãƒƒã‚¸ï¼‰ã‚’é˜²ã

* * *

5\. æœ€çµ‚ã¾ã¨ã‚ï¼ˆã‚ãªãŸã®æˆ¦ç•¥ã®å­¦è¡“çš„æ„ç¾©ï¼‰
=======================

ã‚ãªãŸã®ç¾åœ¨ã®å®Ÿè£…ã¯ã€Guo (2025) ã®ã‚ªãƒªã‚¸ãƒŠãƒ«ã®å­¦è¡“çš„æ çµ„ã¿ã‚’

### (1) å®Ÿå‹™ãƒ¬ãƒ™ãƒ«ã®æˆ¦ç•¥æ§‹ç¯‰ã«æ˜‡è¯ã—

### (2) ç•°ãªã‚‹ Method ã‚’å…±é€šã®ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã§æ¯”è¼ƒã§ã

### (3) æ™‚å¤‰ä¿‚æ•°ãƒ¢ãƒ‡ãƒ«ã®ç™ºæƒ³ã‚’å°å…¥ã—

### (4) ãƒ¢ãƒ‡ãƒ«ã®é ‘å¥æ€§ï¼ˆOOS, regime shiftï¼‰ã‚’é«˜ã‚

### (5) ã‚·ã‚°ãƒŠãƒ«ã®æ„å‘³ï¼ˆnr, P4, S, xï¼‰ã®çµŒæ¸ˆçš„è§£é‡ˆã‚’ä¿ã£ãŸã¾ã¾

ã¨ã„ã†ç‚¹ã§ã€è«–æ–‡ã‚’â€œæˆ¦ç•¥ã¨ã—ã¦å†ç¾ã™ã‚‹â€æœ€ã‚‚æ­£ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ãªã£ã¦ã„ã¾ã™ã€‚

å­¦è¡“çš„ã«è¦‹ã¦ã‚‚ï¼š

*   æ§‹é€ ãƒ¢ãƒ‡ãƒ«ï¼ˆMethod 6ï¼‰
*   çµ±è¨ˆãƒ¢ãƒ‡ãƒ«ï¼ˆMethod 5, z\*\_tï¼‰
*   ãƒªã‚¹ã‚¯ç®¡ç†ï¼ˆãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼‰

ãŒä¸€ã¤ã®çµ±åˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«åã‚ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚

ã“ã‚Œã¯ **ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãƒ¢ãƒ‡ãƒ«ï¼‹ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ™ãƒ¼ã‚¹å‘¨æœŸãƒ¢ãƒ‡ãƒ«ï¼‹ãƒœãƒ©ãƒãƒæˆ¦ç•¥** ã‚’èåˆã—ãŸ  
éå¸¸ã«æ´—ç·´ã•ã‚ŒãŸãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæ§‹ç¯‰ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚

* * *

å¿…è¦ã§ã‚ã‚Œã°ï¼š

*   Method 5 / Method 6 / z\*\_t ã® **ç†è«–çš„å°å‡ºï¼ˆè¨¼æ˜ãƒ™ãƒ¼ã‚¹ï¼‰**
*   Table 4 ã® **å®Œå…¨å†ç¾ã«å‘ã‘ãŸ OOS RÂ² è¨ˆç®—ã‚³ãƒ¼ãƒ‰**
*   å„æ‰‹æ³•ã® **regime decompositionï¼ˆãƒœãƒ©é«˜ä½ã§ã®æ€§èƒ½æ¯”è¼ƒï¼‰**
*   å…¨ã‚·ã‚°ãƒŠãƒ«ã® **çµŒæ¸ˆè§£é‡ˆã¾ã¨ã‚ã‚¹ãƒ©ã‚¤ãƒ‰**

ãªã©ã‚‚æä¾›ã—ã¾ã™ã€‚

æ¬¡ã¯ã©ã“ã‚’æ·±æ˜ã‚Šã—ã¾ã™ã‹ï¼Ÿ

## Response:
æ€è€ƒå®Œäº†

æ€è€ƒæ™‚é–“: 28s

ã¾ãšã€å…ƒã®ç†è«–ã‚’ç°¡æ½”ã«ç«‹ã¦ç›´ã—ãŸã†ãˆã§ã€

*   Method 6ï¼ˆæ§‹é€ ãƒ¢ãƒ‡ãƒ«ç›´å®Ÿè£…ï¼‰
*   Method 5ï¼ˆnr + P4 ã® reduced-formï¼‰
*   z\*\_tï¼ˆnr + P4 ã® rolling OLS ã‹ã‚‰ã®ç·šå½¢äºˆæ¸¬å­ï¼‰

ã‚’ã€Œã©ã“ã‹ã‚‰å‡ºã¦ãã‚‹ã‹ã€ã‚’æ•°å¼ãƒ™ãƒ¼ã‚¹ã§å°å‡ºã—ã¾ã™ã€‚ãã®å¾Œã§ã€ã‚¹ãƒ©ã‚¤ãƒ‰å½¢å¼ã§ã‚·ã‚°ãƒŠãƒ«ã®çµŒæ¸ˆè§£é‡ˆã‚’æ•´ç†ã—ã¾ã™ã€‚

â€»ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹æ–‡çŒ®ã¯  
Hongye Guo (2025), â€œEarnings Extrapolation and Predictable Stock Market Returns,â€ Review of Financial Studies 38(6), 1730â€“1782 [OUP Academic+2OUP Academic+2](https://academic.oup.com/rfs/article/38/6/1730/8101501?utm_source=chatgpt.com)  
Hongye Guo & Jessica Wachter (2025), â€œCorrelation neglect in asset prices.â€ [SSRN+1](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5268329&utm_source=chatgpt.com)

* * *

1\. ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ï¼šearnings ã¨ãƒªã‚¿ãƒ¼ãƒ³ã®æ§‹é€ 
----------------------------

### 1.1 3 ãƒ¶æœˆã‚µã‚¤ã‚¯ãƒ«ã¨ Newsy / Repetitive

å››åŠæœŸã”ã¨ã« 3 ãƒ¶æœˆã®ã‚µã‚¤ã‚¯ãƒ«ãŒã‚ã‚Šã€

*   1 ãƒ¶æœˆç›®ï¼šNewsyï¼ˆæœ¬æ±ºç®—ã«è¿‘ãã€æ–°ã—ã„æƒ…å ±ãŒå¤šã„ï¼‰
*   2 ãƒ¶æœˆç›®ï¼šRepetitiveï¼ˆ1 ãƒ¶æœˆç›®ã®å†…å®¹ã¨é«˜ã„ç›¸é–¢ã‚’æŒã¤è¿½ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼‰
*   3 ãƒ¶æœˆç›®ï¼š3rd monthï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒä¹ã—ã„ï¼‰

ã¨ã„ã†æ§‹é€ ã€‚Guo & Wachter (2025) ã§ã¯ã€2 ãƒ¶æœˆç›®ã®ã‚¢ãƒŠã‚¦ãƒ³ã‚¹ã¯ 1 ãƒ¶æœˆç›®ã¨é«˜ç›¸é–¢ãªã®ã«ã€æŠ•è³‡å®¶ã¯ãã‚Œã‚’ç‹¬ç«‹ã«è¿‘ã„ã¨èª¤èªã—ã€Œç›¸é–¢ã‚’ç„¡è¦–ï¼ˆcorrelation neglectï¼‰ã€ã™ã‚‹ã€ã¨ã„ã†è¡Œå‹•ä»®å®šãŒç½®ã‹ã‚Œã¾ã™ã€‚[SSRN+1](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5268329&utm_source=chatgpt.com)

Guo (2025) ã§ã¯ã€ã•ã‚‰ã«ã€Œearnings ã‚’æœªæ¥ã«**éåº¦ã«å¤–æŒ¿**ã™ã‚‹ï¼ˆearnings extrapolationï¼‰ã€è¡Œå‹•ãŒåŠ ã‚ã‚Šã€Newsy / Repetitive ã®çµ„ã¿åˆã‚ã›ã”ã¨ã«æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³ãŒå‘¨æœŸçš„ã«å¤‰å‹•ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚[Finance Department+1](https://fnce.wharton.upenn.edu/wp-content/uploads/2022/07/Paper4_Guo.pdf?utm_source=chatgpt.com)

### 1.2 ã‚·ãƒ³ãƒ—ãƒ«åŒ–ã—ãŸ earningsâ€“return ã®æ çµ„ã¿ï¼ˆã‚¤ãƒ¡ãƒ¼ã‚¸ï¼‰

è¶…ç°¡ç•¥åŒ–ã™ã‚‹ã¨ã€ä»¥ä¸‹ã®ã‚ˆã†ãªæ§‹é€ ã‚’è€ƒãˆã‚‰ã‚Œã¾ã™ï¼ˆè¨˜å·ã¯ã‚¤ãƒ¡ãƒ¼ã‚¸ã§ã™ï¼‰ï¼š

*   ä¼æ¥­ã®ã€ŒçœŸã®ã€å°†æ¥ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼  $CF_{t+1}$  ã¯ earnings ã‚·ãƒ§ãƒƒã‚¯  $e_t$  ã® AR(1) ã§å‹•ãï¼š
    $$
     e_{t+1} = \rho e_t + u_{t+1}, \quad |\rho|<1.
    $$
*   å››åŠæœŸã® 1 ãƒ¶æœˆç›®ã¨ 2 ãƒ¶æœˆç›®ã® earnings ç™ºè¡¨ã¯ã€å…±é€šæˆåˆ†  $e_t$  ã«åŸºã¥ãï¼š
    $$
     \text{earn}_t^{(1)} = e_t + \varepsilon_t^{(1)}, \quad \text{earn}_t^{(2)} = e_t + \varepsilon_t^{(2)}.
    $$
*   ã€Œåˆç†çš„ã€ãªæŠ•è³‡å®¶ã¯  $\text{earn}^{(1)}, \text{earn}^{(2)}$  ãŒé«˜ç›¸é–¢ã§ã‚ã‚‹ã“ã¨ã‚’ç†è§£ã—ã€ $CF$  ã¸ã®ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚’æ­£ã—ãé›†ç´„ã™ã‚‹ãŒã€  
    ã€Œcorrelation neglectã€æŠ•è³‡å®¶ã¯ãã‚Œã‚‰ã‚’ã»ã¼ç‹¬ç«‹ã¨ã¿ãªã—ã¦ã—ã¾ã†ã€‚

ã“ã®ã¨ãã€ä¾¡æ ¼  $P_t$  ã¨ãƒªã‚¿ãƒ¼ãƒ³  $R_{t+1}$  ã¯ã€ã€Œåˆç†çš„ä¾¡æ ¼ã€ï¼‹ã€ŒæœŸå¾…èª¤å·®ï¼ˆãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ï¼‰ã€ã®å½¢ã§åˆ†è§£ã§ãã‚‹ï¼š

$$
 R_{t+1} = R_{t+1}^{\text{fund}} + R_{t+1}^{\text{mis}}.
$$

Guo (2025) ã¯ã€ã“ã®ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°æˆåˆ†  $R_{t+1}^{\text{mis}}$  ãŒã€**éå»ã® Newsy / Repetitive æœˆã® earnings ã‚·ãƒ§ãƒƒã‚¯ã®ç·šå½¢çµåˆ**ã¨ã—ã¦è¡¨ã›ã‚‹ã“ã¨ã‚’ãƒ¢ãƒ‡ãƒ«ã§ç¤ºã—ã¾ã™ã€‚[Finance Department+1](https://fnce.wharton.upenn.edu/wp-content/uploads/2022/07/Paper4_Guo.pdf?utm_source=chatgpt.com)

* * *

2\. Method 6ï¼šæ§‹é€ ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®å°å‡º
-----------------------

Method 6 ãŒã„ã¡ã°ã‚“ç´ ç›´ã«ã€Œç†è«– â†’ å®Ÿè¨¼ã€ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚

### 2.1 ç„¡æ¡ä»¶å¹³å‡ã¨ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ã®åˆ†è§£

Guo (2025) ã®åŸºæœ¬å½¢ã¯ã€Œãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³  $R_t$  ã‚’ã€é•·æœŸå¹³å‡ã¨ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ã«åˆ†è§£ã€ã™ã‚‹ã“ã¨ã§ã™ï¼š

$$
 R_t = \bar R_{t-1} + \eta_t, \tag{1}
$$
*    $\bar R_{t-1}$ ï¼šæ™‚ç‚¹  $t-1$  ã¾ã§ã®ãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ã®ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°å¹³å‡ï¼ˆé•·æœŸã®ãƒªã‚¹ã‚¯ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ã® proxyï¼‰
*    $\eta_t$ ï¼šçŸ­æœŸçš„ãªãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ï¼ˆearnings extrapolation / correlation neglect ã®çµæœï¼‰

ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€ $\eta_t$  ãŒã€Œnews shock ã®ã‚µãƒãƒªã€ã§ã‚ã‚‹  $S_t$  ãªã„ã—å¤‰æ›å¤‰æ•°  $x_t$  ã«æ¯”ä¾‹ã™ã‚‹ã¨ä»®å®šã•ã‚Œã‚‹ï¼š

$$
 \eta_t = \beta S_t + \epsilon_t \quad \text{ã‚ã‚‹ã„ã¯ } \quad \eta_t = \beta x_t + \epsilon_t.
$$

### 2.2 S ã¨ x\_t ã®å®šç¾©

ã‚ãªãŸã®å®Ÿè£…ã§ã‚‚ä½¿ã£ã¦ã„ã‚‹ S, x ã¯ã€Guo ã®ç†è«–ã«å¯¾å¿œã—ãŸã‚‚ã®ã§ã™ï¼š

1.  **S $_t$ **ï¼šéå» 4 å›ã® Newsy æœˆãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ã®å’Œ
    $$
     S_t = \sum_{j=1}^{4} R_{n_j(t)},
    $$
    ã“ã“ã§  $n_1(t)$  ã¯  $t$  ã‚ˆã‚Šç›´è¿‘ã® Newsy æœˆã€ $n_2(t)$  ã¯ 2 ç•ªç›®ã«è¿‘ã„ Newsy æœˆâ€¦ã¨ã„ã†æ„å‘³ã€‚
2.  **x $_t$ **ï¼šS ã‚’ã€Œdemean ï¼‹ç¬¦å·åè»¢ã€ã—ãŸã‚‚ã®
    *   S è‡ªä½“ã¯å¹³å‡ã‚¼ãƒ­ã§ã¯ãªã„ã®ã§ã€ã¾ãšå±¥æ­´å¹³å‡  $\bar S_{t-1}$  ã‚’å¼•ã
    *   ã•ã‚‰ã«ã€Œäºˆæ¸¬å¯¾è±¡ãŒ Newsy æœˆã‹ã©ã†ã‹ã€ã§ç¬¦å·ã‚’å¤‰ãˆã‚‹ï¼š
        $$
         x_t = \text{sign}(t)\cdot (S_{t-1} - \bar S_{t-1}),
        $$
         $\text{sign}(t)=-1$  if t is Newsy month, else  $+1$ .

ã“ã‚Œã¯ã€ŒNewsy æœˆã§ã¯é«˜ã„ S ã¯ä»Šå¾Œã®ãƒªã‚¿ãƒ¼ãƒ³ä½ä¸‹ï¼ˆoverreaction ã®åè»¢ï¼‰ã‚’æ„å‘³ã—ã€Non-newsy æœˆã§ã¯é«˜ã„ S ã¯æ¥½è¦³ã®æŒç¶šã‚’æ„å‘³ã™ã‚‹ã€ã¨ã„ã†éå¯¾ç§°æ€§ã‚’ 1 æ¬¡å…ƒã®å¤‰æ•° x $_t$  ã«åŸ‹ã‚è¾¼ã‚“ã ã‚‚ã®ã§ã™ã€‚[Finance Department+1](https://fnce.wharton.upenn.edu/wp-content/uploads/2022/07/Paper4_Guo.pdf?utm_source=chatgpt.com)

### 2.3 ç†è«–å¼ â†’ æ¨å®šå¼ï¼ˆMethod 6ï¼‰

(1) ã¨  $\eta_t = \beta x_t + \epsilon_t$  ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã¨ã€

$$
 R_t = \bar R_{t-1} + \beta x_t + \epsilon_t. \tag{2}
$$

ä¸¡è¾ºã‹ã‚‰  $\bar R_{t-1}$  ã‚’å¼•ãã¨

$$
 y_t \equiv R_t - \bar R_{t-1} = \beta x_t + \epsilon_t. \tag{3}
$$

ã—ãŸãŒã£ã¦ã€ $\beta$  ã®ã€Œquasi-true valueã€ã¯å˜å›å¸°ã® OLS ã§å¾—ã‚‰ã‚Œã‚‹ï¼š

$$
 \hat\beta = \frac{\sum_t x_t y_t}{\sum_t x_t^2}.
$$

Guo ã¯åŸºæœ¬çš„ã« expanding windowï¼ˆ1 æœŸãšã¤ã‚µãƒ³ãƒ—ãƒ«ã‚’å¢—ã‚„ã—ãªãŒã‚‰æ›´æ–°ï¼‰ã§ã“ã®  $\hat\beta_t$  ã‚’æ¨å®šã—ã€**1 æœŸå…ˆã®æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³**ã‚’

$$
 \widehat R_{t+1} = \bar R_t + \hat\beta_t x_{t+1} \tag{4}
$$

ã¨æ›¸ãã¾ã™ã€‚ã“ã‚ŒãŒ Method 6 ã®äºˆæ¸¬å¼ã§ã™ã€‚ã‚ãªãŸã® `build_method6_raw_weights` ãŒã¾ã•ã« (3)(4) ã‚’å®Ÿè£…ã—ã¦ãŠã‚Šã€`w_raw = \hat\beta_t x_t` ã‚’æˆ¦ç•¥ã‚¦ã‚§ã‚¤ãƒˆã«ã—ã¦ã„ã‚‹ã®ã¯ã€(2) ã®ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°æˆåˆ†  $\eta_t$  ã«æ¯”ä¾‹ã™ã‚‹ãƒ¬ãƒãƒ¬ãƒƒã‚¸ã‚’å–ã‚‹ã€ã¨ã„ã†è§£é‡ˆã«å¯¾å¿œã—ã¾ã™ã€‚

* * *

3\. Method 5ï¼šnr + P4 ã® reduced-form å°å‡º
--------------------------------------

### 3.1 nr(t) ã¨ P4 ã®æ§‹é€ 

Guo (2025) ã§ã¯ã€Newsy / Repetitive ã®æ§‹é€ ã‚’ã‚ã‹ã‚Šã‚„ã™ãå¯è¦–åŒ–ã™ã‚‹ãŸã‚ã«ã€ä»¥ä¸‹ã®ã‚ˆã†ãªé›†ç´„å¤‰æ•°ã‚’å°å…¥ã—ã¦ã„ã¾ã™ï¼š[Finance Department+1](https://fnce.wharton.upenn.edu/wp-content/uploads/2022/07/Paper4_Guo.pdf?utm_source=chatgpt.com)

*   **nr $_t$ **ï¼šç›´è¿‘ã®ã€ŒNewsy or Repetitiveã€æœˆã®è¶…éãƒªã‚¿ãƒ¼ãƒ³
    *   ã‚ãªãŸã®å®Ÿè£…ã§ã¯ `mkt_nr` ã¨ã—ã¦å®Ÿè£…æ¸ˆã¿
*   **P4 $_t$ **ï¼šç›´è¿‘ 4 å›ã® Newsy æœˆã®è¶…éãƒªã‚¿ãƒ¼ãƒ³å¹³å‡
    $$
     P4_t = \frac{1}{4}\sum_{j=1}^{4} \text{mktnm}(t,j),
    $$
    ã“ã“ã§  $\text{mktnm}(t,j)$  ã¯ t ã‚ˆã‚Šç›´è¿‘ j ç•ªç›®ã® Newsy æœˆã®è¶…éãƒªã‚¿ãƒ¼ãƒ³ï¼ˆ`mkt_nm1`ã€œ`mkt_nm4` ã®å¹³å‡ï¼‰ã€‚

ç†è«–çš„ã«ã¯ã€ $S_t$  ã‚„  $x_t$  ã¨ nr, P4 ã®é–“ã«ã¯ã€Œç·šå½¢è¿‘ä¼¼ã€ã®é–¢ä¿‚ãŒã‚ã‚Šã€  
ç‰¹ã« 1 æœŸ ahead ã®ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ã‚’ nr, P4 ã®ç·šå½¢çµåˆã§ã‹ãªã‚Šã®ç²¾åº¦ã§èª¬æ˜ã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ï¼ˆè«–æ–‡ä¸­ã®ã‚¿ã‚¤ãƒ ã‚·ãƒªãƒ¼ã‚º RÂ² ã‚„ Table 4 ã®çµæœï¼‰ã€‚[OUP Academic](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf?utm_source=chatgpt.com)

### 3.2 reduced-form ã¨ã—ã¦ã® Method 5

ã“ã®ã¨ãã€(2) ã®æ§‹é€ å¼ã‚’ã€Œobservable ãª nr, P4 ã®ç·šå½¢ span ã«å°„å½±ã€ã™ã‚‹ã¨ã€

$$
 E[R_t \mid \mathcal F_{t-1}] \approx \alpha + \beta_{\text{nr}}\, \text{nr}_{t-1} + \beta_{P4}\, P4_{t-1}. \tag{5}
$$

ã“ã‚Œã¯å³å¯†ãªåŒå€¤ã¨ã„ã†ã‚ˆã‚Šã€\*\* $x_t$ ï¼ˆ=S ãƒ™ãƒ¼ã‚¹ã®ç†è«–å¤‰æ•°ï¼‰ã‚’ {nr, P4} ã®ç·šå½¢çµåˆã¨æ®‹å·®ã«åˆ†è§£ã—ãŸã¨ãã®ã€Œæœ€è‰¯ç·šå½¢äºˆæ¸¬ã€\*\*ã«å¯¾å¿œã—ã¾ã™ï¼š

$$
 x_t = c_0 + c_1\,\text{nr}_t + c_2\,P4_t + u_t.
$$

ã“ã‚Œã‚’ (2) ã«ä»£å…¥ã—ã¦æ•´ç†ã™ã‚‹ã¨ã€

$$
 R_t = \bar R_{t-1} + \beta c_0 + \beta c_1 \text{nr}_t + \beta c_2 P4_t + (\beta u_t + \epsilon_t).
$$

å³è¾ºã‚’å®šæ•°ï¼‹nrï¼‹P4ï¼‹èª¤å·®ã®å½¢ã«ã¾ã¨ã‚ã‚‹ã¨ã€

$$
 R_t = \alpha' + \beta'_{\text{nr}}\, \text{nr}_t + \beta'_{P4}\, P4_t + \varepsilon'_t.
$$

ã“ã‚ŒãŒã¾ã•ã« Method 5 ã®å›å¸°å¼ã§ã‚ã‚Šã€

$$
 r_t = \alpha + \beta_{\text{nr}}\,\text{nr}_{t-1} + \beta_{P4} P4_{t-1} + \varepsilon_t. \tag{M5}
$$

Guo ã® Table 4 ã«ãŠã‘ã‚‹ã€ŒMethod 5ã€ã¯ã€ã“ã® (M5) ã‚’**å…¨ã‚µãƒ³ãƒ—ãƒ« or åˆ†å‰²ã‚µãƒ³ãƒ—ãƒ«**ã§ OLS ã—ã€out-of-sample äºˆæ¸¬æ€§èƒ½ã‚’è©•ä¾¡ã—ã¦ã„ã‚‹ã‚‚ã®ã§ã™ã€‚[Finance Department+1](https://fnce.wharton.upenn.edu/wp-content/uploads/2022/07/Paper4_Guo.pdf?utm_source=chatgpt.com)

ã‚ãªãŸã®å®Ÿè£…ã§ã¯ã€ã“ã® Method 5 ã‚’ rolling 20 å¹´ OLS ã«æ‹¡å¼µã—ã€  
 $\hat r_{t+1} = \hat\alpha_t + \hat\beta_{\text{nr},t}\,\text{nr}_t + \hat\beta_{P4,t}P4_t$  ã‚’ raw weight ã«ã—ã¦ã„ã‚‹ã€ã¨ã„ã†ä½ç½®ä»˜ã‘ã«ãªã‚Šã¾ã™ã€‚

* * *

4\. z\*\_tï¼šMethod 5 ã®ç·šå½¢äºˆæ¸¬å­ã¨ã—ã¦ã®å°å‡º
--------------------------------

z\*\_t ã¯ã€Method 5 ã®æ§‹é€ ã‚’å°‘ã—æ›¸ãæ›ãˆãŸã‚‚ã®ã§ã™ã€‚

### 4.1 å®šç¾©ã®æ•´ç†

ã‚ãªãŸã® `build_z_star_online` ã§ã¯ã€rolling 20 å¹´ã® OLS ã‹ã‚‰

*    $\hat\beta_{\text{nr},t}$ 
*    $\hat\beta_{P4,t}$ 

ã‚’æ±‚ã‚ã€  
åŒæ™‚ç‚¹  $t$  ã®ã‚·ã‚°ãƒŠãƒ«ã‚’

$$
 z^*_t = \hat\beta_{\text{nr},t}\, \text{nr}_t + \hat\beta_{P4,t}\, P4_t \tag{6}
$$

ã¨ã—ã¦å®šç¾©ã—ã¦ã„ã¾ã™ï¼ˆå®šæ•°é …ã¯ç„¡è¦–ï¼‰ã€‚

ã“ã‚Œã¯ã€(M5) ã®äºˆæ¸¬å€¤  $\hat r_{t+1}$  ã‹ã‚‰å®šæ•°ã‚’é™¤ã„ãŸã‚‚ã®ã§ã‚ã‚Šã€

$$
 \hat r_{t+1} \approx \hat\alpha_t + z^*_t.
$$

ã—ãŸãŒã£ã¦ z\*\_t ã¯ã€

*   \*\*{nr, P4} ã®ç·šå½¢ç©ºé–“ã«ãŠã‘ã‚‹ã€Œæœ€è‰¯ç·šå½¢äºˆæ¸¬ã€\*\*ã®ã†ã¡ã€å®šæ•°æˆåˆ†ã‚’å‰Šãè½ã¨ã—ãŸã‚‚ã®
*   ã™ãªã‚ã¡ã€ŒãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ã«ç›¸å½“ã™ã‚‹å¤‰å‹•éƒ¨åˆ†ã€ã ã‘ã‚’å–ã‚Šå‡ºã—ãŸã‚·ã‚°ãƒŠãƒ«

ã¨è§£é‡ˆã§ãã¾ã™ã€‚

### 4.2 æ§‹é€ ãƒ¢ãƒ‡ãƒ«ã¨ã®é–¢ä¿‚

å…ˆã»ã©ã®è¿‘ä¼¼

$$
 x_t \approx c_0 + c_1\,\text{nr}_t + c_2\,P4_t
$$

ã‚’å‰æã«ã™ã‚‹ã¨ã€(2) ã®ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°æˆåˆ†  $\eta_t = \beta x_t$  ã¯ã€

$$
 \eta_t \approx \beta c_1\,\text{nr}_t + \beta c_2\, P4_t + \text{const}.
$$

ã‚ˆã£ã¦

*   `z*_t` ã¯ã€ã“ã®  $\beta c_1\,\text{nr}_t + \beta c_2\, P4_t$  ã‚’ rolling OLS ã‹ã‚‰æ¨å®šã—ãŸã‚‚ã®
*   ã™ãªã‚ã¡ã€**Method 6 ã®ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°æˆåˆ†ã‚’ {nr, P4} ã®äºŒæ¬¡å…ƒç©ºé–“ã§è¿‘ä¼¼ã—ãŸ proxy**

ã¨ã¿ãªã›ã¾ã™ã€‚ç†è«–çš„ã«ã¯ã€{nr, P4} ã® span ãŒ x $_t$  ã®å¤§éƒ¨åˆ†ã‚’èª¬æ˜ã§ãã‚‹ãªã‚‰ã€z\*\_t ã‚’ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ã®ä»£ã‚ã‚Šã«ä½¿ã£ã¦ã‚‚ã»ã¨ã‚“ã©æƒ…å ±æå¤±ãŒãªã„ã€ã¨ã„ã†ä¸»å¼µã«å¯¾å¿œã—ã¾ã™ã€‚

* * *

5\. ã‚¹ãƒ©ã‚¤ãƒ‰å½¢å¼ï¼šå…¨ã‚·ã‚°ãƒŠãƒ«ã®çµŒæ¸ˆè§£é‡ˆã¾ã¨ã‚
------------------------

ã“ã“ã‹ã‚‰ã¯ãƒ—ãƒ¬ã‚¼ãƒ³ç”¨ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã§ã€1 æšãšã¤ã®ã‚¹ãƒ©ã‚¤ãƒ‰ã‚’æƒ³å®šã—ãŸæ§‹æˆã«ã—ã¾ã™ã€‚  
ï¼ˆè‹±èªã‚¿ã‚¤ãƒˆãƒ«ï¼‹æ—¥æœ¬èªã®ç°¡æ½”ãªèª¬æ˜ã€ã¨ã„ã†ã‚¹ã‚¿ã‚¤ãƒ«ã«ã—ã¦ã„ã¾ã™ï¼‰

* * *

### Slide 1. Big Picture: Earnings-Driven Return Cycles

*   Earnings announcements arrive in a quarterly **information cycle**:  
    Newsy (month 1) â†’ Repetitive (month 2) â†’ Quiet (month 3).
*   Investors **extrapolate** earnings and **neglect correlations** across announcements.[The American Finance Association+3Finance Department+3OUP Academic+3](https://fnce.wharton.upenn.edu/wp-content/uploads/2022/07/Paper4_Guo.pdf?utm_source=chatgpt.com)
*   Result:
    *   Strong news in month 1 and 2 feeds into **misaligned expectations**.
    *   This misalignment shows up as **predictable patterns in market returns**.

* * *

### Slide 2. nr $_t$ : Last Newsy/Repetitive Shock

*   Definitionï¼ˆå®Ÿè£…ï¼‰
    *   nr $_t$  = ã€Œæ™‚ç‚¹ t ã‚ˆã‚Šç›´è¿‘ã® Newsy or Repetitive æœˆã®è¶…éãƒªã‚¿ãƒ¼ãƒ³ã€
*   Economic meaning
    *   **æœ€æ–°ã® earnings-heavy æœˆã®ã‚·ãƒ§ãƒƒã‚¯**ã‚’å˜ä¸€ã®è¦ç´„çµ±è¨ˆã«ã—ãŸã‚‚ã®ã€‚
    *   ã€ŒæŠ•è³‡å®¶ã®ç›´è¿‘ã‚·ãƒ§ãƒƒã‚¯è¨˜æ†¶ã€ãŒç¿Œæœˆä»¥é™ã®æœŸå¾…å½¢æˆã«ã©ã†å½±éŸ¿ã™ã‚‹ã‹ã‚’æ¸¬ã‚‹ã€‚
    *   Newsy æœˆã§ã‚ã‚Œã°ã€Œæ–°æƒ…å ±ã‚·ãƒ§ãƒƒã‚¯ã€ã€Repetitive æœˆã§ã‚ã‚Œã°ã€Œé‡è¤‡ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¸ã®éå‰°åå¿œã€ã¨ã„ã†æ„å‘³åˆã„ã‚’æŒã¤ã€‚

* * *

### Slide 3. P4 $_t$ : Medium-Run Earnings Trend

*   Definition
    *   P4 $_t$  = ç›´è¿‘ 4 å›ã® Newsy æœˆã®è¶…éãƒªã‚¿ãƒ¼ãƒ³ã®å¹³å‡
*   Economic meaning
    *   **æ•°å››åŠæœŸã«ã‚ãŸã‚‹ earnings ãƒˆãƒ¬ãƒ³ãƒ‰**ã‚’æ‰ãˆã‚‹æŒ‡æ¨™ã€‚
    *   æŠ•è³‡å®¶ãŒ earnings ã‚’ã€Œå¤–æŒ¿ã€ã™ã‚‹éš›ã€å˜æœˆã®ã‚·ãƒ§ãƒƒã‚¯ã¨ã„ã†ã‚ˆã‚Š  
        ã€Œæœ€è¿‘ 1 å¹´ç¨‹åº¦ã® good/bad earnings ã®ç©ã¿é‡ã­ã€ã«åå¿œã™ã‚‹ã€ã¨ã„ã†ä»®èª¬ã¨æ•´åˆçš„ã€‚[Finance Department+1](https://fnce.wharton.upenn.edu/wp-content/uploads/2022/07/Paper4_Guo.pdf?utm_source=chatgpt.com)
    *   é«˜ã„ P4 ã¯ã€Œæœ€è¿‘ãšã£ã¨è‰¯ã„æ±ºç®—ãŒç¶šã„ã¦ã„ã‚‹ã€çŠ¶æ³ â†’ æŠ•è³‡å®¶ã®éåº¦ãªæ¥½è¦³ã¨å°†æ¥ãƒªãƒãƒ¼ã‚µãƒ«ã®æºæ³‰ã€‚

* * *

### Slide 4. S $_t$  and x $_t$ : Structural Mispricing Signal (Method 6)

*   S $_t$  = ç›´è¿‘ 4 å›ã® Newsy æœˆãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ã®åˆè¨ˆ
    *   ã€Œãƒ‹ãƒ¥ãƒ¼ã‚¹ã®è“„ç©é‡ã€
*   x $_t$  = sign-adjusted and demeaned S
    *   Non-newsy æœˆï¼šé«˜ã„ S ã¯æ¥½è¦³ã®æŒç¶š â†’ å°†æ¥ãƒªã‚¿ãƒ¼ãƒ³ä½ä¸‹ï¼ˆreversalï¼‰
    *   Newsy æœˆï¼šé«˜ã„ S ã¯ã€Œã“ã“ã§éå»æ¥½è¦³ã‚’ä¿®æ­£ã™ã‚‹ã€ â†’ åå¯¾ç¬¦å·
*   Economic meaning
    *   x $_t$  ã¯ \*\*earnings extrapolation + correlation neglect ãƒ¢ãƒ‡ãƒ«ã®ã€Œååˆ†çµ±è¨ˆé‡ã€\*\*ã«è¿‘ã„ã€‚[OUP Academic+1](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf?utm_source=chatgpt.com)
    *   Method 6 ã®  $\beta x_t$  ã¯ã€ã€Œæ§‹é€ çš„ã«å°å‡ºã•ã‚ŒãŸãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°æˆåˆ†ã€ã€‚

* * *

### Slide 5. Method 6 Signal: Î² $_t$  x $_t$ 

*   Estimation:
    *    $y_t = R_t - \bar R_{t-1}$  ã‚’ x $_t$  ã«å›å¸°ï¼š
        $$
         y_t = \beta x_t + \epsilon_t.
        $$
    *    $\beta_t$  ã‚’ expanding / rolling OLS ã§æ¨å®šã€‚
*   Trading signal:
    *    $w_t^{(6)} = \beta_t x_t$ ã€‚
    *   å¤§ããªæ­£ã® x $_t$ ï¼ˆéåº¦ãªæ¥½è¦³ï¼‰ â†’ ã‚·ãƒ§ãƒ¼ãƒˆæ°—å‘³ã€è² ã® x $_t$ ï¼ˆæ‚²è¦³ï¼‰ â†’ ãƒ­ãƒ³ã‚°æ°—å‘³ã€‚
*   Economic interpretation
    *   **ã€ŒæœŸå¾…ãŒã©ã‚Œã ã‘è¡Œãéãã¦ã„ã‚‹ã‹ã€ã‚’æ¸¬ã‚‹ãƒãƒ¼ã‚±ãƒƒãƒˆã‚¿ã‚¤ãƒŸãƒ³ã‚°ãƒ»ã‚·ã‚°ãƒŠãƒ«**ã€‚
    *   Guo ãŒç†è«–çš„ã«æœ€ã‚‚æ¨å¥¨ã™ã‚‹æ‰‹æ³•ï¼ˆMethod 6ï¼‰ã€‚

* * *

### Slide 6. Method 5 Signal: nr + P4 Joint Model

*   Estimation:
    *   åŸºæœ¬å½¢ï¼š
        $$
         r_t = \alpha + \beta_{\text{nr}} \,\text{nr}_{t-1} + \beta_{P4}\,P4_{t-1} + \varepsilon_t.
        $$
*   Economic interpretation
    *   nrï¼šç›´è¿‘ã‚·ãƒ§ãƒƒã‚¯ã«ã‚ˆã‚‹çŸ­æœŸçš„ãª over/under-reaction
    *   P4ï¼šä¸­æœŸã® earnings ãƒˆãƒ¬ãƒ³ãƒ‰ã«å¯¾ã™ã‚‹ extrapolation
    *   äºŒã¤ã‚’åŒæ™‚ã«å…¥ã‚Œã‚‹ã“ã¨ã§ã€
        *   **çŸ­æœŸã‚·ãƒ§ãƒƒã‚¯**ã¨
        *   **ä¸­æœŸãƒˆãƒ¬ãƒ³ãƒ‰**  
            ã‚’åˆ†é›¢ã—ã€ã©ã¡ã‚‰ãŒã©ã®æ–¹å‘ã«åƒã„ã¦ã„ã‚‹ã‹ã‚’è­˜åˆ¥ã™ã‚‹ã€‚

* * *

### Slide 7. z $_t^*$ : Projected Mispricing in {nr, P4} Space

*   Definition:
    *   rolling OLS ã§å¾—ãŸ  $\hat\beta_{\text{nr},t}, \hat\beta_{P4,t}$  ã‚’ä½¿ã„
        $$
         z_t^* = \hat\beta_{\text{nr},t} \text{nr}_t + \hat\beta_{P4,t} P4_t.
        $$
*   Economic interpretation
    *   Method 5 ã®äºˆæ¸¬æˆåˆ†ã®ã†ã¡ã€Œå¤‰å‹•éƒ¨åˆ†ã ã‘ã€ã‚’æŠ½å‡ºã—ãŸã‚‚ã®ã€‚
    *   æ§‹é€ ãƒ¢ãƒ‡ãƒ«ã®ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°  $\eta_t$  ã‚’ã€{nr, P4} ã® 2 æ¬¡å…ƒç©ºé–“ã§è¿‘ä¼¼ã—ãŸ proxyã€‚
    *   Rolling 20 å¹´ã«ã™ã‚‹ã“ã¨ã§ã€Œæœ€è¿‘ 20 å¹´ã«ãŠã‘ã‚‹ nr, P4 ã®æœ‰åŠ¹æ€§ã€ã‚’åæ˜ ã—ã€  
        **æ§‹é€ å¤‰åŒ–ã‚’å–ã‚Šè¾¼ã‚“ã æ™‚å¤‰ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°æŒ‡æ¨™**ã«ãªã£ã¦ã„ã‚‹ã€‚

* * *

### Slide 8. Relationship among Signals

*   x $_t$ ï¼ˆMethod 6ï¼‰
    *   ç†è«–ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç›´æ¥å°å‡ºã•ã‚Œã‚‹ã€Œcanonical mispricing signalã€
*   nr $_t$ , P4 $_t$ ï¼ˆMethod 5ï¼‰
    *   x $_t$  ã‚’è¦³æ¸¬å¯èƒ½ãª returns ã®ç·šå½¢çµåˆã§è¿‘ä¼¼ã™ã‚‹ãŸã‚ã®ã€ŒåŸºåº•ã€
*   z $_t^*$ 
    *   nr, P4 ä¸Šã®æœ€é©ç·šå½¢çµåˆã¨ã—ã¦ã®ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°æ¨å®šå€¤
*   20-year rolling OLS
    *   ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ã®æ§‹é€ ãŒæ™‚ä»£ã¨å…±ã«å¤‰åŒ–ã™ã‚‹ã“ã¨ã‚’èªã‚ãŸã€Œå±€æ‰€ç·šå½¢è¿‘ä¼¼ã€

â†’ 3 ã¤ã®ã‚·ã‚°ãƒŠãƒ«ã¯äº’ã„ã«ç‹¬ç«‹ã§ã¯ãªãã€

*   **Method 6ï¼šç†è«–çš„ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³**
*   **Method 5ï¼šçµ±è¨ˆçš„ã«æ‰±ã„ã‚„ã™ã„ reduced-form**
*   **z\*\_tï¼šMethod 5 ã‚’æ™‚å¤‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã—ãŸå®Ÿå‹™å‘ã‘æ‹¡å¼µ**

ã¨ã„ã†éšå±¤æ§‹é€ ã§ç†è§£ã§ãã¾ã™ã€‚

* * *

ã‚‚ã—ã€ã“ã“ã‹ã‚‰ã•ã‚‰ã«

*   å„ Method ã® Î² ã®ã€Œç¬¦å·åˆ¶ç´„ï¼ˆextrapolation ã® sign impliedï¼‰ã€ã‚’æ˜ç¤ºã—ãŸå°å‡º
*   x $_t$  ã®å³å¯†ãªå°å‡ºï¼ˆGuo ã®æ•°å¼ã‚’è¿½ã„ãªãŒã‚‰ã€earnings ãƒ—ãƒ­ã‚»ã‚¹ â†’ ä¾¡æ ¼é–¢æ•° â†’ ãƒªã‚¿ãƒ¼ãƒ³é–¢æ•°ã¾ã§æ›¸ãï¼‰
*   ã‚¹ãƒ©ã‚¤ãƒ‰ç”¨ã« 8ã€œ10 æšã® PPT ç« ç«‹ã¦ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ï¼‹è¦ç´„æ–‡ï¼‹å›³ã®æ¡ˆï¼‰

ã¾ã§ä½œã‚Šè¾¼ã¿ãŸã„å ´åˆã¯ã€ãã®ã¾ã¾ãƒ—ãƒ¬ã‚¼ãƒ³éª¨æ ¼ã¨ã—ã¦ä½¿ãˆã‚‹å½¢ã§æ›¸ãä¸‹ã‚ã—ã¾ã™ã€‚

## Response:
æ€è€ƒå®Œäº†

æ€è€ƒå®Œäº†

æ€è€ƒæ™‚é–“: 42s

ã“ã“ã§ã¯ã€

1.  ã‚ãªãŸã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§å®Ÿè£…ã—ã¦ã„ã‚‹ \*\*Method 6ï¼ˆÎ²\_t x\_t ã‚·ã‚°ãƒŠãƒ«ï¼‰\*\*ã‚’ã€
    *   Guo (2025) ã®ç†è«–ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã©ã†å°ã‹ã‚Œã‚‹ã‹
    *   ãã‚Œã‚’ã©ã®ã‚ˆã†ã«ã€Œæ¨å®šå¼ â†’ ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ç‰ˆã€ã«ã—ã¦ã„ã‚‹ã‹
2.  ãã®ä¸Šã«ä¹—ã£ã¦ã„ã‚‹ **ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒ†ã‚£ãƒ³ã‚°**ãŒã€
    *   ã©ã‚“ãªç›®çš„é–¢æ•°ã‹ã‚‰æ¥ã¦ã„ã¦
    *   æ•°å¼çš„ã«ã©ã†æ©Ÿèƒ½ã—ã¦ã„ã‚‹ã‹

ã‚’ã€ã§ãã‚‹ã ã‘å³å¯†ã«ã¤ãªã’ã¦èª¬æ˜ã—ã¾ã™ã€‚

å‚ç…§æ–‡çŒ®ï¼ˆç†è«–ã®ãƒ™ãƒ¼ã‚¹ï¼‰

*   Hongye Guo, â€œEarnings Extrapolation and Predictable Stock Market Returns,â€ Review of Financial Studies 38(6), 1730â€“1782, 2025. [OUP Academic+1](https://academic.oup.com/rfs/article/38/6/1730/8101501?utm_source=chatgpt.com)
*   Hongye Guo & Jessica Wachter, â€œCorrelation Neglect in Asset Prices,â€ SSRN Working Paper, 2025. [SSRN+1](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5268329&utm_source=chatgpt.com)
*   Alan Moreira & Tyler Muir, â€œVolatility-Managed Portfolios,â€ Journal of Finance 72(4), 1611â€“1644, 2017. [Wiley Online Library+1](https://onlinelibrary.wiley.com/doi/abs/10.1111/jofi.12513?utm_source=chatgpt.com)

* * *

1\. Guo ãƒ¢ãƒ‡ãƒ«ã®éª¨æ ¼ï¼šãƒªã‚¿ãƒ¼ãƒ³åˆ†è§£ã¨ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°
------------------------------

### 1.1 ã€Œãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ï¼‹ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ã€ã®åˆ†è§£

Guo ã®ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã¯ã€ï¼ˆé€£ç¶šè¤‡åˆ©ã®ï¼‰å¸‚å ´ãƒªã‚¿ãƒ¼ãƒ³  $R_t$  ã‚’

$$
R_t = R_t^{\text{fund}} + R_t^{\text{mis}}
$$

ã«åˆ†è§£ã™ã‚‹ã¨ã“ã‚ã‹ã‚‰å§‹ã¾ã‚Šã¾ã™ã€‚ã“ã“ã§ï¼š

*    $R_t^{\text{fund}}$ ï¼šåˆç†çš„ãªå‰²å¼•ä¿‚æ•°ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼ã®ã‚‚ã¨ã§æ±ºã¾ã‚‹ã€Œãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã€ãƒªã‚¿ãƒ¼ãƒ³
*    $R_t^{\text{mis}}$ ï¼šearnings extrapolation / correlation neglect ã«ã‚ˆã£ã¦ç”Ÿã˜ã‚‹**æœŸå¾…ã®æ­ªã¿**

Guo ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€å››åŠæœŸã”ã¨ã®ã€ŒNewsy / Repetitive / Quietã€æ§‹é€ ã¨ earnings ã®è‡ªå·±ç›¸é–¢ã‹ã‚‰ã€

*   Newsy æœˆã®ãƒªã‚¿ãƒ¼ãƒ³ã¯ã€Œæ–°ã—ã„å››åŠæœŸã®æ±ºç®—ã€ã§ã‚ã‚Šéå»ã¨ã®ç›¸é–¢ãŒä½ã„
*   Non-newsy æœˆï¼ˆç‰¹ã« Repetitiveï¼‰ã¯éå»ã®æ±ºç®—ã¨ã»ã¼åŒã˜æƒ…å ±ã‚’å†è¡¨æ˜ã—ã¦ã„ã‚‹ãŸã‚ç›¸é–¢ãŒé«˜ã„

ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€æŠ•è³‡å®¶ãŒã“ã‚Œã‚’ååˆ†ã«åŒºåˆ¥ã—ãªã„ãŸã‚ã«ã€**earnings ã‚’èª¤ã£ãŸä¿‚æ•°ã§å¤–æŒ¿**ã—ã¦ã—ã¾ã„ã€ãã‚ŒãŒ  $R_t^{\text{mis}}$  ã«ç¾ã‚Œã‚‹ã€ã¨ã„ã†å½¢ã§å®šå¼åŒ–ã•ã‚Œã¾ã™ã€‚[Finance Department+1](https://fnce.wharton.upenn.edu/wp-content/uploads/2022/07/Paper4_Guo.pdf?utm_source=chatgpt.com)

### 1.2 ã€Œé•·æœŸå¹³å‡ï¼‹ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ã€ã¸ã®è¿‘ä¼¼

å®Ÿè¨¼ã«è½ã¨ã™éš›ã«ã¯ã€ $R_t^{\text{fund}}$  ã®è©³ç´°ãªæ§‹é€ ã‚’ã™ã¹ã¦æ˜ç¤ºã™ã‚‹ã®ã§ã¯ãªãã€é•·æœŸã®å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³  $\mu$  ã«é›†ç´„ã—ã€çŸ­æœŸçš„ãªæ­ªã¿ã‚’ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°  $\eta_t$  ã¨ã—ã¦ã¾ã¨ã‚ã¾ã™ï¼š

$$
R_t = \mu + \eta_t + \varepsilon_t,
$$

ã“ã“ã§

*    $\mu$ ï¼šé•·æœŸã®ãƒªã‚¹ã‚¯ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ï¼ˆå®šæ•°ã¨ã¿ãªã™ï¼‰
*    $\eta_t$ ï¼šearnings ãƒ™ãƒ¼ã‚¹ã®ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ï¼ˆå¾Œã§  $x_t$  ã®ç·šå½¢é–¢æ•°ã«ãªã‚‹ï¼‰
*    $\varepsilon_t$ ï¼šãƒ›ãƒ¯ã‚¤ãƒˆãƒã‚¤ã‚ºçš„ãªæ®‹å·®

Guo ã®æ§‹é€ ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€ã“ã®  $\eta_t$  ãŒã€Œéå»ã® Newsy earnings shock ã®é›†ç´„é‡ã€ã‹ã‚‰å°ã‹ã‚Œã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã™ã€‚ã“ã‚Œã‚’è¦ç´„ã™ã‚‹å¤‰æ•°ãŒ **S\_t** ã§ã‚ã‚Šã€ãã®å¤‰æ›ãŒ **x\_t** ã§ã™ã€‚

* * *

2\. S\_t ã¨ x\_tï¼šæ§‹é€ ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®å°å‡º
--------------------------

### 2.1 S\_tï¼šNewsy earnings shock ã®è“„ç©

ã‚ãªãŸã®å®Ÿè£…ã§ã¯ã€

*   æœˆæ¬¡ãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³  $R_t^{\text{tot}} = \text{mkt\_excess}_t + \text{rf}_t$  ã‚’
*   Newsy æœˆã ã‘æŠœãå‡ºã—ã¦æ™‚ç³»åˆ—  $\{R_{n_k}\}$  ã‚’ä½œã‚Šï¼ˆ`is_newsy` ã§ãƒ•ã‚£ãƒ«ã‚¿ï¼‰
*   ç›´è¿‘ 4 å›ã® Newsy æœˆãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ã®åˆè¨ˆã‚’
    
$$
S_t = \sum_{j=1}^{4} R_{n_j(t)},
$$

ã¨ã—ã¦è¨ˆç®—ã—ã¦ã„ã¾ã™ï¼ˆ`compute_S_and_x_for_method6` å†…ï¼‰ã€‚ã“ã“ã§  $n_1(t)$  ã¯ t ã‚ˆã‚Šç›´è¿‘ã® Newsy æœˆã€ $n_2(t)$  ã¯ 2 ç•ªç›®ã«è¿‘ã„ Newsy æœˆâ€¦ã§ã™ã€‚

Guo ã®æ§‹é€ ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€éå»æ•°å››åŠæœŸã® earnings news ãŒç¾åœ¨ã®ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ã«å¯„ä¸ã™ã‚‹ãŸã‚ã€\*\*S\_t ã¯ã€Œearnings news ã®è“„ç©é‡ã€\*\*ã¨ã—ã¦è§£é‡ˆã§ãã¾ã™ã€‚[Finance Department+1](https://fnce.wharton.upenn.edu/wp-content/uploads/2022/07/Paper4_Guo.pdf?utm_source=chatgpt.com)

### 2.2 x\_tï¼šS\_t ã‚’ã€Œã‚»ãƒ³ã‚¿ãƒªãƒ³ã‚°ï¼‹ç¬¦å·åè»¢ã€ã—ãŸãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°æŒ‡æ¨™

S\_t ã¯ãƒ¬ãƒ™ãƒ«ãŒæ™‚æœŸã«ã‚ˆã£ã¦ç•°ãªã‚‹ã®ã§ã€ãã®ã¾ã¾ã ã¨ã€Œã©ã®ç¨‹åº¦éç†±ã—ã¦ã„ã‚‹ã‹ã€ã‚’æ¸¬ã‚‹ã®ã«é©ã—ã¦ã„ã¾ã›ã‚“ã€‚ãã“ã§ Guo ã¯ã€S\_t ã®å±¥æ­´å¹³å‡ã‚’å¼•ã„ãŸ

$$
\tilde S_{t-1} = S_{t-1} - \bar S_{t-1}, \quad \bar S_{t-1} = \frac{1}{t-1}\sum_{s\le t-1} S_s
$$

ã‚’ä½¿ã„ã¾ã™ã€‚

ã•ã‚‰ã«ã€Newsy æœˆã¨ Non-newsy æœˆã§ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ã®æ–¹å‘ãŒé€†ã«ãªã‚‹ã€ã¨ã„ã†ç†è«–çš„å«æ„ã«åˆã‚ã›ã¦ç¬¦å·ã‚’å¤‰ãˆã¾ã™ï¼š

*   t ãŒ **Newsy Month** ã®ã¨ãï¼š  
    éå»ã® S ãŒé«˜ã‹ã£ãŸï¼ˆï¼ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒç¶šã„ã¦ã„ãŸï¼‰ãªã‚‰ã€  
    ç¾åœ¨ã® Newsy æœˆã§ã¯\*\*ãƒªãƒãƒ¼ã‚µãƒ«ï¼ˆä½ã„ãƒªã‚¿ãƒ¼ãƒ³ï¼‰\*\*ãŒæœŸå¾…ã•ã‚Œã‚‹ â†’ ç¬¦å·ãƒã‚¤ãƒŠã‚¹
*   t ãŒ \*\*Non-newsyï¼ˆRãƒ»3rdï¼‰\*\*ã®ã¨ãï¼š  
    éå»ã® S ãŒé«˜ã„ã»ã©ã€æ¥½è¦³ãŒç¶™ç¶š â†’ **é«˜ã„ãƒªã‚¿ãƒ¼ãƒ³**ãŒæœŸå¾…ã•ã‚Œã‚‹ â†’ ãƒ—ãƒ©ã‚¹

ã—ãŸãŒã£ã¦ã€å®Ÿè£…ã®

$$
x_t = \text{sign}(t)\cdot (S_{t-1} - \bar S_{t-1}),
$$

ï¼ˆ`sign(t)=-1` if t is newsy, else `+1`ï¼‰ã¯ã€ç†è«–ã®

> ã€Œéå»æ•°å››åŠæœŸã® earnings news ã®è“„ç©ãŒã€Newsy æœˆã¨ Non-newsy æœˆã§é€†æ–¹å‘ã®æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿã‚€ã€

ã¨ã„ã†ä¸»å¼µã‚’ 1 æ¬¡å…ƒã§è¡¨ç¾ã™ã‚‹ã‚‚ã®ã§ã™ã€‚[Finance Department+1](https://fnce.wharton.upenn.edu/wp-content/uploads/2022/07/Paper4_Guo.pdf?utm_source=chatgpt.com)

* * *

3\. æ§‹é€ å¼ â†’ æ¨å®šå¼ï¼šMethod 6 ã®å›å¸°å½¢å¼
----------------------------

### 3.1 ç†è«–å¼

å‰ç¯€ã¾ã§ã‚’ã¾ã¨ã‚ã‚‹ã¨ã€Guo ã®æ§‹é€ ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰è‡ªç„¶ã«å‡ºã¦ãã‚‹å½¢ã¯

$$
R_t = \mu + \beta x_t + \epsilon_t, \tag{1}
$$

ã§ã™ã€‚ã“ã“ã§

*    $\mu$ ï¼šé•·æœŸå¹³å‡ãƒªã‚¿ãƒ¼ãƒ³
*    $x_t$ ï¼šä¸Šã§å®šç¾©ã—ãŸãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°æŒ‡æ¨™
*    $\beta$ ï¼šãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ãŒãƒªã‚¿ãƒ¼ãƒ³ã«ã©ã‚Œã ã‘åæ˜ ã•ã‚Œã‚‹ã‹ã‚’è¡¨ã™æ„Ÿåº¦

ã“ã®  $\beta$  ã¯ã€earnings ãƒ—ãƒ­ã‚»ã‚¹ã¨æŠ•è³‡å®¶ã® extrapolation rule ã‹ã‚‰ç†è«–çš„ã«å°å‡ºã§ãã€sign ã‚„ã‚ªãƒ¼ãƒ€ãƒ¼ã«ã¤ã„ã¦ä»®èª¬ãŒç«‹ã¡ã¾ã™ãŒã€å®Ÿå‹™ä¸Šã¯**ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ OLS ã§æ¨å®š**ã—ã¾ã™ã€‚[IDEAS/RePEc+1](https://ideas.repec.org/a/oup/rfinst/v38y2025i6p1730-1782..html?utm_source=chatgpt.com)

### 3.2 å®Ÿå‹™çš„æ¨å®šï¼š $\mu$  ã‚’ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°å¹³å‡ã«ç½®ãæ›ãˆã‚‹

ã‚ãªãŸã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ã¯ã€ $\mu$  ã‚’å›ºå®šã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã—ã¦ã§ã¯ãªãã€Œã“ã‚Œã¾ã§ã®å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³ã€ã§è¿‘ä¼¼ã—ã¦ã„ã¾ã™ï¼š

$$
\bar R_{t-1} = \frac{1}{t-1} \sum_{s\le t-1} R_s^{\text{tot}},
$$

ï¼ˆ`mkt_mean = mkt_total.expanding().mean().shift(1)`ï¼‰

ã“ã®ã¨ãã€(1) ã‚’

$$
R_t^{\text{tot}} = \bar R_{t-1} + \beta x_t + \epsilon_t \tag{2}
$$

ã¨å†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã—ã¾ã™ã€‚ã“ã“ã§  $R_t^{\text{tot}} = \text{mkt\_excess}_t + \text{rf}_t$  ã§ã™ã€‚

ä¸¡è¾ºã‹ã‚‰  $\bar R_{t-1}$  ã‚’å¼•ãã¨

$$
y_t \equiv R_t^{\text{tot}} - \bar R_{t-1} = \beta x_t + \epsilon_t. \tag{3}
$$

ã“ã‚ŒãŒã€ã‚ãªãŸãŒ `y_adj = mkt_total - mkt_mean` ã¨ã—ã¦æ§‹ç¯‰ã—ã¦ã„ã‚‹ç³»åˆ—ã§ã™ã€‚

### 3.3 Î² ã®æ¨å®šï¼ˆOLSï¼‰

(3) ã¯åˆ‡ç‰‡ãªã—ã®å˜å›å¸°ãªã®ã§ã€OLS æ¨å®šé‡ã¯

$$
\hat\beta_T = \frac{\sum_{t\le T} x_t y_t} {\sum_{t\le T} x_t^2}. \tag{4}
$$

ã‚ãªãŸã®ã‚³ãƒ¼ãƒ‰ `build_method6_raw_weights` ã§ã¯ã€å„æ™‚ç‚¹ T ã§

```python
xi = x[mask].values
yi = y_adj[mask].values
denom = (xi ** 2).sum()
beta[t] = (xi * yi).sum() / denom
```

ã¨ã—ã¦ (4) ã‚’è¨ˆç®—ã—ã¦ã„ã¾ã™ã€‚

*   `mask` ã¯ã€Œx ã¨ y ãŒæ¬ æã§ãªã„éå»ã‚µãƒ³ãƒ—ãƒ«ã€ã®ã¿ã‚’å–ã‚‹ã®ã§ã€**æƒ…å ±ã¯å¸¸ã« t ä»¥å‰**ã—ã‹ä½¿ã£ã¦ã„ãªã„ï¼ˆå…ˆèª­ã¿ãªã—ï¼‰
*   `min_obs` ã«ã‚ˆã£ã¦ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºãŒå°ã•ã„ã†ã¡ã¯æ¨å®šã—ãªã„ï¼ˆ $\hat\beta_t = \text{NaN}$ ï¼‰

ã“ã®  $\hat\beta_t$  ã¯ã€Guo ã® Method 6 ã«å¯¾å¿œã™ã‚‹

> ã€Œearnings extrapolation ã«ã‚ˆã£ã¦ç”Ÿã˜ãŸãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ãŒã€ã©ã®ç¨‹åº¦ãƒªã‚¿ãƒ¼ãƒ³ã«åæ˜ ã•ã‚Œã‚‹ã‹ã€

ã®æ¨å®šå€¤ã§ã™ã€‚

* * *

4\. ãƒˆãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚·ã‚°ãƒŠãƒ«ï¼š $w_t = \hat\beta_t x_t$  ã®å°å‡º
---------------------------------------------

### 4.1 1 æœŸé–“ã®å°‘æ•°è³‡ç”£ãƒ»äºŒè³‡ç”£ãƒ¢ãƒ‡ãƒ«

ã‚·ãƒ³ãƒ—ãƒ«ã«ã€æ¬¡ã® 1 æœŸé–“ã®ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå•é¡Œã‚’è€ƒãˆã¾ã™ï¼š

*   ç„¡ãƒªã‚¹ã‚¯è³‡ç”£ï¼šãƒªã‚¿ãƒ¼ãƒ³  $R_f$ ï¼ˆã“ã“ã§ã¯æœˆæ¬¡å›½å‚µï¼‰
*   ãƒªã‚¹ã‚¯è³‡ç”£ï¼ˆå¸‚å ´ï¼‰ï¼šè¶…éãƒªã‚¿ãƒ¼ãƒ³  $r_{t+1} = R_{t+1}^{\text{tot}} - R_f$ 

ã‚ãªãŸã¯ã€Œå¸‚å ´ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã ã‘ã€ã® 2 è³‡ç”£ä¸–ç•Œã§ã€w\_t ã‚’æ™‚ç‚¹ t ã«ãŠã‘ã‚‹å¸‚å ´ã®ãƒ¬ãƒãƒ¬ãƒƒã‚¸ï¼ˆãƒ­ãƒ³ã‚°ãªã‚‰æ­£ã€ã‚·ãƒ§ãƒ¼ãƒˆãªã‚‰è² ï¼‰ã¨ã—ã¦é¸ã³ã¾ã™ã€‚

ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®è¶…éãƒªã‚¿ãƒ¼ãƒ³ã¯

$$
r_{p,t+1} = w_t r_{t+1}.
$$

### 4.2 æœŸå¾…è¶…éãƒªã‚¿ãƒ¼ãƒ³ã‚’  $x_t$  ã§è¿‘ä¼¼

æ§‹é€ å¼ (2)â€“(3) ã‹ã‚‰ã€ $r_{t+1} \equiv R_{t+1}^{\text{tot}}-R_f$  ã®æ¡ä»¶ä»˜ãæœŸå¾…å€¤ã¯

$$
E_t[r_{t+1}] \approx \hat\beta_t x_t,
$$

ã¨è¿‘ä¼¼ã§ãã¾ã™ï¼ˆ $\bar R_t - R_f$  ã¯å®šæ•°éƒ¨åˆ†ã¨ã¿ãªã—ã€ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ç”±æ¥ã®å¤‰å‹•ã‚’  $\hat\beta_t x_t$  ã«é›†ç´„ï¼‰ã€‚

ã¤ã¾ã‚Šã€**ä»Šè¦‹ãˆã¦ã„ã‚‹ x\_t ã«æ¯”ä¾‹ã—ã¦ã€ç¿Œæœˆã®è¶…éãƒªã‚¿ãƒ¼ãƒ³ãŒæœŸå¾…ã§ãã‚‹**ã¨ã—ã¾ã™ã€‚

### 4.3 å¹³å‡åˆ†æ•£ãƒ»è¿‘ä¼¼äºŒæ¬¡åŠ¹ç”¨ä¸‹ã§ã®æœ€é©ãƒ¬ãƒãƒ¬ãƒƒã‚¸

æ™‚ç‚¹ t ã«ãŠã‘ã‚‹ã€Œè¿‘ä¼¼äºŒæ¬¡åŠ¹ç”¨ã€ã¾ãŸã¯å¹³å‡åˆ†æ•£ã®ç›®çš„é–¢æ•°ã‚’

$$
\max_{w_t} \quad E_t[r_{p,t+1}] - \frac{\gamma}{2}\,\text{Var}_t(r_{p,t+1})
$$

ã¨ã™ã‚‹ã¨ã€

$$
E_t[r_{p,t+1}] = w_t E_t[r_{t+1}] \approx w_t\,\hat\beta_t x_t,
$$
 
$$
\text{Var}_t(r_{p,t+1}) = w_t^2 \text{Var}_t(r_{t+1}) \approx w_t^2 \sigma^2,
$$

ã¨è¿‘ä¼¼ã§ãã¾ã™ï¼ˆ $\sigma^2$  ã¯ç¾åœ¨ã®å¸‚å ´ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼‰ã€‚

ã“ã®ã¨ãã®ä¸€éšæ¡ä»¶ã¯

$$
\frac{\partial}{\partial w_t} \left( w_t \hat\beta_t x_t - \frac{\gamma}{2} w_t^2 \sigma^2 \right) = 0
$$

ã‚ˆã‚Š

$$
\hat\beta_t x_t - \gamma \sigma^2 w_t = 0 \quad \Rightarrow \quad w_t^* = \frac{\hat\beta_t x_t}{\gamma \sigma^2}. \tag{5}
$$

ã¤ã¾ã‚Šã€æœ€é©ãƒ¬ãƒãƒ¬ãƒƒã‚¸ã¯ ** $\hat\beta_t x_t$  ã«æ¯”ä¾‹**ã—ã¾ã™ã€‚

ã‚ãªãŸã®å®Ÿè£…ã§ã¯ã€ãƒªã‚¹ã‚¯è¨±å®¹åº¦  $1/\gamma$  ã‚„  $\sigma^2$  ã‚’æ˜ç¤ºçš„ã«ã¯æ¨å®šã›ãšã€ã¾ãš

$$
w_t^{\text{raw}} = \hat\beta_t x_t
$$

ã¨ã—ã€ãã®å¾Œã§ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒ†ã‚£ãƒ³ã‚°ã§ scale ã‚’åˆã‚ã›ã¦ã„ã¾ã™ã€‚

ã“ã‚Œã¯ã€ã€Œ**çµŒæ¸ˆçš„ã«æ„å‘³ã®ã‚ã‚‹æ–¹å‘ã¨ç›¸å¯¾çš„ãªå¼·ã•**ã€ã‚’  $\hat\beta_t x_t$  ã«æŒãŸã›ã€çµ¶å¯¾ãƒ¬ãƒãƒ¬ãƒƒã‚¸ã¯å¾Œæ®µã®ãƒœãƒ©åˆ¶å¾¡ã«ä»»ã›ã‚‹ã€ã¨ã„ã†åˆ†æ¥­ã«ãªã£ã¦ã„ã¾ã™ã€‚

* * *

5\. ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒ†ã‚£ãƒ³ã‚°ã®å³å¯†ãªèª¬æ˜
--------------------------

### 5.1 ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ã‚„ã£ã¦ã„ã‚‹å‡¦ç†

ã‚ãªãŸã® `vol_target_from_weights` ã¯æ¦‚ã­æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã™ï¼š

1.  æˆ¦ç•¥ã®ã€Œrawã€è¶…éãƒªã‚¿ãƒ¼ãƒ³ã‚’
    $$
    r_{p,t}^{\text{raw}} = w_t^{\text{raw}} \cdot r_{t} \quad (r_t = \text{mkt\_excess}_t)
    $$
    ã¨è¨ˆç®—
2.  å…¨ã‚µãƒ³ãƒ—ãƒ«ã®å®Ÿç¾æ¨™æº–åå·®ã‚’
    $$
    \hat\sigma_{\text{raw}} = \sqrt{\frac{1}{T-1}\sum_{t=1}^T \left( r_{p,t}^{\text{raw}} - \bar r_p^{\text{raw}} \right)^2}
    $$
    ã¨æ¨å®šï¼ˆã‚³ãƒ¼ãƒ‰ã§ã¯å˜ç´”ã« `.std(ddof=1)`ï¼‰
3.  ç›®æ¨™ãƒœãƒ©  $\sigma^\*$ ï¼ˆä¾‹ï¼šæœˆæ¬¡ 5%ï¼‰ã‚’ä¸ãˆã€ã‚¹ã‚±ãƒ¼ãƒ«ä¿‚æ•°
    $$
    k = \frac{\sigma^\*}{\hat\sigma_{\text{raw}}}
    $$
    ã‚’è¨ˆç®—
4.  æœ€çµ‚çš„ãªã‚¦ã‚§ã‚¤ãƒˆãƒ»ãƒªã‚¿ãƒ¼ãƒ³ã‚’
    $$
    w_t^{\text{final}} = k\, w_t^{\text{raw}}, \quad r_{p,t}^{\text{final}} = k\, r_{p,t}^{\text{raw}}
    $$
    ã¨ã™ã‚‹

### 5.2 ãªãœãƒœãƒ©ãŒã»ã¼  $\sigma^\*$  ã«ãªã‚‹ã‹

ç·šå½¢ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãªã®ã§ã€åˆ†æ•£ã¯

$$
\text{Var}(r_{p}^{\text{final}}) = k^2\,\text{Var}(r_{p}^{\text{raw}}) \approx \left(\frac{\sigma^\*}{\hat\sigma_{\text{raw}}}\right)^2 \hat\sigma_{\text{raw}}^2 = (\sigma^\*)^2.
$$

ã‚µãƒ³ãƒ—ãƒ«æ¨å®šã‚†ãˆã«èª¤å·®ã¯ã‚ã‚Šã¾ã™ãŒã€ã€Œraw æˆ¦ç•¥ã®ãƒœãƒ©ã€ã‚’ã‚ã¨ã‹ã‚‰ä¸€æ‹¬ã§  $\sigma^\*$  ã«åˆã‚ã›ã‚‹æ“ä½œã«ãªã£ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚

### 5.3 Sharpe æ¯”ã¨åŠ¹ç”¨ã®è¦³ç‚¹ã‹ã‚‰ã®æ­£å½“åŒ–

ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒ†ã‚£ãƒ³ã‚°ã¯ã€Moreira & Muir (2017) ã® **volatility-managed portfolios** ã¨åŒã˜ã‚¢ã‚¤ãƒ‡ã‚£ã‚¢ã§ã™ï¼š[Wiley Online Library+1](https://onlinelibrary.wiley.com/doi/abs/10.1111/jofi.12513?utm_source=chatgpt.com)

*   åŸºæœ¬æˆ¦ç•¥ï¼ˆä»Šå›ã® Î²\_t x\_t ãƒ™ãƒ¼ã‚¹ï¼‰ã®ã€Œ**æ–¹å‘æ€§ã¨ç›¸å¯¾å¼·åº¦**ã€ã¯ç¶­æŒã—ã¤ã¤
*   ãƒ¬ãƒãƒ¬ãƒƒã‚¸ã‚’èª¿æ•´ã—ã¦ã€Œç›®æ¨™ãƒªã‚¹ã‚¯ã«åˆã‚ã›ã‚‹ã€

ã“ã¨ã«ã‚ˆã‚Šã€

1.  ç•°ãªã‚‹ã‚·ã‚°ãƒŠãƒ«åŒå£«ã® **Sharpe æ¯”ã‚’å…¬å¹³ã«æ¯”è¼ƒ**ã§ãã‚‹
2.  å¹³å‡åˆ†æ•£ã®è¦³ç‚¹ã‹ã‚‰ã€**æŠ•è³‡å®¶ã®ãƒªã‚¹ã‚¯è¨±å®¹åº¦ã«åˆã£ãŸã‚µã‚¤ã‚º**ã«èª¿æ•´ã§ãã‚‹
3.  æ¥µç«¯ãªãƒ¬ãƒãƒ¬ãƒƒã‚¸ã‚„ drawdown ã‚’æŠ‘åˆ¶ã—ã€**é‹ç”¨ä¸Šè¨±å®¹å¯èƒ½ãªãƒ¬ãƒ³ã‚¸**ã«åã‚ã‚‹

ã¨ã„ã†ãƒ¡ãƒªãƒƒãƒˆãŒã‚ã‚Šã¾ã™ã€‚

ç†è«–çš„ã«ã¯ã€(5) ã®æœ€é©ãƒ¬ãƒãƒ¬ãƒƒã‚¸å¼

$$
w_t^* = \frac{\hat\beta_t x_t}{\gamma \sigma^2}
$$

ã‹ã‚‰ã€ $\gamma$  ã‚„  $\sigma^2$  ã®ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒé¢å€’ãªã¨ãã«ã€\*\*ã€Œã¾ãš  $\hat\beta_t x_t$  ã‚’ä½œã‚Šã€å¾Œã§å…¨ä½“ãƒœãƒ©ã‚’æ‰€æœ›ã®æ°´æº–ã«åˆã‚ã›ã‚‹ã€\*\*ã¨ã„ã†å½¢ã§åŒã˜ã“ã¨ã‚’å®Ÿç¾ã—ã¦ã„ã‚‹ã€ã¨è¦‹ãªã›ã¾ã™ã€‚

* * *

6\. ã¾ã¨ã‚ï¼šã‚ãªãŸã® Method 6 å®Ÿè£…ã¯ä½•ã‚’ã—ã¦ã„ã‚‹ã‹
--------------------------------

1.  **æ§‹é€ ãƒ¢ãƒ‡ãƒ«ã®æ ¸å¿ƒ**
    *   Earnings extrapolation ï¼‹ correlation neglect ã«ã‚ˆã£ã¦ç”Ÿã˜ã‚‹  
        ã€ŒNewsy / Non-newsy æœˆé–“ã®äºˆæ¸¬å¯èƒ½ãªãƒªã‚¿ãƒ¼ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã€ã‚’  
        S\_t â†’ x\_t ã¨ã„ã†ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°æŒ‡æ¨™ã§è¦ç´„
2.  **æ¨å®šå¼ã®æ§‹ç¯‰**
    *   ç†è«–å¼  $R_t^{\text{tot}} = \mu + \beta x_t + \epsilon_t$  ã‚’  
         $\mu â‰ˆ \bar R_{t-1}$  ã¨ã—ã¦  
         $y_t = R_t^{\text{tot}} - \bar R_{t-1} = \beta x_t + \epsilon_t$  ã«å¤‰å½¢
    *   ã“ã‚Œã‚’åˆ‡ç‰‡ãªã— OLS ã§æ¨å®šã—ã€ $\hat\beta_t$  ã‚’é€æ¬¡æ›´æ–°
3.  **ãƒˆãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚·ã‚°ãƒŠãƒ«**
    *   ä¸€æœŸå…ˆã®æœŸå¾…è¶…éãƒªã‚¿ãƒ¼ãƒ³ã‚’  $\hat\beta_t x_t$  ã¨è¿‘ä¼¼
    *   å¹³å‡åˆ†æ•£ã®è¦³ç‚¹ã‹ã‚‰æœ€é©ãƒ¬ãƒãƒ¬ãƒƒã‚¸ã¯ã“ã‚Œã«æ¯”ä¾‹ã™ã‚‹ã®ã§  
         $w_t^{\text{raw}} = \hat\beta_t x_t$  ã‚’ raw weight ã¨ã—ã¦æ¡ç”¨
4.  **ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒ†ã‚£ãƒ³ã‚°**
    *   raw æˆ¦ç•¥ã®å®Ÿç¾ãƒœãƒ©  $\hat\sigma_{\text{raw}}$  ã‚’æ¸¬ã‚Šã€  
        ã‚¹ã‚±ãƒ¼ãƒ«ä¿‚æ•°  $k = \sigma^\*/\hat\sigma_{\text{raw}}$  ã‚’æ›ã‘ã‚‹ã“ã¨ã§  
        **æœ€çµ‚ãƒœãƒ© â‰ˆ ç›®æ¨™ãƒœãƒ©  $\sigma^\*$ ** ã‚’å®Ÿç¾
    *   ã“ã‚Œã«ã‚ˆã‚Š
        *   ä»–æˆ¦ç•¥ã¨ã®æ¯”è¼ƒãŒå…¬å¹³
        *   ãƒ¬ãƒãƒ¬ãƒƒã‚¸ãŒå®Ÿå‹™çš„ãªæ°´æº–ã«èª¿æ•´
        *   Moreira & Muir å‹ã®ã€Œrisk-managed factorã€ã¨ã—ã¦ã®è§£é‡ˆã‚‚å¯èƒ½

ã“ã®æ„å‘³ã§ã€ã‚ãªãŸã® Method 6 å®Ÿè£…ã¯

> Guo (2025) ã®æ§‹é€ ãƒ¢ãƒ‡ãƒ«ã§ç†è«–çš„ã«å°å‡ºã•ã‚ŒãŸãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°æŒ‡æ¨™  $x_t$  ã¨ãã®æ„Ÿåº¦  $\beta_t$  ã‚’ç”¨ã„ã€ãã‚Œã‚’å¹³å‡åˆ†æ•£ã®è¦³ç‚¹ã‹ã‚‰æœ€é©ã«è¿‘ã„ãƒ¬ãƒãƒ¬ãƒƒã‚¸ã‚·ã‚°ãƒŠãƒ«  $w_t \propto \beta_t x_t$  ã«å¤‰æ›ã—ã€æœ€å¾Œã«ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒ†ã‚£ãƒ³ã‚°ã§å®Ÿå‹™çš„ãªãƒªã‚¹ã‚¯æ°´æº–ã«åˆã‚ã›ãŸæˆ¦ç•¥

ã«ãªã£ã¦ã„ã¾ã™ã€‚

* * *

ã‚‚ã—æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¨ã—ã¦ã€

*   Î²\_t æ¨å®šã‚’ã€Œexpandingã€ç‰ˆã¨ã€Œrollingã€ç‰ˆã§ç†è«–çš„ã«æ¯”è¼ƒã—ãŸã„
*   x\_t ã®å°å‡ºã‚’ã€earnings ãƒ—ãƒ­ã‚»ã‚¹ï¼ˆAR(1)ï¼‹quarter structureï¼‰ã‹ã‚‰æ•°å¼ãƒ¬ãƒ™ãƒ«ã§è¿½ã„ã‹ã‘ãŸã„
*   Method 6 æˆ¦ç•¥ã® **OOS RÂ² ã‚„ regime-wiseï¼ˆNewsy/Non-newsyï¼‰ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†è§£**ã‚’ç†è«–å¼ã®è¦³ç‚¹ã‹ã‚‰èª¬æ˜ã—ãŸã„

ã¨ã„ã£ãŸã¨ã“ã‚ã‚’æ˜ã‚Šä¸‹ã’ãŸã‘ã‚Œã°ã€ãã“ã‚‚æ•°å¼ãƒ¬ãƒ™ãƒ«ã§æ•´ç†ã—ã¾ã™ã€‚

## Response:
æ€è€ƒæ™‚é–“: 7s

ä»¥ä¸‹ã«ã€\*\*Method 6 å°‚ç”¨ã®ã€Œæ•´ç†æ¸ˆã¿ãƒ•ãƒ«å®Ÿè£…ã€\*\*ã‚’ç¤ºã—ã¾ã™ã€‚

*   Fama-French æœˆæ¬¡ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ã®èª­ã¿è¾¼ã¿
*   Newsy / Repetitive / 3rd month ã®åˆ¤å®š
*    $S_t, x_t$  ã®è¨ˆç®—ï¼ˆGuo æ–¹å¼ï¼‰
*    $\beta_t$  ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ¨å®šï¼ˆexpanding OLSï¼‰
*    $w_t = \beta_t x_t$  ã®ç”Ÿæˆ
*   ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒ†ã‚£ãƒ³ã‚°ï¼ˆç›®æ¨™ãƒœãƒ©ã«åˆã‚ã›ãŸã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼‰
*   ç°¡å˜ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é›†è¨ˆã¨ãƒ—ãƒ­ãƒƒãƒˆ

ã¨ã—ã¦ä¸€é€šã‚Šå®Œçµã™ã‚‹å½¢ã«ã—ã¾ã—ãŸã€‚

* * *

1\. Method 6: å®Œå…¨å®Ÿè£…ã‚³ãƒ¼ãƒ‰
---------------------

```python
import pandas as pd
import numpy as np
import math
import matplotlib.pyplot as plt
import statsmodels.api as sm

# ============================================================
# 0. Fama-French (monthly) èª­ã¿è¾¼ã¿
# ============================================================

def load_ff_monthly_from_ken_french(csv_path: str) -> pd.DataFrame:
    """
    Ken French ã® F-F_Research_Data_Factors.csv ã‹ã‚‰
    æœˆæ¬¡ã® Mkt-RF, RF ã‚’æŠ½å‡ºã—ã¦ DataFrame ã‚’è¿”ã™ã€‚

    æˆ»ã‚Šå€¤: index = æœˆæœ« (Timestamp)
            columns = ['mkt_excess', 'rf']
    """
    raw = pd.read_csv(csv_path, skiprows=4)

    # "YYYYMM" ã®ã‚ˆã†ãªæ•´æ•°ãŒå…¥ã£ã¦ã„ã‚‹è¡Œã ã‘æœˆæ¬¡
    num = pd.to_numeric(raw['Unnamed: 0'], errors='coerce')
    mask_monthly = num > 10000
    monthly = raw[mask_monthly].copy()

    monthly = monthly.rename(columns={'Unnamed: 0': 'date'})
    monthly['date'] = pd.to_datetime(monthly['date'].astype(int), format="%Y%m")
    monthly = monthly.set_index('date').sort_index()

    for col in ['Mkt-RF', 'RF']:
        monthly[col] = pd.to_numeric(monthly[col], errors='coerce')

    ff = monthly[['Mkt-RF', 'RF']].copy()
    ff['mkt_excess'] = ff['Mkt-RF'] / 100.0
    ff['rf']         = ff['RF'] / 100.0

    return ff[['mkt_excess', 'rf']].dropna()

# ============================================================
# 1. month_type: N / R / 3 ã®åˆ†é¡
# ============================================================

def classify_month_type(index: pd.DatetimeIndex) -> pd.Series:
    """
    Guo & Wachter / Guo (2025) ã® 3 ãƒ¶æœˆã‚µã‚¤ã‚¯ãƒ«ã«å¯¾å¿œã™ã‚‹æœˆã‚¿ã‚¤ãƒ—ã€‚
    - month % 3 == 1 -> 'N' (Newsy)
    - month % 3 == 2 -> 'R' (Repetitive)
    - month % 3 == 0 -> '3' (third month)
    """
    mt = pd.Series(index=index, dtype="object")
    for t in index:
        m = t.month % 3
        if m == 1:
            mt[t] = 'N'
        elif m == 2:
            mt[t] = 'R'
        else:
            mt[t] = '3'
    return mt

# ============================================================
# 2. S_t, x_t ã®è¨ˆç®—ï¼ˆMethod 6 ç”¨ï¼‰
# ============================================================

def compute_S_and_x_for_method6(mkt_total: pd.Series):
    """
    Guo (2025) ã® Method 6 ã«å¯¾å¿œã™ã‚‹ S_t, x_t ã‚’æ§‹æˆã™ã‚‹ã€‚

    å¼•æ•°:
        mkt_total : å¸‚å ´ãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ã‚·ãƒªãƒ¼ã‚º (Mkt-RF + RF)

    æˆ»ã‚Šå€¤:
        S          : ç›´è¿‘4ã¤ã® Newsy æœˆãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ã®å’Œ
        x          : sign-adjusted & demeaned S (æ§‹é€ ãƒ¢ãƒ‡ãƒ«ã® mispricing æŒ‡æ¨™)
        month_type : 'N'/'R'/'3' ã®æœˆã‚¿ã‚¤ãƒ—
    """
    idx = mkt_total.index
    month_type = classify_month_type(idx)
    is_newsy = (month_type == "N")

    # Newsy æœˆã®ã¿æŠ½å‡º
    news_series = mkt_total[is_newsy]

    # ç›´è¿‘4ã¤ã® Newsy æœˆã®åˆè¨ˆ S_t
    S = pd.Series(index=idx, dtype=float)
    for t in idx:
        past = news_series[news_series.index <= t]
        if len(past) >= 4:
            S[t] = past.iloc[-4:].sum()
        else:
            S[t] = np.nan

    # x_t = sign * (S_{t-1} - mean_{s<=t-1} S_s)
    x = pd.Series(index=idx, dtype=float)
    S_hist = []
    for i in range(1, len(idx)):
        prev_date = idx[i-1]
        curr_date = idx[i]

        s_prev = S.loc[prev_date]
        if np.isnan(s_prev):
            x[curr_date] = np.nan
            continue

        S_hist.append(s_prev)
        s_bar = float(np.mean(S_hist))

        sign = -1.0 if is_newsy[curr_date] else 1.0
        x[curr_date] = sign * (s_prev - s_bar)

    return S, x, month_type

# ============================================================
# 3. Method 6: Î²_t x_t ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ¨å®š
# ============================================================

def build_method6_raw_weights(
    ff: pd.DataFrame,
    min_obs: int = 120,
) -> (pd.Series, pd.Series, pd.Series):
    """
    Method 6 ã®ã€Œæ§‹é€ ãƒ¢ãƒ‡ãƒ«ã€å®Ÿè£…ï¼š
      R_t^tot = mean_{s<t} R_s^tot + Î² x_t + Îµ_t
    ã‹ã‚‰ Î² ã‚’ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ¨å®šã—ã€
      w_t^raw = Î²_t x_t
    ã‚’ç”Ÿæˆã™ã‚‹ã€‚

    å¼•æ•°:
        ff      : ['mkt_excess','rf'] ã‚’æŒã¤ DataFrame
        min_obs : Î² æ¨å®šã«å¿…è¦ãªæœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°

    æˆ»ã‚Šå€¤:
        x       : mispricing predictor x_t
        beta    : å„æ™‚ç‚¹ t ã«ãŠã‘ã‚‹ Î²_t
        w_raw   : Î²_t x_t ï¼ˆNaN ã¯ 0 ã«ç½®ãæ›ãˆï¼‰
    """
    mkt_excess = ff["mkt_excess"].copy()
    rf         = ff["rf"].copy()
    mkt_total  = mkt_excess + rf
    idx        = mkt_total.index

    # S_t, x_t ã‚’è¨ˆç®—
    S, x, month_type = compute_S_and_x_for_method6(mkt_total)

    # ç„¡æ¡ä»¶å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆãƒ©ãƒ³ãƒ‹ãƒ³ã‚°å¹³å‡ï¼‰ã‚’æ§‹æˆ
    mkt_mean = mkt_total.expanding().mean().shift(1)

    # y_t = R_t^tot - mean_{s<t} R_s^tot
    y_adj    = mkt_total - mkt_mean

    beta = pd.Series(index=idx, dtype=float)

    for i, t in enumerate(idx):
        # t æ™‚ç‚¹ã§åˆ©ç”¨å¯èƒ½ãªéå»æƒ…å ±ã®ã¿ã‚’ä½¿ã£ã¦ Î²_t ã‚’æ¨å®š
        mask = (idx <= t) & x.notna() & y_adj.notna()
        n = mask.sum()
        if n < min_obs:
            beta[t] = np.nan
            continue

        xi = x[mask].values
        yi = y_adj[mask].values
        denom = (xi ** 2).sum()
        beta[t] = (xi * yi).sum() / denom if denom > 0 else np.nan

    # w_t^raw = Î²_t x_t
    w_raw = pd.Series(index=idx, dtype=float)
    for t in idx:
        if np.isnan(beta[t]) or np.isnan(x[t]):
            w_raw[t] = 0.0
        else:
            w_raw[t] = beta[t] * x[t]

    return x, beta, w_raw

# ============================================================
# 4. ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒ†ã‚£ãƒ³ã‚°
# ============================================================

def vol_target_from_weights(
    mkt_excess: pd.Series,
    rf: pd.Series,
    w_raw: pd.Series,
    target_vol: float = 0.05,
) -> pd.DataFrame:
    """
    ä»»æ„ã® raw weight w_raw ã«å¯¾ã—ã¦ã€
    - strat_excess_raw = w_raw * mkt_excess
    - ãã®å®Ÿç¾ãƒœãƒ©ã‹ã‚‰ã‚¹ã‚±ãƒ¼ãƒ«ä¿‚æ•°ã‚’è¨ˆç®—
    - ç›®æ¨™ãƒœãƒ© target_vol ã«åˆã‚ã›ã‚‹

    æˆ»ã‚Šå€¤:
      DataFrame:
        ['mkt_excess','rf',
         'w_raw','w_scaled',
         'strat_excess_raw','strat_excess','strat_total']
    """
    data = pd.concat(
        [mkt_excess.rename("mkt_excess"),
         rf.rename("rf"),
         w_raw.rename("w_raw")],
        axis=1
    ).dropna(subset=["mkt_excess", "rf"])

    strat_excess_raw = data["w_raw"] * data["mkt_excess"]

    # å®Ÿç¾ãƒœãƒ©
    realized_vol = strat_excess_raw.std(ddof=1)
    if realized_vol is None or realized_vol == 0 or np.isnan(realized_vol):
        scale = 1.0
    else:
        scale = target_vol / realized_vol

    w_scaled     = data["w_raw"] * scale
    strat_excess = strat_excess_raw * scale
    strat_total  = data["rf"] + strat_excess

    out = pd.DataFrame({
        "mkt_excess": data["mkt_excess"],
        "rf": data["rf"],
        "w_raw": data["w_raw"],
        "w_scaled": w_scaled,
        "strat_excess_raw": strat_excess_raw,
        "strat_excess": strat_excess,
        "strat_total": strat_total,
    })
    out.attrs["scale"] = scale
    out.attrs["target_vol"] = target_vol
    return out

# ============================================================
# 5. è©•ä¾¡ç”¨ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ============================================================

def annualized_stats(r: pd.Series):
    """
    æœˆæ¬¡ãƒªã‚¿ãƒ¼ãƒ³ç³»åˆ— r ã‹ã‚‰å¹´ç‡å¹³å‡ãƒ»å¹´ç‡ãƒœãƒ©ãƒ»å¹´ç‡ã‚·ãƒ£ãƒ¼ãƒ—ã‚’è¨ˆç®—ã€‚
    """
    r = r.dropna()
    mu_m = r.mean()
    sd_m = r.std(ddof=1)
    mu_a = mu_m * 12
    sd_a = sd_m * math.sqrt(12)
    sharpe = mu_a / sd_a if sd_a > 0 else np.nan
    return mu_a, sd_a, sharpe

# ============================================================
# 6. å®Ÿè¡Œä¾‹ (main)
# ============================================================

if __name__ == "__main__":
    # 1) Fama-French æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    csv_path = "F-F_Research_Data_Factors.csv"
    ff = load_ff_monthly_from_ken_french(csv_path)

    # 2) Method 6: Î²_t x_t ã® raw weights ã‚’æ§‹æˆ
    x_m6, beta_m6, w_m6 = build_method6_raw_weights(ff, min_obs=120)

    # 3) ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒ†ã‚£ãƒ³ã‚°ï¼ˆä¾‹: æœˆæ¬¡ 5%ï¼‰
    target_vol = 0.05
    strat_m6 = vol_target_from_weights(ff["mkt_excess"], ff["rf"], w_m6, target_vol=target_vol)

    # 4) ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™
    mu_a, sd_a, sh = annualized_stats(strat_m6["strat_total"])
    print(f"[Method 6 (Î²_t x_t, vol-targeted @ {target_vol:.0%})]")
    print(f"  Annualized Return : {mu_a:.2%}")
    print(f"  Annualized Vol    : {sd_a:.2%}")
    print(f"  Sharpe Ratio      : {sh:.2f}")
    print(f"  Scale (k)         : {strat_m6.attrs['scale']:.3f}")

    # 5) ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³ã®ãƒ—ãƒ­ãƒƒãƒˆï¼ˆå¸‚å ´ vs Method 6ï¼‰
    common_index = strat_m6["strat_total"].dropna().index
    mkt_total = (ff["mkt_excess"] + ff["rf"]).reindex(common_index)
    sw_m6 = (1.0 + strat_m6["strat_total"].reindex(common_index)).cumprod()
    mw    = (1.0 + mkt_total).cumprod()

    plt.figure(figsize=(14, 5))
    plt.plot(sw_m6, label="Method 6 (Î²_t x_t, vol-targeted)", linewidth=2)
    plt.plot(mw,    label="Market (Buy & Hold)", linestyle="--")
    plt.title("Cumulative Wealth: Method 6 vs Market")
    plt.legend()
    plt.grid(True)
    plt.show()
```

* * *

2\. å®Ÿè£…å†…å®¹ã®æ•´ç†ï¼ˆMethod 6 ã®è¦³ç‚¹ï¼‰
-------------------------

ä¸Šè¨˜ã‚³ãƒ¼ãƒ‰ã¯ã€Method 6 ã‚’æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã«åˆ†è§£ã—ã¦ã„ã¾ã™ã€‚

1.  **å¸‚å ´ãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ã®æ§‹ç¯‰**  
     $\displaystyle R_t^{\text{tot}} = \text{mkt\_excess}_t + \text{rf}_t$ 
2.  **Newsy / Repetitive / 3rd month ã®åˆ¤å®š**  
    `classify_month_type` ã§ `N / R / 3` ã‚’è¨­å®š
3.  **S\_t ã®æ§‹ç¯‰**
    *   Newsy æœˆã®ã¿æŠœãå‡ºã—
    *   ç›´è¿‘ 4 å›ã® Newsy æœˆãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ã‚’åˆè¨ˆ â†’  $S_t$ 
4.  **x\_t ã®æ§‹ç¯‰**
    *    $S_{t-1}$  ã¨ãã®å±¥æ­´å¹³å‡  $\bar S_{t-1}$  ã®å·®ã‚’å–ã‚Š
    *   äºˆæ¸¬å¯¾è±¡ãŒ Newsy æœˆãªã‚‰ç¬¦å·ãƒã‚¤ãƒŠã‚¹ã€ãã‚Œä»¥å¤–ãªã‚‰ãƒ—ãƒ©ã‚¹
    *   â†’  $x_t$  ã¯ã€ŒãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°æ–¹å‘ãƒ»å¤§ãã•ã€ã‚’è¡¨ã™
5.  ** $\beta_t$  ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ¨å®š**
    *    $y_t = R_t^{\text{tot}} - \bar R_{t-1}$  ã‚’æ§‹æˆ
    *   `min_obs` ä»¥ä¸Šã®ã‚µãƒ³ãƒ—ãƒ«ãŒæºœã¾ã‚‹ã¾ã§ã¯ Î² ã¯æ¨å®šã—ãªã„
    *   åˆ‡ç‰‡ãªã— OLS
        $$
         y_t = \beta x_t + \epsilon_t
        $$
    *   éå»ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§  $\hat\beta_t$  ã‚’è¨ˆç®—ï¼ˆå…ˆèª­ã¿ãªã—ï¼‰
6.  **raw weight ã®ç”Ÿæˆ**
    $$
     w_t^{\text{raw}} = \hat\beta_t x_t
    $$
    â†’ ç†è«–çš„ã«ã¯ã€ŒãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ã«æ¯”ä¾‹ã—ãŸãƒ¬ãƒãƒ¬ãƒƒã‚¸ã€
7.  **ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒ†ã‚£ãƒ³ã‚°**
    *   raw æˆ¦ç•¥ã®å®Ÿç¾ãƒœãƒ©  $\hat\sigma_{\text{raw}}$  ã‚’è¨ˆç®—
    *   ç›®æ¨™ãƒœãƒ©  $\sigma^\*$  ã«å¯¾ã—ã¦  $k = \sigma^\*/\hat\sigma_{\text{raw}}$ 
    *   æœ€çµ‚ weight  $w_t^{\text{final}} = k\,w_t^{\text{raw}}$ ã€  
        è¶…éãƒªã‚¿ãƒ¼ãƒ³  $r_{p,t} = k\,w_t^{\text{raw}} mkt\_excess_t$ 

* * *

ã“ã‚Œã‚’ãƒ™ãƒ¼ã‚¹ã«ã€

*   rolling window ç‰ˆï¼ˆ20 å¹´ã ã‘ã§ Î² ã‚’æ¨å®šï¼‰
*   sign æˆ¦ç•¥ï¼ˆ`w_raw = np.sign(Î²_t x_t)`ï¼‰
*   Method 5 / z\*\_t ã¨ã®å®Œå…¨æ¯”è¼ƒ

ãªã©ã‚‚åŒã˜æ çµ„ã¿ã§æ‹¡å¼µã§ãã¾ã™ã€‚

å¿…è¦ã§ã‚ã‚Œã°ã€  
ã€Œexpanding ç‰ˆã¨ rolling ç‰ˆã® Î²\_t ã®é•ã„ã‚’å¯è¦–åŒ–ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã€ã‚„ã€  
ã€ŒNewsy æœˆ / é Newsy æœˆåˆ¥ã«æˆ¦ç•¥ãƒªã‚¿ãƒ¼ãƒ³ã‚’åˆ†è§£ã™ã‚‹åˆ†æã‚³ãƒ¼ãƒ‰ã€ã‚‚è¿½åŠ ã§ãã¾ã™ã€‚

## Response:
æ€è€ƒæ™‚é–“: 26s

äº†è§£ã—ã¾ã—ãŸã€‚  
å…ˆã»ã©ã® **Method 6 å®Ÿè£…**ã‚’å‰æã«ã—ã¦ã€

1.  **expanding Î²\_t ã¨ rolling Î²\_t ã‚’æ¯”è¼ƒãƒ»å¯è¦–åŒ–ã™ã‚‹ã‚³ãƒ¼ãƒ‰**
2.  **Newsy / é Newsyï¼ˆæœˆã‚¿ã‚¤ãƒ—ï¼‰åˆ¥ã«æˆ¦ç•¥ãƒªã‚¿ãƒ¼ãƒ³ã‚’åˆ†è§£ã™ã‚‹ã‚³ãƒ¼ãƒ‰**

ã‚’ã€Œãã®ã¾ã¾å·®ã—è¾¼ã‚ã‚‹å½¢ã€ã§è¿½åŠ ã—ã¾ã™ã€‚

ä»¥ä¸‹ã§ã¯ã€ã™ã§ã«å®šç¾©æ¸ˆã¿ã¨ä»®å®šã—ã¦ã„ã‚‹ã‚‚ã®ã¯ï¼š

*   `load_ff_monthly_from_ken_french`
*   `classify_month_type`
*   `compute_S_and_x_for_method6`
*   `build_method6_raw_weights`ï¼ˆexpanding ç‰ˆï¼‰
*   `vol_target_from_weights`
*   `annualized_stats`

ã§ã™ã€‚

* * *

1\. rolling ç‰ˆ Î²\_t ã¨ expanding ç‰ˆ Î²\_t ã®æ¯”è¼ƒãƒ»å¯è¦–åŒ–
---------------------------------------------

### 1-1. rolling ç‰ˆ Î²\_t ã®æ¨å®šé–¢æ•°

```python
def build_method6_raw_weights_rolling(
    ff: pd.DataFrame,
    lookback_years: int = 20,
    min_obs: int = 120,
) -> (pd.Series, pd.Series, pd.Series):
    """
    Method 6 ã® Î²_t ã‚’ã€Œç›´è¿‘ lookback_years å¹´ï¼ˆ= 12*years ãƒ¶æœˆï¼‰ã€ã§
    rolling OLS æ¨å®šã™ã‚‹ç‰ˆã€‚
    
      y_t = R_t^tot - mean_{s<t} R_s^tot
      x_t = mispricing predictor (Method 6 ã® x_t)
      Î²_t = argmin âˆ‘ (y_s - Î² x_s)^2, s âˆˆ {ç›´è¿‘Lãƒ¶æœˆ & s<=t}
      w_t^raw = Î²_t x_t

    å¼•æ•°:
        ff           : ['mkt_excess','rf'] ã‚’æŒã¤ DataFrame
        lookback_years : rolling window ã®å¹´æ•°
        min_obs      : çª“å†…ã§ Î² æ¨å®šã«å¿…è¦ãªæœ€å°è¦³æ¸¬æ•°

    æˆ»ã‚Šå€¤:
        x       : mispricing predictor x_t
        beta    : rolling çª“ã§æ¨å®šã—ãŸ Î²_t
        w_raw   : Î²_t x_tï¼ˆNaN ã¯ 0 ã«ï¼‰
    """
    mkt_excess = ff["mkt_excess"].copy()
    rf         = ff["rf"].copy()
    mkt_total  = mkt_excess + rf
    idx        = mkt_total.index

    # S_t, x_t ã‚’è¨ˆç®—ï¼ˆexpanding ç‰ˆã¨åŒã˜ï¼‰
    S, x, month_type = compute_S_and_x_for_method6(mkt_total)

    # ç„¡æ¡ä»¶å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆãƒ©ãƒ³ãƒ‹ãƒ³ã‚°å¹³å‡ï¼‰ã¯ Method 6 ã¨åŒã˜æ§‹é€ 
    mkt_mean = mkt_total.expanding().mean().shift(1)
    y_adj    = mkt_total - mkt_mean

    beta = pd.Series(index=idx, dtype=float)

    lookback_months = lookback_years * 12

    for i, t in enumerate(idx):
        # rolling çª“ï¼ši ã‚’å«ã‚€ã€Œç›´è¿‘ lookback_months æœ¬ã€ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç¯„å›²
        start_i = max(0, i - lookback_months + 1)
        window_idx = idx[start_i:(i + 1)]

        mask = window_idx.to_series().index
        # ã“ã® window ã®ä¸­ã§ x, y_adj ãŒæ¬ æã§ãªã„ã‚‚ã®ã ã‘ä½¿ç”¨
        x_win = x.loc[window_idx].dropna()
        y_win = y_adj.loc[window_idx].dropna()
        common_idx = x_win.index.intersection(y_win.index)

        if len(common_idx) < min_obs:
            beta[t] = np.nan
            continue

        xi = x_win.loc[common_idx].values
        yi = y_win.loc[common_idx].values
        denom = (xi ** 2).sum()
        beta[t] = (xi * yi).sum() / denom if denom > 0 else np.nan

    # w_t^raw = Î²_t x_t
    w_raw = pd.Series(index=idx, dtype=float)
    for t in idx:
        if np.isnan(beta[t]) or np.isnan(x[t]):
            w_raw[t] = 0.0
        else:
            w_raw[t] = beta[t] * x[t]

    return x, beta, w_raw
```

### 1-2. expanding vs rolling Î²\_t ã®å¯è¦–åŒ–é–¢æ•°

```python
def plot_beta_expanding_vs_rolling(
    ff: pd.DataFrame,
    rolling_years: int = 20,
    min_obs: int = 120,
):
    """
    Method 6 ã® Î²_t ã«ã¤ã„ã¦ã€
    - expanding ç‰ˆ
    - rolling (lookback_years å¹´) ç‰ˆ
    ã‚’åŒã˜ã‚°ãƒ©ãƒ•ä¸Šã«ãƒ—ãƒ­ãƒƒãƒˆã—ã¦æ¯”è¼ƒã™ã‚‹ã€‚
    """
    # expanding ç‰ˆ
    x_exp, beta_exp, w_exp = build_method6_raw_weights(ff, min_obs=min_obs)
    # rolling ç‰ˆ
    x_roll, beta_roll, w_roll = build_method6_raw_weights_rolling(
        ff,
        lookback_years=rolling_years,
        min_obs=min_obs,
    )

    # å…±é€šã‚µãƒ³ãƒ—ãƒ«ï¼ˆä¸¡æ–¹ã¨ã‚‚ Î²_t ãŒé NaNï¼‰
    beta_df = pd.concat(
        [beta_exp.rename("beta_exp"), beta_roll.rename("beta_roll")],
        axis=1
    ).dropna()

    plt.figure(figsize=(14, 5))
    plt.plot(beta_df.index, beta_df["beta_exp"], label="Expanding Î²_t", linewidth=1.5)
    plt.plot(beta_df.index, beta_df["beta_roll"], label=f"Rolling Î²_t ({rolling_years}y)", linewidth=1.5)
    plt.axhline(0.0, color="black", linewidth=0.8, linestyle="--")
    plt.title(f"Method 6: Expanding vs Rolling Î²_t (lookback={rolling_years} years)")
    plt.legend()
    plt.grid(True)
    plt.show()

    # Î²_exp vs Î²_roll ã® scatter (å‚è€ƒ)
    plt.figure(figsize=(5, 5))
    plt.scatter(beta_df["beta_exp"], beta_df["beta_roll"], alpha=0.5)
    lims = [
        min(beta_df["beta_exp"].min(), beta_df["beta_roll"].min()),
        max(beta_df["beta_exp"].max(), beta_df["beta_roll"].max()),
    ]
    plt.plot(lims, lims, linestyle="--")  # 45åº¦ç·š
    plt.xlim(lims)
    plt.ylim(lims)
    plt.xlabel("Expanding Î²_t")
    plt.ylabel(f"Rolling Î²_t ({rolling_years}y)")
    plt.title("Method 6: Î²_t (Expanding vs Rolling)")
    plt.grid(True)
    plt.show()
```

### 1-3. å‘¼ã³å‡ºã—ä¾‹ï¼ˆmain ã®ä¸­ï¼‰

```python
if __name__ == "__main__":
    csv_path = "F-F_Research_Data_Factors.csv"
    ff = load_ff_monthly_from_ken_french(csv_path)

    # 20 å¹´ rolling ã¨ expanding ã® Î²_t ã‚’æ¯”è¼ƒ
    plot_beta_expanding_vs_rolling(ff, rolling_years=20, min_obs=120)
```

* * *

2\. Newsy / é Newsy åˆ¥ æˆ¦ç•¥ãƒªã‚¿ãƒ¼ãƒ³åˆ†è§£ã‚³ãƒ¼ãƒ‰
---------------------------------

Method 6 ã®æˆ¦ç•¥ï¼ˆvol-target å¾Œï¼‰ã«ã¤ã„ã¦ã€

*   æœˆã‚¿ã‚¤ãƒ—åˆ¥ã«æ€§èƒ½ã‚’ã¾ã¨ã‚ã‚‹ï¼ˆN / R / 3ï¼‰
*   ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³ã‚’ã€ŒNewsy ã®è²¢çŒ®ã€ã€ŒRepetitive ã®è²¢çŒ®ã€ãªã©ã«åˆ†è§£ã—ã¦å¯è¦–åŒ–

ã‚’è¡Œã†ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã§ã™ã€‚

### 2-1. æœˆã‚¿ã‚¤ãƒ—ã‚’æˆ¦ç•¥ DataFrame ã«ä»˜ä¸

```python
def attach_month_type_to_strat(strat_df: pd.DataFrame) -> pd.DataFrame:
    """
    strat_dfï¼ˆindex ãŒæœˆæ¬¡æ—¥ä»˜ï¼‰ã«å¯¾ã—ã¦ã€
    month_type ('N','R','3') ã‚’ä»˜ä¸ã™ã‚‹ã€‚
    """
    mt = classify_month_type(strat_df.index)
    out = strat_df.copy()
    out["month_type"] = mt
    return out
```

### 2-2. æœˆã‚¿ã‚¤ãƒ—åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é›†è¨ˆ

```python
def summarize_by_month_type(strat_df_with_mt: pd.DataFrame):
    """
    strat_df_with_mt: 'strat_total', 'strat_excess', 'month_type' ã‚’æŒã¤ DataFrame
    
    å„ month_type ã”ã¨ã«ï¼š
      - å¹´ç‡å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³
      - å¹´ç‡ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
      - Sharpe ratio
    ã‚’è¡¨ç¤ºã™ã‚‹ã€‚
    """
    print("\n=== Performance by month_type (N / R / 3) ===")
    for mt in ["N", "R", "3"]:
        sub = strat_df_with_mt[strat_df_with_mt["month_type"] == mt]["strat_total"]
        if len(sub.dropna()) < 12:  # ã‚µãƒ³ãƒ—ãƒ«ãŒå°‘ãªã™ãã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            print(f"[{mt}] too few observations")
            continue
        mu_a, sd_a, sh = annualized_stats(sub)
        print(f"[{mt}]  Return={mu_a:.2%}, Vol={sd_a:.2%}, Sharpe={sh:.2f}")

    # N vs é Nï¼ˆR + 3ï¼‰ã®æ¯”è¼ƒã‚‚å‚è€ƒã¾ã§ã«
    is_newsy = strat_df_with_mt["month_type"] == "N"
    sub_N  = strat_df_with_mt.loc[is_newsy, "strat_total"]
    sub_nonN = strat_df_with_mt.loc[~is_newsy, "strat_total"]
    if len(sub_N.dropna()) >= 12 and len(sub_nonN.dropna()) >= 12:
        muN, sdN, shN = annualized_stats(sub_N)
        muO, sdO, shO = annualized_stats(sub_nonN)
        print("\n[N vs Non-N (R + 3)]")
        print(f"  N      : Ret={muN:.2%}, Vol={sdN:.2%}, Sharpe={shN:.2f}")
        print(f"  Non-N  : Ret={muO:.2%}, Vol={sdO:.2%}, Sharpe={shO:.2f}")
```

### 2-3. Newsy / Repetitive / 3rd ã®ã€Œç´¯ç©è²¢çŒ®ã€ã®ãƒ—ãƒ­ãƒƒãƒˆ

ã€Œæˆ¦ç•¥ã® total return ã‚’ãã®ã¾ã¾ N / R / 3 ã«åˆ†ã‘ã‚‹ã€ã®ã§ã¯ãªãã€Guo è«–æ–‡ã® Table 7 çš„ãªã‚¤ãƒ¡ãƒ¼ã‚¸ã§ã€

*   N ã®æœˆã ã‘æˆ¦ç•¥ãƒªã‚¿ãƒ¼ãƒ³ã‚’å–ã‚Šã€ä»–ã®æœˆã¯ 0
*   R ã®æœˆã ã‘æˆ¦ç•¥ãƒªã‚¿ãƒ¼ãƒ³ã‚’å–ã‚Šã€ä»–ã®æœˆã¯ 0
*   3 ã®æœˆã ã‘â€¦

ã¨ã—ã€ãã‚Œãã‚Œã®ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³ã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã¾ã™ã€‚

```python
def plot_month_type_decomposition(strat_df_with_mt: pd.DataFrame):
    """
    Newsy / Repetitive / 3rd month ã”ã¨ã®ã€Œç´¯ç©è¶…éãƒªã‚¿ãƒ¼ãƒ³è²¢çŒ®ã€ã‚’å¯è¦–åŒ–ã€‚

    strat_excess ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€
      - N æœˆã ã‘ã®è¶…éãƒªã‚¿ãƒ¼ãƒ³
      - R æœˆã ã‘ã®è¶…éãƒªã‚¿ãƒ¼ãƒ³
      - 3 æœˆã ã‘ã®è¶…éãƒªã‚¿ãƒ¼ãƒ³
    ã®ç´¯ç©ã‚’ãƒ—ãƒ­ãƒƒãƒˆã™ã‚‹ã€‚
    """
    df = strat_df_with_mt.copy()

    # å„ã‚¿ã‚¤ãƒ—ã®ã¿ãƒªã‚¿ãƒ¼ãƒ³ã‚’æ®‹ã—ã€ãã‚Œä»¥å¤–ã¯ 0 ã«
    excess_N  = df["strat_excess"].where(df["month_type"] == "N", 0.0)
    excess_R  = df["strat_excess"].where(df["month_type"] == "R", 0.0)
    excess_3  = df["strat_excess"].where(df["month_type"] == "3", 0.0)

    wealth_N  = (1.0 + excess_N).cumprod()
    wealth_R  = (1.0 + excess_R).cumprod()
    wealth_3  = (1.0 + excess_3).cumprod()

    plt.figure(figsize=(14, 5))
    plt.plot(wealth_N, label="Contribution from Newsy months (N)")
    plt.plot(wealth_R, label="Contribution from Repetitive months (R)")
    plt.plot(wealth_3, label="Contribution from 3rd months (3)")
    plt.axhline(1.0, color="black", linewidth=0.8, linestyle="--")
    plt.title("Method 6 Strategy: Cumulative Contribution by Month Type")
    plt.legend()
    plt.grid(True)
    plt.show()
```

### 2-4. ï¼ˆä»»æ„ï¼‰å¹´æ¬¡ Ã— æœˆã‚¿ã‚¤ãƒ—åˆ¥ã®é›†è¨ˆï¼ˆTable 7 ã£ã½ã„å½¢ï¼‰

ã‚ˆã‚Šè«–æ–‡ Table 7 ã«è¿‘ã¥ã‘ã‚‹ãŸã‚ã€**å¹´æ¬¡ Ã— Newsy / Repetitive ã”ã¨ã®åˆè¨ˆãƒªã‚¿ãƒ¼ãƒ³**ã‚’è¡¨ã«ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚‚ä»˜ã‘ã¦ãŠãã¾ã™ã€‚

```python
def yearly_decomposition_by_month_type(strat_df_with_mt: pd.DataFrame):
    """
    å¹´æ¬¡ Ã— month_type ã”ã¨ã«æˆ¦ç•¥ã®è¶…éãƒªã‚¿ãƒ¼ãƒ³ã‚’åˆè¨ˆã™ã‚‹ã€‚
    Guo & Wachter Table 7 ã®ã€Œyear-by-year continuation / reversal decompositionã€ã«å¯¾å¿œã€‚

    å‡ºåŠ›:
      DataFrame:
        index : å¹´
        columns : ['N','R','3'] ãã‚Œãã‚Œã®å¹´æ¬¡åˆè¨ˆè¶…éãƒªã‚¿ãƒ¼ãƒ³
    """
    df = strat_df_with_mt.copy()
    df["year"] = df.index.year

    # è¶…éãƒªã‚¿ãƒ¼ãƒ³ã‚’ä½¿ç”¨ï¼ˆstrat_total ã§ã¯ãªãã€Î±ã£ã½ã•ã‚’è¦‹ã‚‹ç›®çš„ãªã‚‰ã“ã¡ã‚‰ï¼‰
    pivot = (
        df.pivot_table(
            index="year",
            columns="month_type",
            values="strat_excess",
            aggfunc="sum",
        )
        .fillna(0.0)
        .rename_axis(columns=None)
    )

    print("\n=== Yearly decomposition of excess returns by month type ===")
    print(pivot)
    return pivot
```

### 2-5. å‘¼ã³å‡ºã—ä¾‹ï¼ˆmain ã«çµ±åˆï¼‰

å…ˆã»ã©ã® Method 6 main ã«è¿½åŠ ã™ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã¯ä»¥ä¸‹ã§ã™ã€‚

```python
if __name__ == "__main__":
    csv_path = "F-F_Research_Data_Factors.csv"
    ff = load_ff_monthly_from_ken_french(csv_path)

    # ------- Method 6: expanding Î²_t ã§æˆ¦ç•¥æ§‹ç¯‰ -------
    x_m6, beta_m6, w_m6 = build_method6_raw_weights(ff, min_obs=120)
    strat_m6 = vol_target_from_weights(
        ff["mkt_excess"],
        ff["rf"],
        w_m6,
        target_vol=0.05,  # æœˆæ¬¡ 5% ãƒœãƒ©
    )

    # ------- æœˆã‚¿ã‚¤ãƒ—ä»˜ã‘ & åˆ†è§£ -------
    strat_m6_mt = attach_month_type_to_strat(strat_m6)

    # 1) æœˆã‚¿ã‚¤ãƒ—åˆ¥ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™
    summarize_by_month_type(strat_m6_mt)

    # 2) N / R / 3 åˆ¥ã®ç´¯ç©è²¢çŒ®ãƒ—ãƒ­ãƒƒãƒˆ
    plot_month_type_decomposition(strat_m6_mt)

    # 3) å¹´æ¬¡ Ã— æœˆã‚¿ã‚¤ãƒ—åˆ¥ã®è¶…éãƒªã‚¿ãƒ¼ãƒ³åˆ†è§£
    yearly_decomposition_by_month_type(strat_m6_mt)

    # 4) expanding vs rolling Î²_t ã®æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆï¼ˆä»»æ„ï¼‰
    plot_beta_expanding_vs_rolling(ff, rolling_years=20, min_obs=120)
```

* * *

ã“ã‚Œã§ï¼š

*   **Method 6 ã® Î²\_t ã‚’ expanding vs rolling ã§æ¯”è¼ƒã—ã€ã©ã®ç¨‹åº¦æ§‹é€ å¤‰åŒ–ã«æ•æ„Ÿã‹**
*   **Newsy / Repetitive / 3rd æœˆãã‚Œãã‚ŒãŒæˆ¦ç•¥ãƒªã‚¿ãƒ¼ãƒ³ã«ã©ã®ç¨‹åº¦å¯„ä¸ã—ã¦ã„ã‚‹ã‹ï¼ˆæ™‚ç³»åˆ—ãƒ»å¹´æ¬¡ï¼‰**

ã‚’ã€æ–‡çŒ®ã®åˆ†è§£ï¼ˆTable 3â€“4ãƒ»Table 7ï¼‰ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ã§è¦‹ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚

ã‚‚ã—ã€

*   2020 å¹´ä»¥é™ã ã‘ã‚’åˆ‡ã‚Šå‡ºã—ã¦åŒã˜åˆ†è§£ã‚’è¡Œã†
*   Method 5 / z\*\_t / nr-only æˆ¦ç•¥ã‚‚åŒã˜é–¢æ•°ã§ã¾ã¨ã‚ã¦æ¯”è¼ƒã™ã‚‹

ã¨ã„ã£ãŸæ‹¡å¼µã‚‚ã—ãŸã‘ã‚Œã°ã€åŒã˜æ çµ„ã¿ã§ã¾ã¨ã‚ã‚‹ã‚³ãƒ¼ãƒ‰ã‚‚ç”¨æ„ã—ã¾ã™ã€‚

## Response:
æ€è€ƒæ™‚é–“: 17s

äº†è§£ã—ã¾ã—ãŸã€‚  
ã“ã“ã§ã¯ **ã€ŒMethod 6 ã®ä»®å®šãƒ»è«–ç†ã‚’è£ä»˜ã‘ã‚‹ãŸã‚ã®å®Ÿè¨¼åˆ†æå°‚ç”¨ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã€** ã‚’ç”¨æ„ã—ã¾ã™ã€‚

*   ç›®çš„ï¼šãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã§ã¯ãªãã€
    *   S\_t / x\_t ã®çµ±è¨ˆçš„æ€§è³ª
    *   S\_t ã®ã€ŒNewsy vs é Newsyã€ã§ã®ç¬¦å·åè»¢
    *   x\_t ãŒå°†æ¥ãƒªã‚¿ãƒ¼ãƒ³ã‚’äºˆæ¸¬ã§ãã‚‹ã‹ï¼ˆå›å¸°ãƒ»ã‚½ãƒ¼ãƒˆãƒ»ãƒ­ãƒ¼ãƒ«ï¼‰  
        ã‚’ç¢ºèªã—ã¦ã€Method 6 ã®ç†è«–çš„å‰æã‚’ãƒ‡ãƒ¼ã‚¿ã§è£œå¼·ã™ã‚‹ã“ã¨ã€‚

ä¸‹è¨˜ã‚³ãƒ¼ãƒ‰ã¯ 1 ãƒ•ã‚¡ã‚¤ãƒ«ã§å®Œçµã™ã‚‹å½¢ã«ã—ã¦ã„ã¾ã™ã€‚

* * *

Method 6 ä»®å®šã®å®Ÿè¨¼åˆ†æãƒ•ãƒ«ã‚³ãƒ¼ãƒ‰
---------------------

```python
import pandas as pd
import numpy as np
import math
import matplotlib.pyplot as plt
import statsmodels.api as sm

# ============================================================
# 0. Fama-French (monthly) èª­ã¿è¾¼ã¿
# ============================================================

def load_ff_monthly_from_ken_french(csv_path: str) -> pd.DataFrame:
    """
    Ken French ã® F-F_Research_Data_Factors.csv ã‹ã‚‰
    æœˆæ¬¡ã® Mkt-RF, RF ã‚’æŠ½å‡ºã—ã¦ DataFrame ã‚’è¿”ã™ã€‚

    æˆ»ã‚Šå€¤: index = æœˆæœ« (Timestamp)
            columns = ['mkt_excess', 'rf']
    """
    raw = pd.read_csv(csv_path, skiprows=4)

    # "YYYYMM" ã®ã‚ˆã†ãªæ•´æ•°ãŒå…¥ã£ã¦ã„ã‚‹è¡Œã ã‘æœˆæ¬¡
    num = pd.to_numeric(raw['Unnamed: 0'], errors='coerce')
    mask_monthly = num > 10000
    monthly = raw[mask_monthly].copy()

    monthly = monthly.rename(columns={'Unnamed: 0': 'date'})
    monthly['date'] = pd.to_datetime(monthly['date'].astype(int), format="%Y%m")
    monthly = monthly.set_index('date').sort_index()

    for col in ['Mkt-RF', 'RF']:
        monthly[col] = pd.to_numeric(monthly[col], errors='coerce')

    ff = monthly[['Mkt-RF', 'RF']].copy()
    ff['mkt_excess'] = ff['Mkt-RF'] / 100.0
    ff['rf']         = ff['RF'] / 100.0

    return ff[['mkt_excess', 'rf']].dropna()

# ============================================================
# 1. month_type: N / R / 3 ã®åˆ†é¡
# ============================================================

def classify_month_type(index: pd.DatetimeIndex) -> pd.Series:
    """
    Guo & Wachter / Guo (2025) ã® 3 ãƒ¶æœˆã‚µã‚¤ã‚¯ãƒ«ã«å¯¾å¿œã™ã‚‹æœˆã‚¿ã‚¤ãƒ—ã€‚
    - month % 3 == 1 -> 'N' (Newsy)
    - month % 3 == 2 -> 'R' (Repetitive)
    - month % 3 == 0 -> '3' (third month)
    """
    mt = pd.Series(index=index, dtype="object")
    for t in index:
        m = t.month % 3
        if m == 1:
            mt[t] = 'N'
        elif m == 2:
            mt[t] = 'R'
        else:
            mt[t] = '3'
    return mt

# ============================================================
# 2. S_t, x_t ã®è¨ˆç®—ï¼ˆMethod 6 ç”¨ï¼‰
# ============================================================

def compute_S_and_x_for_method6(mkt_total: pd.Series):
    """
    Guo (2025) ã® Method 6 ã«å¯¾å¿œã™ã‚‹ S_t, x_t ã‚’æ§‹æˆã™ã‚‹ã€‚

    å¼•æ•°:
        mkt_total : å¸‚å ´ãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ã‚·ãƒªãƒ¼ã‚º (Mkt-RF + RF)

    æˆ»ã‚Šå€¤:
        S          : ç›´è¿‘4ã¤ã® Newsy æœˆãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ã®å’Œ
        x          : sign-adjusted & demeaned S (æ§‹é€ ãƒ¢ãƒ‡ãƒ«ã® mispricing æŒ‡æ¨™)
        month_type : 'N'/'R'/'3' ã®æœˆã‚¿ã‚¤ãƒ—
    """
    idx = mkt_total.index
    month_type = classify_month_type(idx)
    is_newsy = (month_type == "N")

    # Newsy æœˆã®ã¿æŠ½å‡º
    news_series = mkt_total[is_newsy]

    # ç›´è¿‘4ã¤ã® Newsy æœˆã®åˆè¨ˆ S_t
    S = pd.Series(index=idx, dtype=float)
    for t in idx:
        past = news_series[news_series.index <= t]
        if len(past) >= 4:
            S[t] = past.iloc[-4:].sum()
        else:
            S[t] = np.nan

    # x_t = sign * (S_{t-1} - mean_{s<=t-1} S_s)
    x = pd.Series(index=idx, dtype=float)
    S_hist = []
    for i in range(1, len(idx)):
        prev_date = idx[i-1]
        curr_date = idx[i]

        s_prev = S.loc[prev_date]
        if np.isnan(s_prev):
            x[curr_date] = np.nan
            continue

        S_hist.append(s_prev)
        s_bar = float(np.mean(S_hist))

        sign = -1.0 if is_newsy[curr_date] else 1.0
        x[curr_date] = sign * (s_prev - s_bar)

    return S, x, month_type

# ============================================================
# 3. Method 6 ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹ç¯‰ï¼š
#    ãƒªã‚¿ãƒ¼ãƒ³ + S_t + x_t + ãƒªãƒ¼ãƒ‰ãƒªã‚¿ãƒ¼ãƒ³
# ============================================================

def build_method6_dataset(ff: pd.DataFrame) -> pd.DataFrame:
    """
    Method 6 ã®ä»®å®šæ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ã€‚

    columns:
        mkt_excess : å¸‚å ´è¶…éãƒªã‚¿ãƒ¼ãƒ³ r_t
        rf         : ç„¡ãƒªã‚¹ã‚¯ãƒªã‚¿ãƒ¼ãƒ³
        mkt_total  : ãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ R_t
        month_type : 'N'/'R'/'3'
        S          : ç›´è¿‘4 Newsy æœˆãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ã®å’Œ (S_t)
        x          : mispricing æŒ‡æ¨™ (x_t)
        lead_excess: r_{t+1}
        lead_total : R_{t+1}
        S_lag      : S_{t-1} (Newsy/Non-newsy ã”ã¨ã®ç¬¦å·æ¤œè¨¼ç”¨)
    """
    df = ff.copy()
    df["mkt_total"] = df["mkt_excess"] + df["rf"]

    # month_type, S, x ã‚’ä½œæˆ
    S, x, month_type = compute_S_and_x_for_method6(df["mkt_total"])
    df["month_type"] = month_type
    df["S"] = S
    df["x"] = x

    # lead ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆ1æœŸå…ˆï¼‰
    df["lead_excess"] = df["mkt_excess"].shift(-1)
    df["lead_total"]  = df["mkt_total"].shift(-1)

    # S_{t-1} ã‚’æ˜ç¤ºçš„ã«ä½œã‚‹ï¼ˆS_lagï¼‰
    df["S_lag"] = df["S"].shift(1)

    # åˆ†æã«ä¸è¦ãªåˆæœŸ NaN ã‚’ã‚ã‚‹ç¨‹åº¦è½ã¨ã™
    df = df.dropna(subset=["mkt_excess", "mkt_total", "S", "x", "lead_excess", "lead_total"])

    return df

# ============================================================
# 4. Method 6 ä»®å®šã‚’æ¤œè¨¼ã™ã‚‹åˆ†æé–¢æ•°ç¾¤
# ============================================================

# 4-1. åŸºæœ¬çµ±è¨ˆ: S, x ã®åˆ†å¸ƒã‚„ç›¸é–¢ã‚’ç¢ºèª

def basic_stats_method6(df: pd.DataFrame):
    """
    S_t, x_t ã®åŸºæœ¬çµ±è¨ˆã‚„ç›¸é–¢ã‚’å‡ºåŠ›ã™ã‚‹ã€‚
    Method 6 ã®ã€Œx ãŒã‚»ãƒ³ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸ mispricing æŒ‡æ¨™ã€ã¨ã—ã¦å¦¥å½“ã‹ã‚’ç¢ºèªã™ã‚‹ã€‚
    """
    print("=== Basic Descriptive Statistics for S_t and x_t ===")
    print(df[["S", "x"]].describe())

    # ç›¸é–¢
    corr_S_x   = df["S"].corr(df["x"])
    corr_x_ret = df["x"].corr(df["lead_excess"])
    print("\nCorrelations:")
    print(f"  Corr(S_t, x_t)         = {corr_S_x:.4f}")
    print(f"  Corr(x_t, r_(t+1))     = {corr_x_ret:.4f}")

    # S_t ã¨ x_t ã®æ•£å¸ƒå›³
    plt.figure(figsize=(5, 5))
    plt.scatter(df["S"], df["x"], alpha=0.4)
    plt.axhline(0.0, color="black", linewidth=0.8)
    plt.axvline(0.0, color="black", linewidth=0.8)
    plt.xlabel("S_t (sum of last 4 newsy R)")
    plt.ylabel("x_t (sign-adjusted, demeaned S)")
    plt.title("Relation between S_t and x_t (Method 6)")
    plt.grid(True)
    plt.show()

# 4-2. predictability regression: r_{t+1} ~ x_t

def regression_predictability_x(df: pd.DataFrame):
    """
    Method 6 ã®ã‚³ã‚¢ä»®å®š:
      E[r_{t+1} | info_t] â‰ˆ Î² x_t
    ã‚’æ¤œè¨¼ã™ã‚‹ãŸã‚ã€æ™‚ç³»åˆ—å›å¸°ã‚’å®Ÿæ–½ã™ã‚‹ã€‚
    """
    print("\n=== Predictability Regression: r_(t+1) on x_t ===")

    # åˆ‡ç‰‡ã‚ã‚Šã€HACæ¨™æº–èª¤å·®ä»˜ã OLS (Newey-West) ãªã©ã‚’ä½¿ã£ã¦ã‚‚ã‚ˆã„ãŒã€
    # ã“ã“ã§ã¯ã‚·ãƒ³ãƒ—ãƒ«ã« OLS + robust(HC0)ã€‚
    y = df["lead_excess"]
    X = sm.add_constant(df["x"])
    model = sm.OLS(y, X).fit(cov_type="HC0")
    print(model.summary())

    beta = model.params["x"]
    tval = model.tvalues["x"]
    r2   = model.rsquared
    print(f"\n  beta_x  = {beta:.4f}, t = {tval:.2f}, R^2 = {r2:.4f}")

# 4-3. S_{t-1} ã®ã€Œç¬¦å·åè»¢ä»®å®šã€æ¤œè¨¼ï¼š
#      Newsy vs Non-newsy ã§ä¿‚æ•°ç¬¦å·ãŒç•°ãªã‚‹ã‹

def regression_S_lag_by_monthtype(df: pd.DataFrame):
    """
    Guo ã®ãƒ­ã‚¸ãƒƒã‚¯ï¼š
      Newsy æœˆã¨ Non-newsy æœˆã§ã¯ã€S_{t-1} ã¨ r_t ã®é–¢ä¿‚ã®ç¬¦å·ãŒé€†ã«ãªã‚‹ã¯ãš
      â†’ S ã‚’ãã®ã¾ã¾ä½¿ã†ã¨äºˆæ¸¬æ–¹å‘ãŒæœˆã‚¿ã‚¤ãƒ—ã§å¤‰ã‚ã‚‹
      â†’ ã“ã‚Œã‚’å˜ä¸€æŒ‡æ¨™ã«ã¾ã¨ã‚ã‚‹ã®ãŒ x_t

    ã“ã“ã§ã¯ã€ãƒªã‚¿ãƒ¼ãƒ³ r_t ã‚’S_{t-1}ã§å›å¸°ã—ã€
    Næœˆãƒ»NonNæœˆï¼ˆR+3ï¼‰åˆ¥ã® Î² ã‚’æ¯”è¼ƒã™ã‚‹ã€‚
    """
    print("\n=== Regression of r_t on S_(t-1) by month_type ===")

    # 1æœŸå…ˆã§ã¯ãªãã€å½“æœŸãƒªã‚¿ãƒ¼ãƒ³ã¨ã®é–¢ä¿‚ã‚’è¦‹ã‚‹ï¼ˆè§£é‡ˆã¯æ¯”è¼ƒã®ãŸã‚ï¼‰
    df2 = df.dropna(subset=["S_lag", "mkt_excess"])

    # Newsy æœˆ
    sub_N = df2[df2["month_type"] == "N"]
    # Non-newsy (R + 3)
    sub_nonN = df2[df2["month_type"] != "N"]

    def _reg(name, sub):
        if len(sub) < 30:
            print(f"[{name}] too few obs")
            return
        y = sub["mkt_excess"]
        X = sm.add_constant(sub["S_lag"])
        m = sm.OLS(y, X).fit(cov_type="HC0")
        beta = m.params["S_lag"]
        tval = m.tvalues["S_lag"]
        print(f"[{name}] beta_Slag = {beta:.4f}, t = {tval:.2f}, R^2 = {m.rsquared:.4f}")

    _reg("N", sub_N)
    _reg("Non-N (R+3)", sub_nonN)

# 4-4. ã‚½ãƒ¼ãƒˆåˆ†æï¼šx_t quintile ã«ã‚ˆã‚‹ r_{t+1} ã®å¹³å‡

def sort_x_quintiles(df: pd.DataFrame):
    """
    x_t ã® quintile ã‚½ãƒ¼ãƒˆã«ã‚ˆã‚Šã€x ãŒé«˜ã„ã»ã© r_{t+1} ãŒå˜èª¿ã«å¤‰åŒ–ã™ã‚‹ã‹ã‚’ç¢ºèªã™ã‚‹ã€‚
    """
    print("\n=== x_t Quintile Sort for r_(t+1) ===")

    df2 = df.dropna(subset=["x", "lead_excess"]).copy()
    df2["x_q"] = pd.qcut(df2["x"], 5, labels=False) + 1  # 1ã€œ5

    res = df2.groupby("x_q")["lead_excess"].mean() * 12  # å¹´ç‡æ›ç®—
    print("Average annualized excess return by x_t quintile:")
    for q, val in res.items():
        print(f"  Quintile {q}: {val:.2%}")

    # ãƒ—ãƒ­ãƒƒãƒˆ
    plt.figure(figsize=(6, 4))
    plt.bar(res.index.astype(str), res.values)
    plt.xlabel("x_t Quintile (1=Low, 5=High)")
    plt.ylabel("Avg annualized excess return")
    plt.title("Method 6: Future returns by x_t quintile")
    plt.grid(True, axis="y")
    plt.show()

# 4-5. Rolling correlation: x_t vs r_{t+1}

def rolling_corr_x_ret(df: pd.DataFrame, window_years: int = 10):
    """
    x_t ã¨ r_{t+1} ã®ç›¸é–¢ãŒæ™‚é–“çš„ã«å®‰å®šã—ã¦ã„ã‚‹ã‹ã‚’ç¢ºèªã™ã‚‹ãŸã‚ã€
    rolling (window_years å¹´) ã§ç›¸é–¢ä¿‚æ•°ã‚’è¨ˆç®—ã—ã¦ãƒ—ãƒ­ãƒƒãƒˆã™ã‚‹ã€‚
    """
    print(f"\n=== Rolling {window_years}-year correlation: x_t vs r_(t+1) ===")

    df2 = df.dropna(subset=["x", "lead_excess"]).copy()
    window = window_years * 12

    rolling_corr = df2["x"].rolling(window).corr(df2["lead_excess"])

    plt.figure(figsize=(14, 4))
    plt.plot(rolling_corr.index, rolling_corr, label="Rolling corr(x_t, r_(t+1))")
    plt.axhline(0.0, color="black", linewidth=0.8, linestyle="--")
    plt.title(f"Rolling {window_years}-Year Correlation between x_t and r_(t+1)")
    plt.ylabel("Correlation")
    plt.grid(True)
    plt.legend()
    plt.show()

# 4-6. Newsy / é Newsy ã”ã¨ã® x_t predictability

def predictability_by_monthtype(df: pd.DataFrame):
    """
    x_t ã®äºˆæ¸¬åŠ›ãŒ Newsy æœˆã¨ Non-newsy æœˆã§ã©ã†é•ã†ã‹ã‚’ç¢ºèªã™ã‚‹ã€‚
    r_{t+1} ~ x_t ã‚’ month_type ã”ã¨ã«å›å¸°ã€‚
    """
    print("\n=== Predictability r_(t+1) ~ x_t by month_type ===")

    for mt in ["N", "R", "3"]:
        sub = df[df["month_type"] == mt].dropna(subset=["x", "lead_excess"])
        if len(sub) < 40:
            print(f"[{mt}] too few obs (N={len(sub)})")
            continue
        y = sub["lead_excess"]
        X = sm.add_constant(sub["x"])
        m = sm.OLS(y, X).fit(cov_type="HC0")
        beta = m.params["x"]
        tval = m.tvalues["x"]
        print(f"[{mt}] beta_x = {beta:.4f}, t = {tval:.2f}, R^2 = {m.rsquared:.4f}")

# ============================================================
# 5. main: Method 6 ä»®å®šã‚’è£ä»˜ã‘ã‚‹å®Ÿè¨¼åˆ†æã®ä¸€æ‹¬å®Ÿè¡Œ
# ============================================================

if __name__ == "__main__":
    # 1) Fama-French ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    csv_path = "F-F_Research_Data_Factors.csv"
    ff = load_ff_monthly_from_ken_french(csv_path)

    # 2) Method 6 ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹ç¯‰
    df_m6 = build_method6_dataset(ff)

    # 3) åŸºæœ¬çµ±è¨ˆï¼šS_t, x_t ã®åˆ†å¸ƒã¨ç›¸é–¢
    basic_stats_method6(df_m6)

    # 4) x_t ã®äºˆæ¸¬å›å¸°ï¼šr_{t+1} ~ x_t
    regression_predictability_x(df_m6)

    # 5) S_{t-1} ã®ç¬¦å·åè»¢ä»®å®šï¼š
    #    Newsy vs Non-newsy ã§ Î²_Slag ã®ç¬¦å·ãƒ»å¤§ãã•ãŒé•ã†ã‹
    regression_S_lag_by_monthtype(df_m6)

    # 6) x_t Quintile ã«ã‚ˆã‚‹ r_{t+1} ã®å˜èª¿æ€§ãƒã‚§ãƒƒã‚¯
    sort_x_quintiles(df_m6)

    # 7) Rolling correlation: x_t ã¨ r_{t+1} ã®é–¢ä¿‚ãŒæ™‚ç³»åˆ—çš„ã«å®‰å®šã‹
    rolling_corr_x_ret(df_m6, window_years=10)

    # 8) Newsy / Repetitive / 3rd åˆ¥ã® x_t predictability
    predictability_by_monthtype(df_m6)
```

* * *

ã“ã®åˆ†æãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ã€Œä½•ãŒæ¤œè¨¼ã§ãã‚‹ã‹ã€
--------------------

1.  **basic\_stats\_method6**
    *   S\_t, x\_t ã®å¹³å‡ãƒ»åˆ†æ•£ãƒ»ç›¸é–¢
    *   S ã¨ x ã® scatter ã§ã€x ãŒã€ŒS ã‚’ã‚»ãƒ³ã‚¿ãƒªãƒ³ã‚°ï¼‹ç¬¦å·å¤‰æ›ã—ãŸã‚‚ã®ã€ã¨ã—ã¦æŒ¯ã‚‹èˆã£ã¦ã„ã‚‹ã‹
2.  **regression\_predictability\_x**
    *   å˜ç´”ãªæ™‚ç³»åˆ—å›å¸°  $r_{t+1} = \alpha + \beta x_t + \varepsilon$ 
    *   Î² ã®ç¬¦å·ãƒ»æœ‰æ„æ€§ãƒ»RÂ² ã‹ã‚‰ã€Œx\_t ãŒå°†æ¥è¶…éãƒªã‚¿ãƒ¼ãƒ³ã‚’èª¬æ˜ã™ã‚‹ã‹ã€ã‚’ç¢ºèª
3.  **regression\_S\_lag\_by\_monthtype**
    *   Newsy æœˆã¨ Non-newsy æœˆã§  
         $r_t = \alpha + \beta S_{t-1} + \varepsilon_t$  ã® Î² ã®ç¬¦å·ãŒç•°ãªã‚‹ã‹ã‚’æ¤œè¨¼
    *   ã“ã‚Œã¯ã€ŒS ã‚’ãã®ã¾ã¾ä½¿ã†ã¨æœˆã‚¿ã‚¤ãƒ—ã§äºˆæ¸¬æ–¹å‘ãŒå¤‰ã‚ã‚‹ â†’ ãã‚Œã‚’ 1 å¤‰æ•°ã«ã¾ã¨ã‚ã‚‹ã®ãŒ x\_tã€ã¨ã„ã† Method 6 ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’è£ä»˜ã‘ã‚‹åˆ†æ
4.  **sort\_x\_quintiles**
    *   x\_t ã‚’åˆ†ä½ç‚¹ã§ã‚½ãƒ¼ãƒˆã—ã€å„ quintile ã®  $r_{t+1}$  å¹³å‡ï¼ˆå¹´ç‡ï¼‰ã‚’è¦‹ã‚‹
    *   x ãŒå¤§ãã„ã»ã©å°†æ¥ãƒªã‚¿ãƒ¼ãƒ³ãŒå˜èª¿ã«æ¸›ã‚‹ï¼ˆã¾ãŸã¯å¢—ãˆã‚‹ï¼‰ãªã‚‰ã€  
        ã€Œx ãŒ mispricing ã®æ–¹å‘ã¨å¤§ãã•ã‚’è¡¨ã—ã¦ã„ã‚‹ã€ã¨ã„ã†ä»®å®šã‚’ã‚µãƒãƒ¼ãƒˆ
5.  **rolling\_corr\_x\_ret**
    *   10 å¹´ãƒ­ãƒ¼ãƒ«ã§ Corr(x\_t, r\_{t+1}) ã‚’å¯è¦–åŒ–
    *   ç›¸é–¢ãŒå®‰å®šã—ã¦ã„ã‚Œã°ã€Œæ§‹é€ çš„ãªé–¢ä¿‚ã€ã€  
        æ™‚æœŸã«ã‚ˆã£ã¦å¤§ããå¤‰ã‚ã‚Œã°ã€Œregime shift ãŒã‚ã‚‹ã€ãªã©ã®è§£é‡ˆ
6.  **predictability\_by\_monthtype**
    *   N / R / 3 åˆ¥ã«  $r_{t+1} ~ x_t$  ã‚’å›å¸°
    *   x\_t ãŒã©ã®æœˆã‚¿ã‚¤ãƒ—ã§å¼·ãåŠ¹ã„ã¦ã„ã‚‹ã‹ï¼ˆNewsy ã§ç‰¹ã«å¼·ã„ï¼Non-newsy ã§å¼·ã„ç­‰ï¼‰ã‚’ç¢ºèªã—ã€  
        Guo ã®ç†è«–ï¼ˆNewsy vs Repetitiveï¼‰ã®éå¯¾ç§°æ€§ã¨æ•´åˆã™ã‚‹ã‹ã‚’è¦‹ã‚‹

* * *

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€Œæˆ¦ç•¥ãƒªã‚¿ãƒ¼ãƒ³ã€ã‚’è¨ˆç®—ã›ãšã€**ãƒãƒ¼ã‚±ãƒƒãƒˆãƒªã‚¿ãƒ¼ãƒ³ãã®ã‚‚ã®ã¨ Method 6 ã®ã‚·ã‚°ãƒŠãƒ«æ§‹é€ ã®é–¢ä¿‚**ã ã‘ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚

*   å¿…è¦ã§ã‚ã‚Œã°ã€ã“ã®ä¸Šã«
    *   rolling OOS RÂ²ï¼ˆwindow ã”ã¨ã®äºˆæ¸¬åŠ›ï¼‰
    *   ã‚µãƒ–ã‚µãƒ³ãƒ—ãƒ«ï¼ˆ1926â€“1960, 1960â€“1990, 1990â€“2025ï¼‰æ¯”è¼ƒ  
        ãªã©ã‚’è¿½åŠ ã—ã¦ã€è«–æ–‡ Table 3 / 4 ã«è¿‘ã„å½¢å¼ã®æ¤œè¨¼ã‚‚çµ„ã¿è¾¼ã‚ã¾ã™ã€‚

## Response:
ä»¥ä¸‹ã«ã€**å­¦è¡“çš„ã§å°‚é–€å®¶å‘ã‘**ã€ã‹ã¤ **Method 6ï¼ˆNewsy/Repetitive æ§‹é€  Ã— Mispricing Signal x\_t Ã— Online Î²\_t æ¨å®š Ã— ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒ†ã‚£ãƒ³ã‚°ï¼‰** ã®ç‰¹å¾´ã‚’æ­£ç¢ºã«åæ˜ ã—ãŸåç§°å€™è£œã‚’åºƒç¯„ã«åˆ—æŒ™ã—ã¾ã™ã€‚

åˆ†é¡ã¯ï¼š

*   **A. å­¦è¡“è«–æ–‡é¢¨ã®æ­£å¼åç§°**
*   **B. å®Ÿå‹™å¯„ã‚Šã®æˆ¦ç•¥åç§°ï¼ˆQuant å®Ÿè£…ãƒãƒ¼ãƒ ã§ä½¿ã‚ã‚Œã‚‹ã‚¿ã‚¤ãƒ—ï¼‰**
*   **C. ã‚·ã‚°ãƒŠãƒ«é‡è¦–å‹ã®åç§°**
*   **D. ç†è«–çš„èƒŒæ™¯ï¼ˆæƒ…å ±å‘¨æœŸ / Mispricing / News Flowï¼‰ã‚’åæ˜ ã—ãŸåç§°**
*   **E. ç•¥ç§°ï¼ˆ3â€“5æ–‡å­—ï¼‰**
*   **F. ä¼æ¥­å‘ã‘ãƒ—ãƒ¬ã‚¼ãƒ³ã§ã‚‚ä½¿ãˆã‚‹è¡¨ç¾**

ã«åˆ†ã‘ã¾ã—ãŸã€‚

* * *

A. å­¦è¡“è«–æ–‡é¢¨ï¼ˆæ­£å¼åã¨ã—ã¦ä½¿ãˆã‚‹ï¼‰
===================

1.  **Cyclic Informationâ€“Adjusted Market Timing Strategy (CIAMTS)**
2.  **News-Cycle Mispricing Timing Strategy (NCMTS)**
3.  **Conditional Information-Cycle Return Forecasting Strategy**
4.  **Information Cycleâ€“Adjusted Î²â€“x Strategy**
5.  **Newsy-Repetitive Cycle Forecasting Model (NRC-FM)**
6.  **Earnings-Extrapolationâ€“Adjusted Market Risk Premia Strategy**
7.  **Cyclic Mispricing Premium Strategy (CMPS)**
8.  **News-Flow Corrected Market-Timing Strategy (NFC-MTS)**
9.  **Dynamic Information Asymmetry Timing Strategy**
10.  **Cyclic News Shockâ€“Driven Expected Return Model**

* * *

B. å®Ÿå‹™å¯„ã‚Šï¼ˆã‚¯ã‚ªãƒ³ãƒ„é‹ç”¨ãƒãƒ¼ãƒ ã§ä¸€èˆ¬çš„ã«ä½¿ã‚ã‚Œã‚‹ã‚¿ã‚¤ãƒ—ï¼‰
==============================

1.  **Cycle-Adjusted Timing (CAT) Strategy**
2.  **News-Flow Timing (NFT)**
3.  **Cyclic Mispricing Timing (CMT)**
4.  **Dynamic Î²â€“x Timing Model (DXT)**
5.  **Information-Cycle Signal Strategy (ICS)**
6.  **News-Adjusted Expected Return Signal (NAERS)**
7.  **Alpha-from-News-Cycle Strategy (ANCS)**
8.  **Rolling Î²â€“x Market Timing**
9.  **Informationâ€“Regime Timing Strategy (IRTS)**
10.  **News-Shock Cycle Model (NSCM)**

* * *

C. ã‚·ã‚°ãƒŠãƒ«åç§°ï¼ˆxâ‚œ ãŒä¸­å¿ƒï¼‰
=================

1.  **x-Signal Timing Strategy**
2.  **Î²â€“x Forecasting Strategy**
3.  **x-Cycle Signal Model**
4.  **Cyclic-x Market Premium Strategy**
5.  **x-Based Mispricing Strategy (x-MPS)**
6.  **Dynamic x-Premium Strategy (DxPS)**
7.  **Cyclic x-Return Predictor**

* * *

D. ç†è«–èƒŒæ™¯ã‚’å¼·èª¿ï¼ˆNewsy / Repetitive ã‚µã‚¤ã‚¯ãƒ«ï¼‰
===================================

1.  **Newsy-Repetitive Cycle Timing Strategy (NRCTS)**
2.  **Newsy Cycle Mispricing Strategy (NCMS)**
3.  **Information-Cycle Premium Strategy (ICPS)**
4.  **Newsy Reversalâ€“Corrected Timing Model**
5.  **Cyclic News Interpretation Strategy (CNIS)**
6.  **News-Shock Persistence/Correction Model**
7.  **Short-Horizon Information-Cycle Model (SHICM)**

* * *

E. ç•¥ç§°ï¼ˆ3ã€œ5 æ–‡å­—ã§è¦šãˆã‚„ã™ã„ã‚‚ã®ï¼‰
=====================

1.  **CMT**ï¼ˆCyclic Mispricing Timingï¼‰
2.  **CAT**ï¼ˆCycle-Adjusted Timingï¼‰
3.  **NFT**ï¼ˆNews-Flow Timingï¼‰
4.  **ICM**ï¼ˆInformation-Cycle Modelï¼‰
5.  **NCM**ï¼ˆNews-Cycle Modelï¼‰
6.  **DXT**ï¼ˆDynamic Î²â€“x Timingï¼‰
7.  **XTS**ï¼ˆx-Timing Strategyï¼‰
8.  **CMS**ï¼ˆCyclic Mispricing Strategyï¼‰
9.  **ISC**ï¼ˆInformation Signal Cycleï¼‰
10.  **NCS**ï¼ˆNewsy Cycle Strategyï¼‰

* * *

F. ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ»è«–æ–‡ã‚¿ã‚¤ãƒˆãƒ«ã§ä½¿ãˆã‚‹æ´—ç·´ã•ã‚ŒãŸåç§°
=========================

1.  **â€œA Market Timing Strategy Based on the Cyclic Structure of Information Flowâ€**
2.  **â€œReturn Forecasting via Cyclic News-Shock Mispricingâ€**
3.  **â€œAn x-Signal Approach to Cyclic Expected Returnsâ€**
4.  **â€œInformation-Cycleâ€“Adjusted Market Risk Premiumsâ€**
5.  **â€œLeveraging Cyclic Mispricing for Equity Market Timingâ€**
6.  **â€œA Dynamic Î²â€“x Model for Equity Return Predictabilityâ€**

* * *

æ¨è–¦ï¼ˆã‚ãªãŸã®å®Ÿè£…ã«æœ€ã‚‚åˆã†åç§°ï¼‰
=================

æœ€ã‚‚æ­£ç¢ºã«ç‰¹å¾´ã‚’æ‰ãˆã¦ã„ã‚‹åç§°
---------------

> **Cyclic Mispricing Timing (CMT) Strategy**

ç†ç”±ï¼š

*   Method 6 ã®ä¸­æ ¸ **Î²\_t Ã— x\_t** ã¯ã€Œå¾ªç’°çš„ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ï¼ˆCyclic Mispricingï¼‰ã€ã®è£œæ­£
*   Timing æˆ¦ç•¥ã§ã‚ã‚‹ã“ã¨ãŒæ˜ç­
*   ç•¥ç§°ï¼ˆCMTï¼‰ãŒã‚·ãƒ³ãƒ—ãƒ«ã§è¦šãˆã‚„ã™ã„
*   è«–æ–‡ã‚¿ã‚¤ãƒˆãƒ«ã«ã‚‚ç ”ç©¶ä¼šç™ºè¡¨ã«ã‚‚ä½¿ãˆã‚‹

ã‚‚ã†ä¸€ã¤ã®å¼·ã„å€™è£œ
---------

> **News-Cycle Mispricing Timing Strategy (NCMTS)**

ç†ç”±ï¼š

*   Newsy / Repetitive ã®æ§‹é€ ã‚’æ˜ç¤º
*   Mispricing Ã— Timing ã‚’æ­£ç¢ºã«èª¬æ˜
*   Method 6 ã®å…¨ä½“åƒã‚’ãã®ã¾ã¾è¨€èªåŒ–ã—ã¦ã„ã‚‹

* * *

å¿…è¦ã§ã‚ã‚Œã°ï¼š
=======

*   åç§°ã®ä¸­ã‹ã‚‰ **æ­£å¼åç§° + ç•¥ç§°** ã®ãƒšã‚¢ã‚’ä½œã‚‹
*   è«–æ–‡ã‚¿ã‚¤ãƒˆãƒ«ç”¨ã«æœ€é©åŒ–
*   æ—¥æœ¬èªåç§°ï¼ˆä¾‹ï¼šæƒ…å ±ã‚µã‚¤ã‚¯ãƒ«å‹ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°æˆ¦ç•¥ï¼‰ã‚’ä½œæˆ
*   ç‰¹è¨±å‡ºé¡˜/å•†æ¨™åˆ©ç”¨ã‚’æƒ³å®šã—ãŸåç§°ãƒ–ãƒ©ãƒƒã‚·ãƒ¥ã‚¢ãƒƒãƒ—

ãªã©ã‚‚å¯èƒ½ã§ã™ã€‚

ã©ã®æ–¹å‘æ€§ã§åç§°ã‚’ä»•ä¸Šã’ãŸã„ã§ã™ã‹ï¼Ÿ

## Response:
ä»¥ä¸‹ã§ã¯ã€**CMTï¼ˆCyclic Mispricing Timingï¼‰Strategy**  
ã¾ãŸã¯ **symmetric Earnings-Cycle Momentum** ã‚’éƒ¨å†…å‘ã‘ã«èª¬æ˜ã™ã‚‹ãŸã‚ã®  
**ç†è«–ï¼‹æ•°ç†ãƒ¢ãƒ‡ãƒ«ï¼‹å®Ÿè¨¼è£œå¼·** ã‚’çµ±åˆã—ãŸã€Œãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æ§‹æˆæ¡ˆã€ã‚’ç¤ºã—ã¾ã™ã€‚

Guo (2025), Guo & Wachter (2025) ã®å†…å®¹ã‚’åœŸå°ã«ã—ã€  
ã‚ãªãŸãŒæ—¢ã«ä½œæˆã—ãŸ Method 6 å‘ã‘å®Ÿè¨¼åˆ†æãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ä½¿ã£ã¦ã€  
**ç†è«– â†’ äºˆæ¸¬å¼ â†’ ã‚·ã‚°ãƒŠãƒ«æ§‹ç¯‰ â†’ æ¤œè¨¼ â†’ æˆ¦ç•¥åŒ–** ã®æµã‚Œã§ç†è§£ã§ãã‚‹  
**å­¦è¡“çš„ã«ä¸€è²«ã—ãŸç™ºè¡¨** ã«ãªã‚‹ã‚ˆã†ã«æ§‹æˆã—ã¦ã„ã¾ã™ã€‚

* * *

â–  ãƒ—ãƒ¬ã‚¼ãƒ³å…¨ä½“æ§‹æˆï¼ˆ10â€“15 åˆ†æƒ³å®šï¼‰
=====================

* * *

1\. å•é¡Œæ„è­˜ï¼šãªãœã€Œæƒ…å ±ã‚µã‚¤ã‚¯ãƒ«ã€ã‚’åˆ©ç”¨ã™ã‚‹ã®ã‹ï¼Ÿ
===========================

å¸‚å ´ã§ã¯ã€çŸ­æœŸçš„ã«ä»¥ä¸‹ãŒç”Ÿã˜ã‚‹ï¼š

*   **æ–°ã—ã„æƒ…å ±ãŒé›†ä¸­çš„ã«åæ˜ ã•ã‚Œã‚‹æœˆï¼ˆNewsyï¼‰**
*   **ãã®æƒ…å ±ãŒæƒ°æ€§çš„ã«ç¹°ã‚Šè¿”ã•ã‚Œã‚‹æœˆï¼ˆRepetitiveï¼‰**

ã“ã‚Œã¯ Guo (2025), Guo & Wachter (2025) ãŒç¤ºã™  
**earnings extrapolationï¼ˆåç›Šã®éå‰°åå¿œï¼‰** ã¨  
**correlation neglectï¼ˆç›¸é–¢ã®ç„¡è¦–ï¼‰** ã«èµ·å› ã™ã‚‹ **è¡Œå‹•çš„ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ã®å‘¨æœŸæ§‹é€ **ã€‚

ã™ãªã‚ã¡å¸‚å ´å‚åŠ è€…ã¯ä»¥ä¸‹ã®ãƒã‚¤ã‚¢ã‚¹ã‚’ã‚‚ã¤ï¼š

*   Newsy æœˆï¼šãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’â€œç‹¬ç«‹â€ã¨èª¤èª â†’ ä¾¡æ ¼åå¿œãŒå¤§ãããªã‚‹
*   ãã®ç¿Œæœˆï¼šãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’â€œç¹°ã‚Šè¿”ã—â€ã¨èª¤èª â†’ éå»ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®å½±éŸ¿ãŒå¼±ã¾ã‚‹

ã“ã‚Œã«ã‚ˆã‚Šã€

$$
E[r_t] \text{ ã¯ 3 ãƒ¶æœˆå‘¨æœŸã®æ§‹é€ ã‚’æŒã¤}
$$

ã¨ã„ã†ä»®èª¬ã‚’æç¤ºã™ã‚‹ã€‚

* * *

2\. ç†è«–ãƒ¢ãƒ‡ãƒ«ã®æ•°ç†ï¼ˆMethod 6 ã®åŸºç¤ï¼‰
==========================

Guo (2025) ã®ã‚³ã‚¢ä»®å®šï¼š

### (1) å¸‚å ´ãƒªã‚¿ãƒ¼ãƒ³ã¯ **æœ¬æºçš„ãƒ—ãƒ¬ãƒŸã‚¢ãƒ  + ã‚µã‚¤ã‚¯ãƒ«èª¤å·®** ã«åˆ†è§£ã•ã‚Œã‚‹

$$
r_t = \mu + \eta_t + \epsilon_t
$$

ã“ã“ã§ï¼š

*    $\mu$ ï¼šé•·æœŸãƒªã‚¹ã‚¯ãƒ—ãƒ¬ãƒŸã‚¢ãƒ 
*    $\eta_t$ ï¼š**æƒ…å ±ã‚µã‚¤ã‚¯ãƒ«èµ·æºã®ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°æˆåˆ†**
*    $\epsilon_t$ ï¼šãƒã‚¤ã‚º

### (2) ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°æˆåˆ†ã¯ Newsy æœˆã®ç´¯ç©ã‚·ãƒ§ãƒƒã‚¯ã§è¿‘ä¼¼

Newsy æœˆã®ç·åˆæŒ‡æ¨™ï¼š

$$
S_t = \sum_{j=0}^{3} R_{N_{t-j}}
$$

ï¼ˆç›´è¿‘4å›ã® Newsy æœˆã®ãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³ã®åˆè¨ˆï¼‰

ã—ã‹ã— S ãã®ã¾ã¾ã§ã¯ Newsy æœˆãƒ»é Newsy æœˆã§ **ç¬¦å·ãŒå¤‰ã‚ã‚‹**ãŸã‚  
ä¸€ã¤ã®ã‚·ã‚°ãƒŠãƒ«ã¨ã—ã¦æ‰±ã„ã¥ã‚‰ã„ã€‚

* * *

3\. x\_t ã®æ§‹ç¯‰ï¼ˆç†è«–ã‹ã‚‰å°ã‹ã‚Œã‚‹ Mispricing æŒ‡æ¨™ï¼‰
====================================

Guo ã¯ **å¯¾ç§°åŒ–ã—ãŸ Mispricing Signal** ã‚’å®šç¾©ï¼š

$$
x_t = \text{sign}(t) \cdot (S_{t-1} - \bar S_{t-1})
$$
*   Newsy æœˆ â‡’ sign = âˆ’1  
    â†’ éå‰°åå¿œã®ä¿®æ­£æ–¹å‘ã‚’åæ˜ 
*   é Newsy æœˆ â‡’ sign = +1  
    â†’ é…å»¶åå¿œï¼ˆunder-reactionï¼‰ã‚’åæ˜ 

ã“ã‚Œã«ã‚ˆã‚Š **1 å¤‰æ•°ã§å…¨æœŸé–“ã®ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ã‚’è¡¨ç¾**ã§ãã‚‹ã€‚

* * *

4\. äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®å°å‡ºï¼ˆMethod 6 ã®ä¸­æ ¸ï¼‰
==========================

å¸‚å ´ã®ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ãŒç·šå½¢ã«ãƒªã‚¿ãƒ¼ãƒ³ã¸åæ˜ ã•ã‚Œã‚‹ã¨ä»®å®šã™ã‚‹ã¨ï¼š

$$
r_{t+1} - \bar r_t = \beta x_t + \varepsilon_{t+1}
$$

é‡è¦ãƒã‚¤ãƒ³ãƒˆï¼š

*   å·¦è¾ºã¯ã€Œå¸‚å ´ãƒªã‚¿ãƒ¼ãƒ³ã®ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°å¹³å‡ã‹ã‚‰ã®ä¹–é›¢ã€
*   å³è¾ºã¯ã€Œæƒ…å ±ã‚µã‚¤ã‚¯ãƒ«èµ·æºã® mispricing ã‚·ã‚°ãƒŠãƒ«ã€
*    $\beta$  ã¯ **expanding ã‚‚ã—ãã¯ rolling OLS ã§æ™‚å¤‰æ¨å®š**

æˆ¦ç•¥ã‚·ã‚°ãƒŠãƒ«ã¯ï¼š

$$
w_t^{\text{raw}} = \beta_t x_t
$$

* * *

5\. CMTï¼ˆCyclic Mispricing Timingï¼‰æˆ¦ç•¥ã®å®šç¾©
======================================

$$
w_t = k \cdot \beta_t x_t
$$

ã“ã“ã§ k ã¯ **ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¿ãƒ¼ã‚²ãƒƒãƒ†ã‚£ãƒ³ã‚°ä¿‚æ•°**

$$
k = \frac{\sigma^\*}{\sigma_{\text{strategy}}}
$$

ï¼ˆMoreira & Muir 2017 å‹ã®æ¨™æº–æ‰‹æ³•ï¼‰

* * *

6\. ç†è«–ä»®å®šã®å®Ÿè¨¼çš„è£œå¼·ï¼ˆMethod 6 ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯ï¼‰
=================================

ä»¥ä¸‹ã® **å®Ÿè¨¼åˆ†æãƒ—ãƒ­ã‚°ãƒ©ãƒ **ã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€ç†è«–ä»®å®šã‚’è£ä»˜ã‘ã‚‰ã‚Œã‚‹ã€‚

* * *

ï¼ˆ1ï¼‰S ã®ç¬¦å·åè»¢ï¼ˆNewsy vs Non-Newsyï¼‰
------------------------------

Newsy æœˆï¼š

$$
\beta_N < 0
$$

Non-Newsy æœˆï¼š

$$
\beta_O > 0
$$

**å®Ÿè¨¼çµæœï¼ˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ç¢ºèªï¼‰**  
â†’ Guo ãŒä¸»å¼µã™ã‚‹ **ãƒ‹ãƒ¥ãƒ¼ã‚¹éå‰°åå¿œï¼ˆNewsyï¼‰ãƒ»é…å»¶åå¿œï¼ˆR+3ï¼‰** ã®éå¯¾ç§°æ€§ãŒå†ç¾ã•ã‚Œã‚‹ã€‚

* * *

ï¼ˆ2ï¼‰x\_t ã® predictabilityï¼ˆãƒªã‚¿ãƒ¼ãƒ³äºˆæ¸¬åŠ›ï¼‰
---------------------------------

å›å¸°ï¼š

$$
r_{t+1} = \alpha + \beta x_t + \epsilon_t
$$

å®Ÿè¨¼ã§ã¯ï¼š

*   Î² > 0ï¼ˆæœ‰æ„ï¼‰
*   x ã®äº”åˆ†ä½ã‚½ãƒ¼ãƒˆã§ **å˜èª¿ã« r\_{t+1} ãŒä¸Šæ˜‡**
*   ãƒ­ãƒ¼ãƒªãƒ³ã‚°ç›¸é–¢ã§ã‚‚é–¢ä¿‚ãŒå®‰å®š

â†’ **x ãŒæœ‰åŠ¹ãª Mispricing Signal**ã§ã‚ã‚‹ã“ã¨ã‚’è£œå¼·ã€‚

* * *

ï¼ˆ3ï¼‰Method 6 ã®å°å‡ºã‚’è£ä»˜ã‘ã‚‹æ§‹é€ çš„è¨¼æ‹ 
-------------------------

*   x ã¨ S ã® scatter â†’ x ãŒ â€œå¯¾ç§°åŒ–ã•ã‚ŒãŸ Sâ€ ã‚’æ­£ã—ãè¡¨ç¾
*   rolling vs expanding Î²\_t ã®æ¯”è¼ƒ â†’  
    å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ å¤‰åŒ–ã«å¿œã˜ã¦ä¿‚æ•°ãŒå®‰å®šã—ã¦å¤‰å‹•

â†’ ã€Œæƒ…å ±ã‚µã‚¤ã‚¯ãƒ«ã«åŸºã¥ãæ™‚å¤‰ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ã€ã¨ã„ã†ä»®å®šã‚’ã‚µãƒãƒ¼ãƒˆã€‚

* * *

7\. æˆ¦ç•¥ã¨ã—ã¦ã®ä½ç½®ã¥ã‘ï¼ˆCMT ã®æ„ç¾©ï¼‰
=======================

1.  **å› æœçš„ã§ã‚ã‚‹**  
    x\_t ã¯ã€Œéå»ã® Newsy shock ã®è“„ç©ã€ãŒå¼•ãèµ·ã“ã™ mispricing ã®é›†ç´„æŒ‡æ¨™ã€‚  
    _å˜ãªã‚‹çµ±è¨ˆçš„éå»å¹³å‡ã§ã¯ãªã„ã€‚_
2.  **è¡Œå‹•ãƒ•ã‚¡ã‚¤ãƒŠãƒ³ã‚¹ç†è«–ã«æ ¹å·®ã™**
    *   earnings extrapolation
    *   correlation neglect
3.  **å¯¾ç§°çš„ï¼ˆsymmetricï¼‰ã§ã‚ã‚‹**  
    ãƒ»Newsy æœˆã¯é€†å¼µã‚Š  
    ãƒ»Non-Newsy æœˆã¯é †å¼µã‚Š  
    â†’ ESGãƒ»é‡‘åˆ©ã‚µã‚¤ã‚¯ãƒ«ã‚’å«ã‚€æ‹¡å¼µå¯èƒ½æ€§ãŒã‚ã‚‹ã€‚
4.  **å¸‚å ´ã‚µã‚¤ã‚¯ãƒ«ã«å¼·ã„**  
    x ã¯ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ã‚·ãƒ§ãƒƒã‚¯ã‚’å¹³æ»‘åŒ–ã™ã‚‹ãŸã‚ã€  
    **å¸‚å ´ã® regime shift ã«å¯¾ã—ã¦ãƒ­ãƒã‚¹ãƒˆ**ã€‚

* * *

8\. éƒ¨å†…ãƒ—ãƒ¬ã‚¼ãƒ³ã®æ¨å¥¨æ§‹æˆã‚¹ãƒ©ã‚¤ãƒ‰ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ï¼‰
=========================

* * *

### ã‚¹ãƒ©ã‚¤ãƒ‰ 1. æˆ¦ç•¥æ¦‚è¦

*   Strategy name: **Cyclic Mispricing Timing (CMT)**
*   åŸºæœ¬ã‚¢ã‚¤ãƒ‡ã‚¢ï¼š**æƒ…å ±ã‚µã‚¤ã‚¯ãƒ«ï¼ˆNewsy / Repetitiveï¼‰ã«ã‚ˆã‚‹ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ã‚’æ´»ç”¨**

* * *

### ã‚¹ãƒ©ã‚¤ãƒ‰ 2. æƒ…å ±ã‚µã‚¤ã‚¯ãƒ«ã®å­˜åœ¨ï¼ˆæ–‡çŒ®ï¼‰

*   Guo (2025)ï¼šNewsy vs Repetitive shock
*   Guo & Wachter (2025)ï¼šCorrelation Neglect Ã— Earnings Extrapolation
*   å®Ÿè¨¼çš„ã« **3 ãƒ¶æœˆå‘¨æœŸæ§‹é€ ** ãŒè¦³æ¸¬ã•ã‚Œã‚‹

* * *

### ã‚¹ãƒ©ã‚¤ãƒ‰ 3. S\_t ã¨ x\_t ã®æ•°ç†å°å‡º

*   æ•°å¼
*   ç¬¦å·åè»¢ã®è«–ç†
*   x ãŒ â€œcycle-corrected mispricing signalâ€ ã§ã‚ã‚‹ã“ã¨ã‚’èª¬æ˜

* * *

### ã‚¹ãƒ©ã‚¤ãƒ‰ 4. ãƒªã‚¿ãƒ¼ãƒ³äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ï¼ˆMethod 6ï¼‰

*   $$
    r_{t+1} - \bar r_t = \beta_t x_t
    $$
*   æ™‚å¤‰ Î² ã® OLS æ¨å®šï¼ˆexpanding / rollingï¼‰

* * *

### ã‚¹ãƒ©ã‚¤ãƒ‰ 5. æˆ¦ç•¥åŒ–

*   $$
    w_t = k \beta_t x_t
    $$
*   ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒ†ã‚£ãƒ³ã‚°ã®ç†è«–çš„æ­£å½“åŒ–ï¼ˆMoreira & Muir 2017ï¼‰

* * *

### ã‚¹ãƒ©ã‚¤ãƒ‰ 6. å®Ÿè¨¼ï¼šS ã®ç¬¦å·åè»¢ï¼ˆæ ¸å¿ƒä»®å®šï¼‰

*   Newsy â†’ Reversal
*   Non-Newsy â†’ Continuation
*   Method 6 ã®å°å‡ºã®æ ¹æ‹ ãŒãƒ‡ãƒ¼ã‚¿ã§ç¢ºèªã§ãã‚‹

* * *

### ã‚¹ãƒ©ã‚¤ãƒ‰ 7. å®Ÿè¨¼ï¼šx ã®äºˆæ¸¬åŠ›

*   å›å¸° Î²
*   quintile ã‚½ãƒ¼ãƒˆ
*   rolling correlation

â†’ x ãŒã€Œèª¤å·®æˆåˆ†ã®å¼·å¼±ã€ã‚’æ¸¬å®šã—ã¦ã„ã‚‹ã“ã¨ã‚’è¨¼æ˜

* * *

### ã‚¹ãƒ©ã‚¤ãƒ‰ 8. Î²\_t ã®æ™‚å¤‰æ€§

*   rolling vs expanding Î²\_t ã‚°ãƒ©ãƒ•  
    â†’ å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ ã¨ mispricing å¼·åº¦ãŒé€£å‹•

* * *

### ã‚¹ãƒ©ã‚¤ãƒ‰ 9. æˆ¦ç•¥ã®æ„ç¾©

*   è¡Œå‹•ç†è«–ï¼‹æƒ…å ±ã‚µã‚¤ã‚¯ãƒ«ã«åŸºã¥ãä¸€è²«ã—ãŸãƒªã‚¿ãƒ¼ãƒ³ãƒ¢ãƒ‡ãƒ«
*   symmetric earnings-cycle momentum ã¨ã—ã¦ä½“ç³»åŒ–
*   ä»Šå¾Œã®æ‹¡å¼µï¼ˆæ¥­ç¨®ã€å›½ã€ãƒœãƒ©ãƒ¢ãƒ‡ãƒ« etc.ï¼‰

* * *

9\. æœ€çµ‚ã¾ã¨ã‚ï¼ˆãƒ—ãƒ¬ã‚¼ãƒ³ã®æ ¸ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰
======================

> **CMT æˆ¦ç•¥ã¯ã€æƒ…å ±ã‚µã‚¤ã‚¯ãƒ«ãŒç”Ÿã¿å‡ºã™ãƒŸã‚¹ãƒ—ãƒ©ã‚¤ã‚·ãƒ³ã‚°ã®å‘¨æœŸæ€§ã‚’ã€  
> å¯¾ç§°çš„ã«ä¿®æ­£ã™ã‚‹ x ã‚·ã‚°ãƒŠãƒ«ã¨æ™‚å¤‰ Î² ã«åŸºã¥ãã€  
> æ§‹é€ çš„ãƒ»ç†è«–çš„ã«è£ä»˜ã‘ã‚‰ã‚ŒãŸæˆ¦ç•¥ã§ã‚ã‚‹ã€‚**

å˜ãªã‚‹éå»ãƒªã‚¿ãƒ¼ãƒ³ã®å›å¸°ã¨ã¯ç•°ãªã‚Šï¼š

*   Newsy / Repetitive ã®æƒ…å ±æ§‹é€ 
*   earnings extrapolation ã®è¡Œå‹•ãƒã‚¤ã‚¢ã‚¹
*   mispricing ã®å¯¾ç§°æ€§
*   return forecasting ã®æ™‚å¤‰æ§‹é€ 

ã‚’çµ±åˆã—ãŸãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ä½ç½®ã¥ã‘ã‚‰ã‚Œã‚‹ã€‚

* * *

å¿…è¦ã§ã‚ã‚Œã°ï¼š

*   ä¸Šè¨˜ã‚¹ãƒ©ã‚¤ãƒ‰ã‚’ \*\*PowerPointï¼ˆå›³å…¥ã‚Šï¼‰\*\*ã§ä½œæˆ
*   æ•°å¼ã®ã‚ˆã‚Šå³å¯†ãªå°å‡ºï¼ˆæœŸå¾…å€¤æ¼”ç®—å­ã«ã‚ˆã‚‹è¨¼æ˜ï¼‰
*   x\_t ã®çµ±è¨ˆçš„æ€§è³ªã®è¿½åŠ åˆ†æï¼ˆADFã€Ljung-Box, HEGYï¼‰
*   åˆ¥æˆ¦ç•¥ï¼ˆMethod 5 / z\*\_tï¼‰ã¨ã®æ¯”è¼ƒã‚¹ãƒ©ã‚¤ãƒ‰

ãªã©ã‚‚æä¾›ã§ãã¾ã™ã€‚

ã©ã®å½¢å¼ã§ã‚¹ãƒ©ã‚¤ãƒ‰ã‚’ç”Ÿæˆã—ã¾ã—ã‚‡ã†ã‹ï¼Ÿ

## Response:
æ€è€ƒæ™‚é–“: 1m 54s

ã¾ãšçµè«–ã‹ã‚‰è¨€ã†ã¨ã€ã„ã¾å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹ Method 6ï¼ˆï¼‹ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒ†ã‚£ãƒ³ã‚°ï¼‰ã¯ã€

*   Guo (2025, _RFS_) ã®
    1.  ã€Œã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼ãƒ»ãƒ¢ãƒ‡ãƒ«ã€éƒ¨åˆ†ï¼ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ 5ï¼‰
    2.  ã€ŒU.S. æœˆæ¬¡ãƒªã‚¿ãƒ¼ãƒ³ã®äºˆæ¸¬å›å¸°ã€éƒ¨åˆ†ï¼ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ 3.2, Table 2ï¼‰

ã‚’çµ„ã¿åˆã‚ã›ã¦ã€**ç†è«–ãƒ¢ãƒ‡ãƒ«ä¸Šã®çŠ¶æ…‹å¤‰æ•°  $x_t^{\exp}$ ** ã‚’ã€**éå»ã® â€œnewsy monthâ€ ãƒªã‚¿ãƒ¼ãƒ³ã®ç·šå½¢çµåˆ**ã¨ã—ã¦æ¨å®šã—ã€ãã‚Œã‚’**ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ»ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ãŸã‚¿ã‚¤ãƒŸãƒ³ã‚°æˆ¦ç•¥**ã«è½ã¨ã—è¾¼ã‚“ã ã‚‚ã®ã€ã¨ã„ã†ä½ç½®ã¥ã‘ã«ãªã‚Šã¾ã™ã€‚

ä»¥ä¸‹ã€æ•°å¼ãƒ¬ãƒ™ãƒ«ã§å³å¯†ã«æ•´ç†ã—ã¤ã¤ã€ã€Œã©ã®å¼ãŒ Guo ã®ã©ã®å¼ï¼éƒ¨åˆ†ã«å¯¾å¿œã—ã¦ã„ã‚‹ã‹ã€ã‚’ã§ãã‚‹ã ã‘æ˜ç¤ºã—ã¾ã™ã€‚

* * *

1\. Guo (2025) ã®ç†è«–ãƒ–ãƒ­ãƒƒã‚¯ã¨å¼ç•ªå·ã¨ã®å¯¾å¿œ
------------------------------

### 1.1 ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼ãƒ»ãƒ—ãƒ­ã‚»ã‚¹ã¨çŠ¶æ…‹å¤‰æ•°

Guo (2025) ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 5 ã§ã¯ã€**é…å½“æˆé•·ã‚·ãƒ§ãƒƒã‚¯**  $db_{t+1}$  ãŒ  
ã€Œnewsy æœŸ (E) ã¨ late æœŸ (L) ã§ç•°ãªã‚‹ä¿‚æ•°ã‚’æŒã¤ã€ã“ã¨ã‚’æ˜ç¤ºçš„ã«çµ„ã¿è¾¼ã‚“ã ãƒ¢ãƒ‡ãƒ«ãŒç½®ã‹ã‚Œã¦ã„ã¾ã™ã€‚

PDF ã®å¼ç•ªå· (4) ã«ç›¸å½“ã™ã‚‹ã®ãŒã€æ¬¡ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼ãƒ»ãƒ—ãƒ­ã‚»ã‚¹ã§ã™ï¼š[OUP Academic](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf)

$$
db_{t+1} = x^{\text{act}}_t + u_{t+1} = \begin{cases} e^{-0.5\delta} \, x^{\exp}_t + u_{t+1} & \text{if } t \text{ is newsy (E)},\\[4pt] e^{+0.5\delta} \, x^{\exp}_t + u_{t+1} & \text{if } t \text{ is late (L)}. \end{cases} \tag{Guo (2025), Eq. (4)}
$$

ã“ã“ã§

*    $x^{\exp}_t$ ï¼šæŠ•è³‡å®¶ãŒæŠ±ã„ã¦ã„ã‚‹ã€Œé–¢é€£ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼ã®æœŸå¾…ã€ï¼ˆstate variableï¼‰
*    $\delta>0$ ï¼šE ã¨ L ã®ã‚ªãƒ¼ãƒˆã‚³ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å·®ã‚’è¡¨ã™ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
*    $u_{t+1}$ ï¼šã‚·ãƒ§ãƒƒã‚¯ï¼ˆiid æ­£è¦ï¼‰

ã§ã™ã€‚E æœŸã§ã¯  $e^{-0.5\delta}<1$ ã€L æœŸã§ã¯  $e^{+0.5\delta}>1$  ã«ãªã‚Šã€**åŒã˜  $x^{\exp}_t$  ã«å¯¾ã™ã‚‹æœŸå¾…æˆé•·ã®å¤§ãã•ãŒã€E ã¨ L ã§éå¯¾ç§°**ã«ãªã‚Šã¾ã™ã€‚

### 1.2 ä¾¡æ ¼ãƒ»ãƒªã‚¿ãƒ¼ãƒ³ã®å°å‡ºï¼ˆEquation (5) ä»¥é™ï¼‰

Guo ã¯ç¶šã„ã¦ã€Campbellâ€“Shiller å‹ã®**ç·šå½¢è¿‘ä¼¼ãƒ¢ãƒ‡ãƒ«**ã‚’ä»®å®šã—ã€  
ä¾¡æ ¼â€“é…å½“æ¯”  $\log P_t - \log D_t$  ã‚’  $x^{\exp}_t$  ã®ç·šå½¢é–¢æ•°ã¨ã—ã¦æ›¸ãã¾ã™ã€‚

PDF ã®ãƒ†ã‚­ã‚¹ãƒˆã§ã¯ã€  
ã€ŒSubstitute the conjecture ... back into Equation (5) ...ã€ã¨ã„ã†è¨˜è¿°ãŒã‚ã‚Šã€Equation (5) ãŒ**ä¾¡æ ¼ã®å®šç¾©å¼**ï¼ˆå‰²å¼•ç¾åœ¨ä¾¡å€¤å¼ï¼‰ã«å¯¾å¿œã—ã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚[OUP Academic](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf)

ã“ã® Equation (5) ã¨ãã®å¾Œã®è§£ï¼ˆåŒã˜ã‚»ã‚¯ã‚·ãƒ§ãƒ³ 5ã€pp. 23â€“24ï¼‰ã‹ã‚‰ã€ä»¥ä¸‹ã®ã‚ˆã†ãª**1 æœŸé–“ãƒªã‚¿ãƒ¼ãƒ³ã®åˆ†è§£**ãŒå°ã‹ã‚Œã¾ã™ï¼š[OUP Academic](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf)

$$
\log(1+R_{1,t+1}) = \begin{cases} \underbrace{(e^{-0.5\delta}-1)(1-\rho)\,x^{\exp}_t}_{\text{äºˆæ¸¬å¯èƒ½æˆåˆ†ï¼šE æœŸã§ã¯è² }} +\underbrace{(1-\rho)u_{t+1}}_{\text{äºˆæ¸¬ä¸å¯èƒ½æˆåˆ†}} + \text{const}_E, & t\text{ is newsy (E)},\\[6pt] \underbrace{(e^{+0.5\delta}-1)(1-\rho)\,x^{\exp}_t}_{\text{äºˆæ¸¬å¯èƒ½æˆåˆ†ï¼šL æœŸã§ã¯æ­£}} +\underbrace{\tilde{c}\,u_{t+1}}_{\text{äºˆæ¸¬ä¸å¯èƒ½æˆåˆ†}} + \text{const}_L, & t\text{ is late (L)}. \end{cases} \tag{ï¼Š}
$$

ã“ã“ã§

*    $\rho$ ï¼šé…å½“æˆé•·ã®è‡ªå·±ç›¸é–¢
*   ä¿‚æ•°  $(e^{\pm0.5\delta}-1)(1-\rho)$  ã®ç¬¦å·ãŒã€E/L ã§åè»¢ï¼ˆE ã§ã¯è² ã€L ã§ã¯æ­£ï¼‰

ã¨ã„ã†ã®ãŒãƒã‚¤ãƒ³ãƒˆã§ã™ã€‚è¨ˆç®—ã®è©³ç´°ã¯ã€å¼ (4) ç›´å¾Œã‹ã‚‰å§‹ã¾ã‚‹ä¿‚æ•°  $a^k_n,b^k_n,c^k_n$  ã®å†å¸°å¼ï¼ˆpp. 23â€“24ï¼‰ã®è§£ã®ä¸€éƒ¨ã¨ã—ã¦ç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚[OUP Academic](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf)

#### çµŒæ¸ˆçš„å«æ„

*    $x^{\exp}_t$  ãŒé«˜ã„ï¼ˆæŠ•è³‡å®¶ãŒã€Œå°†æ¥ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼ã«å¼·æ°—ã€ï¼‰ã¨ãã€
    *   non-newsy æœŸï¼ˆLï¼‰ã§ã¯ã€æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³ã¯æ­£ï¼ˆãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ï¼‰
    *   newsy æœŸï¼ˆEï¼‰ã§ã¯ã€æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³ã¯è² ï¼ˆãƒªãƒãƒ¼ã‚µãƒ«ï¼‰
*   ã¤ã¾ã‚Šã€**åŒã˜çŠ¶æ…‹å¤‰æ•°ã§ã‚‚ã€æœˆã® â€œã‚¿ã‚¤ãƒŸãƒ³ã‚°â€ ã«ã‚ˆã£ã¦æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³ã®ç¬¦å·ãŒå¤‰ã‚ã‚‹**ã€ã¨ã„ã†ã®ãŒ Guo ã®ç†è«–çš„ãªã‚³ã‚¢ã§ã™ã€‚

* * *

2\. Empirical Method 5 / 6 ã«ã¤ãªãŒã‚‹ã€Œäºˆæ¸¬å›å¸°ã€ã®ãƒ–ãƒ­ãƒƒã‚¯
-------------------------------------------

ç†è«–ãƒ¢ãƒ‡ãƒ«ã§ã®\*\*ã€Œ $x^{\exp}_t$  ãŒæœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³ã‚’æ±ºã‚ã‚‹ã€**ã¨ã„ã†æ§‹é€ ã‚’ã€ãƒ‡ãƒ¼ã‚¿ä¸Šã§ã¯**éå»ã® â€œnewsy monthâ€ ãƒªã‚¿ãƒ¼ãƒ³ã®ç·šå½¢çµåˆ\*\*ã§ä»£ç†ã—ã¾ã™ã€‚

### 2.1 Guo ã®ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹äºˆæ¸¬å›å¸°ï¼ˆTable 2ï¼‰

RFS ç‰ˆã® Table 2 ã®èª¬æ˜æ–‡ã§ã¯ã€æ¬¡ã®æ™‚ç³»åˆ—å›å¸°ãŒæ˜ç¤ºã•ã‚Œã¦ã„ã¾ã™ï¼š[OUP Academic](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf)

$$
mkt_t = \alpha + \sum_{j=1}^{4}\beta_j\,mktnm(t,j) + \varepsilon_t. \tag{Guo (2025), Section 3.2, Table 2}
$$
*    $mkt_t$ ï¼šæœˆ  $t$  ã®ç±³å›½æ ªå¼å¸‚å ´ã®ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆvalue-weightedï¼‰
*    $mktnm(t,j)$ ï¼šæœˆ  $t$  ã‚ˆã‚Šå‰ã® ** $j$  ç•ªç›®ã® â€œnewsy monthâ€ ã®ãƒªã‚¿ãƒ¼ãƒ³**  
    ï¼ˆFigure 1 ã«ã€å…·ä½“çš„ãªãƒ©ã‚®ãƒ³ã‚°ã®ä¾‹ãŒå›³ç¤ºã•ã‚Œã¦ã„ã‚‹ï¼‰[OUP Academic](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf)

ã“ã®å›å¸°ã®ã€Œç†è«–çš„ãªèª­ã¿æ›¿ãˆã€ã¯ã€

$$
E[mkt_t \mid \mathcal{F}_{t-1}] \approx \alpha + \sum_{j=1}^4 \beta_j\, mktnm(t,j) \;\simeq\; \alpha + \tilde{\kappa}\,x^{\exp}_{t-1},
$$

ã¨ã„ã†ã‚‚ã®ã§ã€** $x^{\exp}_{t-1}$  ã‚’è¦³æ¸¬ã§ããªã„ãŸã‚ã€ãã®æœ€å°äºŒä¹—å°„å½±ã¨ã—ã¦  $\sum_j \beta_j mktnm(t,j)$  ã‚’ä½¿ã†**ã€ã¨ã„ã†è§£é‡ˆã§ã™ã€‚

*   Newsy month ã®å ´åˆã¨ non-newsy month ã®å ´åˆã§ã€åŒã˜ RHS ã«å¯¾ã™ã‚‹ä¿‚æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒé€†ç¬¦å·ã«ãªã‚‹ã“ã¨ãŒ Table 2 ã® Column 2ï¼ˆnewsyï¼‰ã¨ Column 3ï¼ˆnon-newsyï¼‰ã®æ¯”è¼ƒã¨ã—ã¦ç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚[OUP Academic](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf)

* * *

3\. æœ¬ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ã® Method 6 ã®ç†è«–çš„å°å‡º
----------------------------

### 3.1 Method 5 ã¨ Method 6 ã®é•ã„ï¼ˆç†è«–ï¼‰

ç°¡ç•¥åŒ–ã®ãŸã‚ã«ã€ä»¥ä¸‹ã®ã‚ˆã†ãª**1 ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼å‹ã®äºˆæ¸¬å¼**ã‚’è€ƒãˆã¾ã™ï¼š

$$
mkt_t = \mu_{t-1} + \beta_t \, z_t + \varepsilon_t. \tag{1}
$$
*    $\mu_{t-1}$ ï¼šæ™‚ç‚¹  $t-1$  æ™‚ç‚¹ã§ã®ã€Œãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³ã€ï¼ˆã“ã“ã§ã¯**éå»ã®å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³**ã® proxyï¼‰
*    $z_t$ ï¼šéå»ã® newsy-month ãƒªã‚¿ãƒ¼ãƒ³ã®ç·šå½¢çµåˆï¼ˆMethod 5/6 ã§ç•°ãªã‚‹å®šç¾©ï¼‰
*    $\beta_t$ ï¼šæ™‚å¤‰ä¿‚æ•°ï¼ˆMethod 5 ã§ã¯å›ºå®š or ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã€Method 6 ã§ã¯**ã‚ªãƒ³ãƒ©ã‚¤ãƒ³/expanding ã§æ›´æ–°**ï¼‰

#### Method 5ï¼ˆå›ºå®šä¿‚æ•°ç‰ˆã®ã‚¤ãƒ¡ãƒ¼ã‚¸ï¼‰

*   å…¨æœŸé–“ï¼ˆ1926â€“2021ãªã©ï¼‰ã§
    $$
    mkt_t = \alpha + \sum_{j=1}^4 \beta_j mktnm(t,j) + \varepsilon_t
    $$
    ã‚’æ¨å®šã—ã€ $\hat\beta_j$  ã‚’å›ºå®šã€‚
*   ã“ã‚Œã‚’ä½¿ã£ã¦
    $$
    z_t^{(5)} = \sum_{j=1}^4 \hat\beta_j mktnm(t,j)
    $$
    ã‚’ã‚·ã‚°ãƒŠãƒ«ã¨ã™ã‚‹ã€‚

#### Method 6ï¼ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³ï¼expanding ä¿‚æ•°ç‰ˆï¼‰

Method 6 ã§ã¯ã€

1.  ** $\mu_{t-1}$  ã‚’ã€Œéå»ã®å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³ã€  $\bar{mkt}_{t-1}$  ã¨ã—ã¦å›ºå®š**
2.  ã€Œå¹³å‡ã‹ã‚‰ã®ä¹–é›¢éƒ¨åˆ†ã€ã ã‘ã‚’èª¬æ˜ã™ã‚‹æ™‚å¤‰ä¿‚æ•°å›å¸°ã‚’ç½®ã

ã¨ã„ã†å½¢ã«æ›¸ãæ›ãˆã¾ã™ï¼š

$$
mkt_t - \bar{mkt}_{t-1} = \beta_t \, s_t + \varepsilon_t, \quad s_t := \sum_{j=1}^4 mktnm(t,j) - 4\bar{mkt}_{t-1}. \tag{2}
$$
*   ã“ã“ã§  $s_t$  ãŒã€Œnewsy-month ãƒªã‚¿ãƒ¼ãƒ³ã®å¹³å‡ã‹ã‚‰ã®ä¹–é›¢ã€ã«å¯¾å¿œã—ã€ç†è«–ä¸Šã¯  $x^{\exp}_{t-1}$  ã‚’ proxy ã™ã‚‹ã¨è§£é‡ˆã§ãã¾ã™ï¼ˆnewsy æœŸã®ã‚·ãƒ§ãƒƒã‚¯ã®è“„ç©ãã®ã‚‚ã®ã€ã¨ã„ã†ã‚¤ãƒ¡ãƒ¼ã‚¸ï¼‰ã€‚
*    $\beta_t$  ã¯ã€**æ™‚ç‚¹  $t$  ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã ã‘**ã‚’ä½¿ã£ãŸ OLS ã§æ¨å®šï¼ˆexpanding ã¾ãŸã¯ 20 å¹´ãƒ­ãƒ¼ãƒªãƒ³ã‚°ï¼‰ï¼š
    
$$
\hat\beta_t = \arg\min_b \sum_{\tau \le t-1} \left(mkt_\tau - \bar{mkt}_{\tau-1} - b\, s_\tau\right)^2. \tag{3}
$$

ã“ã®ã¨ãã®**äºˆæ¸¬ãƒªã‚¿ãƒ¼ãƒ³**ã¯

$$
\widehat{E}[mkt_t \mid \mathcal{F}_{t-1}] = \bar{mkt}_{t-1} + \hat\beta_t \, s_t. \tag{4}
$$

ã“ã“ã§

*    $\bar{mkt}_{t-1}$  ã®ä¿‚æ•°ã‚’ 1 ã«å›ºå®šã—ã¦ã„ã‚‹ç‚¹ãŒã€Guo ã®ã€Œunconditional mean ã‚’åˆ¥æ‰±ã„ã«ã—ã¤ã¤ã€äºˆæ¸¬æˆåˆ†ã ã‘ã‚’ newsy ã‚·ãƒ§ãƒƒã‚¯ã«ç´ã¥ã‘ã‚‹ã€ã¨ã„ã†ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã«å¯¾å¿œã—ã¦ã„ã¾ã™ï¼ˆRFS è«–æ–‡ã§ã¯æ˜ç¤ºçš„ãªå¼ç•ªå·ã¯ä»˜ã„ã¦ã„ã¾ã›ã‚“ãŒã€Table 2 ã‚„ Table 5 ã®å›å¸°å¼ã«å¯¾å¿œï¼‰ã€‚[OUP Academic+1](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf)

#### ç†è«–ãƒ¢ãƒ‡ãƒ«ã¨ã®å¯¾å¿œ

ç†è«–ãƒ¢ãƒ‡ãƒ« (ï¼Š) ã‹ã‚‰ã¯ã€

$$
E[mkt_t \mid \mathcal{F}_{t-1}] = \mu + k_{\text{type}(t)}\,x^{\exp}_{t-1} \quad\text{with}\quad k_{\text{newsy}}<0,\quad k_{\text{non-newsy}}>0.
$$

Method 6 ã§ã¯ã€

*    $x^{\exp}_{t-1} \approx \lambda \, s_t$ ï¼ˆç·šå½¢å°„å½±ï¼‰
*   ä¿‚æ•°  $k_{\text{type}(t)}\lambda$  ã‚’ã€æ™‚ç‚¹  $t$  ã¾ã§ã® OLS ã«ã‚ˆã£ã¦é€æ¬¡æ¨å®šã—ãŸã‚‚ã®ãŒ  $\hat\beta_t$ 

ã¨ã„ã†è§£é‡ˆã«ãªã£ã¦ã„ã¾ã™ã€‚**ã¤ã¾ã‚Š Method 6 ã¯ã€ã€ŒE æœŸã¨ L æœŸã§ç¬¦å·ãŒå¤‰ã‚ã‚‹  $k_{\text{type}(t)}$ ã€ã‚’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚†ã£ãã‚Šå­¦ç¿’ã—ã¦ã„ã**æˆ¦ç•¥ã§ã™ã€‚

* * *

4\. ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒ†ã‚£ãƒ³ã‚°ã¨ã®çµ„ã¿åˆã‚ã›
---------------------------

å®Ÿè£…æ¸ˆã¿ã®æˆ¦ç•¥ã§ã¯ã€ä¸Šã§å¾—ãŸ**ã‚¹ã‚«ãƒ©ãƒ¼äºˆæ¸¬å­  $z_t := \hat\beta_t s_t$ ** ã‚’ã€ã„ã‚ã‚†ã‚‹ã€Œvolatility-managedã€ãªãƒã‚¸ã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚ºã«å¤‰æ›ã—ã¦ã„ã¾ã™ã€‚

### 4.1 ã‚·ã‚°ãƒŠãƒ«ã®æ¨™æº–åå·®ã¨ãƒ¬ãƒãƒ¬ãƒƒã‚¸ä¿‚æ•°

æ™‚ç‚¹  $t$  ã®ç›´å‰ã«åˆ©ç”¨å¯èƒ½ãªãƒ’ã‚¹ãƒˆãƒªãƒ¼ã§ã€ã‚·ã‚°ãƒŠãƒ«  $z_\tau$  ã®æ¨™æº–åå·®ã‚’æ¨è¨ˆï¼š

$$
\hat\sigma_{z,t-1} = \sqrt{\frac{1}{N_{t-1}-1} \sum_{\tau \le t-1} \Big(z_\tau - \bar{z}_{t-1}\Big)^2}. \tag{5}
$$
*   å®Ÿè£…ã§ã¯ expanding ã‚‚ã—ãã¯ãƒ­ãƒ¼ãƒªãƒ³ã‚°æ¨™æº–åå·®ã‚’åˆ©ç”¨ã€‚

ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¹´ç‡ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£  $\sigma^\ast$  ã‚’ä¸ãˆã€**æœˆæ¬¡æ›ç®—**ã—ãŸä¸Šã§ã€æ ªå¼ã‚¨ã‚¯ã‚¹ãƒãƒ¼ã‚¸ãƒ£ãƒ¼  $w_t$  ã‚’

$$
w_t = \begin{cases} 0, & t \text{ ãŒã‚µãƒ³ãƒ—ãƒ«åˆæœŸãªã©ã§ } \hat\sigma_{z,t-1} \approx 0,\\[4pt] \mathrm{clip}\left( \displaystyle \frac{\sigma^\ast}{\hat\sigma_{z,t-1}} z_t, \; -L_{\max},\; +L_{\max} \right), & \text{otherwise}. \end{cases} \tag{6}
$$
*    $\mathrm{clip}(\cdot)$ ï¼š $[-L_{\max}, L_{\max}]$  ã«ã‚¯ãƒªãƒƒãƒ—
*    $\sigma^\ast$ ï¼šã‚¿ãƒ¼ã‚²ãƒƒãƒˆæœˆæ¬¡ãƒœãƒ©ï¼ˆã‚³ãƒ¼ãƒ‰ä¸Šã¯ 0.05 ãªã©ï¼‰
*    $L_{\max}$ ï¼šæœ€å¤§ãƒ¬ãƒãƒ¬ãƒƒã‚¸ï¼ˆ3.0 ãªã©ï¼‰

ã“ã‚Œã¯ã€Moreira & Muir (2017) å‹ã®ã€Œãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ»ãƒãƒãƒ¼ã‚¸ãƒ‰ãƒ»ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã€ã®æµå„€ï¼ˆ $1/\sigma$  ã«æ¯”ä¾‹ã—ãŸãƒã‚¸ã‚·ãƒ§ãƒ³ï¼‰ã¨åŒã˜æ§‹é€ ã§ã™ã€‚Guo ã®è«–æ–‡è‡ªä½“ã¯ãƒœãƒ©ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¯æ¡ç”¨ã—ã¦ã„ã¾ã›ã‚“ãŒã€**ç†è«–çš„ã«ã¯ã€Œä¿¡å·ã®ä¿¡é ¼åº¦ãŒä½ã„ã¨ãï¼ˆ $\hat\sigma_z$  å°ï¼‰ã«ã¯ãƒ¬ãƒãƒ¬ãƒƒã‚¸ã‚’æŠ‘ãˆã‚‹ã€ãŸã‚ã®è‡ªç„¶ãªæ‹¡å¼µ**ã§ã™ã€‚[UTS Sydney+1](https://www.uts.edu.au/globalassets/sites/default/files/FDG_Seminar_140730.pdf?utm_source=chatgpt.com)

### 4.2 æˆ¦ç•¥ãƒªã‚¿ãƒ¼ãƒ³

æœˆ  $t$  ã®è¶…éãƒªã‚¿ãƒ¼ãƒ³ã¯

$$
r^{\text{strat}}_t = w_{t-1}\, mkt^{\text{excess}}_t, \tag{7}
$$

ç·ãƒªã‚¿ãƒ¼ãƒ³ã¯

$$
r^{\text{tot}}_t = rf_t + r^{\text{strat}}_t. \tag{8}
$$

ã“ã“ã¾ã§ãŒã€ç¾åœ¨ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§å®Ÿè£…ã—ã¦ã„ã‚‹ **â€œMethod 6 + volatility targetingâ€** ã®å®Œå…¨ãªæ•°å¼æ•´ç†ã¨è¨€ãˆã¾ã™ã€‚

* * *

5\. å‡ºå…¸ã®æ•´ç†ï¼ˆã©ã®å¼ãŒã©ã®æ–‡çŒ®ã®ã©ã“ã‹ï¼‰
-----------------------

æœ€å¾Œã«ã€ä¸Šè¨˜ã®å„ãƒ–ãƒ­ãƒƒã‚¯ãŒã©ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ»ã©ã®å¼ã«å¯¾å¿œã™ã‚‹ã‹ã‚’ã€ç®‡æ¡æ›¸ãã§ã¾ã¨ã‚ã¾ã™ã€‚

1.  **ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ãƒ­ãƒ¼ãƒ»ãƒ—ãƒ­ã‚»ã‚¹**
    *   å¼ (4)ï¼š
        $$
        db_{t+1} = x^{\text{act}}_t + u_{t+1} = \begin{cases} e^{-0.5\delta} x^{\exp}_t + u_{t+1} & (t\text{ is E}),\\ e^{+0.5\delta} x^{\exp}_t + u_{t+1} & (t\text{ is L}). \end{cases}
        $$
        â†’ Guo (2025, _RFS_), Section 5 â€œA Simple Earnings Extrapolation Modelâ€, Equation (4).[OUP Academic](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf)
2.  **ä¾¡æ ¼ãƒ»é…å½“æ¯”ã¨ä¿‚æ•°ã®å†å¸°å¼**
    *   Equation (5)ï¼šä¾¡æ ¼ã®å‰²å¼•ç¾åœ¨ä¾¡å€¤é–¢ä¿‚ï¼ˆlog-linearization ã®åŸºç¤ï¼‰ã§ã‚ã‚Šã€  
        ãã®å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆã§  $a^k_n,b^k_n,c^k_n$  ã®å†å¸°å¼ãŒå°ã‹ã‚Œã‚‹ã€‚  
        â†’ åŒã˜ã Guo (2025), Section 5, pp. 23â€“24ã€‚[OUP Academic](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf)
3.  **1 æœŸé–“ãƒªã‚¿ãƒ¼ãƒ³ã®åˆ†è§£ (ï¼Š)**
    *   log ãƒªã‚¿ãƒ¼ãƒ³ãŒã€Œäºˆæ¸¬å¯èƒ½æˆåˆ†ï¼ˆ $x^{\exp}_t$  ã«æ¯”ä¾‹ï¼‰ã€ï¼‹ã€Œäºˆæ¸¬ä¸å¯èƒ½æˆåˆ†ï¼ˆ $u_{t+1}$  ã«æ¯”ä¾‹ï¼‰ã€ã«åˆ†è§£ã•ã‚Œã€  
        E vs L ã§äºˆæ¸¬å¯èƒ½æˆåˆ†ã®ç¬¦å·ãŒåè»¢ã™ã‚‹ã“ã¨ãŒã€pp. 23â€“24 ã®è­°è«–ã¨ã—ã¦ç¤ºã•ã‚Œã‚‹ã€‚[OUP Academic](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf)
4.  **U.S. æœˆæ¬¡ãƒªã‚¿ãƒ¼ãƒ³ã®äºˆæ¸¬å›å¸°**
    *    $mkt_t = \alpha + \sum_{j=1}^4 \beta_j mktnm(t,j) + \varepsilon_t$   
        â†’ Guo (2025), Section 3.2 â€œBaseline Pattern of Return Predictabilityâ€, Table 2 ã®ç›´å‰ã®èª¬æ˜æ–‡ã¨ Figure 1ã€‚[OUP Academic](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf)
5.  **çŠ¶æ…‹å¤‰æ•°  $x^{\exp}_t$  ã®çµŒæ¸ˆçš„è§£é‡ˆ**
    *   â€œI gather investorsâ€™ expectations of  $db_t$ , captured by a state variable  $x^{\exp}_t$ , from Figure 4.â€ ã¨ã„ã†è¨˜è¿°ã«å¯¾å¿œã€‚  
        â†’ Guo (2025), Section 5, p. 20ã€‚[OUP Academic](https://academic.oup.com/rfs/article-pdf/38/6/1730/62822209/hhaf020.pdf)
6.  **Correlation Neglect ã¨ earnings-cycle ã®æ•´åˆæ€§**
    *   ã€Œcertainly uncertain shocksã€ã‚„ E/L ã®è§£é‡ˆãŒ Guo & Wachter (2025, SSRN WP â€œCorrelation Neglect in Asset Pricesâ€) ã«ã¦ã‚ˆã‚Šåºƒã„æ çµ„ã¿ã§è­°è«–ã•ã‚Œã‚‹ã€‚  
        â†’ æˆ‘ã€…ã® nr å¤‰æ›ã‚„ Newsy/Repetitive ã®æ‹¡å¼µã¯ã“ã®è«–æ–‡ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’å–ã‚Šè¾¼ã‚“ã ã‚‚ã®ã§ã€ç›´æ¥ã®æ•°å¼å¯¾å¿œã¨ã„ã†ã‚ˆã‚Š**æ¦‚å¿µçš„ãªç¶™æ‰¿**ã€‚[SSRN](https://papers.ssrn.com/sol3/Delivery.cfm/5268329.pdf?abstractid=5268329&mirid=1)
7.  **ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒ†ã‚£ãƒ³ã‚°**
    *    $w_t \propto \sigma^{-1}_{t-1}$  ã¨ã„ã†ã‚¢ã‚¤ãƒ‡ã‚¢ã¯ Moreira & Muir (2017, _JF_) â€œVolatility Managed Portfoliosâ€ ã«ç›¸å½“ã€‚  
        â†’ Guo ã®å…ƒè«–æ–‡ã«ã¯æ˜ç¤ºçš„ã«ã¯å‡ºã¦ã“ãªã„ãŒã€æˆ‘ã€…ã®å®Ÿè£…ã§ã¯ã“ã®ãƒªã‚¹ã‚¯ãƒ»ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆæ‰‹æ³•ã‚’ä¸Šä¹—ã›ã—ã¦ã„ã‚‹ã€‚[UTS Sydney+1](https://www.uts.edu.au/globalassets/sites/default/files/FDG_Seminar_140730.pdf?utm_source=chatgpt.com)

* * *

ã‚‚ã—ã‚ˆã‚ã—ã‘ã‚Œã°ã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¨ã—ã¦ï¼š

*   ã“ã®ç†è«–æ•´ç†ã«å¯¾å¿œã™ã‚‹ã‹ãŸã¡ã§ã€
    *   ã€Œnewsy / non-newsy åˆ¥ã®æ¡ä»¶ä»˜ãæœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³ã®æ¨è¨ˆã€
    *   ã€Œ $\hat\beta_t$  ã®æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆã¨ã€ç†è«–ä¸Šã®ç¬¦å·æ¡ä»¶ï¼ˆE ã§ã¯è² ã€non-newsy ã§ã¯æ­£ï¼‰ã¨ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã€  
        ã‚’è¡Œã†ãŸã‚ã®è£œåŠ©ã‚³ãƒ¼ãƒ‰ã‚‚ãŠå‡ºã—ã§ãã¾ã™ã€‚



---
Powered by [ChatGPT Exporter](https://www.chatgptexporter.com)