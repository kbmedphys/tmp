# å°‚é–€å®¶å‘ã‘è§£èª¬

**User:** Anonymous (kbmedphys@gmail.com)  
**Created:** 11/12/2025 14:41:54  
**Updated:** 11/12/2025 19:03:53  
**Exported:** 11/12/2025 20:45:00  
**Link:** [https://chatgpt.com/c/69141e21-f434-8320-a094-56fa36fe7e12](https://chatgpt.com/c/69141e21-f434-8320-a094-56fa36fe7e12)  

## Response:
ä»¥ä¸‹ã¯ã€æ·»ä»˜è«–æ–‡ **â€œDynamic Asset Allocation with Asset-Specific Regime Forecastsâ€ (Yizhan Shu, Chenyu Yu, John Mulvey, 2024)** ã®å†…å®¹ã‚’å°‚é–€å®¶å‘ã‘ã«æ—¥æœ¬èªã§è©³ç´°ã«è§£èª¬ã—ãŸã‚‚ã®ã§ã™

2406.09578v2

ã€‚  
æœ¬è«–æ–‡ã¯ã€é‡‘èå¸‚å ´ã«ãŠã‘ã‚‹\*\*è³‡ç”£ã”ã¨ã®ãƒ¬ã‚¸ãƒ¼ãƒ äºˆæ¸¬ã‚’çµ„ã¿è¾¼ã‚“ã å‹•çš„è³‡ç”£é…åˆ†ï¼ˆDynamic Asset Allocationï¼‰\*\*ã®æ–°ã—ã„æ çµ„ã¿ã‚’æç¤ºã—ã¦ã„ã¾ã™ã€‚

* * *

ğŸ”¹ 1. ç ”ç©¶èƒŒæ™¯ã¨ç›®çš„
-------------

### ãƒãƒ¼ã‚³ã‚¦ã‚£ãƒƒãƒ„ç†è«–ã®é™ç•Œ

Markowitzï¼ˆ1952ï¼‰ã®å¹³å‡åˆ†æ•£ç†è«–ã§ã¯ã€ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–ã¯

1.  ãƒªã‚¿ãƒ¼ãƒ³ã¨ãƒªã‚¹ã‚¯ã®äºˆæ¸¬ï¼ˆforecastingï¼‰
2.  æœ€é©åŒ–ï¼ˆoptimizationï¼‰  
    ã®2æ®µéšã§è¡Œã‚ã‚Œã¾ã™ã€‚  
    ã—ã‹ã—ã€**äºˆæ¸¬ã®èª¤å·®**ãŒå¤§ãã„ã¨ã€æœ€é©åŒ–æ®µéšã¯ã€Œèª¤å·®å¢—å¹…å™¨ï¼ˆerror maximizerï¼‰ã€ã«ãªã‚Šã†ã‚‹ï¼ˆMichaud, 1989ï¼‰ã€‚

æœ¬ç ”ç©¶ã¯ã€ãƒªã‚¿ãƒ¼ãƒ³ãã®ã‚‚ã®ã‚’äºˆæ¸¬ã™ã‚‹ä»£ã‚ã‚Šã«ã€**å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ ï¼ˆbullish/bearishçŠ¶æ…‹ï¼‰ã‚’äºˆæ¸¬å¯¾è±¡ã¨ã™ã‚‹**ã“ã¨ã§ã€ä¿¡å·å¯¾é›‘éŸ³æ¯”ï¼ˆSNRï¼‰ã‚’é«˜ã‚ã€ã‚ˆã‚Šé ‘å¥ãªæœ€é©åŒ–ã‚’å®Ÿç¾ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚

* * *

ğŸ”¹ 2. å¾“æ¥æ‰‹æ³•ã¨ã®é•ã„
--------------

å¾“æ¥ã®ãƒ¬ã‚¸ãƒ¼ãƒ ãƒ™ãƒ¼ã‚¹æ‰‹æ³•ã¯ã€ãƒã‚¯ãƒ­çµŒæ¸ˆæŒ‡æ¨™ã‚„æ ªä¾¡æŒ‡æ•°ã‚’åŸºã«**å…¨è³‡ç”£å…±é€šã®çµŒæ¸ˆãƒ¬ã‚¸ãƒ¼ãƒ **ï¼ˆä¾‹ï¼šæ™¯æ°—æ‹¡å¼µãƒ»å¾Œé€€ï¼‰ã‚’æ¨å®šã—ã¦ã„ã¾ã—ãŸï¼ˆAng & Bekaert, 2004 ãªã©ï¼‰ã€‚  
æœ¬ç ”ç©¶ã®é©æ–°ç‚¹ã¯ã€**å„è³‡ç”£ã”ã¨ã«ç‹¬ç«‹ã—ãŸå¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ ã‚’è­˜åˆ¥ãƒ»äºˆæ¸¬**ã™ã‚‹ç‚¹ã«ã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è³‡ç”£é–“ã§ç•°ãªã‚‹å¸‚å ´ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã‚’æ‰ãˆã€ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå…¨ä½“ã®æŸ”è»Ÿæ€§ã¨å¤šæ§˜æ€§ã‚’å‘ä¸Šã•ã›ã¾ã™

2406.09578v2

ã€‚

* * *

ğŸ”¹ 3. ãƒ¢ãƒ‡ãƒ«æ§‹é€ ã®æ¦‚è¦
--------------

### ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ»ãƒ¬ã‚¸ãƒ¼ãƒ äºˆæ¸¬ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

æœ¬ç ”ç©¶ã¯2æ®µéšã®ã€Œ**unsupervised-supervised hybrid**ã€æ§‹é€ ã‚’æ¡ç”¨ã—ã¾ã™ã€‚

1.  **ãƒ¬ã‚¸ãƒ¼ãƒ è­˜åˆ¥ï¼ˆIdentificationï¼‰**
    *   ãƒ¢ãƒ‡ãƒ«ï¼š**Statistical Jump Model (JM)**
    *   ç›®çš„ï¼šéå»ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ¬ã‚¸ãƒ¼ãƒ ï¼ˆbull/bearï¼‰ã‚’**æ•™å¸«ãªã—ã§**è­˜åˆ¥
    *   ç‰¹å¾´é‡ï¼šè³‡ç”£ãƒªã‚¿ãƒ¼ãƒ³ç³»åˆ—ã‹ã‚‰å°ã‹ã‚Œã‚‹8ç¨®ã®æŒ‡æ¨™ï¼ˆç§»å‹•å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³ãƒ»ãƒ€ã‚¦ãƒ³ã‚µã‚¤ãƒ‰åå·®ãƒ»Sortinoæ¯”ãªã©ï¼‰
    *   å‡ºåŠ›ï¼šå„æ—¥ä»˜ã«å¯¾ã™ã‚‹ãƒ¬ã‚¸ãƒ¼ãƒ ãƒ©ãƒ™ãƒ«  $s_t$ 
2.  **ãƒ¬ã‚¸ãƒ¼ãƒ äºˆæ¸¬ï¼ˆForecastingï¼‰**
    *   ãƒ¢ãƒ‡ãƒ«ï¼š**XGBooståˆ†é¡å™¨**ï¼ˆGradient Boosted Decision Treeï¼‰
    *   ç›®çš„ï¼šç¿Œæ—¥ã®ãƒ¬ã‚¸ãƒ¼ãƒ ã‚’**æ•™å¸«ã‚ã‚Šã§**äºˆæ¸¬
    *   ç‰¹å¾´é‡ï¼š
        *   è³‡ç”£å›ºæœ‰ã®ãƒªã‚¿ãƒ¼ãƒ³ç‰¹å¾´ï¼ˆä¸Šè¨˜8ç¨®ï¼‰
        *   ã‚¯ãƒ­ã‚¹ã‚¢ã‚»ãƒƒãƒˆãƒ»ãƒã‚¯ãƒ­ç‰¹å¾´ï¼ˆ5ç¨®ï¼šé‡‘åˆ©ãƒ»ã‚¤ãƒ¼ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ–ãƒ»VIXãƒ»æ ªå‚µç›¸é–¢ãªã©ï¼‰
    *   å‡ºåŠ›ï¼šç¿Œæ—¥ã®ãƒ¬ã‚¸ãƒ¼ãƒ ç¢ºç‡  $f_{t+1}$ 

ã“ã®ã€Œ**ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°â†’åˆ†é¡**ã€æ§‹æˆã«ã‚ˆã‚Šã€ãƒ¬ã‚¸ãƒ¼ãƒ ãƒ©ãƒ™ãƒ«ã‚’æ•™å¸«ä¿¡å·ã¨ã—ã¦æ´»ç”¨ã—ã€ãƒã‚¤ã‚ºã‚’æŠ‘ãˆãŸäºˆæ¸¬ãŒå¯èƒ½ã¨ãªã‚Šã¾ã™

2406.09578v2

ã€‚

* * *

ğŸ”¹ 4. Statistical Jump Modelï¼ˆJMï¼‰ã®è©³ç´°
-----------------------------------

### ãƒ¢ãƒ‡ãƒ«å®šå¼åŒ–

æ™‚ç³»åˆ—ç‰¹å¾´  $x_t \in \mathbb{R}^D$  ã«å¯¾ã—ã€JMã¯ä»¥ä¸‹ã®æœ€é©åŒ–å•é¡Œã‚’è§£ãã¾ã™ï¼š

$$
\min_{\Theta,S} \sum_{t=0}^{T-1} l(x_t,\theta_{s_t}) + \lambda \sum_{t=1}^{T-1} \mathbf{1}_{\{s_{t-1} \neq s_t\}}
$$
*    $l(\cdot,\cdot)$ ï¼šè·é›¢ï¼ˆé€šå¸¸ã¯äºŒä¹—èª¤å·®ï¼‰
*    $\lambda$ ï¼š**ã‚¸ãƒ£ãƒ³ãƒ—ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆjump penaltyï¼‰**  
    â†’ ãƒ¬ã‚¸ãƒ¼ãƒ é·ç§»ã®é »åº¦ã‚’æŠ‘ãˆã€æ™‚ç³»åˆ—ã®å¹³æ»‘æ€§ã‚’èª¿æ•´
*    $s_t \in \{0,1\}$ ï¼šå„æœŸã®ãƒ¬ã‚¸ãƒ¼ãƒ ï¼ˆbull/bearï¼‰

 $\lambda$  ã‚’å¤§ããã™ã‚‹ã¨ãƒ¬ã‚¸ãƒ¼ãƒ ã¯ã‚ˆã‚Š**æŒç¶šçš„ï¼ˆpersistentï¼‰**ã«ãªã‚Šã€å°ã•ã„ã¨**é«˜é »åº¦ã§åˆ‡ã‚Šæ›¿ã‚ã‚‹**ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚  
ã—ãŸãŒã£ã¦  $\lambda$  ã¯SNRã®èª¿æ•´ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã—ã¦æ©Ÿèƒ½ã—ã¾ã™

2406.09578v2

ã€‚

### ç‰¹å¾´é‡è¨­è¨ˆ

| ç¨®é¡ | ãƒãƒ¼ãƒ•ãƒ©ã‚¤ãƒ• | å†…å®¹ |
| --- | --- | --- |
| Downside Deviationï¼ˆå¯¾æ•°ï¼‰ | 5æ—¥ãƒ»21æ—¥ | ä¸‹æ–¹ãƒªã‚¹ã‚¯æŒ‡æ¨™ |
| å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³ | 5, 10, 21æ—¥ | ãƒªã‚¿ãƒ¼ãƒ³å‚¾å‘ |
| Sortino Ratio | 5, 10, 21æ—¥ | ãƒªã‚¹ã‚¯èª¿æ•´ãƒªã‚¿ãƒ¼ãƒ³ |

ã“ã‚Œã‚‰ã®ç‰¹å¾´é‡ã¯å„è³‡ç”£ã”ã¨ã«è¨ˆç®—ã•ã‚Œã€JMãŒ**è³‡ç”£å›ºæœ‰ã®å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ **ã‚’æŠ½å‡ºã—ã¾ã™ã€‚

* * *

ğŸ”¹ 5. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
------------------

### æ™‚ç³»åˆ—ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³

*   æ¤œè¨¼æœŸé–“ï¼šç›´è¿‘5å¹´é–“
*   è©•ä¾¡æŒ‡æ¨™ï¼š**0/1æˆ¦ç•¥ã®Sharpeæ¯”**

0/1æˆ¦ç•¥ã¨ã¯ã€äºˆæ¸¬ãƒ¬ã‚¸ãƒ¼ãƒ ãŒbullishãªã‚‰100%ãƒªã‚¹ã‚¯è³‡ç”£ã€bearishãªã‚‰100%ç„¡ãƒªã‚¹ã‚¯è³‡ç”£ã«æŠ•è³‡ã™ã‚‹å˜ç´”æˆ¦ç•¥ã€‚  
å„è³‡ç”£ã«ãŠã„ã¦ã“ã®Sharpeæ¯”ã‚’æœ€å¤§åŒ–ã™ã‚‹ $\lambda$ ã‚’é¸æŠã—ã€æ¬¡ã®åŠå¹´é–“ã«é©ç”¨ã—ã¾ã™

2406.09578v2

ã€‚

* * *

ğŸ”¹ 6. ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–ã‚¹ãƒ†ãƒƒãƒ—
--------------------

### å…±é€šæ•°ç†å½¢å¼

$$
\max_w \; w^\top \mu - \gamma_{\text{risk}} w^\top \Sigma w - \gamma_{\text{trade}} a \|w - w_{\text{pre}}\|_1
$$

subject to:

$$
0 \le w \le w_{ub}, \quad 1^\top w \le L
$$
*    $\mu$ ï¼šãƒªã‚¿ãƒ¼ãƒ³äºˆæ¸¬ï¼ˆãƒ¬ã‚¸ãƒ¼ãƒ ä¾å­˜ï¼‰
*    $\Sigma$ ï¼šEWMå…±åˆ†æ•£ï¼ˆåŠæ¸›æœŸ252æ—¥ï¼‰
*    $a$ ï¼šå–å¼•ã‚³ã‚¹ãƒˆï¼ˆ5bpsï¼‰

* * *

ğŸ”¹ 7. ä¸‰ã¤ã®ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒ¢ãƒ‡ãƒ«
-------------------

| ãƒ¢ãƒ‡ãƒ« | ãƒ¬ã‚¸ãƒ¼ãƒ æ´»ç”¨æ–¹æ³• | ç‰¹å¾´ |
| --- | --- | --- |
| **MinVar (JM-XGB)** | bullishè³‡ç”£ã«10bpsãƒªã‚¿ãƒ¼ãƒ³ã‚’å‰²å½“ | ä½ãƒªã‚¹ã‚¯ãƒ»é«˜å®‰å®šæ€§ |
| **MV (JM-XGB)** | JMã®ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¥å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³ã‚’åˆ©ç”¨ | å¹³å‡åˆ†æ•£æœ€é©åŒ– |
| **EW (JM-XGB)** | bullishè³‡ç”£é–“ã§å‡ç­‰é…åˆ† | ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¯”è¼ƒç”¨ |

ã„ãšã‚Œã‚‚ã€bullishè³‡ç”£ãŒ3éŠ˜æŸ„ä»¥ä¸‹ã®å ´åˆã¯**å…¨é¡ãƒªã‚¹ã‚¯ãƒ•ãƒªãƒ¼**ã¨ã™ã‚‹å®‰å…¨å¼ã‚’è¨­ã‘ã¦ã„ã¾ã™

2406.09578v2

ã€‚

* * *

ğŸ”¹ 8. å®Ÿè¨¼åˆ†æï¼ˆ1991â€“2023ï¼‰
---------------------

### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

*   12è³‡ç”£ï¼‹ç„¡ãƒªã‚¹ã‚¯è³‡ç”£  
    ï¼ˆä¾‹ï¼šS&P500, EAFE, EM, AggBond, REIT, Commodity, Gold ãªã©ï¼‰
*   æ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³ï¼šBloomberg
*   ãƒªã‚¹ã‚¯ãƒ•ãƒªãƒ¼ï¼š3M Treasuryï¼ˆFREDï¼‰

### ä¸»ãªçµæœ

1.  **0/1æˆ¦ç•¥**
    *   ã™ã¹ã¦ã®è³‡ç”£ã§æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ãŒå¤§å¹…æ¸›å°‘ï¼ˆä¾‹ï¼šS&P500ã§ã¯åŠæ¸›ï¼‰
    *   Sharpeæ¯”ã¯è²·ã„æŒã¡æˆ¦ç•¥ã‚’ä¸€è²«ã—ã¦ä¸Šå›ã‚‹
2.  **JM-XGBãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª**
    *   MinVar, MV, EWã®ã„ãšã‚Œã®ãƒ¢ãƒ‡ãƒ«ã§ã‚‚**ãƒªã‚¹ã‚¯èª¿æ•´å¾Œãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒæ”¹å–„**
    *   ãƒ™ã‚¢å±€é¢ã§æœ‰åŠ¹ãª**ãƒ€ã‚¦ãƒ³ã‚µã‚¤ãƒ‰ä¿è­·åŠ¹æœ**ã‚’ç¢ºèª
3.  **è³‡ç”£é–“ã®å¤šæ§˜ãªãƒ¬ã‚¸ãƒ¼ãƒ æŒ™å‹•**
    *   REITã®ãƒ™ã‚¢å±€é¢ã¯LargeCapã‚ˆã‚Šæ—©æœŸï¼ˆã‚µãƒ–ãƒ—ãƒ©ã‚¤ãƒ å½±éŸ¿ï¼‰
    *   å‚µåˆ¸ã¨æ ªå¼ã§ãƒ¬ã‚¸ãƒ¼ãƒ éåŒæœŸæ€§ã‚’è¦³æ¸¬ â†’ åˆ†æ•£åŠ¹æœã‚’å¼·åŒ–

* * *

ğŸ”¹ 9. ç†è«–çš„å«æ„ã¨å®Ÿå‹™çš„è²¢çŒ®
-----------------

*   **ç†è«–çš„è²¢çŒ®**
    *   ãƒ¬ã‚¸ãƒ¼ãƒ è­˜åˆ¥ï¼ˆunsupervisedï¼‰ã¨äºˆæ¸¬ï¼ˆsupervisedï¼‰ã‚’æ˜ç¢ºã«åˆ†é›¢
    *   ã‚¸ãƒ£ãƒ³ãƒ—ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚Šãƒ¬ã‚¸ãƒ¼ãƒ ãƒ©ãƒ™ãƒ«ã®**SNRæœ€é©åŒ–**ã‚’å®šé‡çš„ã«å®Ÿæ–½
    *   ã€Œasset-specific regimeã€ã¨ã„ã†æ–°ã—ã„æ¦‚å¿µã‚’å°å…¥
*   **å®Ÿå‹™çš„è²¢çŒ®**
    *   å„è³‡ç”£ã”ã¨ã®ãƒ¬ã‚¸ãƒ¼ãƒ æƒ…å ±ã‚’ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–ã«çµ±åˆ
    *   å–å¼•ã‚³ã‚¹ãƒˆã‚’è€ƒæ…®ã—ãŸ**å®Ÿé‹ç”¨å¯èƒ½ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**
    *   Gurobiã«ã‚ˆã‚‹é«˜é€Ÿæœ€é©åŒ–ï¼ˆ12è³‡ç”£ã§1æ—¥ã‚ãŸã‚Š5ç§’ä»¥å†…ï¼‰

* * *

ğŸ”¹ 10. ã¾ã¨ã‚ã¨ä»Šå¾Œã®å±•æœ›
----------------

æœ¬ç ”ç©¶ã¯ã€ãƒ¬ã‚¸ãƒ¼ãƒ äºˆæ¸¬ã‚’è³‡ç”£å˜ä½ã§ç”Ÿæˆã—ã€Markowitzæœ€é©åŒ–ã«çµ±åˆã™ã‚‹ã“ã¨ã§ã€

*   ãƒã‚¤ã‚ºã«å¼·ãã€
*   å‹•çš„ã«é©å¿œã—ã€
*   ãƒ€ã‚¦ãƒ³ã‚µã‚¤ãƒ‰ãƒªã‚¹ã‚¯ã‚’è»½æ¸›ã™ã‚‹

ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæ§‹ç¯‰æ³•ã‚’å®Ÿç¾ã—ã¾ã—ãŸã€‚  
ä»Šå¾Œã¯ã€**ãƒ¬ã‚¸ãƒ¼ãƒ æƒ…å ±ã‚’å…±åˆ†æ•£æ§‹é€ ã«ã‚‚çµ„ã¿è¾¼ã‚€æ‹¡å¼µ**ã‚„ã€**ãƒãƒ«ãƒãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ãƒ»ãƒ–ãƒ©ãƒƒã‚¯ãƒªãƒƒã‚¿ãƒ¼ãƒãƒ³ãƒ¢ãƒ‡ãƒ«ã¨ã®çµ±åˆ**ãŒæœŸå¾…ã•ã‚Œã¾ã™ã€‚

* * *

ã”å¸Œæœ›ãŒã‚ã‚Œã°ã€ã“ã®å†…å®¹ã‚’\*\*ã‚¹ãƒ©ã‚¤ãƒ‰æ§‹æˆï¼ˆæ¦‚è¦â†’ãƒ¢ãƒ‡ãƒ«â†’å®Ÿè¨¼â†’çµè«–ï¼‰\*\*ã«ã¾ã¨ã‚ã‚‹è‹±èªç‰ˆã¾ãŸã¯æ—¥æœ¬èªç‰ˆã®ç™ºè¡¨ç”¨è³‡æ–™ã¨ã—ã¦æ•´å½¢ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™ã€‚ä½œæˆã„ãŸã—ã¾ã—ã‚‡ã†ã‹ï¼Ÿ

## Response:
æ€è€ƒæ™‚é–“: 23s

äº†è§£ã§ã™ã€‚è«–æ–‡ã®JMã§ä½¿ã†ã€Œè³‡ç”£ã”ã¨ã®ãƒªã‚¿ãƒ¼ãƒ³ç”±æ¥ã®8ç‰¹å¾´é‡ã€ã‚’ä½œã‚‹ Python å®Ÿè£…ã‚’ç”¨æ„ã—ã¾ã—ãŸã€‚  
ï¼ˆEWMï¼æŒ‡æ•°åŠ é‡ã€DDï¼ãƒ€ã‚¦ãƒ³ã‚µã‚¤ãƒ‰åå·®ï¼ˆãƒ­ã‚°å¤‰æ›ç‰ˆã§ç‰¹å¾´é‡åŒ–ï¼‰ã€å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³ã€Sortino æ¯”ï¼‰

*   DDï¼ˆãƒ­ã‚°ï¼‰ï¼šåŠæ¸›æœŸ 5, 21 æ—¥
*   å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³ï¼šåŠæ¸›æœŸ 5, 10, 21 æ—¥
*   Sortino æ¯”ï¼šåŠæ¸›æœŸ 5, 10, 21 æ—¥ï¼ˆ= å¹³å‡ / DDï¼‰
*   æ¨™æº–åŒ–ï¼šå­¦ç¿’åŒºé–“ã§ z-score ã‚’å­¦ç¿’ã—ã€é©ç”¨ï¼ˆã‚¹ã‚­ãƒ¼ãƒã¯ scikit-learn é¢¨ï¼‰

å˜ä¸€è³‡ç”£ Series ã§ã‚‚ã€è¤‡æ•°è³‡ç”£ DataFrame ã§ã‚‚å‹•ãã¾ã™ï¼ˆåˆ—ã”ã¨ã«ç‹¬ç«‹ã«è¨ˆç®—ï¼‰ã€‚

```python
import numpy as np
import pandas as pd
from dataclasses import dataclass, field
from typing import Iterable, Optional, Dict, Tuple, Union

ArrayLike = Union[pd.Series, pd.DataFrame]

def _ewm_mean(x: pd.Series, halflife: int) -> pd.Series:
    return x.ewm(halflife=halflife, adjust=False, min_periods=1).mean()

def _ewm_downside_dev(ret: pd.Series, halflife: int, eps: float = 1e-12) -> pd.Series:
    """
    EWM ä¸‹ã§ã®ãƒ€ã‚¦ãƒ³ã‚µã‚¤ãƒ‰åå·®ï¼ˆè² ãƒªã‚¿ãƒ¼ãƒ³ã®äºŒä¹—å¹³å‡ã®å¹³æ–¹æ ¹ï¼‰ã€‚
    """
    neg = ret.clip(upper=0.0)
    var_dd = neg.pow(2).ewm(halflife=halflife, adjust=False, min_periods=1).mean()
    dd = np.sqrt(var_dd).clip(lower=eps)  # æ•°å€¤å®‰å®šåŒ–
    return dd

def _ensure_df(x: ArrayLike) -> pd.DataFrame:
    if isinstance(x, pd.Series):
        return x.to_frame("asset")
    elif isinstance(x, pd.DataFrame):
        return x
    else:
        raise TypeError("Input must be pandas Series or DataFrame.")

@dataclass
class JMFeatureEngineer:
    """
    Jump Model (JM) ç”¨ã®ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°:
      - DD(log): halflife in {5, 21}
      - Mean:    halflife in {5, 10, 21}
      - Sortino: halflife in {5, 10, 21}
    å­¦ç¿’ï¼ˆfitï¼‰åŒºé–“ã§å„ç‰¹å¾´ã‚’ z-score åŒ–ã™ã‚‹ãŸã‚ã®å¹³å‡ãƒ»æ¨™æº–åå·®ã‚’ä¿æŒã€‚
    """
    dd_halflives: Iterable[int] = (5, 21)
    mean_halflives: Iterable[int] = (5, 10, 21)
    sortino_halflives: Iterable[int] = (5, 10, 21)
    eps: float = 1e-12

    # feature_name -> (mean, std)
    scalers_: Dict[str, Tuple[float, float]] = field(default_factory=dict)
    fitted_: bool = False

    def compute_raw_features(
        self,
        excess_returns: ArrayLike,
    ) -> pd.DataFrame:
        """
        ç”Ÿã®ç‰¹å¾´é‡ã‚’è¨ˆç®—ï¼ˆæ¨™æº–åŒ–ã¯ã—ãªã„ï¼‰ã€‚
        Parameters
        ----------
        excess_returns : Series or DataFrame
            è¶…éãƒªã‚¿ãƒ¼ãƒ³ï¼ˆä¾‹ï¼šè³‡ç”£ãƒªã‚¿ãƒ¼ãƒ³ - ç„¡ãƒªã‚¹ã‚¯ãƒªã‚¿ãƒ¼ãƒ³ï¼‰ã€‚æ—¥æ¬¡æ¨å¥¨ã€‚
        Returns
        -------
        DataFrame: åˆ—ã¯ MultiIndex (asset, feature) ã§è¿”ã™
        """
        df = _ensure_df(excess_returns).copy()
        # åˆ—åã‚’ string ã«çµ±ä¸€
        df.columns = [str(c) for c in df.columns]

        out_cols = {}
        for col in df.columns:
            r = df[col].astype(float)

            # Downside Deviation (log)
            for hl in self.dd_halflives:
                dd = _ewm_downside_dev(r, halflife=hl, eps=self.eps)
                dd_log = np.log(dd)  # è«–æ–‡ã¯ DD ã‚’ãƒ­ã‚°å¤‰æ›ã—ã¦ç‰¹å¾´åŒ–
                out_cols[(col, f"dd_log_hl{hl}")] = dd_log

            # EWM Mean
            for hl in self.mean_halflives:
                mu = _ewm_mean(r, halflife=hl)
                out_cols[(col, f"mean_hl{hl}")] = mu

            # Sortino Ratio = Mean / DDï¼ˆDD ã¯ãƒ­ã‚°å¤‰æ›ã›ãšã«ä½¿ç”¨ï¼‰
            for hl in self.sortino_halflives:
                mu = _ewm_mean(r, halflife=hl)
                dd = _ewm_downside_dev(r, halflife=hl, eps=self.eps)
                sortino = mu / dd.replace(0, np.nan)
                out_cols[(col, f"sortino_hl{hl}")] = sortino

        feat = pd.DataFrame(out_cols)
        feat.columns = pd.MultiIndex.from_tuples(feat.columns, names=["asset", "feature"])
        return feat

    def fit(
        self,
        features: pd.DataFrame,
        train_slice: Optional[slice] = None,
    ) -> "JMFeatureEngineer":
        """
        å­¦ç¿’åŒºé–“ï¼ˆtrain_sliceï¼‰ã§å„ç‰¹å¾´ã®å¹³å‡ãƒ»æ¨™æº–åå·®ã‚’å­¦ç¿’ï¼ˆz-score ç”¨ï¼‰ã€‚
        features: MultiIndex columns: (asset, feature)
        train_slice: ä¾‹) slice("2000-01-01", "2010-12-31") ã¾ãŸã¯ Noneï¼ˆå…¨æœŸé–“ï¼‰
        """
        if train_slice is not None:
            X = features.loc[train_slice]
        else:
            X = features

        # ç‰¹å¾´ã”ã¨ï¼ˆasset åˆ¥ã«åŒå feature ã¯åŒã˜ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã—ãŸã„å ´åˆã¯ã€
        # ä¸‹ã® groupby level ã‚’ "feature" ã®ã¿ã«å¤‰ãˆã‚‹ã€‚ã“ã“ã§ã¯è³‡ç”£åˆ¥ã«ç‹¬ç«‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼‰
        for col in X.columns:
            s = X[col].astype(float)
            m = float(s.mean(skipna=True))
            v = float(s.std(skipna=True, ddof=0))
            # ã‚¼ãƒ­åˆ†æ•£å¯¾ç­–
            if not np.isfinite(v) or v < self.eps:
                v = 1.0
            self.scalers_[str(col)] = (m, v)

        self.fitted_ = True
        return self

    def transform(self, features: pd.DataFrame) -> pd.DataFrame:
        """
        å­¦ç¿’æ¸ˆã¿ã‚¹ã‚±ãƒ¼ãƒ©ã§ z-score æ¨™æº–åŒ–ã€‚
        """
        if not self.fitted_:
            raise RuntimeError("Call fit() before transform().")
        Z = pd.DataFrame(index=features.index, columns=features.columns, dtype=float)
        for col in features.columns:
            key = str(col)
            m, v = self.scalers_.get(key, (0.0, 1.0))
            Z[col] = (features[col].astype(float) - m) / v
        return Z

    def fit_transform(
        self,
        features: pd.DataFrame,
        train_slice: Optional[slice] = None,
    ) -> pd.DataFrame:
        self.fit(features, train_slice=train_slice)
        return self.transform(features)

def compute_excess_return(
    asset_returns: ArrayLike,
    rf_returns: Optional[pd.Series] = None,
) -> ArrayLike:
    """
    è¶…éãƒªã‚¿ãƒ¼ãƒ³ã‚’è¨ˆç®—ã€‚rf_returns ãŒ None ã®å ´åˆã¯ãã®ã¾ã¾è¿”ã™ã€‚
    - asset_returns: Series or DataFrameï¼ˆãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆã§ã¯ãªãå®Ÿæ•°ï¼š0.01 = 1%ï¼‰
    - rf_returns:    Seriesï¼ˆæ—¥æ¬¡ã®ç„¡ãƒªã‚¹ã‚¯ãƒªã‚¿ãƒ¼ãƒ³ï¼‰
    """
    X = _ensure_df(asset_returns).astype(float)
    if rf_returns is None:
        return X if isinstance(asset_returns, pd.DataFrame) else X.iloc[:, 0]
    rf = rf_returns.reindex(X.index).astype(float).fillna(0.0)
    if isinstance(asset_returns, pd.Series):
        return (X.iloc[:, 0] - rf).rename(asset_returns.name)
    else:
        return X.sub(rf, axis=0)

# ===== ä½¿ã„æ–¹ï¼ˆä¾‹ï¼‰ =====
if __name__ == "__main__":
    # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ä½œæˆï¼ˆå®Ÿé‹ç”¨ã§ã¯å®Ÿãƒ‡ãƒ¼ã‚¿ã«ç½®ãæ›ãˆï¼‰
    idx = pd.date_range("2000-01-01", "2024-12-31", freq="B")
    np.random.seed(7)
    # å¹´ç‡ ~10%ãƒ»å¹´ãƒœãƒ© ~15% ã‚’æ—¥æ¬¡ã«æ›ç®—ã—ãŸãƒ©ãƒ•ãªæ“¬ä¼¼ãƒ‡ãƒ¼ã‚¿
    mu_d = 0.10 / 252
    sig_d = 0.15 / np.sqrt(252)
    r1 = pd.Series(np.random.normal(mu_d, sig_d, len(idx)), index=idx, name="assetA")
    r2 = pd.Series(np.random.normal(mu_d*0.7, sig_d*1.2, len(idx)), index=idx, name="assetB")
    rf = pd.Series(0.02/252, index=idx, name="rf")  # å¹´ç‡2%ç›¸å½“ã®ä¸€å®šç„¡ãƒªã‚¹ã‚¯

    # è¤‡æ•°è³‡ç”£ã® DataFrame
    R = pd.concat([r1, r2], axis=1)

    # è¶…éãƒªã‚¿ãƒ¼ãƒ³
    Rex = compute_excess_return(R, rf_returns=rf)

    # ç‰¹å¾´é‡è¨ˆç®—
    fe = JMFeatureEngineer()
    raw_feat = fe.compute_raw_features(Rex)

    # å­¦ç¿’åŒºé–“ï¼ˆä¾‹ï¼š2000-01-01ã€œ2010-12-31ï¼‰ã§æ¨™æº–åŒ–ã‚’å­¦ç¿’ã—ã€å…¨æœŸé–“ã«é©ç”¨
    Z = fe.fit_transform(raw_feat, train_slice=slice("2000-01-01", "2010-12-31"))

    # å˜ä¸€è³‡ç”£ã ã‘ã‚’æ¸¡ã™å ´åˆï¼ˆSeriesï¼‰
    Rex_single = compute_excess_return(r1, rf_returns=rf)
    raw_single = fe.compute_raw_features(Rex_single)
    Z_single = fe.fit_transform(raw_single, train_slice=slice("2000-01-01", "2010-12-31"))

    # çµæœã®åˆ—ï¼ˆMultiIndexï¼‰ï¼š(asset, feature)
    print(Z.columns[:10])
    print(Z.tail())
```

### å®Ÿè£…ãƒ¡ãƒ¢

*   \*\*DDï¼ˆãƒ­ã‚°ï¼‰\*\*ã¯ `np.log(DD)` ã‚’æ¡ç”¨ï¼ˆæ•°å€¤å®‰å®šåŒ–ã®ãŸã‚ã‚¯ãƒªãƒƒãƒ—ï¼†epsã‚’ä»˜ä¸ï¼‰ã€‚
*   **Sortino æ¯”** ã¯ `å¹³å‡ / DD`ï¼ˆDD ã¯ãƒ­ã‚°å‰ã®å€¤ã‚’ä½¿ç”¨ï¼‰ã€‚
*   **æ¨™æº–åŒ–**ã¯è³‡ç”£Ã—ç‰¹å¾´ã®å„åˆ—ã”ã¨ï¼ˆåˆ—å˜ä½ï¼‰ã« z-scoreã€‚è³‡ç”£æ¨ªæ–­ã§åŒä¸€ç‰¹å¾´ã‚’å…±é€šã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ãŸã„å ´åˆã¯ `fit()` å†…ã§åˆ—ãƒ¬ãƒ™ãƒ«ã‚’ `"feature"` ã®ã¿ã«ã¾ã¨ã‚ã‚‹å®Ÿè£…ã«å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚
*   **å­¦ç¿’çª“**ã¯è«–æ–‡ã«ãªã‚‰ã„ã€Œéå»11å¹´ã€ã‚’æƒ³å®šã§ãã¾ã™ã€‚é‹ç”¨æ™‚ã¯åŠå¹´ã”ã¨ã« `fit` ã—ç›´ã™é‹ç”¨ãŒè‡ªç„¶ã§ã™ã€‚
*   **å…¥åŠ›**ã¯ã€Œ**è¶…éãƒªã‚¿ãƒ¼ãƒ³**ã€ã‚’æƒ³å®šã€‚`compute_excess_return` ã§ç„¡ãƒªã‚¹ã‚¯ã‚’å·®ã—å¼•ã‘ã¾ã™ã€‚

å¿…è¦ã§ã‚ã‚Œã°ã€ã“ã®å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‹ã‚‰ **JM å­¦ç¿’å™¨ï¼ˆã‚¯ãƒ©ã‚¹ã‚¿æ•°=2ï¼‰ç”¨ã« X è¡Œåˆ—ã‚’ä½œã‚‹ãƒ˜ãƒ«ãƒ‘**ã‚„ã€**åŠæ¸›æœŸã®å€™è£œã‚’å¤‰ãˆã‚‹è¨­å®š**ã€**å­¦ç¿’çª“ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£**ã‚‚è¿½è¨˜ã—ã¾ã™ã€‚

## Response:
ä»¥ä¸‹ã¯ã€JMï¼ˆJump Modelï¼‰ç”¨ç‰¹å¾´é‡ã‚’**æœ€å°æ§‹æˆã§è¨ˆç®—ã™ã‚‹ã‚·ãƒ³ãƒ—ãƒ«å®Ÿè£…**ã§ã™ã€‚  
ä¾å­˜ã¯ `pandas` ã¨ `numpy` ã®ã¿ã§ã™ã€‚

```python
import pandas as pd
import numpy as np

def jm_features(returns: pd.Series) -> pd.DataFrame:
    """
    JMï¼ˆStatistical Jump Modelï¼‰ç”¨ç‰¹å¾´é‡ã®æœ€å°å®Ÿè£…ã€‚
    å…¥åŠ›: returns â€¦ è³‡ç”£ã®è¶…éãƒªã‚¿ãƒ¼ãƒ³ï¼ˆSeries, indexã¯æ—¥ä»˜ï¼‰
    å‡ºåŠ›: DataFrameï¼ˆ8åˆ—ï¼‰
    """
    # æŒ‡æ•°åŠ é‡ç§»å‹•å¹³å‡
    def ewm_mean(x, hl): return x.ewm(halflife=hl, adjust=False).mean()
    def ewm_downside(x, hl):
        neg = x.clip(upper=0)
        dd = np.sqrt((neg**2).ewm(halflife=hl, adjust=False).mean())
        return np.log(dd + 1e-8)  # logå¤‰æ›
    
    feats = pd.DataFrame(index=returns.index)
    
    # Downside Deviation (log)
    feats["dd_log_hl5"] = ewm_downside(returns, 5)
    feats["dd_log_hl21"] = ewm_downside(returns, 21)
    
    # å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³
    for hl in [5, 10, 21]:
        feats[f"mean_hl{hl}"] = ewm_mean(returns, hl)
    
    # Sortinoæ¯” = å¹³å‡ / DDï¼ˆélogç‰ˆï¼‰
    for hl in [5, 10, 21]:
        dd = np.sqrt((returns.clip(upper=0)**2).ewm(halflife=hl, adjust=False).mean())
        feats[f"sortino_hl{hl}"] = ewm_mean(returns, hl) / (dd + 1e-8)
    
    return feats

# === ä½¿ç”¨ä¾‹ ===
if __name__ == "__main__":
    np.random.seed(0)
    idx = pd.date_range("2020-01-01", "2024-12-31", freq="B")
    r = pd.Series(np.random.normal(0.0003, 0.01, len(idx)), index=idx)
    
    features = jm_features(r)
    print(features.head())
```

### ğŸ” èª¬æ˜

| ç‰¹å¾´é‡ | å†…å®¹ | åŠæ¸›æœŸ |
| --- | --- | --- |
| `dd_log_hl5`, `dd_log_hl21` | ãƒ€ã‚¦ãƒ³ã‚µã‚¤ãƒ‰åå·®ï¼ˆlogï¼‰ | 5æ—¥ãƒ»21æ—¥ |
| `mean_hl5`, `mean_hl10`, `mean_hl21` | æŒ‡æ•°åŠ é‡å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³ | 5,10,21æ—¥ |
| `sortino_hl5`, `sortino_hl10`, `sortino_hl21` | Sortinoæ¯” | 5,10,21æ—¥ |

ã“ã®é–¢æ•°ã§å¾—ã‚‰ã‚Œã‚‹8åˆ—ã®ç‰¹å¾´é‡ã‚’ã€å„è³‡ç”£ã”ã¨ã« JM ã®å…¥åŠ›ç‰¹å¾´ã¨ã—ã¦åˆ©ç”¨ã§ãã¾ã™ã€‚

## Response:
äº†è§£ã§ã™ã€‚**JMã§å¾—ãŸãƒ¬ã‚¸ãƒ¼ãƒ ãƒ©ãƒ™ãƒ«ï¼ˆ0/1ï¼‰ã‚’ã€Œç¿Œæ—¥ãƒ¬ã‚¸ãƒ¼ãƒ ã€ã¸æ•™å¸«ã‚ã‚Šå­¦ç¿’ã™ã‚‹ XGBoost æœ€å°å®Ÿè£…**ã‚’ç¤ºã—ã¾ã™ã€‚  
å…¥åŠ›ã¯ã€Œç‰¹å¾´é‡ DataFrameï¼ˆè¡Œ=æ—¥ä»˜ã€åˆ—=ç‰¹å¾´ï¼‰ã€ã€ŒJMãŒä»˜ä¸æ¸ˆã¿ã®ãƒ¬ã‚¸ãƒ¼ãƒ  Seriesï¼ˆ0/1ã€è¡Œ=æ—¥ä»˜ã€å½“æ—¥ãƒ¬ã‚¸ãƒ¼ãƒ ï¼‰ã€ã®2ã¤ã ã‘ã€‚  
å‡ºåŠ›ã¯å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¨ã€ãƒ†ã‚¹ãƒˆåŒºé–“ã®äºˆæ¸¬ç¢ºç‡ãƒ»äºˆæ¸¬ãƒ©ãƒ™ãƒ«ã§ã™ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ç¢ºç‡ã®EWMå¹³æ»‘åŒ–ã‚‚å¯ï¼‰ã€‚

```python
# æœ€å°ä¾å­˜: pandas, numpy, xgboost
import numpy as np
import pandas as pd
from typing import Optional, Dict, Any
from dataclasses import dataclass
from xgboost import XGBClassifier

@dataclass
class XGBRegimeForecaster:
    """
    Jump Modelï¼ˆJMï¼‰ã§æ¨å®šã—ãŸå½“æ—¥ãƒ¬ã‚¸ãƒ¼ãƒ  s_t (0/1) ã‚’æ•™å¸«ä¿¡å·ã«ã€
    ç‰¹å¾´é‡ x_t ã‹ã‚‰ç¿Œæ—¥ãƒ¬ã‚¸ãƒ¼ãƒ  s_{t+1} ã‚’äºˆæ¸¬ã™ã‚‹æœ€å°å®Ÿè£…ã€‚

    - feat_df: å½¢çŠ¶ (T, D) ã®ç‰¹å¾´é‡ï¼ˆè¡Œ=æ—¥ä»˜index, åˆ—=ç‰¹å¾´ï¼‰
    - regime_labels: å½¢çŠ¶ (T,) ã® Seriesï¼ˆJMã®å½“æ—¥ãƒ¬ã‚¸ãƒ¼ãƒ  0/1ï¼‰
                     â€» 0=ãƒ–ãƒ«ã€1=ãƒ™ã‚¢ï¼ˆè«–æ–‡ã«åˆã‚ã›ã‚‹ãªã‚‰ã“ã®å‘ãï¼‰
    - horizon: æ—¢å®š=1ï¼ˆç¿Œæ—¥ãƒ¬ã‚¸ãƒ¼ãƒ ã‚’äºˆæ¸¬ï¼‰
    - train_end: å­¦ç¿’æœŸé–“ã®æœ€çµ‚æ—¥ï¼ˆæ–‡å­—åˆ— "YYYY-MM-DD" ãªã©ï¼‰ã€‚
                 None ã®å ´åˆã¯å…ˆé ­80%ã‚’å­¦ç¿’ã«ä½¿ç”¨ï¼ˆæ™‚ç³»åˆ—ã‚¹ãƒ—ãƒªãƒƒãƒˆï¼‰
    - smooth_halflife: äºˆæ¸¬ç¢ºç‡ã®æŒ‡æ•°å¹³æ»‘ã®åŠæ¸›æœŸï¼ˆNoneã§å¹³æ»‘ãªã—ï¼‰
    - xgb_params: XGBClassifier ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆæŒ‡å®šã—ãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæœ€å°æ§‹æˆï¼‰
    """
    feat_df: pd.DataFrame
    regime_labels: pd.Series
    horizon: int = 1
    train_end: Optional[str] = None
    smooth_halflife: Optional[int] = None
    xgb_params: Optional[Dict[str, Any]] = None

    def fit_predict(self):
        # 1) æ•™å¸«ä¿¡å·ã‚’ horizon ã ã‘å…ˆã«ã‚·ãƒ•ãƒˆï¼ˆs_{t+1} ã‚’ t ã®ç‰¹å¾´ã§å½“ã¦ã‚‹ï¼‰
        y = self.regime_labels.shift(-self.horizon).reindex(self.feat_df.index)
        # ãƒ©ãƒ™ãƒ«ãŒæ¬ ã‘ã‚‹æœ«å°¾ã‚’è½ã¨ã™
        valid_idx = y.dropna().index
        X = self.feat_df.loc[valid_idx]
        y = y.loc[valid_idx].astype(int)

        # 2) æ™‚ç³»åˆ—ã‚¹ãƒ—ãƒªãƒƒãƒˆï¼ˆtrain_end æŒ‡å®šãŒç„¡ã„å ´åˆã¯ 8:2ï¼‰
        if self.train_end is not None:
            train_mask = X.index <= pd.to_datetime(self.train_end)
        else:
            split = int(len(X) * 0.8)
            train_mask = pd.Series(False, index=X.index)
            train_mask.iloc[:split] = True

        X_train, y_train = X.loc[train_mask], y.loc[train_mask]
        X_test,  y_test  = X.loc[~train_mask], y.loc[~train_mask]

        # 3) XGBoost æœ€å°æ§‹æˆï¼ˆãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ åˆ†å‰²ã§é«˜é€Ÿï¼‰
        params = dict(
            n_estimators=200,
            learning_rate=0.05,
            max_depth=4,
            subsample=0.9,
            colsample_bytree=0.9,
            objective="binary:logistic",
            eval_metric="logloss",
            tree_method="hist",
            random_state=42,
            n_jobs=-1,
        )
        if self.xgb_params:
            params.update(self.xgb_params)

        clf = XGBClassifier(**params)
        clf.fit(X_train, y_train)

        # 4) äºˆæ¸¬ï¼ˆç¢ºç‡ï¼‰
        proba_test = pd.Series(
            clf.predict_proba(X_test)[:, 1],
            index=X_test.index,
            name="p_bear_next"
        )

        # 5) ã‚ªãƒ—ã‚·ãƒ§ãƒ³: ç¢ºç‡ã®æŒ‡æ•°å¹³æ»‘ï¼ˆãƒ¬ã‚¸ãƒ¼ãƒ æŒç¶šæ€§ã®å¼±ã•ã‚’ç·©å’Œï¼‰
        if self.smooth_halflife is not None and self.smooth_halflife > 0:
            proba_smoothed = proba_test.ewm(halflife=self.smooth_halflife, adjust=False).mean()
        else:
            proba_smoothed = proba_test.copy()

        # 6) é–¾å€¤ 0.5 ã§ã‚¯ãƒ©ã‚¹åŒ–ï¼ˆ>0.5 ã‚’ãƒ™ã‚¢=1ï¼‰
        y_pred = (proba_smoothed >= 0.5).astype(int)
        y_pred.name = "y_pred_bear_next"

        # 7) è¿”å´ï¼ˆå­¦ç¿’å™¨ãƒ»ãƒ†ã‚¹ãƒˆæœŸé–“ã®å®Ÿæ¸¬/ç¢ºç‡/äºˆæ¸¬ï¼‰
        return {
            "model": clf,
            "X_train": X_train, "y_train": y_train,
            "X_test": X_test,   "y_test": y_test,
            "proba_raw": proba_test,
            "proba_smoothed": proba_smoothed,
            "y_pred": y_pred,
            "feature_importance": pd.Series(clf.feature_importances_, index=X.columns, name="gain")
        }

# ===== ä½¿ã„æ–¹ï¼ˆæœ€å°ä¾‹ï¼‰ =====
if __name__ == "__main__":
    # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ä½œæˆ: ç‰¹å¾´é‡(3åˆ—) + JMãƒ©ãƒ™ãƒ«(0/1)
    idx = pd.date_range("2010-01-01", "2020-12-31", freq="B")
    rng = np.random.default_rng(0)
    feat = pd.DataFrame({
        "mean_hl5":  rng.normal(0, 1, len(idx)),
        "dd_log_hl5":rng.normal(0, 1, len(idx)),
        "sortino_hl5":rng.normal(0, 1, len(idx)),
    }, index=idx)

    # JMã§å¾—ãŸå½“æ—¥ãƒ¬ã‚¸ãƒ¼ãƒ ï¼ˆ0=ãƒ–ãƒ«, 1=ãƒ™ã‚¢ï¼‰ã¨ä»®å®šï¼ˆã“ã“ã§ã¯ãƒ€ãƒŸãƒ¼ï¼‰
    base = rng.normal(0, 1, len(idx)).cumsum()
    regime = pd.Series((base > np.median(base)).astype(int), index=idx, name="regime_t")

    forecaster = XGBRegimeForecaster(
        feat_df=feat,
        regime_labels=regime,
        horizon=1,                 # s_{t+1} ã‚’äºˆæ¸¬
        train_end="2017-12-31",    # æ™‚ç³»åˆ—ã§å­¦ç¿’æœŸé–“ã‚’åŒºåˆ‡ã‚‹ï¼ˆæœªæŒ‡å®šãªã‚‰8:2ï¼‰
        smooth_halflife=8,         # äºˆæ¸¬ç¢ºç‡ã‚’å°‘ã—å¹³æ»‘åŒ–ï¼ˆç„¡ã—ãªã‚‰ Noneï¼‰
        xgb_params=None            # è¿½åŠ /ä¸Šæ›¸ãã—ãŸã„æ™‚ã«è¾æ›¸ã‚’æ¸¡ã™
    )
    res = forecaster.fit_predict()

    print("Test AUC-ish quick check (not exact AUC):",
          np.corrcoef(res["y_test"], res["proba_smoothed"])[0,1])
    print("Feature importance (gain):")
    print(res["feature_importance"].sort_values(ascending=False).head())

    # ãƒ¬ã‚¸ãƒ¼ãƒ ã«åŸºã¥ã 0/1 æˆ¦ç•¥ã®ç°¡æ˜“ãƒ“ãƒ¥ãƒ¼ï¼ˆãƒ™ã‚¢=1ãªã‚‰ç„¡ãƒªã‚¹ã‚¯ã¨ä»®å®šï¼‰
    # ã“ã“ã§ã¯ãƒ†ã‚¹ãƒˆæœŸé–“ã®ã€Œè³‡ç”£ãƒªã‚¿ãƒ¼ãƒ³ã€ã‚’ãƒ€ãƒŸãƒ¼ç”Ÿæˆã—ã¦è©•ä¾¡ä¾‹ã‚’ä»˜ä¸
    r_test = pd.Series(rng.normal(0.0003, 0.01, len(res["y_test"])), index=res["y_test"].index)
    rf_test = pd.Series(0.02/252, index=r_test.index)  # å¹´ç‡2%ã®ç„¡ãƒªã‚¹ã‚¯
    # äºˆæ¸¬ãŒãƒ™ã‚¢=1ã®ã¨ãã¯ rfã€ãƒ–ãƒ«=0ã®ã¨ãã¯ r ã‚’æ¡ç”¨
    strategy_ret = np.where(res["y_pred"]==1, rf_test.values, r_test.values)
    strat = pd.Series(strategy_ret, index=r_test.index)
    sharpe = strat.mean() / strat.std(ddof=0) * np.sqrt(252)
    print("0/1 strategy Sharpe (test):", sharpe)
```

### ä½¿ã„æ–¹ã®è¦ç‚¹

*   **å­¦ç¿’ãƒ‡ãƒ¼ã‚¿**
    *   `feat_df`: JMç‰¹å¾´é‡ï¼ˆä¾‹ï¼šå…ˆã«ä½œæˆã—ãŸ `jm_features()` ã®å‡ºåŠ›ã‚„è¿½åŠ ãƒã‚¯ãƒ­ç‰¹å¾´ã‚’é€£çµã—ãŸã‚‚ã®ï¼‰ã€‚
    *   `regime_labels`: JMã§å¾—ãŸ**å½“æ—¥**ãƒ¬ã‚¸ãƒ¼ãƒ ï¼ˆ0/1ï¼‰ã€‚æœ¬å®Ÿè£…å†…ã§ `shift(-1)` ã—ã€**ç¿Œæ—¥ãƒ©ãƒ™ãƒ«**ã‚’æ•™å¸«ä¿¡å·ã«ã—ã¾ã™ã€‚
*   **æ™‚ç³»åˆ—åˆ†å‰²**
    *   `train_end="YYYY-MM-DD"` ã‚’æŒ‡å®šã™ã‚‹ã¨ã€ãã®æ—¥ã¾ã§ã‚’å­¦ç¿’ã€ãã®å¾Œã‚’ãƒ†ã‚¹ãƒˆã«ã—ã¾ã™ã€‚æœªæŒ‡å®šãªã‚‰ 8:2 ã§å…ˆé ­ã‚’å­¦ç¿’ã«ã€‚
*   **ç¢ºç‡ã®å¹³æ»‘åŒ–**
    *   `smooth_halflife` ã‚’æŒ‡å®šã™ã‚‹ã¨ `predict_proba` ã®ç³»åˆ—ã« EWM å¹³æ»‘ã‚’ã‹ã‘ã€æŒç¶šæ€§ã®ãƒ–ãƒ¬ã‚’æŠ‘ãˆã¾ã™ï¼ˆä¾‹ï¼š8ï¼‰ã€‚
*   **ã—ãã„å€¤**
    *   æ—¢å®šã¯ 0.5ï¼ˆ>0.5 ã‚’ãƒ™ã‚¢=1ï¼‰ã€‚å¿…è¦ã«å¿œã˜ã¦å¤‰æ•°åŒ–ã—ã¦ãã ã•ã„ã€‚

å¿…è¦ã§ã‚ã‚Œã°ã€**ãƒã‚¯ãƒ­ç‰¹å¾´ï¼ˆ2Yé‡‘åˆ©ã€10Y-2Yã‚¹ãƒ­ãƒ¼ãƒ—ã€VIXã€æ ªå‚µç›¸é–¢ï¼‰ã‚’è¿½åŠ ã—ã¦ `feat_df` ã«çµåˆã™ã‚‹æœ€å°é–¢æ•°**ã‚„ã€**è¤‡æ•°è³‡ç”£ã‚’åŒæ™‚ã«å›ã™ãƒ©ãƒƒãƒ‘**ã€\*\*0/1æˆ¦ç•¥ã®è©•ä¾¡é–¢æ•°ï¼ˆãƒªã‚¿ãƒ¼ãƒ³ç³»åˆ—ã‚’æ¸¡ã—ã¦Sharpe/MDDã‚’ç®—å‡ºï¼‰\*\*ã‚‚ã™ãè¶³ã—ã¾ã™ã€‚

## Response:
äº†è§£ã§ã™ã€‚è«–æ–‡ã® Table 3 ã«æ²¿ã£ã¦ã€**2Yé‡‘åˆ©ãƒ»10Yâ€“2Yã‚¹ãƒ­ãƒ¼ãƒ—ãƒ»VIXãƒ»æ ªå‚µç›¸é–¢**ã‚’è¨ˆç®—ã—ã€æ—¢å­˜ã® `feat_df`ï¼ˆè¡Œ=æ—¥ä»˜ãƒ»åˆ—=ç‰¹å¾´ï¼‰ã«çµåˆã™ã‚‹**æœ€å°å®Ÿè£…**ã§ã™ã€‚ä¾å­˜ã¯ `pandas` ã¨ `numpy` ã®ã¿ã€‚

```python
import pandas as pd
import numpy as np

def add_macro_features(
    feat_df: pd.DataFrame,
    y2: pd.Series,          # ç±³å›½2å¹´é‡‘åˆ©ï¼ˆå®Ÿæ•° or %ã€‚å˜ä½ã¯ä¸€è²«ã—ã¦ã„ã‚Œã°OKï¼‰
    y10: pd.Series,         # ç±³å›½10å¹´é‡‘åˆ©
    vix: pd.Series,         # VIXæŒ‡æ•°ï¼ˆãƒ¬ãƒ™ãƒ«ï¼‰
    stock_ret: pd.Series,   # æ ªå¼ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆä¾‹ï¼šLargeCapæ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³ï¼‰
    bond_ret: pd.Series,    # å‚µåˆ¸ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆä¾‹ï¼šAggBondæ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³ï¼‰
    corr_window: int = 252  # æ ªå‚µç›¸é–¢ã®ãƒ­ãƒ¼ãƒªãƒ³ã‚°çª“ï¼ˆå–¶æ¥­æ—¥æ›ç®—ã§1å¹´ï¼‰
) -> pd.DataFrame:
    """
    è«–æ–‡ã®ã‚¯ãƒ­ã‚¹ã‚¢ã‚»ãƒƒãƒˆãƒ»ãƒã‚¯ãƒ­ç‰¹å¾´ã‚’è¨ˆç®—ã—ã¦ feat_df ã«çµåˆï¼ˆæœ€å°å®Ÿè£…ï¼‰ã€‚

    - 2Yé‡‘åˆ©ã®å·®åˆ†ã®EWMA(hl=21): y2_diff_ewm21
    - ã‚¤ãƒ¼ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ–(10Y-2Y)ã®EWMA(hl=10): slope_ewm10
    - ã‚¤ãƒ¼ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ–å·®åˆ†ã®EWMA(hl=21): slope_diff_ewm21
    - VIXã®logå·®åˆ†ã®EWMA(hl=63): vix_logdiff_ewm63
    - æ ªå‚µç›¸é–¢ï¼ˆãƒ­ãƒ¼ãƒªãƒ³ã‚°ç›¸é–¢, çª“=252å–¶æ¥­æ—¥ï¼‰: stock_bond_corr_252d
    """
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ•´å½¢ & ã‚¢ãƒ©ã‚¤ãƒ³
    idx = pd.Index(feat_df.index).sort_values()
    y2  = y2.reindex(idx).astype(float)
    y10 = y10.reindex(idx).astype(float)
    vix = vix.reindex(idx).astype(float)
    stock_ret = stock_ret.reindex(idx).astype(float)
    bond_ret  = bond_ret.reindex(idx).astype(float)

    # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
    def ewm_mean(x, hl): 
        return x.ewm(halflife=hl, adjust=False).mean()

    # 2Yé‡‘åˆ© å·®åˆ†ã®EWMA(hl=21)
    y2_diff_ewm21 = ewm_mean(y2.diff(), hl=21).rename("y2_diff_ewm21")

    # ã‚¤ãƒ¼ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ–ï¼ˆ10Y-2Yï¼‰
    slope = (y10 - y2)
    slope_ewm10       = ewm_mean(slope, hl=10).rename("slope_ewm10")
    slope_diff_ewm21  = ewm_mean(slope.diff(), hl=21).rename("slope_diff_ewm21")

    # VIX: logå·®åˆ†ã®EWMA(hl=63)
    vix_logdiff = np.log(vix.replace(0, np.nan)).diff()  # 0å›é¿
    vix_logdiff_ewm63 = ewm_mean(vix_logdiff, hl=63).rename("vix_logdiff_ewm63")

    # æ ªå‚µç›¸é–¢ï¼ˆãƒ­ãƒ¼ãƒªãƒ³ã‚°ç›¸é–¢ï¼‰
    stock_bond_corr = stock_ret.rolling(corr_window).corr(bond_ret).rename(f"stock_bond_corr_{corr_window}d")

    macro = pd.concat(
        [y2_diff_ewm21, slope_ewm10, slope_diff_ewm21, vix_logdiff_ewm63, stock_bond_corr],
        axis=1
    )

    return pd.concat([feat_df, macro], axis=1)

# ===== ä½¿ã„æ–¹ï¼ˆæœ€å°ä¾‹ï¼‰ =====
if __name__ == "__main__":
    np.random.seed(7)
    idx = pd.date_range("2012-01-01", "2024-12-31", freq="B")

    # ä¾‹: æ—¢å­˜ã®JMç‰¹å¾´ï¼ˆãƒ€ãƒŸãƒ¼3åˆ—ï¼‰
    feat_df = pd.DataFrame({
        "mean_hl5":   np.random.normal(0, 1, len(idx)),
        "dd_log_hl5": np.random.normal(0, 1, len(idx)),
        "sortino_hl5":np.random.normal(0, 1, len(idx)),
    }, index=idx)

    # ãƒã‚¯ãƒ­å…¥åŠ›ï¼ˆãƒ€ãƒŸãƒ¼ï¼‰
    y2  = pd.Series(0.02 + 0.00001*np.arange(len(idx)) + np.random.normal(0, 0.0005, len(idx)), index=idx)  # 2Y
    y10 = pd.Series(0.03 + 0.00001*np.arange(len(idx)) + np.random.normal(0, 0.0005, len(idx)), index=idx)  # 10Y
    vix = pd.Series(18 + np.random.normal(0, 0.5, len(idx)), index=idx)  # ãƒ¬ãƒ™ãƒ«
    stock_ret = pd.Series(np.random.normal(0.0003, 0.01, len(idx)), index=idx)
    bond_ret  = pd.Series(np.random.normal(0.00015, 0.004, len(idx)), index=idx)

    feat_all = add_macro_features(feat_df, y2, y10, vix, stock_ret, bond_ret)
    print(feat_all.tail())
```

### ãƒ¡ãƒ¢

*   **å˜ä½**ï¼šé‡‘åˆ©ãƒ»VIXã®å˜ä½ã¯å·®åˆ†/æ¯”ç‡ã§ä½¿ã†ãŸã‚ã€%ã§ã‚‚å®Ÿæ•°ã§ã‚‚ä¸€è²«ã—ã¦ã„ã‚Œã°å•é¡Œã‚ã‚Šã¾ã›ã‚“ï¼ˆå·®åˆ†ã¯ã€Œï¼…ãƒã‚¤ãƒ³ãƒˆå·®ã€ã«ãªã‚Šã¾ã™ï¼‰ã€‚
*   **æŒ‡æ•°å¹³æ»‘(EWMA)**ï¼š
    *   2Yå·®åˆ†â†’hl=21ã€ã‚¹ãƒ­ãƒ¼ãƒ—â†’hl=10ã€ã‚¹ãƒ­ãƒ¼ãƒ—å·®åˆ†â†’hl=21ã€VIX logå·®åˆ†â†’hl=63ï¼ˆè«–æ–‡è¨­å®šï¼‰
*   **æ ªå‚µç›¸é–¢**ï¼š`Series.rolling(window).corr(other)` ã§é«˜é€Ÿã«ç®—å‡ºï¼ˆã“ã“ã§ã¯ 252 å–¶æ¥­æ—¥ â‰’ 1å¹´ï¼‰ã€‚
*   **ã‚¢ãƒ©ã‚¤ãƒ³**ï¼š`feat_df.index` ã«å…¨å…¥åŠ›Seriesã‚’ `reindex` ã—ã¦çµåˆï¼ˆæœ€å°å®Ÿè£…ã®ãŸã‚æ¬ æåŸ‹ã‚ã¯ã—ã¾ã›ã‚“ï¼‰ã€‚

ã“ã® `feat_all` ã‚’ãã®ã¾ã¾ `XGBRegimeForecaster(feat_df=feat_all, ...)` ã«æ¸¡ã›ã°ã€JMãƒ©ãƒ™ãƒ«ã‹ã‚‰**ç¿Œæ—¥ãƒ¬ã‚¸ãƒ¼ãƒ ç¢ºç‡**ã‚’äºˆæ¸¬ã§ãã¾ã™ã€‚

## Response:
Federal Reserve Bank of St. Louis ã® Federal Reserve Economic Data (FRED) ã‹ã‚‰ãƒã‚¯ãƒ­å¤‰æ•°ã‚’å–å¾—ã™ã‚‹ãŸã‚ã«å¿…è¦ãª API ã‚­ãƒ¼ã«ã¤ã„ã¦ã€ä»¥ä¸‹ã«æ•´ç†ã—ã¾ã™ã€‚

* * *

### âœ… å¿…è¦ãªã‚­ãƒ¼ï¼æº–å‚™äº‹é …

1.  FRED ç”¨ã® **API ã‚­ãƒ¼ï¼ˆ32 æ–‡å­—ã®è‹±æ•°å­—ãƒ»å°æ–‡å­—ï¼‰** ã‚’å–å¾—ã™ã‚‹ã€‚ [FRED+1](https://fred.stlouisfed.org/docs/api/api_key.html?utm_source=chatgpt.com)
2.  API ã‚’å‘¼ã³å‡ºã™éš›ã¯ã€URL ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¾ãŸã¯ HTTP ãƒ˜ãƒƒãƒ€ãƒ¼ã«ã“ã®ã‚­ãƒ¼ã‚’å«ã‚ã‚‹ã€‚ä¾‹ãˆã°ï¼š
    ```
    https://api.stlouisfed.org/fred/series/observations?series_id=UNRATE&api_key=<ã‚ãªãŸã®ã‚­ãƒ¼>&file_type=json
    ```
    [FRED+1](https://fred.stlouisfed.org/docs/api/api_key.html?utm_source=chatgpt.com)  
    ã¾ãŸãƒãƒ¼ã‚¸ãƒ§ãƒ³ 2 ä»¥é™ã§ã¯ã€ãƒ˜ãƒƒãƒ€ãƒ¼ã« `Authorization: Bearer <ã‚­ãƒ¼>` ã‚’ä½¿ãˆã‚‹ã¨ã„ã†èª¬æ˜ã‚‚ã‚ã‚Šã¾ã™ã€‚ [FRED](https://fred.stlouisfed.org/docs/api/fred/v2/api_key.html?utm_source=chatgpt.com)
3.  ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç™»éŒ²ãŒå¿…è¦ã€‚ãƒ­ã‚°ã‚¤ãƒ³å¾Œã«ã€ŒRequest or view your API keysã€ã‹ã‚‰è‡ªåˆ†å°‚ç”¨ã®ã‚­ãƒ¼ã‚’ç™ºè¡Œã§ãã¾ã™ã€‚ [FRED+1](https://fred.stlouisfed.org/docs/api/api_key.html?utm_source=chatgpt.com)
4.  Python ãªã©ã§åˆ©ç”¨ã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆä¾‹ï¼š fredapi ï¼‰ã‚’ä½¿ã†å ´åˆã¯ã€ç’°å¢ƒå¤‰æ•° `FRED_API_KEY` ã«ã‚­ãƒ¼ã‚’è¨­å®šã™ã‚‹ã®ãŒä¸€èˆ¬çš„ã§ã™ã€‚ [PyPI+1](https://pypi.org/project/fredapi/?utm_source=chatgpt.com)

* * *

ã‚‚ã—ã‚ˆã‚ã—ã‘ã‚Œã°ã€ **2 å¹´é‡‘åˆ©ãƒ»10 å¹´â€2 å¹´ã‚¹ãƒ­ãƒ¼ãƒ—ãƒ»VIXãƒ»æ ªå‚µç›¸é–¢** ã‚’ FRED ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ï¼ˆã‚­ãƒ¼èª­ã¿è¾¼ã¿è¾¼ã¿ï¼‰ã‚‚ä½œæˆã§ãã¾ã™ã€‚ã„ã‹ãŒã—ã¾ã™ã‹ï¼Ÿ

## Response:
è‰¯ã„è³ªå•ã§ã™ã€‚  
FREDï¼ˆFederal Reserve Economic Dataï¼‰ã§ã€è«–æ–‡ã§ä½¿ã‚ã‚ŒãŸã‚ˆã†ãªãƒã‚¯ãƒ­å¤‰æ•°ï¼ˆ2Yé‡‘åˆ©ã€10Yâ€“2Yã‚¹ãƒ­ãƒ¼ãƒ—ã€VIXã€æ ªå‚µç›¸é–¢ï¼‰ã‚’å–å¾—ã™ã‚‹ãŸã‚ã®ä»£è¡¨çš„ **tickerï¼ˆseries IDï¼‰** ã‚’ä»¥ä¸‹ã«ã¾ã¨ã‚ã¾ã™ã€‚  
ã“ã‚Œã‚‰ã¯ FRED ã® REST API ã‚„ Python ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆ`fredapi`ï¼‰ã§ç›´æ¥åˆ©ç”¨å¯èƒ½ã§ã™ã€‚

* * *

ğŸ“Š ä¸»ãªãƒã‚¯ãƒ­å¤‰æ•°ã® FRED Ticker ä¸€è¦§
--------------------------

| ç›®çš„ | å†…å®¹ | FRED Ticker | å˜ä½ãƒ»å‚™è€ƒ |
| --- | --- | --- | --- |
| **çŸ­æœŸé‡‘åˆ©** | ç±³å›½2å¹´å›½å‚µåˆ©å›ã‚Š | `DGS2` | æ—¥æ¬¡ã€å˜ä½: %ã€U.S. Treasury Constant Maturity 2-Year |
| **é•·æœŸé‡‘åˆ©** | ç±³å›½10å¹´å›½å‚µåˆ©å›ã‚Š | `DGS10` | æ—¥æ¬¡ã€å˜ä½: %ã€U.S. Treasury Constant Maturity 10-Year |
| **ã‚¤ãƒ¼ãƒ«ãƒ‰ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰** | 10å¹´ï¼2å¹´ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ | `T10Y2Y` | æ—¥æ¬¡ã€å˜ä½: %ã€(10Y â€“ 2Y) è‡ªå‹•è¨ˆç®—æ¸ˆã¿ series |
| **ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æŒ‡æ¨™** | CBOE Volatility Index (VIX) | `VIXCLS` | æ—¥æ¬¡ã€å˜ä½: index level |
| **æ ªå¼ãƒªã‚¿ãƒ¼ãƒ³** | S&P500æ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³ | `SP500` | æ—¥æ¬¡ã€indexã€‚ãƒªã‚¿ãƒ¼ãƒ³ã«ã™ã‚‹å ´åˆã¯ `pct_change()` |
| **å‚µåˆ¸ãƒªã‚¿ãƒ¼ãƒ³** | Bloomberg Barclays U.S. Aggregate Bond Index (è¿‘ä¼¼ä»£æ›¿) | `BAMLCC0A0CMTRIV` | æ—¥æ¬¡ã€Total Return Indexï¼ˆICE BofA U.S. Corporate, proxyï¼‰ |
| **ç„¡ãƒªã‚¹ã‚¯é‡‘åˆ©** | 3ã‹æœˆå›½åº«çŸ­æœŸè¨¼åˆ¸åˆ©å›ã‚Š | `TB3MS` | æœˆæ¬¡ï¼ˆå¿…è¦ãªã‚‰æ—¥æ¬¡è£œé–“ï¼‰ |
| **ã‚¤ãƒ³ãƒ•ãƒ¬ç‡ï¼ˆè£œè¶³ï¼‰** | æ¶ˆè²»è€…ç‰©ä¾¡æŒ‡æ•°ï¼ˆCPIï¼‰ | `CPIAUCSL` | æœˆæ¬¡ã€è£œè¶³æŒ‡æ¨™ã«ä½¿ç”¨å¯èƒ½ |

* * *

ğŸ’¡ Python ã§ã®å–å¾—ä¾‹ï¼ˆ`fredapi`ï¼‰
--------------------------

```python
from fredapi import Fred
import pandas as pd

fred = Fred(api_key="YOUR_FRED_API_KEY")

# é‡‘åˆ©ç³»
y2 = fred.get_series('DGS2')      # 2å¹´é‡‘åˆ©
y10 = fred.get_series('DGS10')    # 10å¹´é‡‘åˆ©
slope = fred.get_series('T10Y2Y') # 10Y-2Y ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰

# ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
vix = fred.get_series('VIXCLS')

# æ ªå¼ãƒ»å‚µåˆ¸ãƒªã‚¿ãƒ¼ãƒ³ç³»åˆ—
sp500 = fred.get_series('SP500')
bond_index = fred.get_series('BAMLCC0A0CMTRIV')

# æ ªå‚µãƒªã‚¿ãƒ¼ãƒ³
stock_ret = sp500.pct_change()
bond_ret  = bond_index.pct_change()

# çµåˆï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
macro_df = pd.concat([y2, y10, slope, vix, stock_ret, bond_ret], axis=1)
macro_df.columns = ["y2", "y10", "slope", "vix", "stock_ret", "bond_ret"]
```

* * *

ğŸ” å‚è€ƒ
-----

| å¤‰æ•° | å‡ºå…¸URL |
| --- | --- |
| DGS2 | [https://fred.stlouisfed.org/series/DGS2](https://fred.stlouisfed.org/series/DGS2) |
| DGS10 | [https://fred.stlouisfed.org/series/DGS10](https://fred.stlouisfed.org/series/DGS10) |
| T10Y2Y | [https://fred.stlouisfed.org/series/T10Y2Y](https://fred.stlouisfed.org/series/T10Y2Y) |
| VIXCLS | [https://fred.stlouisfed.org/series/VIXCLS](https://fred.stlouisfed.org/series/VIXCLS) |
| SP500 | [https://fred.stlouisfed.org/series/SP500](https://fred.stlouisfed.org/series/SP500) |
| BAMLCC0A0CMTRIV | [https://fred.stlouisfed.org/series/BAMLCC0A0CMTRIV](https://fred.stlouisfed.org/series/BAMLCC0A0CMTRIV) |
| TB3MS | [https://fred.stlouisfed.org/series/TB3MS](https://fred.stlouisfed.org/series/TB3MS) |

* * *

ã‚‚ã—ã”å¸Œæœ›ãŒã‚ã‚Œã°ã€ã“ã‚Œã‚‰ã‚’ã™ã¹ã¦è‡ªå‹•ã§å–å¾—ãƒ»åŠ å·¥ã—ã¦  
`add_macro_features()` ã«ç›´æ¥æ¸¡ã›ã‚‹å½¢ï¼ˆDataFrameï¼‰ã«æ•´ãˆã‚‹  
å®Œå…¨ãª Python ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼‹æ•´å½¢ï¼‰ã‚‚ãŠä½œã‚Šã—ã¾ã™ã€‚  
ä½œæˆã—ã¾ã™ã‹ï¼Ÿ

## Response:
æ€è€ƒæ™‚é–“: 1m 0s

äº†è§£ã§ã™ã€‚è«–æ–‡ã® XGBoost ã§ä½¿ã£ã¦ã„ã‚‹**ãƒã‚¯ãƒ­ç‰¹å¾´ã«é™å®š**ã™ã‚‹ã¨ã€FRED ã‹ã‚‰å¿…è¦ã«ãªã‚‹ tickerï¼ˆseries IDï¼‰ã¯æ¬¡ã®ã¨ãŠã‚Šã§ã™ï¼ˆæ ªå‚µç›¸é–¢ã¯â€œè¨ˆç®—â€ãªã®ã§ FRED ã® ticker ã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰ã€‚

å¿…è¦ãª FRED tickerï¼ˆXGBoostç”¨ãƒã‚¯ãƒ­ç‰¹å¾´ã«å¯¾å¿œï¼‰
---------------------------------

*   **2å¹´é‡‘åˆ©ï¼ˆUS 2Y Treasury Constant Maturityï¼‰**: `DGS2`
    *   ä½¿ã„æ–¹ï¼šå·®åˆ† â†’ EWMA(halflife=21) ã‚’ç‰¹å¾´åŒ–ï¼ˆ`y2_diff_ewm21`ï¼‰
*   **ã‚¤ãƒ¼ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ–ãƒ»ã‚¹ãƒ­ãƒ¼ãƒ—ï¼ˆ10Yâˆ’2Yï¼‰**: `T10Y2Y`
    *   ä½¿ã„æ–¹ï¼šãƒ¬ãƒ™ãƒ«ã® EWMA(hl=10)ï¼ˆ`slope_ewm10`ï¼‰ã¨ã€å·®åˆ†ã® EWMA(hl=21)ï¼ˆ`slope_diff_ewm21`ï¼‰
    *   â€» ã‚¹ãƒ­ãƒ¼ãƒ—ã‚’è‡ªå‰è¨ˆç®—ã™ã‚‹ãªã‚‰ `DGS10` ã¨ `DGS2` ã‹ã‚‰ `DGS10 - DGS2` ã§ã‚‚å¯ï¼ˆè«–æ–‡ã¯ã‚¹ãƒ­ãƒ¼ãƒ—ç³»åˆ—ã‚’ç›´æ¥åˆ©ç”¨ï¼‰
*   **VIXï¼ˆCBOE Volatility Indexï¼‰**: `VIXCLS`
    *   ä½¿ã„æ–¹ï¼š`log(VIX)` ã®å·®åˆ† â†’ EWMA(hl=63)ï¼ˆ`vix_logdiff_ewm63`ï¼‰

FRED ã« ticker ãŒç„¡ã„ã‚‚ã®
-------------------

*   **æ ªå‚µç›¸é–¢ï¼ˆStockâ€“Bond Correlationï¼‰**: ãªã—ï¼ˆè‡ªå‰è¨ˆç®—ï¼‰
    *   S&P 500ï¼ˆä¾‹ï¼š`SP500`ï¼‰ã¨ **Bloomberg US Aggregate Bond Indexï¼ˆAggBondï¼‰** ã®**æ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³**ã‹ã‚‰ã€ãƒ­ãƒ¼ãƒªãƒ³ã‚°ç›¸é–¢ï¼ˆä¾‹ï¼š252 å–¶æ¥­æ—¥ï¼‰ã‚’è¨ˆç®—
    *   â€» AggBond ã®ãƒˆãƒ¼ã‚¿ãƒ«ãƒªã‚¿ãƒ¼ãƒ³æŒ‡æ•°ã¯ **FREDã«ã¯ç›´æ¥ã®å…¬å¼ç³»åˆ—ãŒã‚ã‚Šã¾ã›ã‚“**ï¼ˆè«–æ–‡ã§ã¯ Bloomberg ç”±æ¥ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰ã€‚ã©ã†ã—ã¦ã‚‚ FRED ã§ä»£æ›¿ã™ã‚‹ãªã‚‰è¿‘ä¼¼ã¨ã—ã¦ **ç¤¾å‚µTR**ï¼ˆä¾‹ï¼š`BAMLCC0A0CMTRIV` ç­‰ï¼‰ã‚’ä½¿ã†æ‰‹ã‚‚ã‚ã‚Šã¾ã™ãŒã€å³å¯†ã«ã¯åˆ¥ç‰©ã§ã™ã€‚

* * *

### æœ€å°ãƒãƒƒãƒ”ãƒ³ã‚°ä¾‹ï¼ˆPythonç”¨ï¼‰

```python
FRED_TICKERS = {
    "y2": "DGS2",        # 2Y yield
    "slope_10y_2y": "T10Y2Y",  # 10Y-2Y spread
    "vix": "VIXCLS",     # VIX index (level)
    # "y10": "DGS10",    # è‡ªå‰ã§ slope = DGS10 - DGS2 ã‚’ä½œã‚‹å ´åˆã®ã¿
    # "spx": "SP500",    # æ ªå‚µç›¸é–¢ã‚’è¨ˆç®—ã™ã‚‹ãªã‚‰ä½¿ã†ï¼ˆä¾¡æ ¼æŒ‡æ•°â†’pct_changeï¼‰
    # AggBond ã¯ FRED ãªã—ï¼ˆBloombergç”±æ¥ï¼‰ã€‚ä»£æ›¿ã®ä¾‹: "BAMLCC0A0CMTRIV"
}
```

ã“ã®3ç³»åˆ—ï¼ˆ`DGS2`, `T10Y2Y`, `VIXCLS`ï¼‰ã«ã€æ‰‹å…ƒã® **S&P500 ãƒªã‚¿ãƒ¼ãƒ³** ã¨ **AggBond ãƒªã‚¿ãƒ¼ãƒ³** ã‚’çµ„ã¿åˆã‚ã›ã‚Œã°ã€è«–æ–‡ã® XGBoost ã§ç”¨ã„ãŸãƒã‚¯ãƒ­ç‰¹å¾´ã ã‘ã«çµã£ã¦å†ç¾ã§ãã¾ã™ã€‚

## Response:
äº†è§£ã€‚FREDã® **3ç³»åˆ—ï¼ˆDGS2, T10Y2Y, VIXCLSï¼‰ã ã‘** ã‚’å–å¾—ã—ã€XGBoostç”¨ãƒã‚¯ãƒ­ç‰¹å¾´ï¼ˆè«–æ–‡æº–æ‹ ï¼‰ã‚’ä½œã£ã¦è¿”ã™**æœ€å°å®Ÿè£…**ã§ã™ã€‚è¿½åŠ ä¾å­˜ã¯ `requests` ã¨ `pandas`ã€`numpy` ã®ã¿ã€‚

```python
import requests
import pandas as pd
import numpy as np

FRED_BASE = "https://api.stlouisfed.org/fred/series/observations"

def _get_fred_series(series_id: str, api_key: str, start: str, end: str) -> pd.Series:
    """
    FRED ã‹ã‚‰ series_id ã‚’æ—¥æ¬¡ã§å–å¾—ã—ã€pd.Series(date -> float) ã‚’è¿”ã™æœ€å°å®Ÿè£…ã€‚
    start/end ã¯ 'YYYY-MM-DD' æ–‡å­—åˆ—ã€‚
    """
    params = {
        "series_id": series_id,
        "api_key": api_key,
        "file_type": "json",
        "observation_start": start,
        "observation_end": end,
        "frequency": "d",          # æ—¥æ¬¡
        "aggregation_method": "eop" # æœˆæ¬¡/é€±æ¬¡ãŒæ¥ã¦ã‚‚æœŸæœ«å€¤ã§æƒãˆã‚‹ä¿é™º
    }
    r = requests.get(FRED_BASE, params=params, timeout=30)
    r.raise_for_status()
    data = r.json().get("observations", [])
    dates = [pd.to_datetime(d["date"]).normalize() for d in data]
    vals = pd.to_numeric([d["value"] for d in data], errors="coerce")
    s = pd.Series(vals, index=pd.DatetimeIndex(dates, name="date")).sort_index()
    return s.dropna()

def build_xgb_macro_features_from_fred(
    api_key: str,
    start: str,
    end: str,
    eps: float = 1e-12
) -> pd.DataFrame:
    """
    è«–æ–‡ã® XGBoost ã§ä½¿ã£ãŸ3ç³»åˆ—ã«é™å®šã—ãŸãƒã‚¯ãƒ­ç‰¹å¾´é‡ã‚’ç”Ÿæˆã—ã¦è¿”ã™ã€‚

    - 2å¹´é‡‘åˆ© (DGS2): å·®åˆ†ã® EWMA(hl=21) â†’ y2_diff_ewm21
    - 10Y-2Y ã‚¹ãƒ­ãƒ¼ãƒ— (T10Y2Y):
        ãƒ¬ãƒ™ãƒ«ã® EWMA(hl=10)           â†’ slope_ewm10
        å·®åˆ†ã® EWMA(hl=21)              â†’ slope_diff_ewm21
    - VIX (VIXCLS): logå·®åˆ†ã® EWMA(hl=63) â†’ vix_logdiff_ewm63
    """
    # 1) FRED ã‹ã‚‰ 3 ç³»åˆ—ã‚’å–å¾—
    y2   = _get_fred_series("DGS2",   api_key, start, end)     # 2Y yield (%)
    slope= _get_fred_series("T10Y2Y", api_key, start, end)     # 10Y-2Y (%)
    vix  = _get_fred_series("VIXCLS", api_key, start, end)     # VIX (level)

    # 2) å…±é€šæ—¥ä»˜ã«æƒãˆã‚‹ï¼ˆæœ€å°å®Ÿè£…: å†…ç©é›†åˆã§ãƒ‰ãƒ­ãƒƒãƒ—ï¼‰
    idx = y2.index.intersection(slope.index).intersection(vix.index)
    y2, slope, vix = y2.loc[idx], slope.loc[idx], vix.loc[idx]

    # 3) ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
    def ewm_mean(x: pd.Series, hl: int) -> pd.Series:
        return x.ewm(halflife=hl, adjust=False, min_periods=1).mean()

    # 4) ç‰¹å¾´é‡ç”Ÿæˆï¼ˆå˜ä½ã¯ä¸€è²«ã—ã¦ã„ã‚Œã°OKã€‚å·®åˆ†â†’ï¼…ãƒã‚¤ãƒ³ãƒˆã€VIXã¯ãƒ­ã‚°å·®åˆ†ï¼‰
    y2_diff_ewm21      = ewm_mean(y2.diff(), hl=21).rename("y2_diff_ewm21")
    slope_ewm10        = ewm_mean(slope, hl=10).rename("slope_ewm10")
    slope_diff_ewm21   = ewm_mean(slope.diff(), hl=21).rename("slope_diff_ewm21")
    vix_logdiff        = np.log(vix.replace(0, np.nan) + eps).diff()
    vix_logdiff_ewm63  = ewm_mean(vix_logdiff, hl=63).rename("vix_logdiff_ewm63")

    # 5) çµåˆã—ã¦è¿”ã™
    feats = pd.concat(
        [y2_diff_ewm21, slope_ewm10, slope_diff_ewm21, vix_logdiff_ewm63],
        axis=1
    )
    return feats

# ===== ä½¿ã„æ–¹ï¼ˆæœ€å°ä¾‹ï¼‰ =====
if __name__ == "__main__":
    # äº‹å‰ã« FRED ã® API ã‚­ãƒ¼ã‚’å–å¾—ã—ã¦ãã ã•ã„ï¼ˆæ–‡å­—åˆ—32æ–‡å­—ç¨‹åº¦ï¼‰
    API_KEY = "YOUR_FRED_API_KEY"
    feats_macro = build_xgb_macro_features_from_fred(
        api_key=API_KEY,
        start="2010-01-01",
        end="2025-12-31"
    )
    print(feats_macro.tail())
```

### ãƒ¡ãƒ¢

*   3ç³»åˆ—ã ã‘å–å¾—ã—ã¦ã„ã‚‹ã®ã§ã€**æ ªå‚µç›¸é–¢ã¯å«ã‚ã¦ã„ã¾ã›ã‚“**ï¼ˆè«–æ–‡ã§ã‚‚XGBã«å…¥ã‚Œã‚‹ãƒã‚¯ãƒ­ã¯ã“ã®3ç³»åˆ—ï¼‹æ ªå‚µç›¸é–¢ã§ã—ãŸãŒã€ç›¸é–¢ã¯è‡ªå‰è¨ˆç®—ãŒå¿…è¦ã§ã™ï¼‰ã€‚
*   æ¬ æã¯æœ€å°å®Ÿè£…ã®ãŸã‚ **å†…ç©é›†åˆã§è½ã¨ã™** ã ã‘ã«ã—ã¦ã„ã¾ã™ï¼ˆå¿…è¦ãªã‚‰ `bfill/ffill` ãªã©ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ï¼‰ã€‚
*   å˜ä½ã¯ FRED ã®ã¾ã¾ï¼ˆ% ãƒ¬ãƒ™ãƒ«ã‚„ index ãƒ¬ãƒ™ãƒ«ï¼‰ã€‚å·®åˆ†ãƒ»ãƒ­ã‚°å·®åˆ†ãƒ»EWMA ãªã®ã§å˜ä½ä¸€è²«æ€§ãŒã‚ã‚Œã°å­¦ç¿’ä¸Šã¯å•é¡Œã«ãªã‚Šã«ãã„ã§ã™ã€‚
*   ãã®ã¾ã¾ `feat_df`ï¼ˆJMã®ç‰¹å¾´ï¼‰ã« `pd.concat([feat_df, feats_macro], axis=1)` ã§çµåˆã—ã€XGBoost ã®å­¦ç¿’ã«æ¸¡ã›ã¾ã™ã€‚

## Response:
ã“ã®ã‚¨ãƒ©ãƒ¼ã¯ã€`response.json()` ã®ä¸­èº«ãŒæœŸå¾…é€šã‚Šã« `"observations"` ã‚’å«ã‚“ã§ã„ãªã„ï¼ˆç©ºã¾ãŸã¯ API ã‚­ãƒ¼ãŒç„¡åŠ¹ï¼‰å ´åˆã«ã€  
`pd.DataFrame(observations)` ãŒ **ç©ºã® DataFrame**ï¼ˆåˆ—ãªã—ï¼‰ã‚’è¿”ã—ã¦ã—ã¾ã„ã€  
ãã®å¾Œã® `df["date"]` ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ **KeyError: 'date'** ãŒèµ·ããŸã‚±ãƒ¼ã‚¹ã§ã™ã€‚

* * *

### âœ… å¯¾å‡¦æ³•ï¼šå®‰å…¨ã«å–å¾—ãƒ»æ¤œæŸ»ã™ã‚‹ã‚ˆã†ä¿®æ­£

ä»¥ä¸‹ã®ã‚ˆã†ã« `get_fred_data()` ã‚’æ›¸ãæ›ãˆã¦ãã ã•ã„ã€‚  
ç©ºãƒ‡ãƒ¼ã‚¿ã‚„APIã‚¨ãƒ©ãƒ¼æ™‚ã«ã‚‚å®‰å…¨ã«å‹•ä½œã—ã¾ã™ã€‚

```python
import requests
import pandas as pd

FRED_URL = "https://api.stlouisfed.org/fred/series/observations"

def get_fred_data(series_id, start_date, end_date, api_key):
    params = {
        "series_id": series_id,
        "api_key": api_key,
        "file_type": "json",
        "observation_start": start_date,
        "observation_end": end_date,
    }
    response = requests.get(FRED_URL, params=params, timeout=30)

    # --- å¿œç­”ã‚’å®‰å…¨ã«å‡¦ç† ---
    if response.status_code != 200:
        raise RuntimeError(f"FRED API error {response.status_code}: {response.text}")

    data = response.json()
    if "observations" not in data:
        raise ValueError(f"No 'observations' in response for {series_id}: {data}")

    observations = data["observations"]
    if not observations:  # ç©ºãƒªã‚¹ãƒˆ
        print(f"Warning: no data returned for {series_id}")
        return pd.DataFrame(columns=["value"], index=pd.DatetimeIndex([], name="date"))

    # --- DataFrameå¤‰æ› ---
    df = pd.DataFrame(observations)
    if "date" not in df.columns or "value" not in df.columns:
        raise ValueError(f"Unexpected FRED format for {series_id}: {df.head()}")

    df["date"] = pd.to_datetime(df["date"])
    df["value"] = pd.to_numeric(df["value"], errors="coerce")
    df = df[["date", "value"]].set_index("date")
    return df
```

* * *

### âœ… ä½¿ç”¨ä¾‹

```python
API_KEY = "ã‚ãªãŸã®FRED_API_KEY"
start_date = "2010-01-01"
end_date   = "2025-12-31"

y2    = get_fred_data("DGS2",   start_date, end_date, API_KEY)
slope = get_fred_data("T10Y2Y", start_date, end_date, API_KEY)
vix   = get_fred_data("VIXCLS", start_date, end_date, API_KEY)

print(y2.tail(), slope.tail(), vix.tail())
```

* * *

### ğŸ’¡è£œè¶³

`KeyError: 'date'` ãŒå‡ºãŸã¨ãã«ç¢ºèªã™ã¹ããƒã‚¤ãƒ³ãƒˆï¼š

1.  **APIã‚­ãƒ¼ãŒæ­£ã—ã„ã‹ï¼Ÿ**  
    â†’ ç„¡åŠ¹ãªã‚­ãƒ¼ã ã¨ `"error_message"` ã®ã¿è¿”ã‚Š `"observations"` ãŒã‚ã‚Šã¾ã›ã‚“ã€‚
2.  **series\_id ãŒå­˜åœ¨ã™ã‚‹ã‹ï¼Ÿ**  
    â†’ èª¤ã£ã¦ `"T10Y2"` ãªã©ã«ã™ã‚‹ã¨ `"observations"` ãŒç©ºã«ãªã‚Šã¾ã™ã€‚
3.  **æœŸé–“ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‹ï¼Ÿ**  
    â†’ å¤ã™ãã‚‹ãƒ»æœªæ¥æ—¥ã‚’æŒ‡å®šã™ã‚‹ã¨ç©ºã®ãƒªã‚¹ãƒˆã«ãªã‚Šã¾ã™ã€‚

* * *

ã“ã®ä¿®æ­£ç‰ˆã‚’ä½¿ãˆã°ã€ã‚­ãƒ¼ãŒç„¡åŠ¹ãƒ»ãƒ‡ãƒ¼ã‚¿ãŒç©ºãƒ»å½¢å¼ãŒå¤‰ã‚ã£ãŸå ´åˆã‚‚æ˜ç¤ºçš„ã«ä¾‹å¤–ã‚’å‡ºã—ã€åŸå› ã‚’ã™ãæŠŠæ¡ã§ãã¾ã™ã€‚

## Response:
å®Œç’§ã§ã™ã€‚ãã®æ„å›³ã§ã‚ã‚Œã°ã€**3ã‹æœˆå›½å‚µï¼ˆDGS3MOï¼‰ã‚’åŸºæº–ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ã—ã¦å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚µãƒ³ãƒ—ãƒ«ãƒ»æ•´åˆ—**ã™ã‚‹ã®ãŒæ­£è§£ã§ã™ã€‚  
ä¸‹ã®ã‚ˆã†ã«ã™ã‚Œã°ã€`rf_fred` ã®å–¶æ¥­æ—¥ãƒ™ãƒ¼ã‚¹ã«ä»–ã®é‡‘åˆ©ã‚„ãƒªã‚¿ãƒ¼ãƒ³ç³»åˆ—ã‚’æƒãˆã‚‰ã‚Œã¾ã™ã€‚

* * *

### âœ… æ¨å¥¨å®Ÿè£…ä¾‹

```python
import numpy as np
import pandas as pd

# --- ç„¡ãƒªã‚¹ã‚¯é‡‘åˆ©ã®å–å¾— ---
rf_fred = get_fred_data("DGS3MO", start_date, end_date, api_key=API_KEY)  # å¹´ç‡(%)
rf = np.log1p(rf_fred / 100) / 252.0  # æ—¥æ¬¡å¯¾æ•°ãƒªã‚¿ãƒ¼ãƒ³ã«æ›ç®—

# --- ä»–ã®ãƒªã‚¿ãƒ¼ãƒ³ã‚„ãƒã‚¯ãƒ­ç³»åˆ—ï¼ˆä¾‹ï¼šrets, y2, slope, vixï¼‰ã‚’ã“ã® rf ã«åˆã‚ã›ã‚‹ ---
# full_index ã‚’ rf ã‚’ãƒ™ãƒ¼ã‚¹ã«æ§‹ç¯‰
full_index = rf.index.union(rets.index).sort_values()

# reindex ã§æƒãˆã€ffill ã§å‰æ–¹è£œå®Œ
raw_data = (
    pd.concat(
        [
            rets.reindex(full_index),
            y2.reindex(full_index),
            slope.reindex(full_index),
            vix.reindex(full_index),
            rf.reindex(full_index),
        ],
        axis=1
    )
    .ffill()
    .dropna()
)

raw_data.columns = ["rets", "y2", "slope", "vix", "rf"]
```

* * *

### ğŸ’¡ãƒã‚¤ãƒ³ãƒˆ

1.  **`rf_fred`ã‚’ãƒ™ãƒ¼ã‚¹ã«çµ±ä¸€**  
    â†’ 3ã‹æœˆå›½å‚µã¯ã»ã¼å¸¸ã«å–¶æ¥­æ—¥ãƒ‡ãƒ¼ã‚¿ã‚’æŒã£ã¦ã„ã‚‹ãŸã‚ã€å®‰å®šã—ãŸæ—¥ä»˜ãƒ™ãƒ¼ã‚¹ã«ãªã‚Šã¾ã™ã€‚
2.  **`np.log1p(rf_fred / 100) / 252` ã®æ„å‘³**  
    å¹´ç‡ï¼ˆ%ï¼‰ã‚’æ—¥æ¬¡å¯¾æ•°ãƒªã‚¿ãƒ¼ãƒ³æ›ç®—ã—ãŸã‚‚ã®ã§ã™ï¼š
    $$
    r_f^{(d)} = \frac{\ln(1 + r_f^{(\text{annual})}/100)}{252}
    $$
3.  **`union` ã¨ `ffill`**  
    â†’ `rets` ã«æ¬ æãŒã‚ã‚‹å ´åˆã‚‚ã€`rf` ã®æ—¥ä»˜ã«æƒãˆã¦å‰æ–¹è£œå®Œã€‚  
    â†’ `dropna()` ã¯å®Œå…¨æ¬ æåˆ—ã‚’å‰Šé™¤ã€‚
4.  **ãƒã‚¯ãƒ­ç‰¹å¾´ã‚’ä½œã‚‹ã¨ãã‚‚åŒæ§˜ã«**  
    `build_xgb_macro_features_from_fred()` ã®å‡ºåŠ›ï¼ˆ`feats_macro`ï¼‰ã‚‚ `reindex(full_index)` â†’ `ffill()` ã§çµ±ä¸€ã€‚

* * *

### ğŸ”§ çµæœçš„ã«

ã“ã®æ§‹é€ ã«ã™ã‚‹ã¨ï¼š

*   `rf` ã®æ—¥ä»˜ãŒãƒ™ãƒ¼ã‚¹ï¼ˆå®‰å®šï¼‰
*   ã™ã¹ã¦ã®ã‚·ãƒªãƒ¼ã‚ºãŒåŒã˜ index
*   ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚„ç‰¹å¾´é‡çµåˆãŒå®‰å…¨ã«è¡Œãˆã‚‹

* * *

ã‚‚ã—ã”å¸Œæœ›ãŒã‚ã‚Œã°ã€  
`get_fred_data()` â†’ `rf` â†’ `build_xgb_macro_features_from_fred()` ã¾ã§ã‚’ä¸€é€£ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§å‡¦ç†ã—ã€  
**å…±é€šæ—¥ä»˜ã§çµ±åˆæ¸ˆã¿ã® DataFrame**ï¼ˆ`rets`, `rf`, `macro_features` ã‚’åˆ—ã«æŒã¤ï¼‰ã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹é–¢æ•°ã‚‚ä½œæˆã§ãã¾ã™ã€‚  
ä½œæˆã—ã¾ã™ã‹ï¼Ÿ

## Response:
äº†è§£ã§ã™ã€‚**å„ãƒã‚¯ãƒ­ç³»åˆ—ã‚’ã¾ãšâ€œè«–æ–‡ã©ãŠã‚Šã«å‰å‡¦ç†â€ã—ã¦ã‹ã‚‰ã€å…±é€šæ—¥ä»˜ã«æƒãˆã‚‹**ãƒ¯ãƒ³ã‚¹ãƒˆãƒƒãƒ—é–¢æ•°ã‚’ç”¨æ„ã—ã¾ã—ãŸã€‚  
å–å¾—å¯¾è±¡ã¯ FRED ã® 3 ç³»åˆ—ï¼ˆ`DGS2`, `T10Y2Y`, `VIXCLS`ï¼‰ï¼‹ç„¡ãƒªã‚¹ã‚¯ï¼ˆ`DGS3MO`ï¼‰ã§ã™ã€‚  
ä¾å­˜ã¯ `requests`, `pandas`, `numpy` ã®ã¿ã€‚

```python
import requests
import pandas as pd
import numpy as np

FRED_URL = "https://api.stlouisfed.org/fred/series/observations"

# ---------- å®‰å…¨ç‰ˆ FRED ãƒ•ã‚§ãƒƒãƒ ----------
def get_fred_data(series_id: str, start_date: str, end_date: str, api_key: str) -> pd.Series:
    """
    FREDã‹ã‚‰ series_id ã‚’å–å¾—ã—ã¦ pd.Series(date->float) ã‚’è¿”ã™ï¼ˆå®‰å…¨ç‰ˆï¼‰ã€‚
    å€¤ã¯ãã®ã¾ã¾ï¼ˆ% ã‚„ãƒ¬ãƒ™ãƒ«ï¼‰ã€‚æ¬ æãƒ»ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆç•°å¸¸ã¯ä¾‹å¤–ã€‚
    """
    params = {
        "series_id": series_id,
        "api_key": api_key,
        "file_type": "json",
        "observation_start": start_date,
        "observation_end": end_date,
        "frequency": "d",           # å¯èƒ½ãªã‚‰æ—¥æ¬¡ã‚’è¦æ±‚
        "aggregation_method": "eop" # é€±æ¬¡/æœˆæ¬¡ãŒæ··åœ¨ã—ã¦ã„ã¦ã‚‚æœŸæœ«ã‚’é¸æŠ
    }
    r = requests.get(FRED_URL, params=params, timeout=30)
    if r.status_code != 200:
        raise RuntimeError(f"FRED API error {r.status_code}: {r.text}")

    data = r.json()
    if "observations" not in data:
        raise ValueError(f"No 'observations' in response for {series_id}: {data}")

    obs = data["observations"]
    if not obs:
        # ç©ºã®ã¨ãã¯ç©ºSeriesã‚’è¿”ã™ï¼ˆå¾Œæ®µã®unionã§æ¶ˆãˆã‚‹å¯èƒ½æ€§ã‚ã‚Šï¼‰
        return pd.Series(dtype=float, name=series_id)

    df = pd.DataFrame(obs)
    if "date" not in df.columns or "value" not in df.columns:
        raise ValueError(f"Unexpected FRED format for {series_id}: {df.head()}")

    s = pd.to_numeric(df["value"], errors="coerce")
    idx = pd.to_datetime(df["date"]).values
    out = pd.Series(s.values, index=pd.DatetimeIndex(idx, name="date")).sort_index()
    return out.dropna().rename(series_id)

# ---------- è«–æ–‡ã©ãŠã‚Šã®å‰å‡¦ç†ï¼ˆå„ç³»åˆ—ã‚’å˜ç‹¬ã§åŠ å·¥ï¼‰ ----------
def _ewm_mean(x: pd.Series, hl: int) -> pd.Series:
    return x.ewm(halflife=hl, adjust=False, min_periods=1).mean()

def preprocess_y2_diff_ewm21(y2: pd.Series) -> pd.Series:
    # 2å¹´é‡‘åˆ©(DGS2)ã®å·®åˆ†â†’EWMA(hl=21)
    return _ewm_mean(y2.diff(), hl=21).rename("y2_diff_ewm21")

def preprocess_slope_features(slope: pd.Series) -> pd.DataFrame:
    # 10Y-2Yã‚¹ãƒ­ãƒ¼ãƒ—(T10Y2Y)ï¼šãƒ¬ãƒ™ãƒ«EWMA(hl=10)ã€å·®åˆ†EWMA(hl=21)
    s_ewm10      = _ewm_mean(slope, hl=10).rename("slope_ewm10")
    s_diff_ewm21 = _ewm_mean(slope.diff(), hl=21).rename("slope_diff_ewm21")
    return pd.concat([s_ewm10, s_diff_ewm21], axis=1)

def preprocess_vix_logdiff_ewm63(vix: pd.Series, eps: float = 1e-12) -> pd.Series:
    # VIX(VIXCLS)ï¼šlogå·®åˆ†â†’EWMA(hl=63)
    vld = np.log(vix.replace(0, np.nan) + eps).diff()
    return _ewm_mean(vld, hl=63).rename("vix_logdiff_ewm63")

def preprocess_rf_daily_logret(rf_3mo_annual_pct: pd.Series) -> pd.Series:
    # ç„¡ãƒªã‚¹ã‚¯é‡‘åˆ©(DGS3MO, å¹´ç‡%) â†’ æ—¥æ¬¡ãƒ­ã‚°ãƒªã‚¿ãƒ¼ãƒ³æ›ç®—
    return (np.log1p(rf_3mo_annual_pct / 100.0) / 252.0).rename("rf")

# ---------- ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼šå‰å‡¦ç†â†’å…±é€šæ—¥ä»˜æƒãˆ ----------
def build_regime_xgb_dataset_with_macro(
    rets: pd.Series,   # å¯¾è±¡è³‡ç”£ã®æ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆä¾‹ï¼šè¶…éã§ã¯ãªãç”Ÿãƒªã‚¿ãƒ¼ãƒ³ï¼‰
    start_date: str,
    end_date: str,
    api_key: str,
    base_on_rf: bool = True,
    dropna: bool = True,
) -> pd.DataFrame:
    """
    1) FREDã‹ã‚‰ DGS2, T10Y2Y, VIXCLS, DGS3MO ã‚’å–å¾—
    2) å„ã‚·ãƒªãƒ¼ã‚ºã‚’ã€Œè«–æ–‡ã®å‰å‡¦ç†ã€ã§å€‹åˆ¥ã«åŠ å·¥ï¼ˆy2_diff_ewm21, slope_ewm10, slope_diff_ewm21, vix_logdiff_ewm63, rfï¼‰
    3) ãã®â€œåŠ å·¥æ¸ˆã¿ç³»åˆ—â€ã«å¯¾ã—ã¦å…±é€šæ—¥ä»˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã€reindexâ†’ffill ã§æ•´åˆ—
       - base_on_rf=True ã®ã¨ãã¯ rf ã¨ rets ã‚’ union ã—ãŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒ™ãƒ¼ã‚¹ã«
       - base_on_rf=False ã®ã¨ãã¯å…¨åŠ å·¥ç³»åˆ—ï¼‹rets ã® union ã‚’ãƒ™ãƒ¼ã‚¹ã«
    4) åˆ—ã‚’çµåˆã—ã¦è¿”ã™ï¼ˆåˆ—: ["rets","rf","y2_diff_ewm21","slope_ewm10","slope_diff_ewm21","vix_logdiff_ewm63"]ï¼‰
    """
    # --- FRED raw fetch ---
    y2_raw    = get_fred_data("DGS2",   start_date, end_date, api_key)
    slope_raw = get_fred_data("T10Y2Y", start_date, end_date, api_key)
    vix_raw   = get_fred_data("VIXCLS", start_date, end_date, api_key)
    rf_raw    = get_fred_data("DGS3MO", start_date, end_date, api_key)

    # --- è«–æ–‡ã©ãŠã‚Šã®å‰å‡¦ç†ï¼ˆå„ã‚·ãƒªãƒ¼ã‚ºã‚’ç‹¬ç«‹ã«åŠ å·¥ã™ã‚‹ï¼‰---
    y2_diff_ewm21     = preprocess_y2_diff_ewm21(y2_raw)
    slope_feats       = preprocess_slope_features(slope_raw)          # 2åˆ—
    vix_logdiff_ewm63 = preprocess_vix_logdiff_ewm63(vix_raw)
    rf_daily_logret   = preprocess_rf_daily_logret(rf_raw)

    # --- ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆå‰å‡¦ç†æ¸ˆã¿ã®ã‚ã¨ã«ä½œã‚‹ï¼‰---
    if base_on_rf:
        base_index = rf_daily_logret.index.union(rets.index).sort_values()
    else:
        base_index = rets.index
        for s in [rf_daily_logret, y2_diff_ewm21, slope_feats.iloc[:,0], slope_feats.iloc[:,1], vix_logdiff_ewm63]:
            base_index = base_index.union(s.index)
        base_index = base_index.sort_values()

    # --- reindexâ†’ffill ã§å…±é€šæ—¥ä»˜ã«æƒãˆã‚‹ï¼ˆå‰å‡¦ç†æ¸ˆã¿ã®ç³»åˆ—ã«å¯¾ã—ã¦ï¼‰---
    pieces = [
        rets.reindex(base_index).rename("rets"),
        rf_daily_logret.reindex(base_index),
        y2_diff_ewm21.reindex(base_index),
        slope_feats.reindex(base_index),
        vix_logdiff_ewm63.reindex(base_index),
    ]
    df = pd.concat(pieces, axis=1).ffill()

    if dropna:
        df = df.dropna()

    # åˆ—é †ã®æ˜ç¤º
    cols = ["rets", "rf", "y2_diff_ewm21", "slope_ewm10", "slope_diff_ewm21", "vix_logdiff_ewm63"]
    df = df.loc[:, [c for c in cols if c in df.columns]]

    return df

# --------- ä½¿ã„æ–¹ï¼ˆæœ€å°ä¾‹ï¼‰ ---------
if __name__ == "__main__":
    # ãƒ€ãƒŸãƒ¼ã®è³‡ç”£ãƒªã‚¿ãƒ¼ãƒ³ã‚’ç”¨æ„ï¼ˆå®Ÿé‹ç”¨ã§ã¯å®Ÿãƒ‡ãƒ¼ã‚¿ã«ç½®ãæ›ãˆï¼‰
    idx = pd.date_range("2012-01-01", "2025-10-31", freq="B")
    np.random.seed(42)
    rets = pd.Series(np.random.normal(0.0003, 0.01, len(idx)), index=idx, name="rets")

    API_KEY = "YOUR_FRED_API_KEY"
    start, end = "2011-01-01", "2025-12-31"

    df_all = build_regime_xgb_dataset_with_macro(
        rets=rets,
        start_date=start,
        end_date=end,
        api_key=API_KEY,
        base_on_rf=True,   # rf + rets ã‚’ãƒ™ãƒ¼ã‚¹ã«å…±é€šæ—¥ä»˜ã‚’ä½œæˆ
        dropna=True
    )
    print(df_all.tail())
```

### ãƒã‚¤ãƒ³ãƒˆ

*   **é †ç•ªã®å³å®ˆ**ï¼š`DGS2 / T10Y2Y / VIXCLS / DGS3MO` ã‚’**ã¾ãšå€‹åˆ¥ã«å‰å‡¦ç†**ï¼ˆ`y2_diff_ewm21`, `slope_ewm10`, `slope_diff_ewm21`, `vix_logdiff_ewm63`, `rf`ï¼‰ã—ã€ãã®**å‰å‡¦ç†æ¸ˆã¿ç³»åˆ—**ã«å¯¾ã—ã¦ **å…±é€šæ—¥ä»˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹** ã‚’ä½œã£ã¦ã„ã¾ã™ã€‚
*   **ãƒ™ãƒ¼ã‚¹é¸æŠ**ï¼š`base_on_rf=True` ã§ã€å‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã”æ„å‘ã©ãŠã‚Š **rfï¼ˆï¼‹retsï¼‰ã‚’ãƒ™ãƒ¼ã‚¹**ã«æ•´åˆ—ã—ã¾ã™ï¼ˆFalse ã«ã™ã‚Œã°å…¨ç³»åˆ— union ãƒ™ãƒ¼ã‚¹ï¼‰ã€‚
*   **ç„¡ãƒªã‚¹ã‚¯ã®å˜ä½å¤‰æ›**ï¼š`DGS3MO`ï¼ˆå¹´ç‡ï¼…ï¼‰â†’**æ—¥æ¬¡ãƒ­ã‚°ãƒªã‚¿ãƒ¼ãƒ³**ã¸å¤‰æ›ï¼ˆ`ln(1+å¹´ç‡%/100)/252`ï¼‰ã€‚
*   **æ¬ æå‡¦ç†**ï¼šæœ€å°å®Ÿè£…ã§ã¯ `ffill`â†’`dropna`ã€‚å¿…è¦ã«å¿œã˜ã¦ `bfill` ã‚„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¦ä»¶ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚
*   **ãã®ã¾ã¾å­¦ç¿’ã¸**ï¼šè¿”å´ `df_all` ã‚’ã€æ—¢å­˜ã® JM ç‰¹å¾´é‡ã¨ `pd.concat([...], axis=1)` ã§çµåˆã—ã€XGBoost ã® `feat_df` ã«å…¥ã‚Œã‚Œã° OK ã§ã™ã€‚

## Response:
äº†è§£ã§ã™ã€‚XGBoost éƒ¨åˆ†ã ã‘ **LightGBM ã«å·®ã—æ›¿ãˆ**ãŸæœ€å°å®Ÿè£…ã‚’ç”¨æ„ã—ã¾ã—ãŸã€‚  
ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼å‡¦ç†ãƒ•ãƒ­ãƒ¼ã¯**ã»ã¼ãã®ã¾ã¾**ã§ã€å­¦ç¿’å™¨ã ã‘ `lightgbm.LGBMClassifier` ã«ç½®ãæ›ãˆã¦ã„ã¾ã™ã€‚

> ä¾å­˜: `pandas`, `numpy`, `lightgbm`  
> ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¾‹: `pip install lightgbm`

```python
# æœ€å°ä¾å­˜: pandas, numpy, lightgbm
import numpy as np
import pandas as pd
from typing import Optional, Dict, Any
from dataclasses import dataclass
from lightgbm import LGBMClassifier

@dataclass
class LGBMRegimeForecaster:
    """
    JMã§å¾—ãŸå½“æ—¥ãƒ¬ã‚¸ãƒ¼ãƒ  s_t (0/1) ã‚’æ•™å¸«ä¿¡å·ã«ã€
    ç‰¹å¾´é‡ x_t ã‹ã‚‰ç¿Œæ—¥ãƒ¬ã‚¸ãƒ¼ãƒ  s_{t+1} ã‚’äºˆæ¸¬ï¼ˆLightGBMç‰ˆã€XGBç‰ˆã¨åŒã˜ä½¿ã„æ–¹ï¼‰ã€‚

    - feat_df: (T, D) ã®ç‰¹å¾´é‡ DataFrameï¼ˆè¡Œ=æ—¥ä»˜ index, åˆ—=ç‰¹å¾´ï¼‰
    - regime_labels: (T,) ã® Seriesï¼ˆJMã®å½“æ—¥ãƒ¬ã‚¸ãƒ¼ãƒ  0/1ï¼‰
    - horizon: æ—¢å®š=1ï¼ˆç¿Œæ—¥ãƒ¬ã‚¸ãƒ¼ãƒ ã‚’äºˆæ¸¬ï¼‰
    - train_end: å­¦ç¿’æœŸé–“ã®æœ€çµ‚æ—¥ï¼ˆ"YYYY-MM-DD"ï¼‰ã€‚None ãªã‚‰å…ˆé ­80%ã‚’å­¦ç¿’ã«ä½¿ç”¨
    - smooth_halflife: äºˆæ¸¬ç¢ºç‡ã®EWMAåŠæ¸›æœŸï¼ˆNone ãªã‚‰å¹³æ»‘ãªã—ï¼‰
    - lgbm_params: LGBMClassifier ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆæœªæŒ‡å®šãªã‚‰æœ€å°æ§‹æˆï¼‰
    """
    feat_df: pd.DataFrame
    regime_labels: pd.Series
    horizon: int = 1
    train_end: Optional[str] = None
    smooth_halflife: Optional[int] = None
    lgbm_params: Optional[Dict[str, Any]] = None

    def fit_predict(self):
        # 1) æ•™å¸«ä¿¡å·ã‚’ horizon ã ã‘å…ˆã«ã‚·ãƒ•ãƒˆï¼ˆs_{t+1} ã‚’ t ã®ç‰¹å¾´ã§å½“ã¦ã‚‹ï¼‰
        y = self.regime_labels.shift(-self.horizon).reindex(self.feat_df.index)
        valid_idx = y.dropna().index
        X = self.feat_df.loc[valid_idx]
        y = y.loc[valid_idx].astype(int)

        # 2) æ™‚ç³»åˆ—ã‚¹ãƒ—ãƒªãƒƒãƒˆï¼ˆtrain_end æŒ‡å®šãŒç„¡ã„å ´åˆã¯ 8:2ï¼‰
        if self.train_end is not None:
            train_mask = X.index <= pd.to_datetime(self.train_end)
        else:
            split = int(len(X) * 0.8)
            train_mask = pd.Series(False, index=X.index)
            train_mask.iloc[:split] = True

        X_train, y_train = X.loc[train_mask], y.loc[train_mask]
        X_test,  y_test  = X.loc[~train_mask], y.loc[~train_mask]

        # 3) LightGBM æœ€å°æ§‹æˆï¼ˆXGBoostç‰ˆã«è¿‘ã„æŒ™å‹•ï¼‰
        params = dict(
            n_estimators=300,
            learning_rate=0.05,
            max_depth=-1,            # LightGBMã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æ·±ã•åˆ¶é™ãªã—
            num_leaves=31,           # depth~5 ç›¸å½“
            subsample=0.9,
            colsample_bytree=0.9,
            objective="binary",
            random_state=42,
            n_jobs=-1,
            metric="binary_logloss",
        )
        if self.lgbm_params:
            params.update(self.lgbm_params)

        clf = LGBMClassifier(**params)
        clf.fit(X_train, y_train)

        # 4) äºˆæ¸¬ï¼ˆç¢ºç‡ï¼‰
        proba_test = pd.Series(
            clf.predict_proba(X_test)[:, 1],
            index=X_test.index,
            name="p_bear_next"
        )

        # 5) ã‚ªãƒ—ã‚·ãƒ§ãƒ³: ç¢ºç‡ã®æŒ‡æ•°å¹³æ»‘
        if self.smooth_halflife is not None and self.smooth_halflife > 0:
            proba_smoothed = proba_test.ewm(halflife=self.smooth_halflife, adjust=False).mean()
        else:
            proba_smoothed = proba_test.copy()

        # 6) é–¾å€¤ 0.5 ã§ã‚¯ãƒ©ã‚¹åŒ–ï¼ˆ>0.5 ã‚’ãƒ™ã‚¢=1ï¼‰
        y_pred = (proba_smoothed >= 0.5).astype(int)
        y_pred.name = "y_pred_bear_next"

        # 7) è¿”å´
        # LightGBM ã® feature_importances_ ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ "split"ï¼ˆåˆ†å‰²å›æ•°ï¼‰
        fi = pd.Series(clf.feature_importances_, index=X.columns, name="importance_split")

        return {
            "model": clf,
            "X_train": X_train, "y_train": y_train,
            "X_test": X_test,   "y_test": y_test,
            "proba_raw": proba_test,
            "proba_smoothed": proba_smoothed,
            "y_pred": y_pred,
            "feature_importance": fi.sort_values(ascending=False),
        }

# ===== ä½¿ã„æ–¹ï¼ˆæœ€å°ä¾‹ï¼‰ =====
if __name__ == "__main__":
    # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ä½œæˆ: ç‰¹å¾´é‡(3åˆ—) + JMãƒ©ãƒ™ãƒ«(0/1)
    idx = pd.date_range("2010-01-01", "2020-12-31", freq="B")
    rng = np.random.default_rng(0)
    feat = pd.DataFrame({
        "mean_hl5":   rng.normal(0, 1, len(idx)),
        "dd_log_hl5": rng.normal(0, 1, len(idx)),
        "sortino_hl5":rng.normal(0, 1, len(idx)),
    }, index=idx)

    # JMã§å¾—ãŸå½“æ—¥ãƒ¬ã‚¸ãƒ¼ãƒ ï¼ˆãƒ€ãƒŸãƒ¼ï¼‰
    base = rng.normal(0, 1, len(idx)).cumsum()
    regime = pd.Series((base > np.median(base)).astype(int), index=idx, name="regime_t")

    forecaster = LGBMRegimeForecaster(
        feat_df=feat,
        regime_labels=regime,
        horizon=1,                 # s_{t+1} ã‚’äºˆæ¸¬
        train_end="2017-12-31",    # æœªæŒ‡å®šãªã‚‰ 8:2 æ™‚ç³»åˆ—ã‚¹ãƒ—ãƒªãƒƒãƒˆ
        smooth_halflife=8,         # äºˆæ¸¬ç¢ºç‡ã‚’å¹³æ»‘åŒ–ï¼ˆç„¡ã—ãªã‚‰ Noneï¼‰
        lgbm_params=None           # è¿½åŠ /ä¸Šæ›¸ããƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¸¡ã›ã¾ã™
    )
    res = forecaster.fit_predict()

    print("Quick check corr(y, p):",
          np.corrcoef(res["y_test"], res["proba_smoothed"])[0, 1])
    print("Feature importance (split counts):")
    print(res["feature_importance"].head())

    # ç°¡æ˜“ 0/1 æˆ¦ç•¥è©•ä¾¡ã®ã‚µãƒ³ãƒ—ãƒ«
    r_test = pd.Series(rng.normal(0.0003, 0.01, len(res["y_test"])), index=res["y_test"].index)
    rf_test = pd.Series(0.02/252, index=r_test.index)
    strat = pd.Series(np.where(res["y_pred"]==1, rf_test.values, r_test.values), index=r_test.index)
    sharpe = strat.mean() / strat.std(ddof=0) * np.sqrt(252)
    print("0/1 strategy Sharpe (test):", sharpe)
```

### ã»ã¼äº’æ›ã§ä½¿ã†ãŸã‚ã®ãƒ¡ãƒ¢

*   `XGBClassifier` â†’ `LGBMClassifier` ã«ç½®æ›ã€‚ãã®ä»–ã¯åŒã˜I/Fã§ä½¿ãˆã¾ã™ã€‚
*   ç‰¹å¾´é‡DFã‚„ãƒ¬ãƒ¼ãƒ™ãƒ«ã€æ™‚ç³»åˆ—ã‚¹ãƒ—ãƒªãƒƒãƒˆã€ç¢ºç‡ã® EWM å¹³æ»‘ã€0.5 é–¾å€¤ã‚‚åŒã˜ã€‚
*   é‡è¦åº¦ã¯ `feature_importances_`ï¼ˆLightGBMã¯æ—¢å®šã§ã€Œsplitã€å°ºåº¦ï¼‰ã€‚`importance_type="gain"` ã‚’æŒ‡å®šã—ãŸã„å ´åˆã¯ `lgbm_params={"importance_type": "gain"}` ã‚’æ¸¡ã—ã¦ãã ã•ã„ã€‚
*   å¤§ããªãƒ‡ãƒ¼ã‚¿ã§ã¯ `device_type="gpu"`ï¼ˆè¦ãƒ“ãƒ«ãƒ‰ç’°å¢ƒï¼‰ã‚„ `num_leaves`ãƒ»`min_data_in_leaf` ã®èª¿æ•´ãŒåŠ¹ãã¾ã™ã€‚

## Response:
äº†è§£ã€‚**(A) å„è³‡ç”£ã‚¯ãƒ©ã‚¹ã”ã¨ã® 0/1 æˆ¦ç•¥è©•ä¾¡** ã¨ **(B) å„è³‡ç”£ã‚¯ãƒ©ã‚¹ã® 0/1 æˆ¦ç•¥ã‚’ç”¨ã„ãŸ MV ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæ§‹ç¯‰** ã‚’ã€ä¾å­˜æœ€å°ï¼ˆ`numpy`/`pandas` ã®ã¿ï¼‰ã§ã¾ã¨ã‚ã¦æ›¸ãã¾ã™ã€‚  
å‰æï¼šå„è³‡ç”£ã”ã¨ã«æ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³ `rets[asset]`ã€ç„¡ãƒªã‚¹ã‚¯ `rf`ã€äºˆæ¸¬ãƒ¬ã‚¸ãƒ¼ãƒ  `pred[asset]`ï¼ˆ**ãƒ™ã‚¢=1ã®ã¨ãç„¡ãƒªã‚¹ã‚¯ã€ãƒ–ãƒ«=0ã®ã¨ãå½“è©²è³‡ç”£**ï¼‰ãŒä¸ãˆã‚‰ã‚Œã¦ã„ã‚‹ã¨ã—ã¾ã™ã€‚

```python
import numpy as np
import pandas as pd
from typing import Dict, Optional, Tuple

# =========================
# 0) ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# =========================
def _align_to_index(base_index: pd.DatetimeIndex, s: pd.Series) -> pd.Series:
    return s.reindex(base_index).ffill()

def _perf_stats(r: pd.Series, ann_factor: int = 252) -> dict:
    """å˜ä¸€ç³»åˆ—ã®è©•ä¾¡æŒ‡æ¨™ã‚’è¿”ã™ï¼ˆå¹´ç‡æ›ç®—: å¹³å‡ãƒ»ãƒœãƒ©ãƒ»Sharpeãƒ»MDDãƒ»CAGRï¼‰ã€‚"""
    r = r.dropna()
    if len(r) == 0:
        return {"ann_mean": np.nan, "ann_vol": np.nan, "sharpe": np.nan, "mdd": np.nan, "cagr": np.nan}
    ann_mean = r.mean() * ann_factor
    ann_vol  = r.std(ddof=0) * np.sqrt(ann_factor)
    sharpe   = np.nan if ann_vol == 0 else ann_mean / ann_vol
    # æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³
    cum = (1 + r).cumprod()
    peak = cum.cummax()
    dd = cum / peak - 1.0
    mdd = dd.min()
    # CAGRï¼ˆæœŸé–“å¹´æ•°ã‚’è¿‘ä¼¼ï¼‰
    n_years = max((r.index[-1] - r.index[0]).days / 365.25, 1e-9)
    cagr = cum.iloc[-1] ** (1 / n_years) - 1
    return {"ann_mean": ann_mean, "ann_vol": ann_vol, "sharpe": sharpe, "mdd": mdd, "cagr": cagr}

# =========================
# (A) å„è³‡ç”£ã‚¯ãƒ©ã‚¹ 0/1 æˆ¦ç•¥ã®è©•ä¾¡
# =========================
def build_binary_strategy_returns(
    rets: Dict[str, pd.Series],
    rf: pd.Series,
    pred: Dict[str, pd.Series],
    base_index: Optional[pd.DatetimeIndex] = None
) -> pd.DataFrame:
    """
    å„è³‡ç”£ã® 0/1 æˆ¦ç•¥ãƒªã‚¿ãƒ¼ãƒ³ã‚’ä½œã‚‹ã€‚
    pred[asset] == 1 ã®æ—¥â†’ rfã€== 0 ã®æ—¥â†’ rets[asset] ã‚’æ¡ç”¨ã€‚
    """
    # ãƒ™ãƒ¼ã‚¹æ—¥ä»˜ï¼ˆæŒ‡å®šãªã‘ã‚Œã° rf ã¨å…¨è³‡ç”£ã® unionï¼‰
    if base_index is None:
        base_index = rf.index
        for a in rets:
            base_index = base_index.union(rets[a].index)
        for a in pred:
            base_index = base_index.union(pred[a].index)
        base_index = base_index.sort_values()

    rf_a = _align_to_index(base_index, rf)
    out = {}
    for a, r in rets.items():
        p = pred[a]
        r_a = _align_to_index(base_index, r)
        p_a = _align_to_index(base_index, p).fillna(1)  # æ¬ ææ—¥ã¯ä¿å®ˆçš„ã«ãƒ™ã‚¢(=1)æ‰±ã„
        strat = np.where(p_a.values.astype(int) == 1, rf_a.values, r_a.values)
        out[a] = pd.Series(strat, index=base_index, name=a)
    return pd.DataFrame(out)

def evaluate_binary_strategies(
    strat_df: pd.DataFrame, ann_factor: int = 252
) -> pd.DataFrame:
    """
    å„åˆ—ï¼ˆè³‡ç”£ï¼‰ã® 0/1 æˆ¦ç•¥ã«å¯¾ã—ã¦è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—ã€‚
    """
    stats = {}
    for col in strat_df.columns:
        stats[col] = _perf_stats(strat_df[col], ann_factor=ann_factor)
    return pd.DataFrame(stats).T[["ann_mean", "ann_vol", "sharpe", "mdd", "cagr"]]

# =========================
# (B) 0/1 æˆ¦ç•¥ã‹ã‚‰ MV ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæ§‹ç¯‰
# =========================
def _gmv_weights(cov: np.ndarray, long_only_clip: bool = True) -> np.ndarray:
    """
    GMVï¼ˆå…¨ä½“åˆ†æ•£æœ€å°ï¼‰é‡ã¿ã€‚ç°¡æ˜“é•·æœŸã®ã¿å¯¾å¿œ: ã‚¯ãƒªãƒƒãƒ—ã—ã¦æ­£è¦åŒ–ï¼ˆãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ï¼‰ã€‚
    """
    n = cov.shape[0]
    ones = np.ones((n, 1))
    # æ•°å€¤å®‰å®šã®ãŸã‚å¯¾è§’ã«å¾®å°ãƒªãƒƒã‚¸
    cov_ = cov + 1e-8 * np.eye(n)
    inv = np.linalg.pinv(cov_)
    w = (inv @ ones) / (ones.T @ inv @ ones)  # å’Œ=1
    w = w.ravel()
    if long_only_clip:
        w = np.clip(w, 0, None)
        s = w.sum()
        w = w / s if s > 0 else np.ones(n) / n
    return w

def _mv_weights(mu: np.ndarray, cov: np.ndarray, risk_aversion: float = 3.0,
                long_only_clip: bool = True) -> np.ndarray:
    """
    å˜ç´” MV: argmax w^T mu - (risk_aversion/2) w^T Î£ w
    â†’ ä¸€æ§˜å’Œ=1åˆ¶ç´„ã‚’ã‚«ãƒ³ã‚¿ãƒ³ã«è¿‘ä¼¼: ã„ã£ãŸã‚“ç„¡åˆ¶ç´„è§£ w* = (1/Î») Î£^{-1} Î¼ ã‚’ç®—å‡ºã—ã€æ­£è¦åŒ–ã€‚
      é•·æœŸã®ã¿ã¯è² ã‚’ã‚¯ãƒªãƒƒãƒ—ã—ã¦å†æ­£è¦åŒ–ï¼ˆãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ï¼‰ã€‚
    """
    cov_ = cov + 1e-8 * np.eye(len(mu))
    inv = np.linalg.pinv(cov_)
    w = (1.0 / max(risk_aversion, 1e-8)) * (inv @ mu)
    # å’Œ=1 ã¸æ­£è¦åŒ–
    s = w.sum()
    w = w / s if np.isfinite(s) and abs(s) > 1e-12 else w
    if long_only_clip:
        w = np.clip(w, 0, None)
        s = w.sum()
        w = w / s if s > 0 else np.ones_like(w) / len(w)
    return w

def build_static_mv_from_binary_strategies(
    strat_df: pd.DataFrame,
    mode: str = "mv",                 # "mv" or "gmv"
    risk_aversion: float = 3.0,       # mode="mv" ã®ã¨ãæœ‰åŠ¹
    use_ewm: bool = True,             # å…±åˆ†æ•£æ¨å®šï¼šEWM or å˜ç´”æ¨™æœ¬
    halflife: int = 252,
    long_only_clip: bool = True
) -> Tuple[pd.Series, float, float]:
    """
    0/1 æˆ¦ç•¥ã®ãƒªã‚¿ãƒ¼ãƒ³åˆ—ï¼ˆåˆ—=è³‡ç”£ï¼‰ã‹ã‚‰ã€å˜ä¸€ã®é™çš„ MV é‡ã¿ã‚’ç®—å‡ºã€‚
    æˆ»ã‚Šå€¤: (weights, port_ann_mean, port_ann_vol)
    """
    X = strat_df.dropna(how="any")
    if len(X) == 0:
        raise ValueError("No overlapping data in strat_df.")

    if use_ewm:
        mu = X.ewm(halflife=halflife, adjust=False).mean().iloc[-1].values
        cov = X.ewm(halflife=halflife, adjust=False).cov().dropna().iloc[-len(X.columns):].values.reshape(len(X.columns), len(X.columns))
    else:
        mu = X.mean().values
        cov = X.cov().values

    if mode == "gmv":
        w = _gmv_weights(cov, long_only_clip=long_only_clip)
    else:
        w = _mv_weights(mu, cov, risk_aversion=risk_aversion, long_only_clip=long_only_clip)

    # ãƒãƒ¼ãƒˆæœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³ãƒ»ãƒœãƒ©ï¼ˆå¹´ç‡ï¼‰
    ann = 252
    port_mean = float((X @ w).mean() * ann)
    port_vol  = float((X @ w).std(ddof=0) * np.sqrt(ann))
    return pd.Series(w, index=X.columns, name="weight"), port_mean, port_vol

def build_rolling_mv_portfolio(
    strat_df: pd.DataFrame,
    window: int = 252,                 # æ¨å®šçª“ï¼ˆæ—¥ï¼‰
    rebalance_freq: str = "M",         # "M"ï¼ˆæœˆæ¬¡ï¼‰/ "W"ï¼ˆé€±æ¬¡ï¼‰/ "D"ï¼ˆæ—¥æ¬¡ï¼‰
    mode: str = "mv",                  # "mv" or "gmv"
    risk_aversion: float = 3.0,
    long_only_clip: bool = True
) -> Tuple[pd.Series, pd.DataFrame]:
    """
    éå» window ã§ Î¼, Î£ ã‚’æ¨å®šã—ã€æŒ‡å®šé »åº¦ã§ãƒªãƒãƒ©ãƒ³ã‚¹ã™ã‚‹ MV ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã€‚
    æˆ»ã‚Šå€¤: (portfolio_returns, weights_history)
    """
    X = strat_df.dropna(how="any").copy()
    if len(X) < window + 5:
        raise ValueError("Not enough data for rolling MV.")

    # ãƒªãƒãƒ©ãƒ³ã‚¹æ—¥
    rebal_days = X.resample(rebalance_freq).last().index
    rebal_days = [d for d in rebal_days if d in X.index and X.index.get_loc(d) >= window]
    weights_hist = []
    port_ret = pd.Series(0.0, index=X.index)

    for d in rebal_days:
        loc = X.index.get_loc(d)
        hist = X.iloc[loc - window:loc]  # ç›´è¿‘ window
        mu = hist.mean().values
        cov = hist.cov().values
        if mode == "gmv":
            w = _gmv_weights(cov, long_only_clip=long_only_clip)
        else:
            w = _mv_weights(mu, cov, risk_aversion=risk_aversion, long_only_clip=long_only_clip)
        w_s = pd.Series(w, index=X.columns, name=d)
        weights_hist.append(w_s)

        # æ¬¡ã®ãƒªãƒãƒ©ãƒ³ã‚¹ç›´å‰ã¾ã§ã“ã® w ã‚’é©ç”¨
        next_loc = X.index.get_loc(rebal_days[rebal_days.index(d)+1]) if d != rebal_days[-1] else len(X)
        sl = slice(loc, next_loc)  # d å½“æ—¥å«ã‚€
        port_ret.iloc[sl] = (X.iloc[sl] @ w)

    W = pd.DataFrame(weights_hist)
    return port_ret, W

# =========================
# ä½¿ã„æ–¹ï¼ˆæœ€å°ä¾‹ï¼‰
# =========================
if __name__ == "__main__":
    np.random.seed(0)
    idx = pd.date_range("2015-01-01", "2025-10-31", freq="B")
    # ãƒ€ãƒŸãƒ¼ï¼š3è³‡ç”£ã®ãƒªã‚¿ãƒ¼ãƒ³
    rets = {
        "Equity": pd.Series(np.random.normal(0.0005, 0.01, len(idx)), index=idx),
        "Bond":   pd.Series(np.random.normal(0.0002, 0.004, len(idx)), index=idx),
        "Gold":   pd.Series(np.random.normal(0.0001, 0.013, len(idx)), index=idx),
    }
    rf = pd.Series(0.02/252, index=idx)  # å¹´ç‡2%ç›¸å½“
    # ãƒ€ãƒŸãƒ¼ï¼šãƒ¬ã‚¸ãƒ¼ãƒ äºˆæ¸¬ï¼ˆãƒ™ã‚¢=1ãªã‚‰ rf æ¡ç”¨ï¼‰
    pred = {
        "Equity": pd.Series((np.random.rand(len(idx)) > 0.6).astype(int), index=idx),
        "Bond":   pd.Series((np.random.rand(len(idx)) > 0.4).astype(int), index=idx),
        "Gold":   pd.Series((np.random.rand(len(idx)) > 0.5).astype(int), index=idx),
    }

    # (A) å„è³‡ç”£ã® 0/1 æˆ¦ç•¥ãƒªã‚¿ãƒ¼ãƒ³ & è©•ä¾¡
    strat_df = build_binary_strategy_returns(rets, rf, pred)             # åˆ—=è³‡ç”£
    stats_df = evaluate_binary_strategies(strat_df)
    print("Per-asset 0/1 stats:\n", stats_df, "\n")

    # (B-1) é™çš„ MVï¼ˆå…¨æœŸé–“ã§ä¸€åº¦æ¨å®šï¼‰
    w_static, pm, pv = build_static_mv_from_binary_strategies(
        strat_df, mode="mv", risk_aversion=3.0, use_ewm=False, long_only_clip=True
    )
    print("Static MV weights:\n", w_static, "\nAnnualized mean/vol:", pm, pv, "\n")

    # (B-2) ãƒ­ãƒ¼ãƒªãƒ³ã‚° MVï¼ˆæœˆæ¬¡ãƒªãƒãƒ©ãƒ³ã‚¹ï¼‰
    port_ret, W = build_rolling_mv_portfolio(
        strat_df, window=252, rebalance_freq="M", mode="mv", risk_aversion=3.0, long_only_clip=True
    )
    print("Rolling MV portfolio Sharpe:",
          (port_ret.mean()*252) / (port_ret.std(ddof=0)*np.sqrt(252)))
    print("Weights (last 5 rebalances):\n", W.tail())
```

### ä½¿ã„æ–¹ã¾ã¨ã‚

*   **(A)** `build_binary_strategy_returns()` ã§è³‡ç”£ã”ã¨ã® 0/1 æˆ¦ç•¥ãƒªã‚¿ãƒ¼ãƒ³ã‚’ä½œã‚Šã€`evaluate_binary_strategies()` ã§ Sharpe/MDD/CAGR ã‚’ä¸€è¦§åŒ–ã€‚
*   **(B-1)** `build_static_mv_from_binary_strategies()` ã¯å…¨æœŸé–“ã§ Î¼, Î£ ã‚’æ¨å®šã—ã¦ **é™çš„** é‡ã¿ã‚’å‡ºã—ã¾ã™ï¼ˆ`mode="gmv"` ã‚‚å¯ï¼‰ã€‚
*   **(B-2)** `build_rolling_mv_portfolio()` ã¯éå» `window` æ—¥ã§æ¨å®šã—ã€æŒ‡å®šé »åº¦ã§**ãƒªãƒãƒ©ãƒ³ã‚¹**ã—ã¦ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚

> æ³¨ï¼šMV æœ€é©åŒ–ã¯ä¾å­˜ã‚’å¢—ã‚„ã•ãªã„ãŸã‚ã€**é•·æœŸã®ã¿åˆ¶ç´„**ã¯ã€Œè² ã‚¦ã‚§ã‚¤ãƒˆã‚’ 0 ã§ã‚¯ãƒªãƒƒãƒ— â†’ å†æ­£è¦åŒ–ã€ã®ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã§å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚å³å¯†ãªåˆ¶ç´„ä»˜ãäºŒæ¬¡è¨ˆç”»ã«ã—ãŸã„å ´åˆã¯ `cvxpy` ç­‰ã«ç½®ãæ›ãˆã¦ãã ã•ã„ã€‚

## Response:
æ€è€ƒæ™‚é–“: 22s

ä»¥ä¸‹ã¯ã€æ·»ä»˜è«–æ–‡ã®**è³‡ç”£ã”ã¨ã®ãƒ¬ã‚¸ãƒ¼ãƒ ã‚’ç¹”ã‚Šè¾¼ã‚“ã å¹³å‡åˆ†æ•£ï¼ˆMVï¼‰ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª**ã®æ§‹æˆæ–¹æ³•ã®è¦ç‚¹ã§ã™ã€‚

1) æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³  $\mu$  ã®ä½œã‚Šæ–¹ï¼ˆè³‡ç”£åˆ¥ãƒ¬ã‚¸ãƒ¼ãƒ åæ˜ ï¼‰
---------------------------------

*   å„è³‡ç”£  $i$  ã«ã¤ã„ã¦ã€JMï¼ˆJump Modelï¼‰ã§éå»ãƒ‡ãƒ¼ã‚¿ã‚’ **bull/bear** ã«ãƒ©ãƒ™ãƒ«ä»˜ã‘ã—ã€å­¦ç¿’çª“å†…ã§**ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¥ã®å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³**ï¼ˆbull å¹³å‡ã€bear å¹³å‡ï¼‰ã‚’è¨ˆç®—ã—ã¦ãŠãã€‚æœ€é©ã‚¸ãƒ£ãƒ³ãƒ—ãƒ»ãƒšãƒŠãƒ«ãƒ†ã‚£  $\hat\lambda$  ã‚’é¸ã‚“ã  JM ã«åŸºã¥ãå€¤ã‚’ä½¿ã†ã€‚
    2406.09578v2
*   ç¿Œæ—¥ã®ãƒ¬ã‚¸ãƒ¼ãƒ ã‚’ JMâ†’XGBoostï¼ˆè«–æ–‡ã®å®Ÿè£…ï¼‰ã§**äºˆæ¸¬**ã—ã€**äºˆæ¸¬ãƒ¬ã‚¸ãƒ¼ãƒ ã«å¯¾å¿œã™ã‚‹å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³**ã‚’ãã®è³‡ç”£ã®**ç¿Œæ—¥æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³**  $\mu_i$  ã¨ã—ã¦æ¡ç”¨ã™ã‚‹ã€‚ä¾‹ãˆã°ã€Œæ˜æ—¥ bull äºˆæ¸¬ã€ãªã‚‰ bull æœŸã®å¹³å‡ã‚’ä½¿ã†ã€‚
    2406.09578v2
*   **bear äºˆæ¸¬æ™‚ã®æ¥µç«¯å€¤æŠ‘åˆ¶**ï¼šbear ã§ã®æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³ã¯ **âˆ’10 bps ã«ä¸Šé™ï¼ˆã‚­ãƒ£ãƒƒãƒ—ï¼‰** ã™ã‚‹ï¼ˆæ¥µç«¯ãªè² å€¤ã®å½±éŸ¿ã‚’æŠ‘ãˆã‚‹ç›®çš„ï¼‰ã€‚
    2406.09578v2

> ç›´æ„Ÿï¼šãƒ¬ã‚¸ãƒ¼ãƒ è­˜åˆ¥â†’ãƒ¬ã‚¸ãƒ¼ãƒ äºˆæ¸¬â†’ã€Œäºˆæ¸¬ãƒ¬ã‚¸ãƒ¼ãƒ ã«å¯¾å¿œã™ã‚‹å±¥æ­´å¹³å‡ã€ã‚’ä½¿ã†ã€ã¨ã„ã†é †ã§  $\mu$  ã‚’æ±ºã‚ã‚‹ã€‚

2) å…±åˆ†æ•£  $\Sigma$  ã®æ¨å®š
---------------------

*   **æŒ‡æ•°åŠ é‡ç§»å‹•ï¼ˆEWMï¼‰å…±åˆ†æ•£**ã‚’ä½¿ç”¨ã€‚**åŠæ¸›æœŸ 252 æ—¥**ã€‚ãƒ¬ã‚¸ãƒ¼ãƒ æƒ…å ±ã¯å½“é¢ $\mu$ å´ã«ã®ã¿åæ˜ ï¼ˆ $\Sigma$  ã¯é€šå¸¸æ¨å®šï¼‰ã€‚
    2406.09578v2
*   MV ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã‚‚åŒæ§˜ã« **EWM å…±åˆ†æ•£ï¼ˆHL=252ï¼‰** ã‚’æ¡ç”¨ã€‚
    2406.09578v2

3) æœ€é©åŒ–ï¼ˆé•·æœŸã®ã¿ã€å–å¼•ã‚³ã‚¹ãƒˆé …ã‚ã‚Šï¼‰
---------------------

*   ãƒ™ãƒ¼ã‚¹ã®ç›®çš„é–¢æ•°ã¯ Markowitz ã®
    $$
    \max_{w}\; w^\top \mu \;-\; \gamma_{\mathrm{risk}}\, w^\top \Sigma w \;-\; \gamma_{\mathrm{trade}}\cdot \text{(å–å¼•ã‚³ã‚¹ãƒˆé …)}
    $$
    ã‚’é•·æœŸã®ã¿åˆ¶ç´„ï¼ˆä¸Šé™ãªã©ï¼‰ä¸‹ã§è§£ãã¨ã„ã†å®Ÿå‹™è¨­å®šã€‚è«–æ–‡å†…ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ ** $\gamma_{\mathrm{risk}}=10.0$ **ï¼ˆãƒ¬ã‚¸ãƒ¼ãƒ å¯¾å¿œ MVï¼‰ã€** $\gamma_{\mathrm{trade}}=1.0$ ** ã‚’æ¡ç”¨ï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ MV ã¯  $\gamma_{\mathrm{risk}}=5.0,\ \gamma_{\mathrm{trade}}=0$ ï¼‰ã€‚
    2406.09578v2
*   **å®‰å…¨å¼**ï¼š**bull äºˆæ¸¬ã®è³‡ç”£ãŒ 3 æœ¬ä»¥ä¸‹**ã®ã¨ãã¯ã€**100% ç„¡ãƒªã‚¹ã‚¯**ã«é€€é¿ï¼ˆé›†ä¸­ãƒªã‚¹ã‚¯å›é¿ï¼‰ã€‚
    2406.09578v2

4) å‚è€ƒï¼šMinVar ã¨ã®ä¸€è²«ç‚¹
------------------

*   MinVar ã§ã‚‚ã€Œ**bull äºˆæ¸¬è³‡ç”£ã®ã¿ã«æŠ•è³‡**ã€ã¨ã„ã†ä½¿ã„æ–¹ï¼ˆbull ã¨åˆ¤å®šã•ã‚ŒãŸé›†åˆå†…ã§ã®æœ€å°åˆ†æ•£ï¼‰ã‚„ã€å°‘æ•°è³‡ç”£ã—ã‹ bull ã§ãªã„ã¨ãã® **ç„¡ãƒªã‚¹ã‚¯ 100%** é€€é¿ãƒ«ãƒ¼ãƒ«ã‚’æ¡ç”¨ã—ã¦ã„ã‚‹ã€‚MV ã‚‚åŒç³»ã®å®Ÿè£…æ–¹é‡ã§ã€å·®ã¯  $\mu$  ã®ä½¿ã„æ–¹ï¼ˆãƒ¬ã‚¸ãƒ¼ãƒ åˆ¥å¹³å‡ï¼‰ã¨  $\gamma$  è¨­å®šã€‚
    2406.09578v2

* * *

### ã¾ã¨ã‚ï¼ˆå®Ÿè£…è¦³ç‚¹ï¼‰

*   ** $\mu_i$ **ï¼šè³‡ç”£  $i$  ã®**äºˆæ¸¬ãƒ¬ã‚¸ãƒ¼ãƒ  r** ã«å¯¾å¿œã™ã‚‹ã€Œå­¦ç¿’çª“ã® JMï¼ˆ $\hat\lambda$ ï¼‰ã§ bull/bear ã”ã¨ã«è¨ˆç®—ã—ãŸå±¥æ­´å¹³å‡ã€ã€‚bear ãªã‚‰  $\max(\mu_i,\ -10\text{bps})$  ã§ã‚¯ãƒªãƒƒãƒ—ã€‚
    2406.09578v2
*   ** $\Sigma$ **ï¼šEWM å…±åˆ†æ•£ï¼ˆHL=252ï¼‰ã€‚
    2406.09578v2
*   **æœ€é©åŒ–**ï¼šé•·æœŸã®ã¿ã€ $\gamma_{\mathrm{risk}}=10.0$ ã€ $\gamma_{\mathrm{trade}}=1.0$ ã€**bull è³‡ç”£ â‰¤3 æœ¬ãªã‚‰ç„¡ãƒªã‚¹ã‚¯ 100%**ã€‚
    2406.09578v2

å¿…è¦ãªã‚‰ã€ä¸Šè¨˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’ãã®ã¾ã¾è¸è¥²ã—ãŸ **MVï¼ˆJM-XGBï¼‰é‡ã¿ç®—å‡ºã®é–¢æ•°**ï¼ˆ $\mu$  ç”Ÿæˆâ†’EWM  $\Sigma$ â†’äºŒæ¬¡è¨ˆç”»/ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ï¼‰ã‚’ã‚³ãƒ¼ãƒ‰ã§ç”¨æ„ã—ã¾ã™ã€‚

## Response:
äº†è§£ã§ã™ã€‚**è³‡ç”£ã”ã¨ã®ãƒ¬ã‚¸ãƒ¼ãƒ äºˆæ¸¬ã‚’åæ˜ ã—ãŸå¹³å‡åˆ†æ•£ï¼ˆMVï¼‰ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª**ã‚’ã€ãã®ã¾ã¾ä½¿ãˆã‚‹æœ€å°å®Ÿè£…ã§ç”¨æ„ã—ã¾ã—ãŸã€‚  
ä¾å­˜ã¯ `numpy` ã¨ `pandas` ã®ã¿ï¼ˆåˆ¶ç´„ä»˜ãQPã¯ä½¿ã‚ãšã€é•·æœŸã®ã¿ã¯ã‚¯ãƒªãƒƒãƒ—ï¼‹å†æ­£è¦åŒ–ã®ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ï¼‰ã€‚

*   ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¥æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³ã¯ **EWM æ¡ä»¶ä»˜ãå¹³å‡**ï¼ˆJMãƒ©ãƒ™ãƒ« 0=ãƒ–ãƒ« / 1=ãƒ™ã‚¢ï¼‰
*   ãƒ™ã‚¢å´ã¯ **âˆ’10bps/æ—¥ã§ä¸‹é™ã‚¯ãƒªãƒƒãƒ—**ï¼ˆè«–æ–‡ã®æ¥µç«¯å€¤æŠ‘åˆ¶ã«å¯¾å¿œï¼›å¤‰æ›´å¯ï¼‰
*   å…±åˆ†æ•£ã¯ **EWM(halflife=252)**
*   **å®‰å…¨å¼**ï¼šãƒ–ãƒ«äºˆæ¸¬è³‡ç”£ãŒ **3 æœ¬ä»¥ä¸‹**ãªã‚‰ã€ãã®æœŸé–“ã¯ **ç„¡ãƒªã‚¹ã‚¯ 100%**
*   ãƒªãƒãƒ©ãƒ³ã‚¹ã¯æ—¢å®š **æœˆæ¬¡**ï¼ˆ`rebalance_freq` ã§å¤‰æ›´å¯ï¼‰

```python
import numpy as np
import pandas as pd
from typing import Tuple, Optional

# ========= ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =========
def ewm_mean(x: pd.Series, halflife: int) -> pd.Series:
    return x.ewm(halflife=halflife, adjust=False, min_periods=1).mean()

def ewm_conditional_mean(r: pd.Series, label: pd.Series, cond: int, halflife: int) -> pd.Series:
    """
    æ¡ä»¶ä»˜ãEWMå¹³å‡: E[r | label==cond] ã‚’æ™‚ç‚¹ã”ã¨ã«æ¨å®š
      = EWM( r * I{label==cond} ) / EWM( I{label==cond} )
    """
    I = (label == cond).astype(float)
    num = ewm_mean(r * I, halflife=halflife)
    den = ewm_mean(I,     halflife=halflife).replace(0, np.nan)
    return (num / den).fillna(0.0)

def ewm_cov_matrix(df: pd.DataFrame, halflife: int) -> np.ndarray:
    """
    EWMå…±åˆ†æ•£è¡Œåˆ—ï¼ˆpandasã®EWM.covã®æœ€å¾Œã®ã‚¹ãƒ©ã‚¤ã‚¹ã‚’æŠ½å‡ºï¼‰
    """
    # pandas ã® EWM.cov ã¯é•·ããªã‚‹ã®ã§ã€ç›´è¿‘ã®å…±åˆ†æ•£è¡Œåˆ—ã‚’å–ã‚Šå‡ºã™
    cov_df = df.ewm(halflife=halflife, adjust=False).cov()
    # ç›´è¿‘æ—¥ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚’å–å¾—
    last_idx = cov_df.index.get_level_values(0).max()
    C = cov_df.loc[last_idx]
    # æ¬ æãŒã‚ã‚Œã°ã‚¼ãƒ­åŸ‹ã‚ï¼‹å¯¾è§’è£œæ­£
    C = C.reindex(index=df.columns, columns=df.columns).fillna(0.0)
    # æ•°å€¤å®‰å®šåŒ–
    C.values[np.diag_indices_from(C.values)] += 1e-8
    return C.values

def mv_weights_long_only(mu: np.ndarray, Sigma: np.ndarray, gamma: float = 10.0,
                         w_ub: Optional[float] = None) -> np.ndarray:
    """
    ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯MVè§£:
      w* = (1/gamma) * Î£^{-1} Î¼ ã‚’æ±‚ã‚ã€è² ã‚’0ã«ã‚¯ãƒªãƒƒãƒ—â†’ä¸Šé™åˆ¶ç´„ã‚ã‚Œã°é©ç”¨â†’å’Œã‚’<=1ã«æ­£è¦åŒ–
    """
    inv = np.linalg.pinv(Sigma)
    w = (inv @ mu) / max(gamma, 1e-8)
    # é•·æœŸã®ã¿
    w = np.clip(w, 0, None)
    # ä¸Šé™ã‚ã‚Œã°é©ç”¨
    if w_ub is not None:
        w = np.minimum(w, w_ub)
    s = w.sum()
    if not np.isfinite(s) or s <= 0:
        # ã™ã¹ã¦0ãªã‚‰ç­‰åˆ†é…ï¼ˆã¾ãŸã¯å…¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ã—ãŸã„ãªã‚‰ã‚¼ãƒ­ã®ã¾ã¾ã§ã‚‚å¯ï¼‰
        w = np.ones_like(w) / len(w)
        s = 1.0
    # å’Œ=1ã®ç¯„å›²ã«æ­£è¦åŒ–ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨±å®¹ãªã‚‰å’Œ<=1ã«ã—ãŸã„å ´åˆã¯ scale<=1ã‚‚å¯ï¼‰
    w = w / s
    return w

# ========= ä¸»è¦é–¢æ•°ï¼šãƒ¬ã‚¸ãƒ¼ãƒ å¯¾å¿œMVï¼ˆãƒ­ãƒ¼ãƒªãƒ³ã‚°é‹ç”¨ï¼‰ =========
def regime_mv_portfolio(
    rets_df: pd.DataFrame,          # å„è³‡ç”£ã®æ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³ï¼ˆåˆ—=è³‡ç”£åï¼‰
    rf: pd.Series,                  # ç„¡ãƒªã‚¹ã‚¯æ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³
    jm_labels_df: pd.DataFrame,     # JMãƒ©ãƒ™ãƒ«ï¼ˆ0=ãƒ–ãƒ«,1=ãƒ™ã‚¢ï¼‰åˆ—ã¯ rets_df ã¨åŒã˜è³‡ç”£åãƒ»åŒã˜index
    pred_regime_df: pd.DataFrame,   # ç¿Œæ—¥ãƒ¬ã‚¸ãƒ¼ãƒ äºˆæ¸¬ï¼ˆ0=ãƒ–ãƒ«,1=ãƒ™ã‚¢ï¼‰åˆ—ã¯ rets_df ã¨åŒã˜è³‡ç”£åãƒ»åŒã˜index
    halflife_mu: int = 126,         # æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³æ¨å®šã®EWMåŠæ¸›æœŸï¼ˆç´„åŠå¹´ï¼‰
    halflife_cov: int = 252,        # å…±åˆ†æ•£æ¨å®šã®EWMåŠæ¸›æœŸï¼ˆç´„1å¹´ï¼‰
    bear_cap_bps_per_day: float = -10.0,  # ãƒ™ã‚¢å¹³å‡ã®ä¸‹é™ï¼ˆbps/æ—¥ï¼‰ã€‚ä¾‹:-10â†’-0.001/æ—¥
    min_bull_assets: int = 3,       # ãƒ–ãƒ«è³‡ç”£æœ¬æ•°ãŒã“ã®é–¾å€¤ä»¥ä¸‹ãªã‚‰ç„¡ãƒªã‚¹ã‚¯100%
    gamma: float = 10.0,            # ãƒªã‚¹ã‚¯å›é¿åº¦
    w_ub: Optional[float] = None,   # å„è³‡ç”£ã®ä¸Šé™ï¼ˆNone=åˆ¶ç´„ãªã—ã€ä¾‹:0.2ï¼‰
    rebalance_freq: str = "M"       # "M" æœˆæ¬¡ / "W" é€±æ¬¡ / "D" æ—¥æ¬¡
) -> Tuple[pd.Series, pd.DataFrame]:
    """
    ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¥EWMå¹³å‡â†’äºˆæ¸¬ãƒ¬ã‚¸ãƒ¼ãƒ ã«å¿œã˜ãŸ Î¼ã€EWMÎ£ã€é•·æœŸã®ã¿MV ã§é‡ã¿ã‚’ç®—å‡ºã—ã€
    æŒ‡å®šé »åº¦ã§ãƒªãƒãƒ©ãƒ³ã‚¹ã—ã¦é‹ç”¨ã€‚æˆ»ã‚Šå€¤: (ãƒãƒ¼ãƒˆæ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³, é‡ã¿å±¥æ­´)
    """
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ•´åˆ—
    idx = rets_df.index.union(rf.index).union(jm_labels_df.index).union(pred_regime_df.index)
    idx = idx.sort_values()
    R  = rets_df.reindex(idx).ffill()
    RF = rf.reindex(idx).ffill()
    L  = jm_labels_df.reindex(idx).ffill()       # JMãƒ©ãƒ™ãƒ«
    P  = pred_regime_df.reindex(idx).ffill()     # äºˆæ¸¬

    assets = list(R.columns)
    n = len(assets)

    # ãƒªãƒãƒ©ãƒ³ã‚¹æ—¥
    rebal_days = R.resample(rebalance_freq).last().index
    # å®Ÿãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã™ã‚‹æ—¥ã«é™å®š
    rebal_days = [d for d in rebal_days if d in R.index]

    weights_hist = []
    port_ret = pd.Series(index=R.index, dtype=float)

    bps2daily = bear_cap_bps_per_day / 10000.0  # bps/æ—¥ â†’ å®Ÿæ•°/æ—¥

    for t in rebal_days:
        loc = R.index.get_loc(t)

        # ç›´è¿‘ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã§ EWM æ¡ä»¶ä»˜ãå¹³å‡ï¼ˆå„è³‡ç”£ã”ã¨ï¼‰
        bull_means = []
        bear_means = []
        for a in assets:
            r_a = R[a].iloc[:loc+1]
            l_a = L[a].iloc[:loc+1]
            mu_bull = ewm_conditional_mean(r_a, l_a, cond=0, halflife=halflife_mu).iloc[-1]
            mu_bear = ewm_conditional_mean(r_a, l_a, cond=1, halflife=halflife_mu).iloc[-1]
            # ãƒ™ã‚¢ã¯ä¸‹é™ã‚¯ãƒªãƒƒãƒ—
            mu_bear = max(mu_bear, bps2daily)
            bull_means.append(mu_bull)
            bear_means.append(mu_bear)
        bull_means = np.array(bull_means)
        bear_means = np.array(bear_means)

        # äºˆæ¸¬ãƒ¬ã‚¸ãƒ¼ãƒ ã«å¿œã˜ã¦ Î¼ ã‚’é¸æŠï¼ˆå½“æ—¥ t ã®äºˆæ¸¬ã‚’ä½¿ç”¨ã—ã€tâ†’æ¬¡ãƒªãƒãƒ©ãƒ³ã‚¹ã¾ã§å›ºå®šï¼‰
        pred_today = P.iloc[loc].values.astype(int)  # shape=(n,)
        mu = np.where(pred_today == 0, bull_means, bear_means)

        # å®‰å…¨å¼ï¼šãƒ–ãƒ«è³‡ç”£ãŒå°‘ãªã‘ã‚Œã°ç„¡ãƒªã‚¹ã‚¯100%
        if (pred_today == 0).sum() <= min_bull_assets:
            w = np.zeros(n)
            # æ¬¡ã®ãƒªãƒãƒ©ãƒ³ã‚¹ç›´å‰ã¾ã§ rf ã‚’é©ç”¨
            next_loc = (R.index.get_loc(rebal_days[rebal_days.index(t)+1])
                        if t != rebal_days[-1] else len(R))
            port_slice = slice(loc, next_loc)
            port_ret.iloc[port_slice] = RF.iloc[port_slice]
            weights_hist.append(pd.Series(w, index=assets, name=t))
            continue

        # EWMå…±åˆ†æ•£ï¼ˆç›´è¿‘ã¾ã§ï¼‰
        Sigma = ewm_cov_matrix(R.iloc[:loc+1], halflife=halflife_cov)

        # MVï¼ˆé•·æœŸã®ã¿, å’Œ=1ã«æ­£è¦åŒ–ï¼‰
        w = mv_weights_long_only(mu, Sigma, gamma=gamma, w_ub=w_ub)

        # æ¬¡ã®ãƒªãƒãƒ©ãƒ³ã‚¹ç›´å‰ã¾ã§ã“ã®é‡ã¿ã‚’é©ç”¨ï¼ˆãƒãƒ¼ãƒˆ= w^T R + æ®‹ä½™ã‚­ãƒ£ãƒƒã‚·ãƒ¥*rf ã‚‚é¸ã¹ã‚‹ãŒã€ã“ã“ã¯å’Œ=1ï¼‰
        next_loc = (R.index.get_loc(rebal_days[rebal_days.index(t)+1])
                    if t != rebal_days[-1] else len(R))
        sl = slice(loc, next_loc)
        port_ret.iloc[sl] = (R.iloc[sl] @ w).values  # å…¨é¡ãƒªã‚¹ã‚¯è³‡ç”£ã«æŠ•è³‡
        weights_hist.append(pd.Series(w, index=assets, name=t))

    W = pd.DataFrame(weights_hist)

    return port_ret.dropna(), W

# ========= ã‚µãƒ³ãƒ—ãƒ«ï¼ˆãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼‰ =========
if __name__ == "__main__":
    np.random.seed(7)
    idx = pd.date_range("2015-01-01", "2025-10-31", freq="B")

    # 3è³‡ç”£ã®ãƒ€ãƒŸãƒ¼æ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³
    rets_df = pd.DataFrame({
        "Equity": np.random.normal(0.0005, 0.01,  len(idx)),
        "Bond":   np.random.normal(0.0002, 0.004, len(idx)),
        "Gold":   np.random.normal(0.0001, 0.013, len(idx)),
    }, index=idx)

    # ç„¡ãƒªã‚¹ã‚¯ï¼ˆå¹´ç‡2%ç›¸å½“ã®ä¸€å®šï¼‰
    rf = pd.Series(0.02/252, index=idx)

    # JMãƒ©ãƒ™ãƒ«ï¼ˆ0ãƒ–ãƒ«/1ãƒ™ã‚¢ï¼‰ã€‚ã“ã“ã§ã¯ãƒ€ãƒŸãƒ¼ï¼šé–¾å€¤ã§åˆ†å‰²
    jm_labels_df = pd.DataFrame(index=idx, columns=rets_df.columns, dtype=int)
    jm_labels_df["Equity"] = (np.sin(np.linspace(0, 60, len(idx))) > 0).astype(int)  # 0/1ã‚’äº¤äº’ã«
    jm_labels_df["Bond"]   = (np.cos(np.linspace(0, 40, len(idx))) > 0).astype(int)
    jm_labels_df["Gold"]   = (np.sin(np.linspace(0, 30, len(idx))) > 0).astype(int)

    # ç¿Œæ—¥ãƒ¬ã‚¸ãƒ¼ãƒ äºˆæ¸¬ï¼ˆ0ãƒ–ãƒ«/1ãƒ™ã‚¢ï¼‰ã€‚ã“ã“ã‚‚ãƒ€ãƒŸãƒ¼ã§ç”Ÿæˆ
    pred_regime_df = (pd.DataFrame({
        "Equity": (np.random.rand(len(idx)) > 0.4).astype(int),
        "Bond":   (np.random.rand(len(idx)) > 0.5).astype(int),
        "Gold":   (np.random.rand(len(idx)) > 0.5).astype(int),
    }, index=idx)).astype(int)

    # å®Ÿè¡Œ
    port_ret, W = regime_mv_portfolio(
        rets_df, rf, jm_labels_df, pred_regime_df,
        halflife_mu=126, halflife_cov=252,
        bear_cap_bps_per_day=-10.0,  # -10bps/æ—¥
        min_bull_assets=3,
        gamma=10.0,
        w_ub=0.5,                    # å„è³‡ç”£50%ä¸Šé™ï¼ˆå¿…è¦ãªã‘ã‚Œã° Noneï¼‰
        rebalance_freq="M"
    )

    # ç°¡æ˜“è©•ä¾¡
    ann = 252
    ann_mean = port_ret.mean() * ann
    ann_vol  = port_ret.std(ddof=0) * np.sqrt(ann)
    sharpe   = ann_mean / ann_vol
    print("Portfolio (MV w/ regimes) â€” ann.mean, ann.vol, Sharpe:",
          round(ann_mean,4), round(ann_vol,4), round(sharpe,3))
    print("Weights (last 6 rebalances):\n", W.tail(6))
```

### ä½¿ã„æ–¹ãƒ»å·®ã—æ›¿ãˆãƒã‚¤ãƒ³ãƒˆ

*   `jm_labels_df` ã¯ **JMã®å½“æ—¥ãƒ©ãƒ™ãƒ«**ï¼ˆ0=ãƒ–ãƒ«/1=ãƒ™ã‚¢ï¼‰ã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚
*   `pred_regime_df` ã¯ **ç¿Œæ—¥äºˆæ¸¬ãƒ¬ã‚¸ãƒ¼ãƒ **ï¼ˆ0/1ï¼‰ã€‚å½“æ—¥ãƒªãƒãƒ©ãƒ³ã‚¹ã§æ¬¡æœŸã¾ã§å›ºå®šã—ã¾ã™ã€‚
*   ãƒ™ã‚¢ä¸‹é™ `bear_cap_bps_per_day` ã¯æ—¢å®š **âˆ’10 bps/æ—¥**ï¼ˆ= âˆ’0.001ï¼‰ã€‚æœˆæ¬¡ä¸‹é™ã‚„å¹´ç‡ä¸‹é™ã«ã—ãŸã„å ´åˆã¯ã“ã“ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚
*   å®‰å…¨å¼ï¼š`min_bull_assets`ï¼ˆæ—¢å®š3ï¼‰ã€‚ã“ã‚Œä»¥ä¸‹ãªã‚‰ **ç„¡ãƒªã‚¹ã‚¯ 100%** ã«é€€é¿ã€‚
*   å’Œ=1ãƒ»é•·æœŸã®ã¿ãƒ»ä¸Šé™ `w_ub` ã‚’æº€ãŸã™ã‚ˆã†ã€**æ“¬ä¼¼MVè§£**ï¼ˆé€†è¡Œåˆ—Ã—Î¼â†’ã‚¯ãƒªãƒƒãƒ—â†’æ­£è¦åŒ–ï¼‰ã§å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚å³å¯†QPã«ã—ãŸã„å ´åˆã¯ `cvxpy` ãªã©ã«åˆ‡æ›¿ãˆã¦ãã ã•ã„ã€‚

å¿…è¦ãªã‚‰ã€ã“ã®é‡ã¿ã®ä¸Šã« **å–å¼•ã‚³ã‚¹ãƒˆï¼ˆL1ï¼‰** ã‚’è¿‘ä¼¼çš„ã«å…¥ã‚Œã‚‹ç‰ˆã‚„ã€**bull ã®ã¿ã§æŠ•è³‡ã™ã‚‹ MinVar** ç‰ˆã‚‚è¿½åŠ ã§ãŠå‡ºã—ã§ãã¾ã™ã€‚



---
Powered by [ChatGPT Exporter](https://www.chatgptexporter.com)